{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoImageProcessor\n",
    "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
    "from transformers import DefaultDataCollator\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "import wandb\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_PROJECT'] = \"Sailboat FGVC\"\n",
    "os.environ[\"WANDB_WATCH\"]=\"false\"\n",
    "os.environ[\"WANDB_LOG_MODEL\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset boats_dataset (C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b34eb9244748b7a68ac05b359ee509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "access_token = \"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\"\n",
    "# login(token=access_token)\n",
    "dataset = load_dataset(\"cringgaard/boats_dataset\" , use_auth_token=access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"google/vit-base-patch16-224\"\n",
    "model_name = \"ViT\"\n",
    "# checkpoint = \"microsoft/resnet-18\"\n",
    "# model_name = \"ResNet18\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "size = (\n",
    "    image_processor.size[\"shortest_edge\"]\n",
    "    if \"shortest_edge\" in image_processor.size\n",
    "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    ")\n",
    "_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    metrics = {}\n",
    "    metrics.update(accuracy.compute(predictions=predictions, references=labels))\n",
    "    metrics.update(f1.compute(predictions=predictions, references=labels , average=\"macro\"))\n",
    "    metrics.update(precision.compute(predictions=predictions, references=labels , average=\"macro\"))\n",
    "    metrics.update(recall.compute(predictions=predictions, references=labels , average=\"macro\"))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.3333333333333333,\n",
       " 'f1': 0.2222222222222222,\n",
       " 'precision': 0.16666666666666666,\n",
       " 'recall': 0.3333333333333333}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics((np.array([[0.1,0.3,0.6],[0.9,0.05,0.05],[0.9,0.1,0.05]]),np.array([1,0,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_types = [\"Hull Type\" , \"Rigging Type\" ,  \"Construction\" , \"Ballast Type\" , \"Designer\"]\n",
    "# label_types = [\"Rigging Type\" ,  \"Construction\" , \"Ballast Type\" , \"Designer\"]\n",
    "# label_types = ['Ballast Type' , 'Designer']\n",
    "# label_types = ['Hull Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcringgaard\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\chris\\OneDrive\\Dokumenter\\GitHub\\SailFGVC\\wandb\\run-20230323_125944-120zsah2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cringgaard/Sailboat%20FGVC/runs/120zsah2\" target=\"_blank\">ViT_Hull Type</a></strong> to <a href=\"https://wandb.ai/cringgaard/Sailboat%20FGVC\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\\cache-7e02f6d0f03e0fc9.arrow and C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\\cache-18fdfce3e1669319.arrow\n",
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\\cache-ba86150308d13aed.arrow\n",
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\\cache-863f23ab075eb295.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 56, 57, 59, 60, 61, 62]\n",
      "[]\n",
      "['Fin w/bulb & spade rudder', 'Centerboard Dinghy', 'Dbrd. Dinghy', 'Fin w/spade rudder', 'Fin with rudder on skeg', 'Fin Keel', 'Swing Keel', 'Centerboard (Trunk)', 'Keel/Cbrd.', 'Long Keel', 'Full keel with attached rudder', 'Foiling Monohull', 'Fin w/transom hung rudder', 'Lifting Keel', 'Catamaran Twin Dbrd.', 'Scow Twin Cbrd.', 'Catamaran Twin Cbrd.', 'Catamaran Twin Keel', 'Fin w/bulb & dual rudders', 'Fin w/bulb and transom hung rudder', 'Twin Keel', 'Long keel w/trans. hung rudder', 'Modified Full Keel', 'Keel/CB & spade rudder', 'Keel/CB w/dual rudders', 'Wing Keel', 'Fin (shoal draft)', 'Full Keel', 'Fin w/rudder on partial skeg', 'Catamaran Single Dbrd.', 'Fin Keel w/bulb', 'Cbrd w/outboard rudder', 'Trimaran Dbrd.', 'Trimaran Cbrd.', 'Twin Centerboards', 'Triple Keel', 'Cbrd (trunk) w/dual rudders', 'Sheel Keel', 'Lifting keel with dual rudders', 'Leeboard', 'Long keel w/rudder on skeg', 'Twin Daggerboards', 'Pram (Centerboard)', 'Scow Sngl. Cbrd.', 'Swing keel w/outboard rudder', 'Catamaran (no boards/asym.)', 'Daggerboard', 'Pram (Daggerboard)', 'Wing keel w/spade rudder', 'Trimaran with fixed unballasted keel', 'Fin w/dual rudders', 'Twin keels with dual rudders', 'Iceboat (bow steerer)', 'Double-ended with leeboards', 'Twin drop plates', 'Tandem keel', 'Tandem keel w/spade rudder', 'Swing keel w/dual rudders', 'Catamaran w/foils', 'Lifting keel w/bulb, trans. hung rudder', 'Catamaran Single Cntrboard', 'Foiling Trimaran', 'Lifting keel w/bulb; spade rudder', 'Pram (Leeboard)', 'Double-ended with long keel', 'Long keel w/two centerboards', 'Keel/CB w/rudder on skeg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([67, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([67]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `WANDB_LOG_MODEL` from true to `end` instead\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8323\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 1950\n",
      "  Number of trainable parameters = 85850179\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5775d7221e6d44298780d2589d99fa3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.2135, 'learning_rate': 2.564102564102564e-06, 'epoch': 0.08}\n",
      "{'loss': 4.0717, 'learning_rate': 5.128205128205128e-06, 'epoch': 0.15}\n",
      "{'loss': 3.9267, 'learning_rate': 7.692307692307694e-06, 'epoch': 0.23}\n",
      "{'loss': 3.6885, 'learning_rate': 1.0256410256410256e-05, 'epoch': 0.31}\n",
      "{'loss': 3.3961, 'learning_rate': 1.282051282051282e-05, 'epoch': 0.38}\n",
      "{'loss': 3.2098, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.46}\n",
      "{'loss': 2.9627, 'learning_rate': 1.794871794871795e-05, 'epoch': 0.54}\n",
      "{'loss': 2.9505, 'learning_rate': 2.0512820512820512e-05, 'epoch': 0.61}\n",
      "{'loss': 2.9197, 'learning_rate': 2.307692307692308e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7649, 'learning_rate': 2.564102564102564e-05, 'epoch': 0.77}\n",
      "{'loss': 2.7861, 'learning_rate': 2.8205128205128207e-05, 'epoch': 0.84}\n",
      "{'loss': 2.6985, 'learning_rate': 3.0769230769230774e-05, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7629, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5aa7b236a60444a923c1fb24b27ebab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Hull Type\\checkpoint-130\n",
      "Configuration saved in models/ViT_Hull Type\\checkpoint-130\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6809535026550293, 'eval_accuracy': 0.26189332051898123, 'eval_f1': 0.028758737004765313, 'eval_precision': 0.040792112470958375, 'eval_recall': 0.03661527995906016, 'eval_runtime': 17.476, 'eval_samples_per_second': 119.078, 'eval_steps_per_second': 7.496, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Hull Type\\checkpoint-130\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Hull Type\\checkpoint-130\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7142, 'learning_rate': 3.58974358974359e-05, 'epoch': 1.08}\n",
      "{'loss': 2.556, 'learning_rate': 3.846153846153846e-05, 'epoch': 1.15}\n",
      "{'loss': 2.5608, 'learning_rate': 4.1025641025641023e-05, 'epoch': 1.23}\n",
      "{'loss': 2.5381, 'learning_rate': 4.358974358974359e-05, 'epoch': 1.31}\n",
      "{'loss': 2.4037, 'learning_rate': 4.615384615384616e-05, 'epoch': 1.38}\n",
      "{'loss': 2.4957, 'learning_rate': 4.871794871794872e-05, 'epoch': 1.46}\n",
      "{'loss': 2.4252, 'learning_rate': 4.985754985754986e-05, 'epoch': 1.54}\n",
      "{'loss': 2.4145, 'learning_rate': 4.9572649572649575e-05, 'epoch': 1.61}\n",
      "{'loss': 2.4035, 'learning_rate': 4.928774928774929e-05, 'epoch': 1.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2711, 'learning_rate': 4.9002849002849004e-05, 'epoch': 1.77}\n",
      "{'loss': 2.331, 'learning_rate': 4.871794871794872e-05, 'epoch': 1.84}\n",
      "{'loss': 2.2514, 'learning_rate': 4.8433048433048433e-05, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3747, 'learning_rate': 4.814814814814815e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa1cf5d76d249e19e244349f34d5db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Hull Type\\checkpoint-260\n",
      "Configuration saved in models/ViT_Hull Type\\checkpoint-260\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3935303688049316, 'eval_accuracy': 0.3157135992311389, 'eval_f1': 0.055333674154430995, 'eval_precision': 0.0687340173468962, 'eval_recall': 0.060412182902314364, 'eval_runtime': 17.576, 'eval_samples_per_second': 118.4, 'eval_steps_per_second': 7.453, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Hull Type\\checkpoint-260\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Hull Type\\checkpoint-260\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3153, 'learning_rate': 4.786324786324787e-05, 'epoch': 2.08}\n",
      "{'loss': 2.1828, 'learning_rate': 4.7578347578347584e-05, 'epoch': 2.15}\n",
      "{'loss': 2.1989, 'learning_rate': 4.72934472934473e-05, 'epoch': 2.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2133, 'learning_rate': 4.700854700854701e-05, 'epoch': 2.31}\n",
      "{'loss': 2.2397, 'learning_rate': 4.672364672364672e-05, 'epoch': 2.38}\n",
      "{'loss': 2.2229, 'learning_rate': 4.643874643874644e-05, 'epoch': 2.46}\n",
      "{'loss': 2.1729, 'learning_rate': 4.615384615384616e-05, 'epoch': 2.54}\n",
      "{'loss': 2.0817, 'learning_rate': 4.586894586894587e-05, 'epoch': 2.61}\n",
      "{'loss': 2.0943, 'learning_rate': 4.558404558404559e-05, 'epoch': 2.69}\n",
      "{'loss': 2.0921, 'learning_rate': 4.52991452991453e-05, 'epoch': 2.77}\n",
      "{'loss': 2.1891, 'learning_rate': 4.501424501424502e-05, 'epoch': 2.84}\n",
      "{'loss': 2.1867, 'learning_rate': 4.472934472934473e-05, 'epoch': 2.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0894, 'learning_rate': 4.4444444444444447e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c945b3a9004d969ee48d64bbf5de1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Hull Type\\checkpoint-390\n",
      "Configuration saved in models/ViT_Hull Type\\checkpoint-390\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.252484083175659, 'eval_accuracy': 0.3604036520903412, 'eval_f1': 0.06863146130791246, 'eval_precision': 0.08480686820972966, 'eval_recall': 0.07577784141913761, 'eval_runtime': 17.6204, 'eval_samples_per_second': 118.102, 'eval_steps_per_second': 7.435, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Hull Type\\checkpoint-390\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Hull Type\\checkpoint-390\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0423, 'learning_rate': 4.415954415954416e-05, 'epoch': 3.08}\n",
      "{'loss': 2.0464, 'learning_rate': 4.3874643874643876e-05, 'epoch': 3.15}\n",
      "{'loss': 1.9758, 'learning_rate': 4.358974358974359e-05, 'epoch': 3.23}\n",
      "{'loss': 1.9995, 'learning_rate': 4.3304843304843306e-05, 'epoch': 3.31}\n",
      "{'loss': 2.006, 'learning_rate': 4.301994301994302e-05, 'epoch': 3.38}\n",
      "{'loss': 2.079, 'learning_rate': 4.2735042735042735e-05, 'epoch': 3.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.038, 'learning_rate': 4.2450142450142457e-05, 'epoch': 3.54}\n",
      "{'loss': 1.9721, 'learning_rate': 4.216524216524217e-05, 'epoch': 3.61}\n",
      "{'loss': 1.9179, 'learning_rate': 4.1880341880341886e-05, 'epoch': 3.69}\n",
      "{'loss': 2.008, 'learning_rate': 4.15954415954416e-05, 'epoch': 3.77}\n",
      "{'loss': 2.0003, 'learning_rate': 4.131054131054131e-05, 'epoch': 3.84}\n",
      "{'loss': 1.9329, 'learning_rate': 4.1025641025641023e-05, 'epoch': 3.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0786, 'learning_rate': 4.074074074074074e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44b8b7ad6ba4c18bc385a0b6ede6b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Hull Type\\checkpoint-520\n",
      "Configuration saved in models/ViT_Hull Type\\checkpoint-520\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.210533618927002, 'eval_accuracy': 0.367611725132148, 'eval_f1': 0.07163858985234978, 'eval_precision': 0.07226974335617596, 'eval_recall': 0.08584787686968637, 'eval_runtime': 17.438, 'eval_samples_per_second': 119.337, 'eval_steps_per_second': 7.512, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Hull Type\\checkpoint-520\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Hull Type\\checkpoint-520\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9165, 'learning_rate': 4.045584045584046e-05, 'epoch': 4.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8313, 'learning_rate': 4.0170940170940174e-05, 'epoch': 4.15}\n",
      "{'loss': 1.9419, 'learning_rate': 3.988603988603989e-05, 'epoch': 4.23}\n",
      "{'loss': 1.9188, 'learning_rate': 3.9601139601139604e-05, 'epoch': 4.31}\n",
      "{'loss': 1.9128, 'learning_rate': 3.931623931623932e-05, 'epoch': 4.38}\n",
      "{'loss': 1.8638, 'learning_rate': 3.903133903133903e-05, 'epoch': 4.46}\n",
      "{'loss': 1.9218, 'learning_rate': 3.874643874643875e-05, 'epoch': 4.54}\n",
      "{'loss': 1.8324, 'learning_rate': 3.846153846153846e-05, 'epoch': 4.61}\n",
      "{'loss': 1.9464, 'learning_rate': 3.817663817663818e-05, 'epoch': 4.69}\n",
      "{'loss': 1.7936, 'learning_rate': 3.789173789173789e-05, 'epoch': 4.77}\n",
      "{'loss': 1.8361, 'learning_rate': 3.760683760683761e-05, 'epoch': 4.84}\n",
      "{'loss': 1.8726, 'learning_rate': 3.732193732193732e-05, 'epoch': 4.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8151, 'learning_rate': 3.7037037037037037e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ad68fbafee4231a99508e8b3c7fb3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Hull Type\\checkpoint-650\n",
      "Configuration saved in models/ViT_Hull Type\\checkpoint-650\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.173140287399292, 'eval_accuracy': 0.36713118692936086, 'eval_f1': 0.0903690533402412, 'eval_precision': 0.09663280399484483, 'eval_recall': 0.09517978442905953, 'eval_runtime': 17.907, 'eval_samples_per_second': 116.212, 'eval_steps_per_second': 7.316, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Hull Type\\checkpoint-650\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Hull Type\\checkpoint-650\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8542, 'learning_rate': 3.675213675213676e-05, 'epoch': 5.08}\n",
      "{'loss': 1.8349, 'learning_rate': 3.646723646723647e-05, 'epoch': 5.15}\n",
      "{'loss': 1.7741, 'learning_rate': 3.618233618233619e-05, 'epoch': 5.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7279, 'learning_rate': 3.58974358974359e-05, 'epoch': 5.31}\n",
      "{'loss': 1.7602, 'learning_rate': 3.561253561253561e-05, 'epoch': 5.38}\n",
      "{'loss': 1.7229, 'learning_rate': 3.5327635327635325e-05, 'epoch': 5.46}\n",
      "{'loss': 1.7931, 'learning_rate': 3.504273504273504e-05, 'epoch': 5.54}\n",
      "{'loss': 1.6632, 'learning_rate': 3.475783475783476e-05, 'epoch': 5.61}\n",
      "{'loss': 1.7375, 'learning_rate': 3.4472934472934476e-05, 'epoch': 5.69}\n",
      "{'loss': 1.7981, 'learning_rate': 3.418803418803419e-05, 'epoch': 5.77}\n",
      "{'loss': 1.7244, 'learning_rate': 3.3903133903133905e-05, 'epoch': 5.84}\n",
      "{'loss': 1.8017, 'learning_rate': 3.361823361823362e-05, 'epoch': 5.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.731, 'learning_rate': 3.3333333333333335e-05, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8eeb6444d84d75956ad24a862d751b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Hull Type\\checkpoint-780\n",
      "Configuration saved in models/ViT_Hull Type\\checkpoint-780\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1682958602905273, 'eval_accuracy': 0.3762614127823162, 'eval_f1': 0.0868613268070926, 'eval_precision': 0.10369502359499184, 'eval_recall': 0.08866253889196335, 'eval_runtime': 17.965, 'eval_samples_per_second': 115.836, 'eval_steps_per_second': 7.292, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Hull Type\\checkpoint-780\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Hull Type\\checkpoint-780\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6663, 'learning_rate': 3.304843304843305e-05, 'epoch': 6.08}\n",
      "{'loss': 1.7627, 'learning_rate': 3.2763532763532764e-05, 'epoch': 6.15}\n",
      "{'loss': 1.6253, 'learning_rate': 3.247863247863248e-05, 'epoch': 6.23}\n",
      "{'loss': 1.7025, 'learning_rate': 3.2193732193732194e-05, 'epoch': 6.31}\n",
      "{'loss': 1.6907, 'learning_rate': 3.190883190883191e-05, 'epoch': 6.38}\n",
      "{'loss': 1.6703, 'learning_rate': 3.162393162393162e-05, 'epoch': 6.46}\n",
      "{'loss': 1.6139, 'learning_rate': 3.133903133903134e-05, 'epoch': 6.54}\n",
      "{'loss': 1.6143, 'learning_rate': 3.105413105413106e-05, 'epoch': 6.61}\n",
      "{'loss': 1.6113, 'learning_rate': 3.0769230769230774e-05, 'epoch': 6.69}\n",
      "{'loss': 1.6658, 'learning_rate': 3.0484330484330486e-05, 'epoch': 6.77}\n",
      "{'loss': 1.6815, 'learning_rate': 3.01994301994302e-05, 'epoch': 6.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7176, 'learning_rate': 2.9914529914529915e-05, 'epoch': 6.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6302, 'learning_rate': 2.962962962962963e-05, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54574704a104484a5742adaab117ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Hull Type\\checkpoint-910\n",
      "Configuration saved in models/ViT_Hull Type\\checkpoint-910\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.11625599861145, 'eval_accuracy': 0.38395002402691014, 'eval_f1': 0.09510190954711686, 'eval_precision': 0.10428437235238001, 'eval_recall': 0.10039938134707842, 'eval_runtime': 17.7716, 'eval_samples_per_second': 117.097, 'eval_steps_per_second': 7.371, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Hull Type\\checkpoint-910\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Hull Type\\checkpoint-910\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6279, 'learning_rate': 2.9344729344729345e-05, 'epoch': 7.08}\n",
      "{'loss': 1.6475, 'learning_rate': 2.9059829059829063e-05, 'epoch': 7.15}\n",
      "{'loss': 1.5969, 'learning_rate': 2.8774928774928778e-05, 'epoch': 7.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5271, 'learning_rate': 2.8490028490028492e-05, 'epoch': 7.31}\n",
      "{'loss': 1.6604, 'learning_rate': 2.8205128205128207e-05, 'epoch': 7.38}\n",
      "{'loss': 1.6176, 'learning_rate': 2.7920227920227922e-05, 'epoch': 7.46}\n",
      "{'loss': 1.624, 'learning_rate': 2.7635327635327633e-05, 'epoch': 7.54}\n",
      "{'loss': 1.6085, 'learning_rate': 2.7350427350427355e-05, 'epoch': 7.61}\n",
      "{'loss': 1.6258, 'learning_rate': 2.706552706552707e-05, 'epoch': 7.69}\n",
      "{'loss': 1.5436, 'learning_rate': 2.6780626780626784e-05, 'epoch': 7.77}\n",
      "{'loss': 1.5662, 'learning_rate': 2.64957264957265e-05, 'epoch': 7.84}\n",
      "{'loss': 1.4999, 'learning_rate': 2.621082621082621e-05, 'epoch': 7.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5326, 'learning_rate': 2.5925925925925925e-05, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8a72deb2a24c3c86ba45b3f88bf176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Hull Type\\checkpoint-1040\n",
      "Configuration saved in models/ViT_Hull Type\\checkpoint-1040\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.110868453979492, 'eval_accuracy': 0.3829889476213359, 'eval_f1': 0.107502420134566, 'eval_precision': 0.14305777374266646, 'eval_recall': 0.10741263890341726, 'eval_runtime': 17.666, 'eval_samples_per_second': 117.797, 'eval_steps_per_second': 7.415, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Hull Type\\checkpoint-1040\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Hull Type\\checkpoint-1040\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.539, 'learning_rate': 2.564102564102564e-05, 'epoch': 8.08}\n",
      "{'loss': 1.5459, 'learning_rate': 2.535612535612536e-05, 'epoch': 8.15}\n",
      "{'loss': 1.5401, 'learning_rate': 2.5071225071225073e-05, 'epoch': 8.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5665, 'learning_rate': 2.4786324786324787e-05, 'epoch': 8.31}\n",
      "{'loss': 1.4234, 'learning_rate': 2.4501424501424502e-05, 'epoch': 8.38}\n",
      "{'loss': 1.5027, 'learning_rate': 2.4216524216524217e-05, 'epoch': 8.46}\n",
      "{'loss': 1.4486, 'learning_rate': 2.3931623931623935e-05, 'epoch': 8.54}\n",
      "{'loss': 1.4575, 'learning_rate': 2.364672364672365e-05, 'epoch': 8.61}\n",
      "{'loss': 1.4833, 'learning_rate': 2.336182336182336e-05, 'epoch': 8.69}\n",
      "{'loss': 1.5079, 'learning_rate': 2.307692307692308e-05, 'epoch': 8.77}\n",
      "{'loss': 1.474, 'learning_rate': 2.2792022792022794e-05, 'epoch': 8.84}\n",
      "{'loss': 1.5178, 'learning_rate': 2.250712250712251e-05, 'epoch': 8.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4807, 'learning_rate': 2.2222222222222223e-05, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f219c84c4f5421199aedaf9096ab895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Hull Type\\checkpoint-1170\n",
      "Configuration saved in models/ViT_Hull Type\\checkpoint-1170\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.084254503250122, 'eval_accuracy': 0.4012493993272465, 'eval_f1': 0.11846853073105343, 'eval_precision': 0.16135086598958667, 'eval_recall': 0.11768868021089293, 'eval_runtime': 16.4836, 'eval_samples_per_second': 126.246, 'eval_steps_per_second': 7.947, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Hull Type\\checkpoint-1170\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Hull Type\\checkpoint-1170\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4391, 'learning_rate': 2.1937321937321938e-05, 'epoch': 9.08}\n",
      "{'loss': 1.3642, 'learning_rate': 2.1652421652421653e-05, 'epoch': 9.15}\n",
      "{'loss': 1.422, 'learning_rate': 2.1367521367521368e-05, 'epoch': 9.23}\n",
      "{'loss': 1.4132, 'learning_rate': 2.1082621082621086e-05, 'epoch': 9.31}\n",
      "{'loss': 1.4162, 'learning_rate': 2.07977207977208e-05, 'epoch': 9.38}\n",
      "{'loss': 1.3635, 'learning_rate': 2.0512820512820512e-05, 'epoch': 9.46}\n",
      "{'loss': 1.4104, 'learning_rate': 2.022792022792023e-05, 'epoch': 9.54}\n",
      "{'loss': 1.4566, 'learning_rate': 1.9943019943019945e-05, 'epoch': 9.61}\n",
      "{'loss': 1.4124, 'learning_rate': 1.965811965811966e-05, 'epoch': 9.69}\n",
      "{'loss': 1.3559, 'learning_rate': 1.9373219373219374e-05, 'epoch': 9.77}\n",
      "{'loss': 1.4287, 'learning_rate': 1.908831908831909e-05, 'epoch': 9.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4189, 'learning_rate': 1.8803418803418804e-05, 'epoch': 9.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4728, 'learning_rate': 1.8518518518518518e-05, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac1c116153440058648f8f5437595e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Hull Type\\checkpoint-1300\n",
      "Configuration saved in models/ViT_Hull Type\\checkpoint-1300\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1179933547973633, 'eval_accuracy': 0.38202787121576165, 'eval_f1': 0.11997420976486864, 'eval_precision': 0.16305389715893773, 'eval_recall': 0.11646111683358241, 'eval_runtime': 16.1331, 'eval_samples_per_second': 128.99, 'eval_steps_per_second': 8.12, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Hull Type\\checkpoint-1300\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Hull Type\\checkpoint-1300\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2739, 'learning_rate': 1.8233618233618236e-05, 'epoch': 10.08}\n",
      "{'loss': 1.3061, 'learning_rate': 1.794871794871795e-05, 'epoch': 10.15}\n",
      "{'loss': 1.283, 'learning_rate': 1.7663817663817662e-05, 'epoch': 10.23}\n",
      "{'loss': 1.3852, 'learning_rate': 1.737891737891738e-05, 'epoch': 10.31}\n",
      "{'loss': 1.3809, 'learning_rate': 1.7094017094017095e-05, 'epoch': 10.38}\n",
      "{'loss': 1.3618, 'learning_rate': 1.680911680911681e-05, 'epoch': 10.46}\n",
      "{'loss': 1.3806, 'learning_rate': 1.6524216524216525e-05, 'epoch': 10.54}\n",
      "{'loss': 1.3413, 'learning_rate': 1.623931623931624e-05, 'epoch': 10.61}\n",
      "{'loss': 1.4314, 'learning_rate': 1.5954415954415954e-05, 'epoch': 10.69}\n",
      "{'loss': 1.3271, 'learning_rate': 1.566951566951567e-05, 'epoch': 10.77}\n",
      "{'loss': 1.3791, 'learning_rate': 1.5384615384615387e-05, 'epoch': 10.84}\n",
      "{'loss': 1.288, 'learning_rate': 1.50997150997151e-05, 'epoch': 10.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.34, 'learning_rate': 1.4814814814814815e-05, 'epoch': 11.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3cf2f771644e0394e76c72e4c6753e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Hull Type\\checkpoint-1430\n",
      "Configuration saved in models/ViT_Hull Type\\checkpoint-1430\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.098583459854126, 'eval_accuracy': 0.3945218644882268, 'eval_f1': 0.11386422239023936, 'eval_precision': 0.153948743768942, 'eval_recall': 0.11407053351490576, 'eval_runtime': 16.5858, 'eval_samples_per_second': 125.469, 'eval_steps_per_second': 7.898, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Hull Type\\checkpoint-1430\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Hull Type\\checkpoint-1430\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3095, 'learning_rate': 1.4529914529914531e-05, 'epoch': 11.08}\n",
      "{'loss': 1.3215, 'learning_rate': 1.4245014245014246e-05, 'epoch': 11.15}\n",
      "{'loss': 1.326, 'learning_rate': 1.3960113960113961e-05, 'epoch': 11.23}\n",
      "{'loss': 1.2455, 'learning_rate': 1.3675213675213677e-05, 'epoch': 11.31}\n",
      "{'loss': 1.3418, 'learning_rate': 1.3390313390313392e-05, 'epoch': 11.38}\n",
      "{'loss': 1.4359, 'learning_rate': 1.3105413105413105e-05, 'epoch': 11.46}\n",
      "{'loss': 1.3221, 'learning_rate': 1.282051282051282e-05, 'epoch': 11.54}\n",
      "{'loss': 1.2894, 'learning_rate': 1.2535612535612536e-05, 'epoch': 11.61}\n",
      "{'loss': 1.3413, 'learning_rate': 1.2250712250712251e-05, 'epoch': 11.69}\n",
      "{'loss': 1.3816, 'learning_rate': 1.1965811965811967e-05, 'epoch': 11.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3223, 'learning_rate': 1.168091168091168e-05, 'epoch': 11.84}\n",
      "{'loss': 1.2569, 'learning_rate': 1.1396011396011397e-05, 'epoch': 11.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2155, 'learning_rate': 1.1111111111111112e-05, 'epoch': 12.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf515324f73241e48d22c8a02b200411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Hull Type\\checkpoint-1560\n",
      "Configuration saved in models/ViT_Hull Type\\checkpoint-1560\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.134882926940918, 'eval_accuracy': 0.39356078808265255, 'eval_f1': 0.10374990249711025, 'eval_precision': 0.13941334279748507, 'eval_recall': 0.10276470188633673, 'eval_runtime': 16.1503, 'eval_samples_per_second': 128.852, 'eval_steps_per_second': 8.111, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Hull Type\\checkpoint-1560\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Hull Type\\checkpoint-1560\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2663, 'learning_rate': 1.0826210826210826e-05, 'epoch': 12.08}\n",
      "{'loss': 1.1839, 'learning_rate': 1.0541310541310543e-05, 'epoch': 12.15}\n",
      "{'loss': 1.2655, 'learning_rate': 1.0256410256410256e-05, 'epoch': 12.23}\n",
      "{'loss': 1.261, 'learning_rate': 9.971509971509972e-06, 'epoch': 12.31}\n",
      "{'loss': 1.2715, 'learning_rate': 9.686609686609687e-06, 'epoch': 12.38}\n",
      "{'loss': 1.2571, 'learning_rate': 9.401709401709402e-06, 'epoch': 12.46}\n",
      "{'loss': 1.2672, 'learning_rate': 9.116809116809118e-06, 'epoch': 12.54}\n",
      "{'loss': 1.2502, 'learning_rate': 8.831908831908831e-06, 'epoch': 12.61}\n",
      "{'loss': 1.3029, 'learning_rate': 8.547008547008548e-06, 'epoch': 12.69}\n",
      "{'loss': 1.2802, 'learning_rate': 8.262108262108262e-06, 'epoch': 12.77}\n",
      "{'loss': 1.2316, 'learning_rate': 7.977207977207977e-06, 'epoch': 12.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3018, 'learning_rate': 7.692307692307694e-06, 'epoch': 12.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2327, 'learning_rate': 7.4074074074074075e-06, 'epoch': 13.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9033599416694e55b403ee995363e24e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Hull Type\\checkpoint-1690\n",
      "Configuration saved in models/ViT_Hull Type\\checkpoint-1690\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1156511306762695, 'eval_accuracy': 0.3983661701105238, 'eval_f1': 0.11402279664986877, 'eval_precision': 0.14891447432227048, 'eval_recall': 0.10977134505890858, 'eval_runtime': 16.1751, 'eval_samples_per_second': 128.655, 'eval_steps_per_second': 8.099, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Hull Type\\checkpoint-1690\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Hull Type\\checkpoint-1690\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3814, 'learning_rate': 7.122507122507123e-06, 'epoch': 13.08}\n",
      "{'loss': 1.1783, 'learning_rate': 6.837606837606839e-06, 'epoch': 13.15}\n",
      "{'loss': 1.2747, 'learning_rate': 6.5527065527065525e-06, 'epoch': 13.23}\n",
      "{'loss': 1.1512, 'learning_rate': 6.267806267806268e-06, 'epoch': 13.31}\n",
      "{'loss': 1.3158, 'learning_rate': 5.982905982905984e-06, 'epoch': 13.38}\n",
      "{'loss': 1.2588, 'learning_rate': 5.6980056980056985e-06, 'epoch': 13.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.191, 'learning_rate': 5.413105413105413e-06, 'epoch': 13.54}\n",
      "{'loss': 1.1924, 'learning_rate': 5.128205128205128e-06, 'epoch': 13.61}\n",
      "{'loss': 1.2061, 'learning_rate': 4.8433048433048435e-06, 'epoch': 13.69}\n",
      "{'loss': 1.1715, 'learning_rate': 4.558404558404559e-06, 'epoch': 13.77}\n",
      "{'loss': 1.2364, 'learning_rate': 4.273504273504274e-06, 'epoch': 13.84}\n",
      "{'loss': 1.1822, 'learning_rate': 3.988603988603989e-06, 'epoch': 13.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2538, 'learning_rate': 3.7037037037037037e-06, 'epoch': 14.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1cf9e428ecd48389575d892984d9348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Hull Type\\checkpoint-1820\n",
      "Configuration saved in models/ViT_Hull Type\\checkpoint-1820\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0978665351867676, 'eval_accuracy': 0.3901970206631427, 'eval_f1': 0.11937304343118764, 'eval_precision': 0.1480159922421468, 'eval_recall': 0.11552416873758017, 'eval_runtime': 16.236, 'eval_samples_per_second': 128.172, 'eval_steps_per_second': 8.068, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Hull Type\\checkpoint-1820\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Hull Type\\checkpoint-1820\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2188, 'learning_rate': 3.4188034188034193e-06, 'epoch': 14.08}\n",
      "{'loss': 1.2068, 'learning_rate': 3.133903133903134e-06, 'epoch': 14.15}\n",
      "{'loss': 1.179, 'learning_rate': 2.8490028490028492e-06, 'epoch': 14.23}\n",
      "{'loss': 1.2043, 'learning_rate': 2.564102564102564e-06, 'epoch': 14.31}\n",
      "{'loss': 1.2213, 'learning_rate': 2.2792022792022796e-06, 'epoch': 14.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2707, 'learning_rate': 1.9943019943019943e-06, 'epoch': 14.46}\n",
      "{'loss': 1.0619, 'learning_rate': 1.7094017094017097e-06, 'epoch': 14.54}\n",
      "{'loss': 1.1535, 'learning_rate': 1.4245014245014246e-06, 'epoch': 14.61}\n",
      "{'loss': 1.1632, 'learning_rate': 1.1396011396011398e-06, 'epoch': 14.69}\n",
      "{'loss': 1.1866, 'learning_rate': 8.547008547008548e-07, 'epoch': 14.77}\n",
      "{'loss': 1.2, 'learning_rate': 5.698005698005699e-07, 'epoch': 14.84}\n",
      "{'loss': 1.1105, 'learning_rate': 2.8490028490028494e-07, 'epoch': 14.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2391, 'learning_rate': 0.0, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "444312969bcf4d629bb643ba1d02bde7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Hull Type\\checkpoint-1950\n",
      "Configuration saved in models/ViT_Hull Type\\checkpoint-1950\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.123955011367798, 'eval_accuracy': 0.3921191734742912, 'eval_f1': 0.11067267519577223, 'eval_precision': 0.13640950470910787, 'eval_recall': 0.10852346421201196, 'eval_runtime': 16.2012, 'eval_samples_per_second': 128.447, 'eval_steps_per_second': 8.086, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Hull Type\\checkpoint-1950\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Hull Type\\checkpoint-1950\\preprocessor_config.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from models/ViT_Hull Type\\checkpoint-1300 (score: 0.11997420976486864).\n",
      "Setting `WANDB_LOG_MODEL` from true to `end` instead\n",
      "Saving model checkpoint to C:\\Users\\chris\\AppData\\Local\\Temp\\tmpuhnugff7\n",
      "Configuration saved in C:\\Users\\chris\\AppData\\Local\\Temp\\tmpuhnugff7\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 2422.6886, 'train_samples_per_second': 51.532, 'train_steps_per_second': 0.805, 'train_loss': 1.735152345315004, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in C:\\Users\\chris\\AppData\\Local\\Temp\\tmpuhnugff7\\pytorch_model.bin\n",
      "Image processor saved in C:\\Users\\chris\\AppData\\Local\\Temp\\tmpuhnugff7\\preprocessor_config.json\n",
      "Logging model artifacts. ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▄▆▆▆▇▇▇█▇███▇█</td></tr><tr><td>eval/f1</td><td>▁▃▄▄▆▅▆▇███▇██▇</td></tr><tr><td>eval/loss</td><td>█▅▃▂▂▂▁▁▁▁▁▂▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▃▄▃▄▅▅▇██▇▇▇▇▆</td></tr><tr><td>eval/recall</td><td>▁▃▄▅▆▅▇▇███▇▇█▇</td></tr><tr><td>eval/runtime</td><td>▆▇▇▆██▇▇▂▁▃▁▁▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▃▂▂▃▁▁▂▂▇█▆████</td></tr><tr><td>eval/steps_per_second</td><td>▃▂▂▃▁▁▂▂▇█▆████</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>▂▃▅▇███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▅▄▄▄▄▃▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.39212</td></tr><tr><td>eval/f1</td><td>0.11067</td></tr><tr><td>eval/loss</td><td>2.12396</td></tr><tr><td>eval/precision</td><td>0.13641</td></tr><tr><td>eval/recall</td><td>0.10852</td></tr><tr><td>eval/runtime</td><td>16.2012</td></tr><tr><td>eval/samples_per_second</td><td>128.447</td></tr><tr><td>eval/steps_per_second</td><td>8.086</td></tr><tr><td>train/epoch</td><td>15.0</td></tr><tr><td>train/global_step</td><td>1950</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.2391</td></tr><tr><td>train/total_flos</td><td>9.679890941138203e+18</td></tr><tr><td>train/train_loss</td><td>1.73515</td></tr><tr><td>train/train_runtime</td><td>2422.6886</td></tr><tr><td>train/train_samples_per_second</td><td>51.532</td></tr><tr><td>train/train_steps_per_second</td><td>0.805</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ViT_Hull Type</strong>: <a href=\"https://wandb.ai/cringgaard/Sailboat%20FGVC/runs/120zsah2\" target=\"_blank\">https://wandb.ai/cringgaard/Sailboat%20FGVC/runs/120zsah2</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230323_125944-120zsah2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352648f9548042a9aa0e2edd40a31a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\chris\\OneDrive\\Dokumenter\\GitHub\\SailFGVC\\wandb\\run-20230323_134047-20ng10rs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cringgaard/Sailboat%20FGVC/runs/20ng10rs\" target=\"_blank\">ViT_Rigging Type</a></strong> to <a href=\"https://wandb.ai/cringgaard/Sailboat%20FGVC\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\\cache-60009d52c7c5e571.arrow and C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\\cache-5ebfa60464b5cdf9.arrow\n",
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\\cache-94ed6d8196f9a191.arrow\n",
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\\cache-b1bc5046c8473b52.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37]\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 36]\n",
      "[36]\n",
      "['Fractional  Sloop', 'Gunter', 'Cat (Marconi)', 'Masthead Sloop', 'Fractional (9/10) Sloop', 'Cat (rotating spar)', 'Wing (multi element)', 'Masthead  Yawl', 'NaN', 'Cutter', 'Staysail Ketch', 'Frac. Sloop (Rotating Spar)', 'Masthead  Ketch', 'Cat (unstayed)', 'Gaff head Cat', 'Lateen', 'Solent', 'Gaff Head Cutter', 'Gaffhead Sloop', 'Fractionally Rigged Ketch', 'Cat Ketch (unstayed)', 'Fractional (7/8) Sloop', 'Gaff-Yawl', 'Frac. Sloop (Free standing)', '2 Mst. Schooner', 'Cat Ketch', 'Gaff Topsail Cutter', 'Junk Rig', 'Gaff head  Ketch', 'Sprit/Lug', 'Gunter-Yawl', 'Standing Lug', 'B&R', 'B&R Fractional', 'Cutter/Ketch', 'Sloop or Yawl', 'Brigantine', 'Fractional Yawl']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\chris/.cache\\huggingface\\hub\\models--google--vit-base-patch16-224\\snapshots\\2ddc9d4e473d7ba52128f0df4723e478fa14fb80\\config.json\n",
      "Model config ViTConfig {\n",
      "  \"_name_or_path\": \"google/vit-base-patch16-224\",\n",
      "  \"architectures\": [\n",
      "    \"ViTForImageClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": true,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\chris/.cache\\huggingface\\hub\\models--google--vit-base-patch16-224\\snapshots\\2ddc9d4e473d7ba52128f0df4723e478fa14fb80\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing ViTForImageClassification.\n",
      "\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([38, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([38]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "Setting `WANDB_LOG_MODEL` from true to `end` instead\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8323\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 1950\n",
      "  Number of trainable parameters = 85827878\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2134c0397647c293dad859b99e3f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7955, 'learning_rate': 2.564102564102564e-06, 'epoch': 0.08}\n",
      "{'loss': 3.5819, 'learning_rate': 5.128205128205128e-06, 'epoch': 0.15}\n",
      "{'loss': 3.1277, 'learning_rate': 7.692307692307694e-06, 'epoch': 0.23}\n",
      "{'loss': 2.5556, 'learning_rate': 1.0256410256410256e-05, 'epoch': 0.31}\n",
      "{'loss': 1.9998, 'learning_rate': 1.282051282051282e-05, 'epoch': 0.38}\n",
      "{'loss': 1.713, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.46}\n",
      "{'loss': 1.5887, 'learning_rate': 1.794871794871795e-05, 'epoch': 0.54}\n",
      "{'loss': 1.6207, 'learning_rate': 2.0512820512820512e-05, 'epoch': 0.61}\n",
      "{'loss': 1.4785, 'learning_rate': 2.307692307692308e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6056, 'learning_rate': 2.564102564102564e-05, 'epoch': 0.77}\n",
      "{'loss': 1.4878, 'learning_rate': 2.8205128205128207e-05, 'epoch': 0.84}\n",
      "{'loss': 1.5087, 'learning_rate': 3.0769230769230774e-05, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3929, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71923d65ad244138ca716d43d1b789e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Rigging Type\\checkpoint-130\n",
      "Configuration saved in models/ViT_Rigging Type\\checkpoint-130\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4594727754592896, 'eval_accuracy': 0.5593464680442095, 'eval_f1': 0.039774611723933234, 'eval_precision': 0.04401090758323893, 'eval_recall': 0.045037811597607544, 'eval_runtime': 16.226, 'eval_samples_per_second': 128.251, 'eval_steps_per_second': 8.073, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Rigging Type\\checkpoint-130\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Rigging Type\\checkpoint-130\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3714, 'learning_rate': 3.58974358974359e-05, 'epoch': 1.08}\n",
      "{'loss': 1.4285, 'learning_rate': 3.846153846153846e-05, 'epoch': 1.15}\n",
      "{'loss': 1.3913, 'learning_rate': 4.1025641025641023e-05, 'epoch': 1.23}\n",
      "{'loss': 1.2814, 'learning_rate': 4.358974358974359e-05, 'epoch': 1.31}\n",
      "{'loss': 1.2537, 'learning_rate': 4.615384615384616e-05, 'epoch': 1.38}\n",
      "{'loss': 1.3792, 'learning_rate': 4.871794871794872e-05, 'epoch': 1.46}\n",
      "{'loss': 1.1827, 'learning_rate': 4.985754985754986e-05, 'epoch': 1.54}\n",
      "{'loss': 1.1849, 'learning_rate': 4.9572649572649575e-05, 'epoch': 1.61}\n",
      "{'loss': 1.2618, 'learning_rate': 4.928774928774929e-05, 'epoch': 1.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2, 'learning_rate': 4.9002849002849004e-05, 'epoch': 1.77}\n",
      "{'loss': 1.155, 'learning_rate': 4.871794871794872e-05, 'epoch': 1.84}\n",
      "{'loss': 1.2307, 'learning_rate': 4.8433048433048433e-05, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1492, 'learning_rate': 4.814814814814815e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7aa9f63c2eb43edb985b97ea4eb8061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Rigging Type\\checkpoint-260\n",
      "Configuration saved in models/ViT_Rigging Type\\checkpoint-260\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2101713418960571, 'eval_accuracy': 0.6198942815953868, 'eval_f1': 0.08117506492483105, 'eval_precision': 0.1280455240588131, 'eval_recall': 0.07503225515249713, 'eval_runtime': 16.193, 'eval_samples_per_second': 128.512, 'eval_steps_per_second': 8.09, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Rigging Type\\checkpoint-260\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Rigging Type\\checkpoint-260\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1995, 'learning_rate': 4.786324786324787e-05, 'epoch': 2.08}\n",
      "{'loss': 1.0806, 'learning_rate': 4.7578347578347584e-05, 'epoch': 2.15}\n",
      "{'loss': 1.0645, 'learning_rate': 4.72934472934473e-05, 'epoch': 2.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1224, 'learning_rate': 4.700854700854701e-05, 'epoch': 2.31}\n",
      "{'loss': 1.0787, 'learning_rate': 4.672364672364672e-05, 'epoch': 2.38}\n",
      "{'loss': 1.1371, 'learning_rate': 4.643874643874644e-05, 'epoch': 2.46}\n",
      "{'loss': 1.0075, 'learning_rate': 4.615384615384616e-05, 'epoch': 2.54}\n",
      "{'loss': 1.0859, 'learning_rate': 4.586894586894587e-05, 'epoch': 2.61}\n",
      "{'loss': 0.9731, 'learning_rate': 4.558404558404559e-05, 'epoch': 2.69}\n",
      "{'loss': 1.0721, 'learning_rate': 4.52991452991453e-05, 'epoch': 2.77}\n",
      "{'loss': 1.1317, 'learning_rate': 4.501424501424502e-05, 'epoch': 2.84}\n",
      "{'loss': 1.0909, 'learning_rate': 4.472934472934473e-05, 'epoch': 2.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9932, 'learning_rate': 4.4444444444444447e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355c54b4604641489e6ff589a45f106b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Rigging Type\\checkpoint-390\n",
      "Configuration saved in models/ViT_Rigging Type\\checkpoint-390\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.093622088432312, 'eval_accuracy': 0.6568957232099952, 'eval_f1': 0.1482581617641229, 'eval_precision': 0.1865270005610004, 'eval_recall': 0.1364519384156851, 'eval_runtime': 16.479, 'eval_samples_per_second': 126.282, 'eval_steps_per_second': 7.95, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Rigging Type\\checkpoint-390\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Rigging Type\\checkpoint-390\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.861, 'learning_rate': 4.415954415954416e-05, 'epoch': 3.08}\n",
      "{'loss': 0.9361, 'learning_rate': 4.3874643874643876e-05, 'epoch': 3.15}\n",
      "{'loss': 0.9773, 'learning_rate': 4.358974358974359e-05, 'epoch': 3.23}\n",
      "{'loss': 0.9844, 'learning_rate': 4.3304843304843306e-05, 'epoch': 3.31}\n",
      "{'loss': 0.9809, 'learning_rate': 4.301994301994302e-05, 'epoch': 3.38}\n",
      "{'loss': 0.9623, 'learning_rate': 4.2735042735042735e-05, 'epoch': 3.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9712, 'learning_rate': 4.2450142450142457e-05, 'epoch': 3.54}\n",
      "{'loss': 1.0163, 'learning_rate': 4.216524216524217e-05, 'epoch': 3.61}\n",
      "{'loss': 0.9719, 'learning_rate': 4.1880341880341886e-05, 'epoch': 3.69}\n",
      "{'loss': 0.9445, 'learning_rate': 4.15954415954416e-05, 'epoch': 3.77}\n",
      "{'loss': 1.0236, 'learning_rate': 4.131054131054131e-05, 'epoch': 3.84}\n",
      "{'loss': 0.9763, 'learning_rate': 4.1025641025641023e-05, 'epoch': 3.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9878, 'learning_rate': 4.074074074074074e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc965799177b4b48968f101396a30097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Rigging Type\\checkpoint-520\n",
      "Configuration saved in models/ViT_Rigging Type\\checkpoint-520\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.061134696006775, 'eval_accuracy': 0.6636232580490149, 'eval_f1': 0.13421978597995704, 'eval_precision': 0.1762172977534197, 'eval_recall': 0.1237423026083039, 'eval_runtime': 16.6294, 'eval_samples_per_second': 125.14, 'eval_steps_per_second': 7.878, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Rigging Type\\checkpoint-520\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Rigging Type\\checkpoint-520\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9655, 'learning_rate': 4.045584045584046e-05, 'epoch': 4.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7906, 'learning_rate': 4.0170940170940174e-05, 'epoch': 4.15}\n",
      "{'loss': 0.9713, 'learning_rate': 3.988603988603989e-05, 'epoch': 4.23}\n",
      "{'loss': 0.9406, 'learning_rate': 3.9601139601139604e-05, 'epoch': 4.31}\n",
      "{'loss': 0.9141, 'learning_rate': 3.931623931623932e-05, 'epoch': 4.38}\n",
      "{'loss': 0.816, 'learning_rate': 3.903133903133903e-05, 'epoch': 4.46}\n",
      "{'loss': 0.8729, 'learning_rate': 3.874643874643875e-05, 'epoch': 4.54}\n",
      "{'loss': 0.858, 'learning_rate': 3.846153846153846e-05, 'epoch': 4.61}\n",
      "{'loss': 0.8247, 'learning_rate': 3.817663817663818e-05, 'epoch': 4.69}\n",
      "{'loss': 0.8132, 'learning_rate': 3.789173789173789e-05, 'epoch': 4.77}\n",
      "{'loss': 0.839, 'learning_rate': 3.760683760683761e-05, 'epoch': 4.84}\n",
      "{'loss': 0.806, 'learning_rate': 3.732193732193732e-05, 'epoch': 4.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7242, 'learning_rate': 3.7037037037037037e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a553dadf89f54876a846de97d223cce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Rigging Type\\checkpoint-650\n",
      "Configuration saved in models/ViT_Rigging Type\\checkpoint-650\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0403414964675903, 'eval_accuracy': 0.667948101874099, 'eval_f1': 0.16151269137328336, 'eval_precision': 0.2619438363962106, 'eval_recall': 0.14858205913123504, 'eval_runtime': 16.2642, 'eval_samples_per_second': 127.95, 'eval_steps_per_second': 8.055, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Rigging Type\\checkpoint-650\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Rigging Type\\checkpoint-650\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8295, 'learning_rate': 3.675213675213676e-05, 'epoch': 5.08}\n",
      "{'loss': 0.6909, 'learning_rate': 3.646723646723647e-05, 'epoch': 5.15}\n",
      "{'loss': 0.7764, 'learning_rate': 3.618233618233619e-05, 'epoch': 5.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7384, 'learning_rate': 3.58974358974359e-05, 'epoch': 5.31}\n",
      "{'loss': 0.737, 'learning_rate': 3.561253561253561e-05, 'epoch': 5.38}\n",
      "{'loss': 0.7985, 'learning_rate': 3.5327635327635325e-05, 'epoch': 5.46}\n",
      "{'loss': 0.8184, 'learning_rate': 3.504273504273504e-05, 'epoch': 5.54}\n",
      "{'loss': 0.8508, 'learning_rate': 3.475783475783476e-05, 'epoch': 5.61}\n",
      "{'loss': 0.7811, 'learning_rate': 3.4472934472934476e-05, 'epoch': 5.69}\n",
      "{'loss': 0.8345, 'learning_rate': 3.418803418803419e-05, 'epoch': 5.77}\n",
      "{'loss': 0.7625, 'learning_rate': 3.3903133903133905e-05, 'epoch': 5.84}\n",
      "{'loss': 0.7936, 'learning_rate': 3.361823361823362e-05, 'epoch': 5.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7632, 'learning_rate': 3.3333333333333335e-05, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc63160fd0f4ca3aa4c804fc0554ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Rigging Type\\checkpoint-780\n",
      "Configuration saved in models/ViT_Rigging Type\\checkpoint-780\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.009352684020996, 'eval_accuracy': 0.6713118692936089, 'eval_f1': 0.1850627558682508, 'eval_precision': 0.2640161062805436, 'eval_recall': 0.1667568749414471, 'eval_runtime': 16.281, 'eval_samples_per_second': 127.818, 'eval_steps_per_second': 8.046, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Rigging Type\\checkpoint-780\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Rigging Type\\checkpoint-780\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7695, 'learning_rate': 3.304843304843305e-05, 'epoch': 6.08}\n",
      "{'loss': 0.7223, 'learning_rate': 3.2763532763532764e-05, 'epoch': 6.15}\n",
      "{'loss': 0.676, 'learning_rate': 3.247863247863248e-05, 'epoch': 6.23}\n",
      "{'loss': 0.7572, 'learning_rate': 3.2193732193732194e-05, 'epoch': 6.31}\n",
      "{'loss': 0.6846, 'learning_rate': 3.190883190883191e-05, 'epoch': 6.38}\n",
      "{'loss': 0.665, 'learning_rate': 3.162393162393162e-05, 'epoch': 6.46}\n",
      "{'loss': 0.7057, 'learning_rate': 3.133903133903134e-05, 'epoch': 6.54}\n",
      "{'loss': 0.7441, 'learning_rate': 3.105413105413106e-05, 'epoch': 6.61}\n",
      "{'loss': 0.7526, 'learning_rate': 3.0769230769230774e-05, 'epoch': 6.69}\n",
      "{'loss': 0.6618, 'learning_rate': 3.0484330484330486e-05, 'epoch': 6.77}\n",
      "{'loss': 0.7217, 'learning_rate': 3.01994301994302e-05, 'epoch': 6.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7026, 'learning_rate': 2.9914529914529915e-05, 'epoch': 6.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7722, 'learning_rate': 2.962962962962963e-05, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7835fdba450442f0be1cc0da4392bb8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Rigging Type\\checkpoint-910\n",
      "Configuration saved in models/ViT_Rigging Type\\checkpoint-910\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0171763896942139, 'eval_accuracy': 0.6703507928880346, 'eval_f1': 0.19695544025038658, 'eval_precision': 0.2744546077179035, 'eval_recall': 0.1747854497427083, 'eval_runtime': 16.5626, 'eval_samples_per_second': 125.645, 'eval_steps_per_second': 7.909, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Rigging Type\\checkpoint-910\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Rigging Type\\checkpoint-910\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6405, 'learning_rate': 2.9344729344729345e-05, 'epoch': 7.08}\n",
      "{'loss': 0.6511, 'learning_rate': 2.9059829059829063e-05, 'epoch': 7.15}\n",
      "{'loss': 0.6643, 'learning_rate': 2.8774928774928778e-05, 'epoch': 7.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6841, 'learning_rate': 2.8490028490028492e-05, 'epoch': 7.31}\n",
      "{'loss': 0.6643, 'learning_rate': 2.8205128205128207e-05, 'epoch': 7.38}\n",
      "{'loss': 0.7227, 'learning_rate': 2.7920227920227922e-05, 'epoch': 7.46}\n",
      "{'loss': 0.6227, 'learning_rate': 2.7635327635327633e-05, 'epoch': 7.54}\n",
      "{'loss': 0.6397, 'learning_rate': 2.7350427350427355e-05, 'epoch': 7.61}\n",
      "{'loss': 0.7132, 'learning_rate': 2.706552706552707e-05, 'epoch': 7.69}\n",
      "{'loss': 0.6441, 'learning_rate': 2.6780626780626784e-05, 'epoch': 7.77}\n",
      "{'loss': 0.6848, 'learning_rate': 2.64957264957265e-05, 'epoch': 7.84}\n",
      "{'loss': 0.6544, 'learning_rate': 2.621082621082621e-05, 'epoch': 7.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6574, 'learning_rate': 2.5925925925925925e-05, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e4b1a8469c48e3b361074f8e14501f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Rigging Type\\checkpoint-1040\n",
      "Configuration saved in models/ViT_Rigging Type\\checkpoint-1040\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0194205045700073, 'eval_accuracy': 0.6847669389716482, 'eval_f1': 0.2061717525807183, 'eval_precision': 0.25264385092533964, 'eval_recall': 0.187566190517443, 'eval_runtime': 16.1664, 'eval_samples_per_second': 128.724, 'eval_steps_per_second': 8.103, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Rigging Type\\checkpoint-1040\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Rigging Type\\checkpoint-1040\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6553, 'learning_rate': 2.564102564102564e-05, 'epoch': 8.08}\n",
      "{'loss': 0.5719, 'learning_rate': 2.535612535612536e-05, 'epoch': 8.15}\n",
      "{'loss': 0.6599, 'learning_rate': 2.5071225071225073e-05, 'epoch': 8.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6225, 'learning_rate': 2.4786324786324787e-05, 'epoch': 8.31}\n",
      "{'loss': 0.6139, 'learning_rate': 2.4501424501424502e-05, 'epoch': 8.38}\n",
      "{'loss': 0.6033, 'learning_rate': 2.4216524216524217e-05, 'epoch': 8.46}\n",
      "{'loss': 0.6213, 'learning_rate': 2.3931623931623935e-05, 'epoch': 8.54}\n",
      "{'loss': 0.5807, 'learning_rate': 2.364672364672365e-05, 'epoch': 8.61}\n",
      "{'loss': 0.6791, 'learning_rate': 2.336182336182336e-05, 'epoch': 8.69}\n",
      "{'loss': 0.683, 'learning_rate': 2.307692307692308e-05, 'epoch': 8.77}\n",
      "{'loss': 0.5703, 'learning_rate': 2.2792022792022794e-05, 'epoch': 8.84}\n",
      "{'loss': 0.6248, 'learning_rate': 2.250712250712251e-05, 'epoch': 8.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5212, 'learning_rate': 2.2222222222222223e-05, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22af3fd8bb0e4c78886923f32dd9e9c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Rigging Type\\checkpoint-1170\n",
      "Configuration saved in models/ViT_Rigging Type\\checkpoint-1170\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.017215609550476, 'eval_accuracy': 0.6905333974050937, 'eval_f1': 0.1924191200629454, 'eval_precision': 0.256453623905414, 'eval_recall': 0.16817701443123526, 'eval_runtime': 16.206, 'eval_samples_per_second': 128.409, 'eval_steps_per_second': 8.083, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Rigging Type\\checkpoint-1170\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Rigging Type\\checkpoint-1170\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6038, 'learning_rate': 2.1937321937321938e-05, 'epoch': 9.08}\n",
      "{'loss': 0.5408, 'learning_rate': 2.1652421652421653e-05, 'epoch': 9.15}\n",
      "{'loss': 0.5581, 'learning_rate': 2.1367521367521368e-05, 'epoch': 9.23}\n",
      "{'loss': 0.5927, 'learning_rate': 2.1082621082621086e-05, 'epoch': 9.31}\n",
      "{'loss': 0.5159, 'learning_rate': 2.07977207977208e-05, 'epoch': 9.38}\n",
      "{'loss': 0.5118, 'learning_rate': 2.0512820512820512e-05, 'epoch': 9.46}\n",
      "{'loss': 0.5554, 'learning_rate': 2.022792022792023e-05, 'epoch': 9.54}\n",
      "{'loss': 0.5573, 'learning_rate': 1.9943019943019945e-05, 'epoch': 9.61}\n",
      "{'loss': 0.594, 'learning_rate': 1.965811965811966e-05, 'epoch': 9.69}\n",
      "{'loss': 0.5786, 'learning_rate': 1.9373219373219374e-05, 'epoch': 9.77}\n",
      "{'loss': 0.5581, 'learning_rate': 1.908831908831909e-05, 'epoch': 9.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6816, 'learning_rate': 1.8803418803418804e-05, 'epoch': 9.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6651, 'learning_rate': 1.8518518518518518e-05, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7faabad8559d4751b918e369828a1289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Rigging Type\\checkpoint-1300\n",
      "Configuration saved in models/ViT_Rigging Type\\checkpoint-1300\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.017815351486206, 'eval_accuracy': 0.6847669389716482, 'eval_f1': 0.21348634542071263, 'eval_precision': 0.2461088559721355, 'eval_recall': 0.20861332352834466, 'eval_runtime': 16.5377, 'eval_samples_per_second': 125.834, 'eval_steps_per_second': 7.921, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Rigging Type\\checkpoint-1300\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Rigging Type\\checkpoint-1300\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5529, 'learning_rate': 1.8233618233618236e-05, 'epoch': 10.08}\n",
      "{'loss': 0.5309, 'learning_rate': 1.794871794871795e-05, 'epoch': 10.15}\n",
      "{'loss': 0.4939, 'learning_rate': 1.7663817663817662e-05, 'epoch': 10.23}\n",
      "{'loss': 0.5379, 'learning_rate': 1.737891737891738e-05, 'epoch': 10.31}\n",
      "{'loss': 0.5641, 'learning_rate': 1.7094017094017095e-05, 'epoch': 10.38}\n",
      "{'loss': 0.5565, 'learning_rate': 1.680911680911681e-05, 'epoch': 10.46}\n",
      "{'loss': 0.5087, 'learning_rate': 1.6524216524216525e-05, 'epoch': 10.54}\n",
      "{'loss': 0.5618, 'learning_rate': 1.623931623931624e-05, 'epoch': 10.61}\n",
      "{'loss': 0.5579, 'learning_rate': 1.5954415954415954e-05, 'epoch': 10.69}\n",
      "{'loss': 0.5591, 'learning_rate': 1.566951566951567e-05, 'epoch': 10.77}\n",
      "{'loss': 0.4939, 'learning_rate': 1.5384615384615387e-05, 'epoch': 10.84}\n",
      "{'loss': 0.5181, 'learning_rate': 1.50997150997151e-05, 'epoch': 10.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4661, 'learning_rate': 1.4814814814814815e-05, 'epoch': 11.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b558578c1441288bd7e45db26e21c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Rigging Type\\checkpoint-1430\n",
      "Configuration saved in models/ViT_Rigging Type\\checkpoint-1430\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9819446206092834, 'eval_accuracy': 0.695819317635752, 'eval_f1': 0.22028052153434374, 'eval_precision': 0.2862622624305365, 'eval_recall': 0.20021185557297042, 'eval_runtime': 16.7403, 'eval_samples_per_second': 124.311, 'eval_steps_per_second': 7.825, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Rigging Type\\checkpoint-1430\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Rigging Type\\checkpoint-1430\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4716, 'learning_rate': 1.4529914529914531e-05, 'epoch': 11.08}\n",
      "{'loss': 0.5144, 'learning_rate': 1.4245014245014246e-05, 'epoch': 11.15}\n",
      "{'loss': 0.5121, 'learning_rate': 1.3960113960113961e-05, 'epoch': 11.23}\n",
      "{'loss': 0.6037, 'learning_rate': 1.3675213675213677e-05, 'epoch': 11.31}\n",
      "{'loss': 0.5174, 'learning_rate': 1.3390313390313392e-05, 'epoch': 11.38}\n",
      "{'loss': 0.5047, 'learning_rate': 1.3105413105413105e-05, 'epoch': 11.46}\n",
      "{'loss': 0.4906, 'learning_rate': 1.282051282051282e-05, 'epoch': 11.54}\n",
      "{'loss': 0.517, 'learning_rate': 1.2535612535612536e-05, 'epoch': 11.61}\n",
      "{'loss': 0.4596, 'learning_rate': 1.2250712250712251e-05, 'epoch': 11.69}\n",
      "{'loss': 0.5556, 'learning_rate': 1.1965811965811967e-05, 'epoch': 11.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5345, 'learning_rate': 1.168091168091168e-05, 'epoch': 11.84}\n",
      "{'loss': 0.4358, 'learning_rate': 1.1396011396011397e-05, 'epoch': 11.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5358, 'learning_rate': 1.1111111111111112e-05, 'epoch': 12.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a52c722d9e34e3ca94bcf6ebfe8d977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Rigging Type\\checkpoint-1560\n",
      "Configuration saved in models/ViT_Rigging Type\\checkpoint-1560\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.041707158088684, 'eval_accuracy': 0.6794810187409899, 'eval_f1': 0.19728528721647492, 'eval_precision': 0.2594194733521644, 'eval_recall': 0.1762721322706157, 'eval_runtime': 16.5687, 'eval_samples_per_second': 125.598, 'eval_steps_per_second': 7.906, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Rigging Type\\checkpoint-1560\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Rigging Type\\checkpoint-1560\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4499, 'learning_rate': 1.0826210826210826e-05, 'epoch': 12.08}\n",
      "{'loss': 0.4936, 'learning_rate': 1.0541310541310543e-05, 'epoch': 12.15}\n",
      "{'loss': 0.4858, 'learning_rate': 1.0256410256410256e-05, 'epoch': 12.23}\n",
      "{'loss': 0.4962, 'learning_rate': 9.971509971509972e-06, 'epoch': 12.31}\n",
      "{'loss': 0.4679, 'learning_rate': 9.686609686609687e-06, 'epoch': 12.38}\n",
      "{'loss': 0.4626, 'learning_rate': 9.401709401709402e-06, 'epoch': 12.46}\n",
      "{'loss': 0.4909, 'learning_rate': 9.116809116809118e-06, 'epoch': 12.54}\n",
      "{'loss': 0.4425, 'learning_rate': 8.831908831908831e-06, 'epoch': 12.61}\n",
      "{'loss': 0.5345, 'learning_rate': 8.547008547008548e-06, 'epoch': 12.69}\n",
      "{'loss': 0.4734, 'learning_rate': 8.262108262108262e-06, 'epoch': 12.77}\n",
      "{'loss': 0.5496, 'learning_rate': 7.977207977207977e-06, 'epoch': 12.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4476, 'learning_rate': 7.692307692307694e-06, 'epoch': 12.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4613, 'learning_rate': 7.4074074074074075e-06, 'epoch': 13.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1012dbe363d49ab8380e5536dbfe3d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Rigging Type\\checkpoint-1690\n",
      "Configuration saved in models/ViT_Rigging Type\\checkpoint-1690\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9957237243652344, 'eval_accuracy': 0.7078327727054301, 'eval_f1': 0.23341680328307565, 'eval_precision': 0.30235613236047937, 'eval_recall': 0.2115961172569109, 'eval_runtime': 16.5283, 'eval_samples_per_second': 125.905, 'eval_steps_per_second': 7.926, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Rigging Type\\checkpoint-1690\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Rigging Type\\checkpoint-1690\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4419, 'learning_rate': 7.122507122507123e-06, 'epoch': 13.08}\n",
      "{'loss': 0.453, 'learning_rate': 6.837606837606839e-06, 'epoch': 13.15}\n",
      "{'loss': 0.4745, 'learning_rate': 6.5527065527065525e-06, 'epoch': 13.23}\n",
      "{'loss': 0.4434, 'learning_rate': 6.267806267806268e-06, 'epoch': 13.31}\n",
      "{'loss': 0.4735, 'learning_rate': 5.982905982905984e-06, 'epoch': 13.38}\n",
      "{'loss': 0.4444, 'learning_rate': 5.6980056980056985e-06, 'epoch': 13.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4954, 'learning_rate': 5.413105413105413e-06, 'epoch': 13.54}\n",
      "{'loss': 0.4655, 'learning_rate': 5.128205128205128e-06, 'epoch': 13.61}\n",
      "{'loss': 0.4757, 'learning_rate': 4.8433048433048435e-06, 'epoch': 13.69}\n",
      "{'loss': 0.4534, 'learning_rate': 4.558404558404559e-06, 'epoch': 13.77}\n",
      "{'loss': 0.4394, 'learning_rate': 4.273504273504274e-06, 'epoch': 13.84}\n",
      "{'loss': 0.4735, 'learning_rate': 3.988603988603989e-06, 'epoch': 13.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4846, 'learning_rate': 3.7037037037037037e-06, 'epoch': 14.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d87c58802af4d54a043e1a546ea6764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Rigging Type\\checkpoint-1820\n",
      "Configuration saved in models/ViT_Rigging Type\\checkpoint-1820\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0425660610198975, 'eval_accuracy': 0.6890917827967323, 'eval_f1': 0.2325981225644445, 'eval_precision': 0.3191056672233251, 'eval_recall': 0.204798629663093, 'eval_runtime': 16.8727, 'eval_samples_per_second': 123.335, 'eval_steps_per_second': 7.764, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Rigging Type\\checkpoint-1820\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Rigging Type\\checkpoint-1820\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.459, 'learning_rate': 3.4188034188034193e-06, 'epoch': 14.08}\n",
      "{'loss': 0.4342, 'learning_rate': 3.133903133903134e-06, 'epoch': 14.15}\n",
      "{'loss': 0.4855, 'learning_rate': 2.8490028490028492e-06, 'epoch': 14.23}\n",
      "{'loss': 0.5152, 'learning_rate': 2.564102564102564e-06, 'epoch': 14.31}\n",
      "{'loss': 0.4117, 'learning_rate': 2.2792022792022796e-06, 'epoch': 14.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3994, 'learning_rate': 1.9943019943019943e-06, 'epoch': 14.46}\n",
      "{'loss': 0.442, 'learning_rate': 1.7094017094017097e-06, 'epoch': 14.54}\n",
      "{'loss': 0.4592, 'learning_rate': 1.4245014245014246e-06, 'epoch': 14.61}\n",
      "{'loss': 0.5083, 'learning_rate': 1.1396011396011398e-06, 'epoch': 14.69}\n",
      "{'loss': 0.4454, 'learning_rate': 8.547008547008548e-07, 'epoch': 14.77}\n",
      "{'loss': 0.4455, 'learning_rate': 5.698005698005699e-07, 'epoch': 14.84}\n",
      "{'loss': 0.4281, 'learning_rate': 2.8490028490028494e-07, 'epoch': 14.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4085, 'learning_rate': 0.0, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4956db5e0842fc9d9b4522c7aca841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Rigging Type\\checkpoint-1950\n",
      "Configuration saved in models/ViT_Rigging Type\\checkpoint-1950\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9976723790168762, 'eval_accuracy': 0.699663623258049, 'eval_f1': 0.2271372701106199, 'eval_precision': 0.3098228692672205, 'eval_recall': 0.1987879672605256, 'eval_runtime': 16.482, 'eval_samples_per_second': 126.259, 'eval_steps_per_second': 7.948, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Rigging Type\\checkpoint-1950\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Rigging Type\\checkpoint-1950\\preprocessor_config.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from models/ViT_Rigging Type\\checkpoint-1690 (score: 0.23341680328307565).\n",
      "Setting `WANDB_LOG_MODEL` from true to `end` instead\n",
      "Saving model checkpoint to C:\\Users\\chris\\AppData\\Local\\Temp\\tmp67t_pn9_\n",
      "Configuration saved in C:\\Users\\chris\\AppData\\Local\\Temp\\tmp67t_pn9_\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 2257.6752, 'train_samples_per_second': 55.298, 'train_steps_per_second': 0.864, 'train_loss': 0.8053199263108082, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in C:\\Users\\chris\\AppData\\Local\\Temp\\tmp67t_pn9_\\pytorch_model.bin\n",
      "Image processor saved in C:\\Users\\chris\\AppData\\Local\\Temp\\tmp67t_pn9_\\preprocessor_config.json\n",
      "Logging model artifacts. ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▄▆▆▆▆▆▇▇▇▇▇█▇█</td></tr><tr><td>eval/f1</td><td>▁▂▅▄▅▆▇▇▇▇█▇███</td></tr><tr><td>eval/loss</td><td>█▄▃▂▂▁▂▂▂▂▁▂▁▂▁</td></tr><tr><td>eval/precision</td><td>▁▃▅▄▇▇▇▆▆▆▇▆███</td></tr><tr><td>eval/recall</td><td>▁▂▅▄▅▆▆▇▆██▇██▇</td></tr><tr><td>eval/runtime</td><td>▂▁▄▆▂▂▅▁▁▅▇▅▅█▄</td></tr><tr><td>eval/samples_per_second</td><td>▇█▅▃▇▇▄██▄▂▄▄▁▅</td></tr><tr><td>eval/steps_per_second</td><td>▇█▅▃▇▇▄██▄▂▄▄▁▅</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>▂▃▅▇███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.69966</td></tr><tr><td>eval/f1</td><td>0.22714</td></tr><tr><td>eval/loss</td><td>0.99767</td></tr><tr><td>eval/precision</td><td>0.30982</td></tr><tr><td>eval/recall</td><td>0.19879</td></tr><tr><td>eval/runtime</td><td>16.482</td></tr><tr><td>eval/samples_per_second</td><td>126.259</td></tr><tr><td>eval/steps_per_second</td><td>7.948</td></tr><tr><td>train/epoch</td><td>15.0</td></tr><tr><td>train/global_step</td><td>1950</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4085</td></tr><tr><td>train/total_flos</td><td>9.677376429807034e+18</td></tr><tr><td>train/train_loss</td><td>0.80532</td></tr><tr><td>train/train_runtime</td><td>2257.6752</td></tr><tr><td>train/train_samples_per_second</td><td>55.298</td></tr><tr><td>train/train_steps_per_second</td><td>0.864</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ViT_Rigging Type</strong>: <a href=\"https://wandb.ai/cringgaard/Sailboat%20FGVC/runs/20ng10rs\" target=\"_blank\">https://wandb.ai/cringgaard/Sailboat%20FGVC/runs/20ng10rs</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230323_134047-20ng10rs\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de90b0221840402493b2fcfaff46e6b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\chris\\OneDrive\\Dokumenter\\GitHub\\SailFGVC\\wandb\\run-20230323_141907-3n2xd9ga</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cringgaard/Sailboat%20FGVC/runs/3n2xd9ga\" target=\"_blank\">ViT_Construction</a></strong> to <a href=\"https://wandb.ai/cringgaard/Sailboat%20FGVC\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\\cache-38cfd790e5446e8a.arrow and C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\\cache-3e7cbabf2a257be5.arrow\n",
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\\cache-baf0a3b3b7c8166f.arrow\n",
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\\cache-7a8cb2e4cc5f6788.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 204, 206, 207, 208, 209, 211, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 257, 258, 259, 261, 263, 264, 265, 266, 267, 268, 269, 270, 272, 273, 274, 275, 276, 277, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 344, 346, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 394, 395, 396, 397, 398, 399, 400, 401, 403, 404, 405, 406, 407, 408, 409, 410, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 444, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 458, 459, 460, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 476, 477, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 494, 495, 496, 497, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 513, 514, 515, 516, 517, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 531, 532, 533, 534, 535, 536, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 567, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 592, 593, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 606, 608, 609, 610, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 633, 634, 635, 636]\n",
      "[2, 3, 4, 6, 7, 8, 9, 10, 15, 16, 18, 19, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 34, 35, 42, 44, 49, 50, 52, 54, 55, 57, 58, 59, 63, 64, 68, 70, 71, 72, 75, 76, 82, 84, 91, 94, 95, 98, 100, 101, 102, 103, 104, 108, 109, 110, 114, 116, 118, 129, 130, 131, 132, 133, 138, 140, 143, 149, 151, 155, 156, 157, 160, 166, 170, 174, 179, 181, 184, 185, 186, 192, 196, 200, 204, 205, 206, 209, 210, 214, 216, 218, 228, 244, 245, 247, 250, 253, 258, 259, 260, 262, 265, 267, 268, 270, 271, 272, 273, 274, 278, 283, 285, 289, 290, 291, 292, 296, 300, 304, 305, 306, 309, 310, 314, 315, 321, 322, 323, 328, 329, 337, 339, 342, 343, 344, 345, 347, 354, 363, 367, 368, 371, 374, 377, 380, 382, 384, 388, 392, 394, 396, 397, 399, 402, 404, 410, 411, 413, 414, 418, 423, 426, 429, 443, 444, 445, 446, 447, 453, 457, 458, 461, 462, 465, 475, 478, 479, 480, 483, 485, 492, 493, 494, 498, 502, 505, 506, 512, 514, 518, 528, 530, 537, 538, 539, 542, 548, 550, 553, 555, 557, 564, 566, 567, 568, 572, 574, 580, 585, 588, 591, 594, 598, 599, 601, 605, 606, 607, 611, 615, 617, 618, 623, 626, 627, 630, 631]\n",
      "[245, 475, 566, 131, 518, 19, 260, 27, 512, 605, 216, 530, 478, 553, 323, 185, 630, 480, 143, 82, 485, 479, 539, 611, 462, 537, 310, 205, 345, 363, 607, 591, 278, 538, 262, 443, 493, 498, 402, 445, 102, 210, 347, 594, 447, 44, 457, 200, 157, 461, 568, 380, 411, 392, 343, 271]\n",
      "['FG w/core,Composite', 'Plywood or GRP', 'Wood', 'Plywood/FG', 'FG', 'Carbon inside/Kevlar ext./SCRIMP', 'Ply with single chine or FG', 'FG or Wood', 'Wood/FG', 'NaN', 'GRP', 'Carbon fiber', 'FG (foam sandwich)', 'GRP Sandwich resin infusion', 'Wood/FG/Composite', 'Wood or FG', 'FG w/balsa core hull & deck', 'FG Foam Core', 'Composite', 'FG/balsa core deck', 'Carbon-epoxy sandwich', 'Carbon/Composite', 'Wood/FG/single chine', 'FG solid hull, balsa cored deck', 'FG w/balsa core deck', 'FG w/cored deck', 'Epoxy w/ Divinycell', 'Cold Molded Mahogany', 'FG (solid)', 'ALU', 'Aluminum', 'FG w/balsa cored deck', 'FG w/foam cored deck', 'Aluminum multi-chine', 'Steel', 'Resin infused GRP', 'wood strip/FG', 'wood strip', 'Ferro Cement', 'FG foam core/infusion', 'FG/ E glass w/balsa core', 'FG /ferro cement', 'FG Composite', 'Wood / FG', 'Wood/FG/multi chine', 'FG Divinycell  & Vinyl', 'FG w/devinacell', 'FG reinforced vinylester with Divinycell core', 'FG Divinycell  & Vinyl w carbon', \"Plywood 'stitch & glue'\", 'TRILAM Polyethylene', 'FG & Plywood', 'Plywood', 'Wood or foam core', 'Plywood/single chine', \"Wood ('hot molded' laminate)\", 'FG solid laminate - fabmat', 'FG/balsa cored deck', 'Molded Plywood', 'Wood (Clinker)', 'FG/infusion', 'FG (Infusion)', 'FG vinylester/infusion', 'FG or plywood', 'Glass/carbon fiber over foam core', 'FG/pre-preg foam core w/carbon', 'E-glass/cabon', 'FG solid laminate hull/ply cored deck', 'Foam-cored, vacuum-infused FG', 'FG infusion/balsa above waterline', 'PVC Foam-cored, vacuum-infused GRP', 'GRP-infused PVC Foam Sandwich', 'GRP infused PVC Foam Sandwich', 'GRP w/ PVC foam sandwich, polyester resin', 'FG Balsa Core', 'FG/Carbon Epoxy Sandwich', 'FG composite', 'GRP w/carbon fiber and foam core', 'FG with wood ', 'Wood (clinker)', 'FG & Wood', 'FG w/carbon & kev.', 'FG with foam core above the waterline', 'FG w/Divinycell hull & deck', 'FG ', 'Wood - carvel (mahogany on oak)', 'Cedar planked over white oak frames', 'Plywood / FG', 'Foam sandwich/Carbon/Kevlar', 'FG Sandwich', 'GRP vinylester sandwich', 'Aluminium', 'Polyester composite', 'FG w/airex cored deck', 'Airex foam core', 'FG solid', 'Wood planked w/double chine', 'Wood plank', 'Wood Planked', 'FG w/airex core', 'Plywood or FG', 'Plywood /single chine', 'FG hull/wood deck and cabin', 'FG w/balsa cored deck and coach', 'Wood planked', 'Wood / Steel', 'Wood - clinker', 'Aluminum/FG', 'ALU/FG', 'FG solid laminate', 'FG (solid laminate)', 'FG vinylester w/balsa deck', 'Solid lam. below waterline w kevlar', 'FG w/Vinylester resin', 'FG or Plywood', 'FG w/vinylester resin', 'FG w/ vacuum infusion', 'plywood, multi-chine', 'Fg', 'Fiberglass', 'FG w/balsa deck', 'Wood (strip planked mahogany)', 'Wood (strip. planked mahogany)', 'FG airex hull, divinicell deck', 'plywood or FG', 'GRP with Vinylester', 'Wood /FG', 'FG solid lamine hull/ cored deck.', 'vinylester, E-glass with Kevlar, foam deck', 'FG hull/wood deck', 'FG/Composite', 'FG (solid) ', 'Polyethyline', 'Wood (strip planked)', 'FG w/divinycell core deck', 'FG w/klegecell core', 'Epoxy-FRP', 'FG/wood superstructure', 'FG  (solid)', 'Carbon w/foam core', 'GRP-infused Foam Sandwich w/Vinylester and Polyester resin', 'FG w/carbon infusion', 'FG w/vacuum infusion and CARBON and aramid fibre', 'Wood planked (teak)', 'Wood planked/Molded Plywood/FG', 'FG w/balsa core above waterline', 'FG/balsa cored foredeck', 'FG w/balsa core', 'FG (solid hull/balsa deck)', 'FG hull', 'GF/Alloy', 'FG w/balsa cored hull & deck', 'Wood/GRP', 'Aluminum or steel', 'Aluminum and steel', 'Any', 'FG/plywood deck', 'FG w/ply deck', 'FG w/Klege-Cell', 'FG solid hull/plywood deck', 'Plywood Epoxy', 'Wood (Stitch and glue plywood)', 'Carbon Epoxy Foam', 'FG w/Airex cored hull', 'Carbon-Airex foam-Araldite Epoxy sandwich', 'FG (balsa core cabin trunk)', 'FRP', 'Wood planked, (Mahogany, Oak frames)', 'Wood ', 'FG w/airex cored hull & deck', 'FG w/airex cored hull', 'Kevlar foam epoxy pre-preg.', 'FG/Klegecell', 'Wood Clinker/FG', 'wood/FG', 'EGlass/Vacuum formed sandwich', 'FG with PVC core', 'FG/Kevlar w/balsa', 'Steel or Alu', 'Tecrothene 121', 'FG poly foam sand.', 'Wood (Mahog. on Oak)', 'FG w/Airex core for deck.', 'GRP w/ vinylester resin and balsa core', 'FG/vinylester (composite infusion)', 'Steel (single chine)', 'FG sandwich UD carbon reinforcement, PVC foam', 'Polyeser-PVC sandwich w/ carbon', 'Wood planked single chine', 'Wood single chine', 'FG/airex core', 'FG w/ Divinycell sandwich core', 'FG (Composite)', 'FG Comp.', 'Ply/single chine', 'FG/foam sandwich', 'FG/Sandwich', 'Sandwich E-Glass', 'FG w/foam core deck', 'FG twaron reiforced w/balsa deck', 'FG, PVC foam above WL', 'FG w/ foam sandwich', 'FG w/poly cored deck', 'FG/solid lam. hull/sandwich deck', 'Cold molded or ply with chine', 'FG/PLY/ALU', 'Wood (Mahogany)', 'GRP with foam core', 'Foam core epoxy', 'Foam core epoxy laminate', 'Wood/FG w/balsa deck', 'Wood/Steel/FG', 'Steel (triple chine)', 'Resin infus./PVC foam hull side/balsa deck', 'GRP w/vacuum infused polyester and vinylester', 'Advanced comp.', 'FG w/foam (polypro.) core', 'various', 'Steel/FG/Ferro', 'Swing Keel', 'Wood (Cold molded)', 'FG w/polyurethane foam sand.', 'FG (poly. core)', 'FG (comp)', 'FG foam/vinyl w/infusion/carbon stringers', 'FG w/ airex core', 'FG sandwich hull & deck', 'Wood - Clinker', 'Vacuum infused polyester with balsa core', 'FG - Composite', 'FG w/foam core', 'FG /Fm. core', 'FG or strip plank', 'Wood/hot molded veneer', 'Wood/hot molded veneer (agba/cedar)', 'Molded fiberglass', 'FG multi chine', 'Wood Mahogany on Oak', 'vinyl-ester w/carbon', 'FG epoxy w/PVC core', 'Carbon/Epoxy Sandwich', 'Divinicell sandwich', 'FG w/Airex core', 'Niels Peter Faurby', 'Polyester sandwich - Infused PVC foam', 'Plywood/multi-chine', 'FG w/carbon & airex', 'FG/balsa sandwich', 'Wood or FG, single chine', 'Wood (hot molded)/FG', 'Vacuum-infused vinylester resin', 'FG/ balsa sand. deck', 'FG/poly. core', 'Balsa sandwich infused FG hull', 'Plywood;single chine/FG', 'ALU multi-chine', 'Pre-preg carbon w/nomex sand.', 'FG with carbon-reinforced vinylester.', 'Wood/Steel', 'FGw/balsa cored hull & deck', 'FG/Steel/Wood', 'FG-foam cored hull-balsa deck', 'Plywood Hot Molded', 'Ply wood', 'Wood/FG/double chine', 'FG with balsa and foam core', 'class rules', 'Plywood/GRP/FRP/Composite', 'Wood/GRP/Composite', 'GRP w/E-glass and vinylester resin', 'FG w/foam PVC sandwich', 'FG sandwich w/carbon ', 'E-glass w/ epoxy vinyester + PVC foam core', 'FG hull; wood coachroof', 'Wood Composite/FG', 'FG w/ vinylester resin and PVC foam core', 'FG balsa cored deck', 'FG w/balsa cored deck & topsides', 'FG/ solid hull & balsa cored deck', 'FG/Carbon infusion', 'FG/epoxy/nomex', 'FRP with Vinylester resin', 'Carbon reinforced GRP', 'FG w/ balsa cored deck', 'Roto-moulded polyethylene', 'Plywoo/FG', 'Wood (carvel)', 'Balsa core sandwich set in polyester resin, exterior layer of vinylester', 'FG w/balsa sandwich', 'GRP w/balsa sandwich', 'GRP w/1st layer Vinylester resin', 'GRP w/1st layer Vinylester resin and balsa sandwich', 'EDPM tire/natural rubber', '1100 dtex EDPM tire/natural rubber', 'Natural rubber', 'Wood or GRP', 'FG infusion w/balsa & klegecell', 'Wood/cold molded', 'Carbon-epoxy sandwich pre-preg', 'Carbon fiber composite', 'Carbon fiber w/corecell foam core', 'Carbon fiber composite foam sandwich', 'Roto-Molded Polyethylene', 'Roto Molded Polyethylene', 'ABS', 'Rotomolded Polyethylene', 'Plywood single chine', 'Wood Clinker', 'Wood - carvel', 'ACP', 'ACP (foam & plastic sandwich)', 'ABS/FG', 'Thermo Plastic', 'HG', 'FG (solid hull and balsa deck)', 'FRP / Balsa sandwich above waterline', 'ACP -Thermo formed Plastic', 'Alum. or Steel', 'FG w/no core', 'Solid FRP', 'Wood and GRP', 'FG w/Divinycell core', 'Wood lapstrake/FG', 'Wood/FG (1971)', 'FG/Carbon', 'Wood/Clinker', 'All materials allowed', 'Molded Plywood/FG', 'GRP w/balsa core', 'FG w/plywood cored deck', 'FG w/divinycell deck', 'Composite infusion', 'E glass w/vinyl/PVC core', 'FG with vinylester resin', 'FG and PVC sandwich', 'FG w/closed cell foam core', 'E glass/PVC core/vinyl.', 'FG foam sand. coach roof and deck', 'Wood/Composite', 'Vacuum infused hull', 'Vacuum infused hull, sandwich balsa/ polyester.', 'GRP with vinylester infusion', 'FG/ABS', 'ALUM', 'Carbon', 'FRP with Airex foam core', 'FG balsa cored deck.', 'E glass, corecell', 'E-glass/epoxy/foam sandwich', 'Mahogany planked on Oak', 'FG/wood deck', 'Single chine Ply/FG', 'Wood; Carvel planked', 'FG/vinylVacuum/foam sandwich', 'GRP w/ PVC foam sandwich', 'Vacuum infused polyester with balsa core.', 'Polyester with balsa core hull', 'Foam Sand. /resin infusion', 'Wood/Epoxy Composite', 'Epoxy foam sand.w/Carbon', 'Cold Molded', 'FG/Termanto PVC foam Hull & deck', 'Techcrothene 109 (roto molded)', 'FG/ balsa cored deck', 'Carbon infused FG', 'FG w/Divinycell sandwich core', 'FG w/ vacuum infused Divinycall', 'Teak/FG', 'FG w/balsa or airex cored deck', 'Cold- molded wood', 'Wood (clinker)/Wood(carvel)', 'molded plywood or FG', 'FG hull, Wood Deck', 'FG with foam core + steel frame', 'Infused composite FG with Vinylester resin and balsa core.', 'Infused FG composite with Vinylester resin and balsa core', 'Infused composite hull with Vinylester resin.', 'Vacuum infused composite FG with Vinylester and balsa core.', 'ABS/Corelite', 'FG w/airex hull/balsa core deck', 'Wood planked/cold molded/FG', 'Vinylester Resin infused thermoformed Core-Cell', 'FG foam sand. hull & deck', 'FG single chine', 'FG/Foam Sandwich', 'FG foam sandwich deck', 'FG w/foam cored hull, balsa deck.', 'Wood strip planked/FG w/balsa deck', 'FG with wood deck and cabin', 'FG Hull, FG over ply Deck & Cabin', 'FG/Balsa hull, airex deck', 'Carbon w/sandwich', 'FG/wood/steel/alum.', 'FG w/PVC core', 'GRP w/PVC core', 'FG PVC sandwich w/carbon', 'WOOD', 'FG w/ airex cored deck', 'epoxy infused carbon & foam core', 'Heytex 5509 (inflatable)', 'FG or PLY', 'Plwood/multi-chine', 'FG hull and wood deck opt.', 'GRP w/vinylester and balsa sandwich', 'FG solid hull/plywood cored deck', 'Various', 'Ply Wood', 'Wood (mahogany)', 'FG w/bals cored deck', 'Mahogany strip planked', 'Plywood (hard chine)', 'Aluminium or FRP', 'Vinylester/Fiberglass', 'GRP carbon epoxy', 'FG foam sandwich', 'FRP epoxy resin with full carbon foam sandwich', 'FRP Epoxy with carbon foam sandwich', 'ALU/Wood', 'Vacuum Infused E-Glass Vinylester/Polyester', 'E-Glass Vinylester', 'Wood/ALU/FG', 'plyood/FG', 'Wood or Fiberglass', 'biax. E glass w/Dyvinicel foam core', 'FG infusion w/klegecell core', 'FG with foam core', 'FG w/poly foam sand.', 'FG with vacuum bonded PVC/foam', 'FG/Closed-cell foam and honeycomb PVC sandwich', 'GRP with Airex PVC foam core', 'Kevlar w/epoxy & balsa', 'Wood double planked', 'Wood planked on steel', 'FG/Aluminum', 'FG w/airex hull/klegecell deck', 'Steel (multi chine)', 'FG single laminate', 'Ply, Aluminium or FG', 'FG solid laminate with balsa cored deck', 'FG w/PVC foam/vinylsester', 'Wood (carvel or ply)/FG', 'Polyester', 'Monolithic polyester contact', 'FG w/pvc core w/infusion', 'Alum., Wood or GRP', 'FG infused w/PVC foam topsides and deck/vinylester', 'Alum.', 'Wood/Ply/FG', 'FG/vinylester-balsa-vacuum', 'Epoxy w/foam sand.', 'Solid FG hull and deck', 'FG/w closed cell foam deck', 'Mahogany on Oak', 'wood', 'FG w/vacuum bagged corecell core', 'FG w/corecell foam core', 'FRP w/balsa core bottom/solid topsides', 'FG/sandwich', 'Wood/FG/composite', 'Wood planked/FG', 'GRP/timber', 'FG (Epoxy)', 'HPDE (Roto molded)', 'FG, PVC foam', 'FG w/polyester foam core', 'Glass, polyester resin, foam sandwich, vacuum infusion', 'Glass, Polyester, PVC foam', 'Wood/FG/other', 'Wood (plywood) w/ glass skin overlay', 'Wood (teak over elm) ', 'FG solid laminate below waterline', 'GRP w/ PVC foam core and 1st layer Vinylester resin', 'GRP w/PVC foam core', 'Infused carbon foam sandwich', 'Carbon fiber, vinylester, epoxy divinycell foam sandwich', 'Hull & Deck vacuum bagged  foam sand.', 'Cold Molded or FG', 'E glass/foam sand.,infusion', 'Wood planked hull w/plywood deck.', 'Wood - planked mahogany', 'FG (vacuum-resin-infused)', 'Steel, Wood or GRP', 'Multi-chine ply w/FG', 'Plywood/epoxy', 'Multi-chine PLYw/Epoxy', 'Plywood-multi-chine/FG', 'multi-chine plywood&epoxy', 'multi chine - ply/epoxy/comp.', 'Ply/multi-chine/FG', 'FG/Wood', 'FG w/divin. deck & hull', 'Wood, carvel planked', 'Comptec PE3 Polyethylene', 'Roto Molded poly.', 'Roto molded poly.', 'Polyethylene', 'VGRP foam sandwich', 'GRP monolithic construction', 'Wood carvel mahog.', 'FG (solid) hull/Balsa cored deck', 'FG/Wood Coachroof', 'FG balsa core hull & deck', 'FG w/vacuum infused Vinylester resin', 'GRP w/polyester resin and balsa core', 'FG w/klegecell', 'Vinly w/PVC', 'Marine ply w/carbon fiber and epoxy resin', 'FG foam w/carbon', 'FG bottom/wood topsides', 'Wood (cedar on oak)', 'FG Airex hull/ balsa deck', 'Mahogany', 'Wood, hard chined', 'Wood clinker', 'FG/solid laminate', 'FG (balsa core  cored deck and coach)', 'FG (solid hull/balsa cored deck)', 'FG (balsa cored deck)', 'FG w/ balsa cord deck', 'FG or Ply', 'plywood, hard chine', 'Steel Alum. or Wood', 'glass w/carbon/vinylester/PVC sand.', 'FG solid hull&deck', 'foam sad/vinylester', 'Infused vinylester and polyester w/ foam core', 'Vacuum infusion vinylester resin with carbon fiber', 'Vacuum infusion vinylester resin with carbon fiber and Kevlar', 'FG w/balsa deck & coach', 'FG sandwich w/kevlar', 'Wood-Clinker', 'Carbon w/honeycomb', 'Tubular steel', 'Carbon (pre-preg)', 'Cored composite', 'Wood (pine on oak)', 'E-Glass/Epoxy/PVC foam', 'FG w/poly sandwich deck', 'GRP w/poly sandwich deck', 'FG/ hull w/ Airex/ Deck w/balsa', 'FG w/klegecell deck', 'Wood (carvel planked)', 'Wood/single chine', 'Plywood or GRP w/foam sandwich', 'Wood/clinker', 'Wood - (clinker)', 'FG/ w/epoxy & Nomex (nylon) core', 'FG prepreg/Nomex core', 'glass/kev/nomex', 'Wood-clinker', 'FG - solid', 'Infusion molded FG', 'Vacuum-bagged resin infusion', 'FG w/kevlar (Aramat K)', 'FG w/ kevlar ', 'GRP using ISO/NPG resin', 'FG balsa cored hull & deck', 'High-Impact Luran', 'Epoxy w/foam core', 'wood/FG/ALU', 'Advanced Comp.', 'Carbon Composite', 's-glass/cedar core/carbon/kevlar', 'Hot molded plywood', 'FG w/ sandwich', 'FG/cored deck', 'foam sand.epoxy infusion', 'Modified epoxy E-glass laminate', 'Epoxy/ATC Core-Cell', 'FRP w/PVC foam core', 'FG Vinylester/PVC hull/Balsa deck ', 'FG w/PVC hull and balsa deck', 'Plywood/FG - single chine', 'Wood with alternate steel frames', 'Molded Ply/FG', 'carbon/kevlar with foam core', 'Wood/Clinker/FG', 'Plywood-epoxy', 'FG/Steel', 'Wood (hot molded veneers)', 'PVC', 'GRP sandwich w/PVC foam and Vinylester resin', 'Wood (cold molded)/FG', 'FGw/Carbon', 'FG w/ DC core', 'FG w/ infused vinylester; PVC foam core', 'FG w/ vinylester resin; PVC foam core', 'Epoxy foam sandwich', 'Roto molded poly/Tri-Skin foam sand.', 'FG w/poly foam, carbon and kev.', 'Plywood & Oak', 'Steel/Alu', 'FG sandwich with PVC foam core', 'Wood(clinker)/FG', 'Wood (cold molded)', 'FG w/ deck of Vetrolex core', 'FG cored deck', 'Wood Mahogany', 'Epoxy/foam sandwich', 'E-glass, foam sandwich', 'Wood composite', 'wood / epoxy', 'Wood/ FG', 'Wood - Teak', 'FG (Airex core)', 'Infused epoxy', 'FG (vacuum infusion resin) w/ balsa sandwich', 'FG /balsa w/infusion', 'FG (vacuum infusion) w/balsa core', 'Ply (multi-chine)/FG', 'Wood multi chine', 'Plywood (double chine)', 'FG solid hull/ply sandwich deck', 'FG w/foam core & carbon beams', 'FG-PVC core', 'Steel (multichine)', 'FG w/Klege-cell core', 'Roto molded Poly.', 'FG w/airex in hull and balsa deck', 'FG with kevlar reinforcement', 'Wood & FG', 'Chantier Wrighton (FRA)', 'FG w/foam cored hull & deck', 'Wood (Carvel)', 'EEP Particle foam', 'Foam w/carbon', 'FG with vacuum infused epoxy', 'Epoxy/foam sand. w/E-glass', 'Epoxy infusion', 'Roto Molded Poly.', 'Epoxy/foam sand. w/carbon', 'E Glass, Divinicel Composite foam infused with Vinylester resins', 'Plywd. Alum. FG double chine', 'Plywood, double chine', 'plywood', 'FG foam core/resin infusion', 'Wood /FG single chine']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\chris/.cache\\huggingface\\hub\\models--google--vit-base-patch16-224\\snapshots\\2ddc9d4e473d7ba52128f0df4723e478fa14fb80\\config.json\n",
      "Model config ViTConfig {\n",
      "  \"_name_or_path\": \"google/vit-base-patch16-224\",\n",
      "  \"architectures\": [\n",
      "    \"ViTForImageClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\",\n",
      "    \"59\": \"LABEL_59\",\n",
      "    \"60\": \"LABEL_60\",\n",
      "    \"61\": \"LABEL_61\",\n",
      "    \"62\": \"LABEL_62\",\n",
      "    \"63\": \"LABEL_63\",\n",
      "    \"64\": \"LABEL_64\",\n",
      "    \"65\": \"LABEL_65\",\n",
      "    \"66\": \"LABEL_66\",\n",
      "    \"67\": \"LABEL_67\",\n",
      "    \"68\": \"LABEL_68\",\n",
      "    \"69\": \"LABEL_69\",\n",
      "    \"70\": \"LABEL_70\",\n",
      "    \"71\": \"LABEL_71\",\n",
      "    \"72\": \"LABEL_72\",\n",
      "    \"73\": \"LABEL_73\",\n",
      "    \"74\": \"LABEL_74\",\n",
      "    \"75\": \"LABEL_75\",\n",
      "    \"76\": \"LABEL_76\",\n",
      "    \"77\": \"LABEL_77\",\n",
      "    \"78\": \"LABEL_78\",\n",
      "    \"79\": \"LABEL_79\",\n",
      "    \"80\": \"LABEL_80\",\n",
      "    \"81\": \"LABEL_81\",\n",
      "    \"82\": \"LABEL_82\",\n",
      "    \"83\": \"LABEL_83\",\n",
      "    \"84\": \"LABEL_84\",\n",
      "    \"85\": \"LABEL_85\",\n",
      "    \"86\": \"LABEL_86\",\n",
      "    \"87\": \"LABEL_87\",\n",
      "    \"88\": \"LABEL_88\",\n",
      "    \"89\": \"LABEL_89\",\n",
      "    \"90\": \"LABEL_90\",\n",
      "    \"91\": \"LABEL_91\",\n",
      "    \"92\": \"LABEL_92\",\n",
      "    \"93\": \"LABEL_93\",\n",
      "    \"94\": \"LABEL_94\",\n",
      "    \"95\": \"LABEL_95\",\n",
      "    \"96\": \"LABEL_96\",\n",
      "    \"97\": \"LABEL_97\",\n",
      "    \"98\": \"LABEL_98\",\n",
      "    \"99\": \"LABEL_99\",\n",
      "    \"100\": \"LABEL_100\",\n",
      "    \"101\": \"LABEL_101\",\n",
      "    \"102\": \"LABEL_102\",\n",
      "    \"103\": \"LABEL_103\",\n",
      "    \"104\": \"LABEL_104\",\n",
      "    \"105\": \"LABEL_105\",\n",
      "    \"106\": \"LABEL_106\",\n",
      "    \"107\": \"LABEL_107\",\n",
      "    \"108\": \"LABEL_108\",\n",
      "    \"109\": \"LABEL_109\",\n",
      "    \"110\": \"LABEL_110\",\n",
      "    \"111\": \"LABEL_111\",\n",
      "    \"112\": \"LABEL_112\",\n",
      "    \"113\": \"LABEL_113\",\n",
      "    \"114\": \"LABEL_114\",\n",
      "    \"115\": \"LABEL_115\",\n",
      "    \"116\": \"LABEL_116\",\n",
      "    \"117\": \"LABEL_117\",\n",
      "    \"118\": \"LABEL_118\",\n",
      "    \"119\": \"LABEL_119\",\n",
      "    \"120\": \"LABEL_120\",\n",
      "    \"121\": \"LABEL_121\",\n",
      "    \"122\": \"LABEL_122\",\n",
      "    \"123\": \"LABEL_123\",\n",
      "    \"124\": \"LABEL_124\",\n",
      "    \"125\": \"LABEL_125\",\n",
      "    \"126\": \"LABEL_126\",\n",
      "    \"127\": \"LABEL_127\",\n",
      "    \"128\": \"LABEL_128\",\n",
      "    \"129\": \"LABEL_129\",\n",
      "    \"130\": \"LABEL_130\",\n",
      "    \"131\": \"LABEL_131\",\n",
      "    \"132\": \"LABEL_132\",\n",
      "    \"133\": \"LABEL_133\",\n",
      "    \"134\": \"LABEL_134\",\n",
      "    \"135\": \"LABEL_135\",\n",
      "    \"136\": \"LABEL_136\",\n",
      "    \"137\": \"LABEL_137\",\n",
      "    \"138\": \"LABEL_138\",\n",
      "    \"139\": \"LABEL_139\",\n",
      "    \"140\": \"LABEL_140\",\n",
      "    \"141\": \"LABEL_141\",\n",
      "    \"142\": \"LABEL_142\",\n",
      "    \"143\": \"LABEL_143\",\n",
      "    \"144\": \"LABEL_144\",\n",
      "    \"145\": \"LABEL_145\",\n",
      "    \"146\": \"LABEL_146\",\n",
      "    \"147\": \"LABEL_147\",\n",
      "    \"148\": \"LABEL_148\",\n",
      "    \"149\": \"LABEL_149\",\n",
      "    \"150\": \"LABEL_150\",\n",
      "    \"151\": \"LABEL_151\",\n",
      "    \"152\": \"LABEL_152\",\n",
      "    \"153\": \"LABEL_153\",\n",
      "    \"154\": \"LABEL_154\",\n",
      "    \"155\": \"LABEL_155\",\n",
      "    \"156\": \"LABEL_156\",\n",
      "    \"157\": \"LABEL_157\",\n",
      "    \"158\": \"LABEL_158\",\n",
      "    \"159\": \"LABEL_159\",\n",
      "    \"160\": \"LABEL_160\",\n",
      "    \"161\": \"LABEL_161\",\n",
      "    \"162\": \"LABEL_162\",\n",
      "    \"163\": \"LABEL_163\",\n",
      "    \"164\": \"LABEL_164\",\n",
      "    \"165\": \"LABEL_165\",\n",
      "    \"166\": \"LABEL_166\",\n",
      "    \"167\": \"LABEL_167\",\n",
      "    \"168\": \"LABEL_168\",\n",
      "    \"169\": \"LABEL_169\",\n",
      "    \"170\": \"LABEL_170\",\n",
      "    \"171\": \"LABEL_171\",\n",
      "    \"172\": \"LABEL_172\",\n",
      "    \"173\": \"LABEL_173\",\n",
      "    \"174\": \"LABEL_174\",\n",
      "    \"175\": \"LABEL_175\",\n",
      "    \"176\": \"LABEL_176\",\n",
      "    \"177\": \"LABEL_177\",\n",
      "    \"178\": \"LABEL_178\",\n",
      "    \"179\": \"LABEL_179\",\n",
      "    \"180\": \"LABEL_180\",\n",
      "    \"181\": \"LABEL_181\",\n",
      "    \"182\": \"LABEL_182\",\n",
      "    \"183\": \"LABEL_183\",\n",
      "    \"184\": \"LABEL_184\",\n",
      "    \"185\": \"LABEL_185\",\n",
      "    \"186\": \"LABEL_186\",\n",
      "    \"187\": \"LABEL_187\",\n",
      "    \"188\": \"LABEL_188\",\n",
      "    \"189\": \"LABEL_189\",\n",
      "    \"190\": \"LABEL_190\",\n",
      "    \"191\": \"LABEL_191\",\n",
      "    \"192\": \"LABEL_192\",\n",
      "    \"193\": \"LABEL_193\",\n",
      "    \"194\": \"LABEL_194\",\n",
      "    \"195\": \"LABEL_195\",\n",
      "    \"196\": \"LABEL_196\",\n",
      "    \"197\": \"LABEL_197\",\n",
      "    \"198\": \"LABEL_198\",\n",
      "    \"199\": \"LABEL_199\",\n",
      "    \"200\": \"LABEL_200\",\n",
      "    \"201\": \"LABEL_201\",\n",
      "    \"202\": \"LABEL_202\",\n",
      "    \"203\": \"LABEL_203\",\n",
      "    \"204\": \"LABEL_204\",\n",
      "    \"205\": \"LABEL_205\",\n",
      "    \"206\": \"LABEL_206\",\n",
      "    \"207\": \"LABEL_207\",\n",
      "    \"208\": \"LABEL_208\",\n",
      "    \"209\": \"LABEL_209\",\n",
      "    \"210\": \"LABEL_210\",\n",
      "    \"211\": \"LABEL_211\",\n",
      "    \"212\": \"LABEL_212\",\n",
      "    \"213\": \"LABEL_213\",\n",
      "    \"214\": \"LABEL_214\",\n",
      "    \"215\": \"LABEL_215\",\n",
      "    \"216\": \"LABEL_216\",\n",
      "    \"217\": \"LABEL_217\",\n",
      "    \"218\": \"LABEL_218\",\n",
      "    \"219\": \"LABEL_219\",\n",
      "    \"220\": \"LABEL_220\",\n",
      "    \"221\": \"LABEL_221\",\n",
      "    \"222\": \"LABEL_222\",\n",
      "    \"223\": \"LABEL_223\",\n",
      "    \"224\": \"LABEL_224\",\n",
      "    \"225\": \"LABEL_225\",\n",
      "    \"226\": \"LABEL_226\",\n",
      "    \"227\": \"LABEL_227\",\n",
      "    \"228\": \"LABEL_228\",\n",
      "    \"229\": \"LABEL_229\",\n",
      "    \"230\": \"LABEL_230\",\n",
      "    \"231\": \"LABEL_231\",\n",
      "    \"232\": \"LABEL_232\",\n",
      "    \"233\": \"LABEL_233\",\n",
      "    \"234\": \"LABEL_234\",\n",
      "    \"235\": \"LABEL_235\",\n",
      "    \"236\": \"LABEL_236\",\n",
      "    \"237\": \"LABEL_237\",\n",
      "    \"238\": \"LABEL_238\",\n",
      "    \"239\": \"LABEL_239\",\n",
      "    \"240\": \"LABEL_240\",\n",
      "    \"241\": \"LABEL_241\",\n",
      "    \"242\": \"LABEL_242\",\n",
      "    \"243\": \"LABEL_243\",\n",
      "    \"244\": \"LABEL_244\",\n",
      "    \"245\": \"LABEL_245\",\n",
      "    \"246\": \"LABEL_246\",\n",
      "    \"247\": \"LABEL_247\",\n",
      "    \"248\": \"LABEL_248\",\n",
      "    \"249\": \"LABEL_249\",\n",
      "    \"250\": \"LABEL_250\",\n",
      "    \"251\": \"LABEL_251\",\n",
      "    \"252\": \"LABEL_252\",\n",
      "    \"253\": \"LABEL_253\",\n",
      "    \"254\": \"LABEL_254\",\n",
      "    \"255\": \"LABEL_255\",\n",
      "    \"256\": \"LABEL_256\",\n",
      "    \"257\": \"LABEL_257\",\n",
      "    \"258\": \"LABEL_258\",\n",
      "    \"259\": \"LABEL_259\",\n",
      "    \"260\": \"LABEL_260\",\n",
      "    \"261\": \"LABEL_261\",\n",
      "    \"262\": \"LABEL_262\",\n",
      "    \"263\": \"LABEL_263\",\n",
      "    \"264\": \"LABEL_264\",\n",
      "    \"265\": \"LABEL_265\",\n",
      "    \"266\": \"LABEL_266\",\n",
      "    \"267\": \"LABEL_267\",\n",
      "    \"268\": \"LABEL_268\",\n",
      "    \"269\": \"LABEL_269\",\n",
      "    \"270\": \"LABEL_270\",\n",
      "    \"271\": \"LABEL_271\",\n",
      "    \"272\": \"LABEL_272\",\n",
      "    \"273\": \"LABEL_273\",\n",
      "    \"274\": \"LABEL_274\",\n",
      "    \"275\": \"LABEL_275\",\n",
      "    \"276\": \"LABEL_276\",\n",
      "    \"277\": \"LABEL_277\",\n",
      "    \"278\": \"LABEL_278\",\n",
      "    \"279\": \"LABEL_279\",\n",
      "    \"280\": \"LABEL_280\",\n",
      "    \"281\": \"LABEL_281\",\n",
      "    \"282\": \"LABEL_282\",\n",
      "    \"283\": \"LABEL_283\",\n",
      "    \"284\": \"LABEL_284\",\n",
      "    \"285\": \"LABEL_285\",\n",
      "    \"286\": \"LABEL_286\",\n",
      "    \"287\": \"LABEL_287\",\n",
      "    \"288\": \"LABEL_288\",\n",
      "    \"289\": \"LABEL_289\",\n",
      "    \"290\": \"LABEL_290\",\n",
      "    \"291\": \"LABEL_291\",\n",
      "    \"292\": \"LABEL_292\",\n",
      "    \"293\": \"LABEL_293\",\n",
      "    \"294\": \"LABEL_294\",\n",
      "    \"295\": \"LABEL_295\",\n",
      "    \"296\": \"LABEL_296\",\n",
      "    \"297\": \"LABEL_297\",\n",
      "    \"298\": \"LABEL_298\",\n",
      "    \"299\": \"LABEL_299\",\n",
      "    \"300\": \"LABEL_300\",\n",
      "    \"301\": \"LABEL_301\",\n",
      "    \"302\": \"LABEL_302\",\n",
      "    \"303\": \"LABEL_303\",\n",
      "    \"304\": \"LABEL_304\",\n",
      "    \"305\": \"LABEL_305\",\n",
      "    \"306\": \"LABEL_306\",\n",
      "    \"307\": \"LABEL_307\",\n",
      "    \"308\": \"LABEL_308\",\n",
      "    \"309\": \"LABEL_309\",\n",
      "    \"310\": \"LABEL_310\",\n",
      "    \"311\": \"LABEL_311\",\n",
      "    \"312\": \"LABEL_312\",\n",
      "    \"313\": \"LABEL_313\",\n",
      "    \"314\": \"LABEL_314\",\n",
      "    \"315\": \"LABEL_315\",\n",
      "    \"316\": \"LABEL_316\",\n",
      "    \"317\": \"LABEL_317\",\n",
      "    \"318\": \"LABEL_318\",\n",
      "    \"319\": \"LABEL_319\",\n",
      "    \"320\": \"LABEL_320\",\n",
      "    \"321\": \"LABEL_321\",\n",
      "    \"322\": \"LABEL_322\",\n",
      "    \"323\": \"LABEL_323\",\n",
      "    \"324\": \"LABEL_324\",\n",
      "    \"325\": \"LABEL_325\",\n",
      "    \"326\": \"LABEL_326\",\n",
      "    \"327\": \"LABEL_327\",\n",
      "    \"328\": \"LABEL_328\",\n",
      "    \"329\": \"LABEL_329\",\n",
      "    \"330\": \"LABEL_330\",\n",
      "    \"331\": \"LABEL_331\",\n",
      "    \"332\": \"LABEL_332\",\n",
      "    \"333\": \"LABEL_333\",\n",
      "    \"334\": \"LABEL_334\",\n",
      "    \"335\": \"LABEL_335\",\n",
      "    \"336\": \"LABEL_336\",\n",
      "    \"337\": \"LABEL_337\",\n",
      "    \"338\": \"LABEL_338\",\n",
      "    \"339\": \"LABEL_339\",\n",
      "    \"340\": \"LABEL_340\",\n",
      "    \"341\": \"LABEL_341\",\n",
      "    \"342\": \"LABEL_342\",\n",
      "    \"343\": \"LABEL_343\",\n",
      "    \"344\": \"LABEL_344\",\n",
      "    \"345\": \"LABEL_345\",\n",
      "    \"346\": \"LABEL_346\",\n",
      "    \"347\": \"LABEL_347\",\n",
      "    \"348\": \"LABEL_348\",\n",
      "    \"349\": \"LABEL_349\",\n",
      "    \"350\": \"LABEL_350\",\n",
      "    \"351\": \"LABEL_351\",\n",
      "    \"352\": \"LABEL_352\",\n",
      "    \"353\": \"LABEL_353\",\n",
      "    \"354\": \"LABEL_354\",\n",
      "    \"355\": \"LABEL_355\",\n",
      "    \"356\": \"LABEL_356\",\n",
      "    \"357\": \"LABEL_357\",\n",
      "    \"358\": \"LABEL_358\",\n",
      "    \"359\": \"LABEL_359\",\n",
      "    \"360\": \"LABEL_360\",\n",
      "    \"361\": \"LABEL_361\",\n",
      "    \"362\": \"LABEL_362\",\n",
      "    \"363\": \"LABEL_363\",\n",
      "    \"364\": \"LABEL_364\",\n",
      "    \"365\": \"LABEL_365\",\n",
      "    \"366\": \"LABEL_366\",\n",
      "    \"367\": \"LABEL_367\",\n",
      "    \"368\": \"LABEL_368\",\n",
      "    \"369\": \"LABEL_369\",\n",
      "    \"370\": \"LABEL_370\",\n",
      "    \"371\": \"LABEL_371\",\n",
      "    \"372\": \"LABEL_372\",\n",
      "    \"373\": \"LABEL_373\",\n",
      "    \"374\": \"LABEL_374\",\n",
      "    \"375\": \"LABEL_375\",\n",
      "    \"376\": \"LABEL_376\",\n",
      "    \"377\": \"LABEL_377\",\n",
      "    \"378\": \"LABEL_378\",\n",
      "    \"379\": \"LABEL_379\",\n",
      "    \"380\": \"LABEL_380\",\n",
      "    \"381\": \"LABEL_381\",\n",
      "    \"382\": \"LABEL_382\",\n",
      "    \"383\": \"LABEL_383\",\n",
      "    \"384\": \"LABEL_384\",\n",
      "    \"385\": \"LABEL_385\",\n",
      "    \"386\": \"LABEL_386\",\n",
      "    \"387\": \"LABEL_387\",\n",
      "    \"388\": \"LABEL_388\",\n",
      "    \"389\": \"LABEL_389\",\n",
      "    \"390\": \"LABEL_390\",\n",
      "    \"391\": \"LABEL_391\",\n",
      "    \"392\": \"LABEL_392\",\n",
      "    \"393\": \"LABEL_393\",\n",
      "    \"394\": \"LABEL_394\",\n",
      "    \"395\": \"LABEL_395\",\n",
      "    \"396\": \"LABEL_396\",\n",
      "    \"397\": \"LABEL_397\",\n",
      "    \"398\": \"LABEL_398\",\n",
      "    \"399\": \"LABEL_399\",\n",
      "    \"400\": \"LABEL_400\",\n",
      "    \"401\": \"LABEL_401\",\n",
      "    \"402\": \"LABEL_402\",\n",
      "    \"403\": \"LABEL_403\",\n",
      "    \"404\": \"LABEL_404\",\n",
      "    \"405\": \"LABEL_405\",\n",
      "    \"406\": \"LABEL_406\",\n",
      "    \"407\": \"LABEL_407\",\n",
      "    \"408\": \"LABEL_408\",\n",
      "    \"409\": \"LABEL_409\",\n",
      "    \"410\": \"LABEL_410\",\n",
      "    \"411\": \"LABEL_411\",\n",
      "    \"412\": \"LABEL_412\",\n",
      "    \"413\": \"LABEL_413\",\n",
      "    \"414\": \"LABEL_414\",\n",
      "    \"415\": \"LABEL_415\",\n",
      "    \"416\": \"LABEL_416\",\n",
      "    \"417\": \"LABEL_417\",\n",
      "    \"418\": \"LABEL_418\",\n",
      "    \"419\": \"LABEL_419\",\n",
      "    \"420\": \"LABEL_420\",\n",
      "    \"421\": \"LABEL_421\",\n",
      "    \"422\": \"LABEL_422\",\n",
      "    \"423\": \"LABEL_423\",\n",
      "    \"424\": \"LABEL_424\",\n",
      "    \"425\": \"LABEL_425\",\n",
      "    \"426\": \"LABEL_426\",\n",
      "    \"427\": \"LABEL_427\",\n",
      "    \"428\": \"LABEL_428\",\n",
      "    \"429\": \"LABEL_429\",\n",
      "    \"430\": \"LABEL_430\",\n",
      "    \"431\": \"LABEL_431\",\n",
      "    \"432\": \"LABEL_432\",\n",
      "    \"433\": \"LABEL_433\",\n",
      "    \"434\": \"LABEL_434\",\n",
      "    \"435\": \"LABEL_435\",\n",
      "    \"436\": \"LABEL_436\",\n",
      "    \"437\": \"LABEL_437\",\n",
      "    \"438\": \"LABEL_438\",\n",
      "    \"439\": \"LABEL_439\",\n",
      "    \"440\": \"LABEL_440\",\n",
      "    \"441\": \"LABEL_441\",\n",
      "    \"442\": \"LABEL_442\",\n",
      "    \"443\": \"LABEL_443\",\n",
      "    \"444\": \"LABEL_444\",\n",
      "    \"445\": \"LABEL_445\",\n",
      "    \"446\": \"LABEL_446\",\n",
      "    \"447\": \"LABEL_447\",\n",
      "    \"448\": \"LABEL_448\",\n",
      "    \"449\": \"LABEL_449\",\n",
      "    \"450\": \"LABEL_450\",\n",
      "    \"451\": \"LABEL_451\",\n",
      "    \"452\": \"LABEL_452\",\n",
      "    \"453\": \"LABEL_453\",\n",
      "    \"454\": \"LABEL_454\",\n",
      "    \"455\": \"LABEL_455\",\n",
      "    \"456\": \"LABEL_456\",\n",
      "    \"457\": \"LABEL_457\",\n",
      "    \"458\": \"LABEL_458\",\n",
      "    \"459\": \"LABEL_459\",\n",
      "    \"460\": \"LABEL_460\",\n",
      "    \"461\": \"LABEL_461\",\n",
      "    \"462\": \"LABEL_462\",\n",
      "    \"463\": \"LABEL_463\",\n",
      "    \"464\": \"LABEL_464\",\n",
      "    \"465\": \"LABEL_465\",\n",
      "    \"466\": \"LABEL_466\",\n",
      "    \"467\": \"LABEL_467\",\n",
      "    \"468\": \"LABEL_468\",\n",
      "    \"469\": \"LABEL_469\",\n",
      "    \"470\": \"LABEL_470\",\n",
      "    \"471\": \"LABEL_471\",\n",
      "    \"472\": \"LABEL_472\",\n",
      "    \"473\": \"LABEL_473\",\n",
      "    \"474\": \"LABEL_474\",\n",
      "    \"475\": \"LABEL_475\",\n",
      "    \"476\": \"LABEL_476\",\n",
      "    \"477\": \"LABEL_477\",\n",
      "    \"478\": \"LABEL_478\",\n",
      "    \"479\": \"LABEL_479\",\n",
      "    \"480\": \"LABEL_480\",\n",
      "    \"481\": \"LABEL_481\",\n",
      "    \"482\": \"LABEL_482\",\n",
      "    \"483\": \"LABEL_483\",\n",
      "    \"484\": \"LABEL_484\",\n",
      "    \"485\": \"LABEL_485\",\n",
      "    \"486\": \"LABEL_486\",\n",
      "    \"487\": \"LABEL_487\",\n",
      "    \"488\": \"LABEL_488\",\n",
      "    \"489\": \"LABEL_489\",\n",
      "    \"490\": \"LABEL_490\",\n",
      "    \"491\": \"LABEL_491\",\n",
      "    \"492\": \"LABEL_492\",\n",
      "    \"493\": \"LABEL_493\",\n",
      "    \"494\": \"LABEL_494\",\n",
      "    \"495\": \"LABEL_495\",\n",
      "    \"496\": \"LABEL_496\",\n",
      "    \"497\": \"LABEL_497\",\n",
      "    \"498\": \"LABEL_498\",\n",
      "    \"499\": \"LABEL_499\",\n",
      "    \"500\": \"LABEL_500\",\n",
      "    \"501\": \"LABEL_501\",\n",
      "    \"502\": \"LABEL_502\",\n",
      "    \"503\": \"LABEL_503\",\n",
      "    \"504\": \"LABEL_504\",\n",
      "    \"505\": \"LABEL_505\",\n",
      "    \"506\": \"LABEL_506\",\n",
      "    \"507\": \"LABEL_507\",\n",
      "    \"508\": \"LABEL_508\",\n",
      "    \"509\": \"LABEL_509\",\n",
      "    \"510\": \"LABEL_510\",\n",
      "    \"511\": \"LABEL_511\",\n",
      "    \"512\": \"LABEL_512\",\n",
      "    \"513\": \"LABEL_513\",\n",
      "    \"514\": \"LABEL_514\",\n",
      "    \"515\": \"LABEL_515\",\n",
      "    \"516\": \"LABEL_516\",\n",
      "    \"517\": \"LABEL_517\",\n",
      "    \"518\": \"LABEL_518\",\n",
      "    \"519\": \"LABEL_519\",\n",
      "    \"520\": \"LABEL_520\",\n",
      "    \"521\": \"LABEL_521\",\n",
      "    \"522\": \"LABEL_522\",\n",
      "    \"523\": \"LABEL_523\",\n",
      "    \"524\": \"LABEL_524\",\n",
      "    \"525\": \"LABEL_525\",\n",
      "    \"526\": \"LABEL_526\",\n",
      "    \"527\": \"LABEL_527\",\n",
      "    \"528\": \"LABEL_528\",\n",
      "    \"529\": \"LABEL_529\",\n",
      "    \"530\": \"LABEL_530\",\n",
      "    \"531\": \"LABEL_531\",\n",
      "    \"532\": \"LABEL_532\",\n",
      "    \"533\": \"LABEL_533\",\n",
      "    \"534\": \"LABEL_534\",\n",
      "    \"535\": \"LABEL_535\",\n",
      "    \"536\": \"LABEL_536\",\n",
      "    \"537\": \"LABEL_537\",\n",
      "    \"538\": \"LABEL_538\",\n",
      "    \"539\": \"LABEL_539\",\n",
      "    \"540\": \"LABEL_540\",\n",
      "    \"541\": \"LABEL_541\",\n",
      "    \"542\": \"LABEL_542\",\n",
      "    \"543\": \"LABEL_543\",\n",
      "    \"544\": \"LABEL_544\",\n",
      "    \"545\": \"LABEL_545\",\n",
      "    \"546\": \"LABEL_546\",\n",
      "    \"547\": \"LABEL_547\",\n",
      "    \"548\": \"LABEL_548\",\n",
      "    \"549\": \"LABEL_549\",\n",
      "    \"550\": \"LABEL_550\",\n",
      "    \"551\": \"LABEL_551\",\n",
      "    \"552\": \"LABEL_552\",\n",
      "    \"553\": \"LABEL_553\",\n",
      "    \"554\": \"LABEL_554\",\n",
      "    \"555\": \"LABEL_555\",\n",
      "    \"556\": \"LABEL_556\",\n",
      "    \"557\": \"LABEL_557\",\n",
      "    \"558\": \"LABEL_558\",\n",
      "    \"559\": \"LABEL_559\",\n",
      "    \"560\": \"LABEL_560\",\n",
      "    \"561\": \"LABEL_561\",\n",
      "    \"562\": \"LABEL_562\",\n",
      "    \"563\": \"LABEL_563\",\n",
      "    \"564\": \"LABEL_564\",\n",
      "    \"565\": \"LABEL_565\",\n",
      "    \"566\": \"LABEL_566\",\n",
      "    \"567\": \"LABEL_567\",\n",
      "    \"568\": \"LABEL_568\",\n",
      "    \"569\": \"LABEL_569\",\n",
      "    \"570\": \"LABEL_570\",\n",
      "    \"571\": \"LABEL_571\",\n",
      "    \"572\": \"LABEL_572\",\n",
      "    \"573\": \"LABEL_573\",\n",
      "    \"574\": \"LABEL_574\",\n",
      "    \"575\": \"LABEL_575\",\n",
      "    \"576\": \"LABEL_576\",\n",
      "    \"577\": \"LABEL_577\",\n",
      "    \"578\": \"LABEL_578\",\n",
      "    \"579\": \"LABEL_579\",\n",
      "    \"580\": \"LABEL_580\",\n",
      "    \"581\": \"LABEL_581\",\n",
      "    \"582\": \"LABEL_582\",\n",
      "    \"583\": \"LABEL_583\",\n",
      "    \"584\": \"LABEL_584\",\n",
      "    \"585\": \"LABEL_585\",\n",
      "    \"586\": \"LABEL_586\",\n",
      "    \"587\": \"LABEL_587\",\n",
      "    \"588\": \"LABEL_588\",\n",
      "    \"589\": \"LABEL_589\",\n",
      "    \"590\": \"LABEL_590\",\n",
      "    \"591\": \"LABEL_591\",\n",
      "    \"592\": \"LABEL_592\",\n",
      "    \"593\": \"LABEL_593\",\n",
      "    \"594\": \"LABEL_594\",\n",
      "    \"595\": \"LABEL_595\",\n",
      "    \"596\": \"LABEL_596\",\n",
      "    \"597\": \"LABEL_597\",\n",
      "    \"598\": \"LABEL_598\",\n",
      "    \"599\": \"LABEL_599\",\n",
      "    \"600\": \"LABEL_600\",\n",
      "    \"601\": \"LABEL_601\",\n",
      "    \"602\": \"LABEL_602\",\n",
      "    \"603\": \"LABEL_603\",\n",
      "    \"604\": \"LABEL_604\",\n",
      "    \"605\": \"LABEL_605\",\n",
      "    \"606\": \"LABEL_606\",\n",
      "    \"607\": \"LABEL_607\",\n",
      "    \"608\": \"LABEL_608\",\n",
      "    \"609\": \"LABEL_609\",\n",
      "    \"610\": \"LABEL_610\",\n",
      "    \"611\": \"LABEL_611\",\n",
      "    \"612\": \"LABEL_612\",\n",
      "    \"613\": \"LABEL_613\",\n",
      "    \"614\": \"LABEL_614\",\n",
      "    \"615\": \"LABEL_615\",\n",
      "    \"616\": \"LABEL_616\",\n",
      "    \"617\": \"LABEL_617\",\n",
      "    \"618\": \"LABEL_618\",\n",
      "    \"619\": \"LABEL_619\",\n",
      "    \"620\": \"LABEL_620\",\n",
      "    \"621\": \"LABEL_621\",\n",
      "    \"622\": \"LABEL_622\",\n",
      "    \"623\": \"LABEL_623\",\n",
      "    \"624\": \"LABEL_624\",\n",
      "    \"625\": \"LABEL_625\",\n",
      "    \"626\": \"LABEL_626\",\n",
      "    \"627\": \"LABEL_627\",\n",
      "    \"628\": \"LABEL_628\",\n",
      "    \"629\": \"LABEL_629\",\n",
      "    \"630\": \"LABEL_630\",\n",
      "    \"631\": \"LABEL_631\",\n",
      "    \"632\": \"LABEL_632\",\n",
      "    \"633\": \"LABEL_633\",\n",
      "    \"634\": \"LABEL_634\",\n",
      "    \"635\": \"LABEL_635\",\n",
      "    \"636\": \"LABEL_636\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_100\": 100,\n",
      "    \"LABEL_101\": 101,\n",
      "    \"LABEL_102\": 102,\n",
      "    \"LABEL_103\": 103,\n",
      "    \"LABEL_104\": 104,\n",
      "    \"LABEL_105\": 105,\n",
      "    \"LABEL_106\": 106,\n",
      "    \"LABEL_107\": 107,\n",
      "    \"LABEL_108\": 108,\n",
      "    \"LABEL_109\": 109,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_110\": 110,\n",
      "    \"LABEL_111\": 111,\n",
      "    \"LABEL_112\": 112,\n",
      "    \"LABEL_113\": 113,\n",
      "    \"LABEL_114\": 114,\n",
      "    \"LABEL_115\": 115,\n",
      "    \"LABEL_116\": 116,\n",
      "    \"LABEL_117\": 117,\n",
      "    \"LABEL_118\": 118,\n",
      "    \"LABEL_119\": 119,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_120\": 120,\n",
      "    \"LABEL_121\": 121,\n",
      "    \"LABEL_122\": 122,\n",
      "    \"LABEL_123\": 123,\n",
      "    \"LABEL_124\": 124,\n",
      "    \"LABEL_125\": 125,\n",
      "    \"LABEL_126\": 126,\n",
      "    \"LABEL_127\": 127,\n",
      "    \"LABEL_128\": 128,\n",
      "    \"LABEL_129\": 129,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_130\": 130,\n",
      "    \"LABEL_131\": 131,\n",
      "    \"LABEL_132\": 132,\n",
      "    \"LABEL_133\": 133,\n",
      "    \"LABEL_134\": 134,\n",
      "    \"LABEL_135\": 135,\n",
      "    \"LABEL_136\": 136,\n",
      "    \"LABEL_137\": 137,\n",
      "    \"LABEL_138\": 138,\n",
      "    \"LABEL_139\": 139,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_140\": 140,\n",
      "    \"LABEL_141\": 141,\n",
      "    \"LABEL_142\": 142,\n",
      "    \"LABEL_143\": 143,\n",
      "    \"LABEL_144\": 144,\n",
      "    \"LABEL_145\": 145,\n",
      "    \"LABEL_146\": 146,\n",
      "    \"LABEL_147\": 147,\n",
      "    \"LABEL_148\": 148,\n",
      "    \"LABEL_149\": 149,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_150\": 150,\n",
      "    \"LABEL_151\": 151,\n",
      "    \"LABEL_152\": 152,\n",
      "    \"LABEL_153\": 153,\n",
      "    \"LABEL_154\": 154,\n",
      "    \"LABEL_155\": 155,\n",
      "    \"LABEL_156\": 156,\n",
      "    \"LABEL_157\": 157,\n",
      "    \"LABEL_158\": 158,\n",
      "    \"LABEL_159\": 159,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_160\": 160,\n",
      "    \"LABEL_161\": 161,\n",
      "    \"LABEL_162\": 162,\n",
      "    \"LABEL_163\": 163,\n",
      "    \"LABEL_164\": 164,\n",
      "    \"LABEL_165\": 165,\n",
      "    \"LABEL_166\": 166,\n",
      "    \"LABEL_167\": 167,\n",
      "    \"LABEL_168\": 168,\n",
      "    \"LABEL_169\": 169,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_170\": 170,\n",
      "    \"LABEL_171\": 171,\n",
      "    \"LABEL_172\": 172,\n",
      "    \"LABEL_173\": 173,\n",
      "    \"LABEL_174\": 174,\n",
      "    \"LABEL_175\": 175,\n",
      "    \"LABEL_176\": 176,\n",
      "    \"LABEL_177\": 177,\n",
      "    \"LABEL_178\": 178,\n",
      "    \"LABEL_179\": 179,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_180\": 180,\n",
      "    \"LABEL_181\": 181,\n",
      "    \"LABEL_182\": 182,\n",
      "    \"LABEL_183\": 183,\n",
      "    \"LABEL_184\": 184,\n",
      "    \"LABEL_185\": 185,\n",
      "    \"LABEL_186\": 186,\n",
      "    \"LABEL_187\": 187,\n",
      "    \"LABEL_188\": 188,\n",
      "    \"LABEL_189\": 189,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_190\": 190,\n",
      "    \"LABEL_191\": 191,\n",
      "    \"LABEL_192\": 192,\n",
      "    \"LABEL_193\": 193,\n",
      "    \"LABEL_194\": 194,\n",
      "    \"LABEL_195\": 195,\n",
      "    \"LABEL_196\": 196,\n",
      "    \"LABEL_197\": 197,\n",
      "    \"LABEL_198\": 198,\n",
      "    \"LABEL_199\": 199,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_200\": 200,\n",
      "    \"LABEL_201\": 201,\n",
      "    \"LABEL_202\": 202,\n",
      "    \"LABEL_203\": 203,\n",
      "    \"LABEL_204\": 204,\n",
      "    \"LABEL_205\": 205,\n",
      "    \"LABEL_206\": 206,\n",
      "    \"LABEL_207\": 207,\n",
      "    \"LABEL_208\": 208,\n",
      "    \"LABEL_209\": 209,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_210\": 210,\n",
      "    \"LABEL_211\": 211,\n",
      "    \"LABEL_212\": 212,\n",
      "    \"LABEL_213\": 213,\n",
      "    \"LABEL_214\": 214,\n",
      "    \"LABEL_215\": 215,\n",
      "    \"LABEL_216\": 216,\n",
      "    \"LABEL_217\": 217,\n",
      "    \"LABEL_218\": 218,\n",
      "    \"LABEL_219\": 219,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_220\": 220,\n",
      "    \"LABEL_221\": 221,\n",
      "    \"LABEL_222\": 222,\n",
      "    \"LABEL_223\": 223,\n",
      "    \"LABEL_224\": 224,\n",
      "    \"LABEL_225\": 225,\n",
      "    \"LABEL_226\": 226,\n",
      "    \"LABEL_227\": 227,\n",
      "    \"LABEL_228\": 228,\n",
      "    \"LABEL_229\": 229,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_230\": 230,\n",
      "    \"LABEL_231\": 231,\n",
      "    \"LABEL_232\": 232,\n",
      "    \"LABEL_233\": 233,\n",
      "    \"LABEL_234\": 234,\n",
      "    \"LABEL_235\": 235,\n",
      "    \"LABEL_236\": 236,\n",
      "    \"LABEL_237\": 237,\n",
      "    \"LABEL_238\": 238,\n",
      "    \"LABEL_239\": 239,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_240\": 240,\n",
      "    \"LABEL_241\": 241,\n",
      "    \"LABEL_242\": 242,\n",
      "    \"LABEL_243\": 243,\n",
      "    \"LABEL_244\": 244,\n",
      "    \"LABEL_245\": 245,\n",
      "    \"LABEL_246\": 246,\n",
      "    \"LABEL_247\": 247,\n",
      "    \"LABEL_248\": 248,\n",
      "    \"LABEL_249\": 249,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_250\": 250,\n",
      "    \"LABEL_251\": 251,\n",
      "    \"LABEL_252\": 252,\n",
      "    \"LABEL_253\": 253,\n",
      "    \"LABEL_254\": 254,\n",
      "    \"LABEL_255\": 255,\n",
      "    \"LABEL_256\": 256,\n",
      "    \"LABEL_257\": 257,\n",
      "    \"LABEL_258\": 258,\n",
      "    \"LABEL_259\": 259,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_260\": 260,\n",
      "    \"LABEL_261\": 261,\n",
      "    \"LABEL_262\": 262,\n",
      "    \"LABEL_263\": 263,\n",
      "    \"LABEL_264\": 264,\n",
      "    \"LABEL_265\": 265,\n",
      "    \"LABEL_266\": 266,\n",
      "    \"LABEL_267\": 267,\n",
      "    \"LABEL_268\": 268,\n",
      "    \"LABEL_269\": 269,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_270\": 270,\n",
      "    \"LABEL_271\": 271,\n",
      "    \"LABEL_272\": 272,\n",
      "    \"LABEL_273\": 273,\n",
      "    \"LABEL_274\": 274,\n",
      "    \"LABEL_275\": 275,\n",
      "    \"LABEL_276\": 276,\n",
      "    \"LABEL_277\": 277,\n",
      "    \"LABEL_278\": 278,\n",
      "    \"LABEL_279\": 279,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_280\": 280,\n",
      "    \"LABEL_281\": 281,\n",
      "    \"LABEL_282\": 282,\n",
      "    \"LABEL_283\": 283,\n",
      "    \"LABEL_284\": 284,\n",
      "    \"LABEL_285\": 285,\n",
      "    \"LABEL_286\": 286,\n",
      "    \"LABEL_287\": 287,\n",
      "    \"LABEL_288\": 288,\n",
      "    \"LABEL_289\": 289,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_290\": 290,\n",
      "    \"LABEL_291\": 291,\n",
      "    \"LABEL_292\": 292,\n",
      "    \"LABEL_293\": 293,\n",
      "    \"LABEL_294\": 294,\n",
      "    \"LABEL_295\": 295,\n",
      "    \"LABEL_296\": 296,\n",
      "    \"LABEL_297\": 297,\n",
      "    \"LABEL_298\": 298,\n",
      "    \"LABEL_299\": 299,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_300\": 300,\n",
      "    \"LABEL_301\": 301,\n",
      "    \"LABEL_302\": 302,\n",
      "    \"LABEL_303\": 303,\n",
      "    \"LABEL_304\": 304,\n",
      "    \"LABEL_305\": 305,\n",
      "    \"LABEL_306\": 306,\n",
      "    \"LABEL_307\": 307,\n",
      "    \"LABEL_308\": 308,\n",
      "    \"LABEL_309\": 309,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_310\": 310,\n",
      "    \"LABEL_311\": 311,\n",
      "    \"LABEL_312\": 312,\n",
      "    \"LABEL_313\": 313,\n",
      "    \"LABEL_314\": 314,\n",
      "    \"LABEL_315\": 315,\n",
      "    \"LABEL_316\": 316,\n",
      "    \"LABEL_317\": 317,\n",
      "    \"LABEL_318\": 318,\n",
      "    \"LABEL_319\": 319,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_320\": 320,\n",
      "    \"LABEL_321\": 321,\n",
      "    \"LABEL_322\": 322,\n",
      "    \"LABEL_323\": 323,\n",
      "    \"LABEL_324\": 324,\n",
      "    \"LABEL_325\": 325,\n",
      "    \"LABEL_326\": 326,\n",
      "    \"LABEL_327\": 327,\n",
      "    \"LABEL_328\": 328,\n",
      "    \"LABEL_329\": 329,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_330\": 330,\n",
      "    \"LABEL_331\": 331,\n",
      "    \"LABEL_332\": 332,\n",
      "    \"LABEL_333\": 333,\n",
      "    \"LABEL_334\": 334,\n",
      "    \"LABEL_335\": 335,\n",
      "    \"LABEL_336\": 336,\n",
      "    \"LABEL_337\": 337,\n",
      "    \"LABEL_338\": 338,\n",
      "    \"LABEL_339\": 339,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_340\": 340,\n",
      "    \"LABEL_341\": 341,\n",
      "    \"LABEL_342\": 342,\n",
      "    \"LABEL_343\": 343,\n",
      "    \"LABEL_344\": 344,\n",
      "    \"LABEL_345\": 345,\n",
      "    \"LABEL_346\": 346,\n",
      "    \"LABEL_347\": 347,\n",
      "    \"LABEL_348\": 348,\n",
      "    \"LABEL_349\": 349,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_350\": 350,\n",
      "    \"LABEL_351\": 351,\n",
      "    \"LABEL_352\": 352,\n",
      "    \"LABEL_353\": 353,\n",
      "    \"LABEL_354\": 354,\n",
      "    \"LABEL_355\": 355,\n",
      "    \"LABEL_356\": 356,\n",
      "    \"LABEL_357\": 357,\n",
      "    \"LABEL_358\": 358,\n",
      "    \"LABEL_359\": 359,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_360\": 360,\n",
      "    \"LABEL_361\": 361,\n",
      "    \"LABEL_362\": 362,\n",
      "    \"LABEL_363\": 363,\n",
      "    \"LABEL_364\": 364,\n",
      "    \"LABEL_365\": 365,\n",
      "    \"LABEL_366\": 366,\n",
      "    \"LABEL_367\": 367,\n",
      "    \"LABEL_368\": 368,\n",
      "    \"LABEL_369\": 369,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_370\": 370,\n",
      "    \"LABEL_371\": 371,\n",
      "    \"LABEL_372\": 372,\n",
      "    \"LABEL_373\": 373,\n",
      "    \"LABEL_374\": 374,\n",
      "    \"LABEL_375\": 375,\n",
      "    \"LABEL_376\": 376,\n",
      "    \"LABEL_377\": 377,\n",
      "    \"LABEL_378\": 378,\n",
      "    \"LABEL_379\": 379,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_380\": 380,\n",
      "    \"LABEL_381\": 381,\n",
      "    \"LABEL_382\": 382,\n",
      "    \"LABEL_383\": 383,\n",
      "    \"LABEL_384\": 384,\n",
      "    \"LABEL_385\": 385,\n",
      "    \"LABEL_386\": 386,\n",
      "    \"LABEL_387\": 387,\n",
      "    \"LABEL_388\": 388,\n",
      "    \"LABEL_389\": 389,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_390\": 390,\n",
      "    \"LABEL_391\": 391,\n",
      "    \"LABEL_392\": 392,\n",
      "    \"LABEL_393\": 393,\n",
      "    \"LABEL_394\": 394,\n",
      "    \"LABEL_395\": 395,\n",
      "    \"LABEL_396\": 396,\n",
      "    \"LABEL_397\": 397,\n",
      "    \"LABEL_398\": 398,\n",
      "    \"LABEL_399\": 399,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_400\": 400,\n",
      "    \"LABEL_401\": 401,\n",
      "    \"LABEL_402\": 402,\n",
      "    \"LABEL_403\": 403,\n",
      "    \"LABEL_404\": 404,\n",
      "    \"LABEL_405\": 405,\n",
      "    \"LABEL_406\": 406,\n",
      "    \"LABEL_407\": 407,\n",
      "    \"LABEL_408\": 408,\n",
      "    \"LABEL_409\": 409,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_410\": 410,\n",
      "    \"LABEL_411\": 411,\n",
      "    \"LABEL_412\": 412,\n",
      "    \"LABEL_413\": 413,\n",
      "    \"LABEL_414\": 414,\n",
      "    \"LABEL_415\": 415,\n",
      "    \"LABEL_416\": 416,\n",
      "    \"LABEL_417\": 417,\n",
      "    \"LABEL_418\": 418,\n",
      "    \"LABEL_419\": 419,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_420\": 420,\n",
      "    \"LABEL_421\": 421,\n",
      "    \"LABEL_422\": 422,\n",
      "    \"LABEL_423\": 423,\n",
      "    \"LABEL_424\": 424,\n",
      "    \"LABEL_425\": 425,\n",
      "    \"LABEL_426\": 426,\n",
      "    \"LABEL_427\": 427,\n",
      "    \"LABEL_428\": 428,\n",
      "    \"LABEL_429\": 429,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_430\": 430,\n",
      "    \"LABEL_431\": 431,\n",
      "    \"LABEL_432\": 432,\n",
      "    \"LABEL_433\": 433,\n",
      "    \"LABEL_434\": 434,\n",
      "    \"LABEL_435\": 435,\n",
      "    \"LABEL_436\": 436,\n",
      "    \"LABEL_437\": 437,\n",
      "    \"LABEL_438\": 438,\n",
      "    \"LABEL_439\": 439,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_440\": 440,\n",
      "    \"LABEL_441\": 441,\n",
      "    \"LABEL_442\": 442,\n",
      "    \"LABEL_443\": 443,\n",
      "    \"LABEL_444\": 444,\n",
      "    \"LABEL_445\": 445,\n",
      "    \"LABEL_446\": 446,\n",
      "    \"LABEL_447\": 447,\n",
      "    \"LABEL_448\": 448,\n",
      "    \"LABEL_449\": 449,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_450\": 450,\n",
      "    \"LABEL_451\": 451,\n",
      "    \"LABEL_452\": 452,\n",
      "    \"LABEL_453\": 453,\n",
      "    \"LABEL_454\": 454,\n",
      "    \"LABEL_455\": 455,\n",
      "    \"LABEL_456\": 456,\n",
      "    \"LABEL_457\": 457,\n",
      "    \"LABEL_458\": 458,\n",
      "    \"LABEL_459\": 459,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_460\": 460,\n",
      "    \"LABEL_461\": 461,\n",
      "    \"LABEL_462\": 462,\n",
      "    \"LABEL_463\": 463,\n",
      "    \"LABEL_464\": 464,\n",
      "    \"LABEL_465\": 465,\n",
      "    \"LABEL_466\": 466,\n",
      "    \"LABEL_467\": 467,\n",
      "    \"LABEL_468\": 468,\n",
      "    \"LABEL_469\": 469,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_470\": 470,\n",
      "    \"LABEL_471\": 471,\n",
      "    \"LABEL_472\": 472,\n",
      "    \"LABEL_473\": 473,\n",
      "    \"LABEL_474\": 474,\n",
      "    \"LABEL_475\": 475,\n",
      "    \"LABEL_476\": 476,\n",
      "    \"LABEL_477\": 477,\n",
      "    \"LABEL_478\": 478,\n",
      "    \"LABEL_479\": 479,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_480\": 480,\n",
      "    \"LABEL_481\": 481,\n",
      "    \"LABEL_482\": 482,\n",
      "    \"LABEL_483\": 483,\n",
      "    \"LABEL_484\": 484,\n",
      "    \"LABEL_485\": 485,\n",
      "    \"LABEL_486\": 486,\n",
      "    \"LABEL_487\": 487,\n",
      "    \"LABEL_488\": 488,\n",
      "    \"LABEL_489\": 489,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_490\": 490,\n",
      "    \"LABEL_491\": 491,\n",
      "    \"LABEL_492\": 492,\n",
      "    \"LABEL_493\": 493,\n",
      "    \"LABEL_494\": 494,\n",
      "    \"LABEL_495\": 495,\n",
      "    \"LABEL_496\": 496,\n",
      "    \"LABEL_497\": 497,\n",
      "    \"LABEL_498\": 498,\n",
      "    \"LABEL_499\": 499,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_500\": 500,\n",
      "    \"LABEL_501\": 501,\n",
      "    \"LABEL_502\": 502,\n",
      "    \"LABEL_503\": 503,\n",
      "    \"LABEL_504\": 504,\n",
      "    \"LABEL_505\": 505,\n",
      "    \"LABEL_506\": 506,\n",
      "    \"LABEL_507\": 507,\n",
      "    \"LABEL_508\": 508,\n",
      "    \"LABEL_509\": 509,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_510\": 510,\n",
      "    \"LABEL_511\": 511,\n",
      "    \"LABEL_512\": 512,\n",
      "    \"LABEL_513\": 513,\n",
      "    \"LABEL_514\": 514,\n",
      "    \"LABEL_515\": 515,\n",
      "    \"LABEL_516\": 516,\n",
      "    \"LABEL_517\": 517,\n",
      "    \"LABEL_518\": 518,\n",
      "    \"LABEL_519\": 519,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_520\": 520,\n",
      "    \"LABEL_521\": 521,\n",
      "    \"LABEL_522\": 522,\n",
      "    \"LABEL_523\": 523,\n",
      "    \"LABEL_524\": 524,\n",
      "    \"LABEL_525\": 525,\n",
      "    \"LABEL_526\": 526,\n",
      "    \"LABEL_527\": 527,\n",
      "    \"LABEL_528\": 528,\n",
      "    \"LABEL_529\": 529,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_530\": 530,\n",
      "    \"LABEL_531\": 531,\n",
      "    \"LABEL_532\": 532,\n",
      "    \"LABEL_533\": 533,\n",
      "    \"LABEL_534\": 534,\n",
      "    \"LABEL_535\": 535,\n",
      "    \"LABEL_536\": 536,\n",
      "    \"LABEL_537\": 537,\n",
      "    \"LABEL_538\": 538,\n",
      "    \"LABEL_539\": 539,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_540\": 540,\n",
      "    \"LABEL_541\": 541,\n",
      "    \"LABEL_542\": 542,\n",
      "    \"LABEL_543\": 543,\n",
      "    \"LABEL_544\": 544,\n",
      "    \"LABEL_545\": 545,\n",
      "    \"LABEL_546\": 546,\n",
      "    \"LABEL_547\": 547,\n",
      "    \"LABEL_548\": 548,\n",
      "    \"LABEL_549\": 549,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_550\": 550,\n",
      "    \"LABEL_551\": 551,\n",
      "    \"LABEL_552\": 552,\n",
      "    \"LABEL_553\": 553,\n",
      "    \"LABEL_554\": 554,\n",
      "    \"LABEL_555\": 555,\n",
      "    \"LABEL_556\": 556,\n",
      "    \"LABEL_557\": 557,\n",
      "    \"LABEL_558\": 558,\n",
      "    \"LABEL_559\": 559,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_560\": 560,\n",
      "    \"LABEL_561\": 561,\n",
      "    \"LABEL_562\": 562,\n",
      "    \"LABEL_563\": 563,\n",
      "    \"LABEL_564\": 564,\n",
      "    \"LABEL_565\": 565,\n",
      "    \"LABEL_566\": 566,\n",
      "    \"LABEL_567\": 567,\n",
      "    \"LABEL_568\": 568,\n",
      "    \"LABEL_569\": 569,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_570\": 570,\n",
      "    \"LABEL_571\": 571,\n",
      "    \"LABEL_572\": 572,\n",
      "    \"LABEL_573\": 573,\n",
      "    \"LABEL_574\": 574,\n",
      "    \"LABEL_575\": 575,\n",
      "    \"LABEL_576\": 576,\n",
      "    \"LABEL_577\": 577,\n",
      "    \"LABEL_578\": 578,\n",
      "    \"LABEL_579\": 579,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_580\": 580,\n",
      "    \"LABEL_581\": 581,\n",
      "    \"LABEL_582\": 582,\n",
      "    \"LABEL_583\": 583,\n",
      "    \"LABEL_584\": 584,\n",
      "    \"LABEL_585\": 585,\n",
      "    \"LABEL_586\": 586,\n",
      "    \"LABEL_587\": 587,\n",
      "    \"LABEL_588\": 588,\n",
      "    \"LABEL_589\": 589,\n",
      "    \"LABEL_59\": 59,\n",
      "    \"LABEL_590\": 590,\n",
      "    \"LABEL_591\": 591,\n",
      "    \"LABEL_592\": 592,\n",
      "    \"LABEL_593\": 593,\n",
      "    \"LABEL_594\": 594,\n",
      "    \"LABEL_595\": 595,\n",
      "    \"LABEL_596\": 596,\n",
      "    \"LABEL_597\": 597,\n",
      "    \"LABEL_598\": 598,\n",
      "    \"LABEL_599\": 599,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_60\": 60,\n",
      "    \"LABEL_600\": 600,\n",
      "    \"LABEL_601\": 601,\n",
      "    \"LABEL_602\": 602,\n",
      "    \"LABEL_603\": 603,\n",
      "    \"LABEL_604\": 604,\n",
      "    \"LABEL_605\": 605,\n",
      "    \"LABEL_606\": 606,\n",
      "    \"LABEL_607\": 607,\n",
      "    \"LABEL_608\": 608,\n",
      "    \"LABEL_609\": 609,\n",
      "    \"LABEL_61\": 61,\n",
      "    \"LABEL_610\": 610,\n",
      "    \"LABEL_611\": 611,\n",
      "    \"LABEL_612\": 612,\n",
      "    \"LABEL_613\": 613,\n",
      "    \"LABEL_614\": 614,\n",
      "    \"LABEL_615\": 615,\n",
      "    \"LABEL_616\": 616,\n",
      "    \"LABEL_617\": 617,\n",
      "    \"LABEL_618\": 618,\n",
      "    \"LABEL_619\": 619,\n",
      "    \"LABEL_62\": 62,\n",
      "    \"LABEL_620\": 620,\n",
      "    \"LABEL_621\": 621,\n",
      "    \"LABEL_622\": 622,\n",
      "    \"LABEL_623\": 623,\n",
      "    \"LABEL_624\": 624,\n",
      "    \"LABEL_625\": 625,\n",
      "    \"LABEL_626\": 626,\n",
      "    \"LABEL_627\": 627,\n",
      "    \"LABEL_628\": 628,\n",
      "    \"LABEL_629\": 629,\n",
      "    \"LABEL_63\": 63,\n",
      "    \"LABEL_630\": 630,\n",
      "    \"LABEL_631\": 631,\n",
      "    \"LABEL_632\": 632,\n",
      "    \"LABEL_633\": 633,\n",
      "    \"LABEL_634\": 634,\n",
      "    \"LABEL_635\": 635,\n",
      "    \"LABEL_636\": 636,\n",
      "    \"LABEL_64\": 64,\n",
      "    \"LABEL_65\": 65,\n",
      "    \"LABEL_66\": 66,\n",
      "    \"LABEL_67\": 67,\n",
      "    \"LABEL_68\": 68,\n",
      "    \"LABEL_69\": 69,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_70\": 70,\n",
      "    \"LABEL_71\": 71,\n",
      "    \"LABEL_72\": 72,\n",
      "    \"LABEL_73\": 73,\n",
      "    \"LABEL_74\": 74,\n",
      "    \"LABEL_75\": 75,\n",
      "    \"LABEL_76\": 76,\n",
      "    \"LABEL_77\": 77,\n",
      "    \"LABEL_78\": 78,\n",
      "    \"LABEL_79\": 79,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_80\": 80,\n",
      "    \"LABEL_81\": 81,\n",
      "    \"LABEL_82\": 82,\n",
      "    \"LABEL_83\": 83,\n",
      "    \"LABEL_84\": 84,\n",
      "    \"LABEL_85\": 85,\n",
      "    \"LABEL_86\": 86,\n",
      "    \"LABEL_87\": 87,\n",
      "    \"LABEL_88\": 88,\n",
      "    \"LABEL_89\": 89,\n",
      "    \"LABEL_9\": 9,\n",
      "    \"LABEL_90\": 90,\n",
      "    \"LABEL_91\": 91,\n",
      "    \"LABEL_92\": 92,\n",
      "    \"LABEL_93\": 93,\n",
      "    \"LABEL_94\": 94,\n",
      "    \"LABEL_95\": 95,\n",
      "    \"LABEL_96\": 96,\n",
      "    \"LABEL_97\": 97,\n",
      "    \"LABEL_98\": 98,\n",
      "    \"LABEL_99\": 99\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": true,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\chris/.cache\\huggingface\\hub\\models--google--vit-base-patch16-224\\snapshots\\2ddc9d4e473d7ba52128f0df4723e478fa14fb80\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing ViTForImageClassification.\n",
      "\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([637, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([637]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "Setting `WANDB_LOG_MODEL` from true to `end` instead\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8323\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 1950\n",
      "  Number of trainable parameters = 86288509\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78003507d5024ad4bce00aeb09246164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.4874, 'learning_rate': 2.564102564102564e-06, 'epoch': 0.08}\n",
      "{'loss': 6.1528, 'learning_rate': 5.128205128205128e-06, 'epoch': 0.15}\n",
      "{'loss': 5.445, 'learning_rate': 7.692307692307694e-06, 'epoch': 0.23}\n",
      "{'loss': 4.3551, 'learning_rate': 1.0256410256410256e-05, 'epoch': 0.31}\n",
      "{'loss': 2.8703, 'learning_rate': 1.282051282051282e-05, 'epoch': 0.38}\n",
      "{'loss': 1.9854, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8619, 'learning_rate': 1.794871794871795e-05, 'epoch': 0.54}\n",
      "{'loss': 1.9556, 'learning_rate': 2.0512820512820512e-05, 'epoch': 0.61}\n",
      "{'loss': 1.7637, 'learning_rate': 2.307692307692308e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0693, 'learning_rate': 2.564102564102564e-05, 'epoch': 0.77}\n",
      "{'loss': 1.9408, 'learning_rate': 2.8205128205128207e-05, 'epoch': 0.84}\n",
      "{'loss': 1.7538, 'learning_rate': 3.0769230769230774e-05, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7715, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca2d78eacf2d42dc914cd5c15b931f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Construction\\checkpoint-130\n",
      "Configuration saved in models/ViT_Construction\\checkpoint-130\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.885122299194336, 'eval_accuracy': 0.7481979817395483, 'eval_f1': 0.0037542316483898035, 'eval_precision': 0.003281570095348896, 'eval_recall': 0.0043859649122807015, 'eval_runtime': 16.2161, 'eval_samples_per_second': 128.329, 'eval_steps_per_second': 8.078, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Construction\\checkpoint-130\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Construction\\checkpoint-130\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8918, 'learning_rate': 3.58974358974359e-05, 'epoch': 1.08}\n",
      "{'loss': 1.7527, 'learning_rate': 3.846153846153846e-05, 'epoch': 1.15}\n",
      "{'loss': 1.7127, 'learning_rate': 4.1025641025641023e-05, 'epoch': 1.23}\n",
      "{'loss': 1.7822, 'learning_rate': 4.358974358974359e-05, 'epoch': 1.31}\n",
      "{'loss': 1.5512, 'learning_rate': 4.615384615384616e-05, 'epoch': 1.38}\n",
      "{'loss': 1.6069, 'learning_rate': 4.871794871794872e-05, 'epoch': 1.46}\n",
      "{'loss': 1.6241, 'learning_rate': 4.985754985754986e-05, 'epoch': 1.54}\n",
      "{'loss': 1.9118, 'learning_rate': 4.9572649572649575e-05, 'epoch': 1.61}\n",
      "{'loss': 1.6955, 'learning_rate': 4.928774928774929e-05, 'epoch': 1.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5987, 'learning_rate': 4.9002849002849004e-05, 'epoch': 1.77}\n",
      "{'loss': 1.6411, 'learning_rate': 4.871794871794872e-05, 'epoch': 1.84}\n",
      "{'loss': 1.8239, 'learning_rate': 4.8433048433048433e-05, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8944, 'learning_rate': 4.814814814814815e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec39467e585945f4b97b8dd0c265fe49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Construction\\checkpoint-260\n",
      "Configuration saved in models/ViT_Construction\\checkpoint-260\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8542389869689941, 'eval_accuracy': 0.7486785199423354, 'eval_f1': 0.004066036338022341, 'eval_precision': 0.006943916014936941, 'eval_recall': 0.004544949056265044, 'eval_runtime': 16.5205, 'eval_samples_per_second': 125.965, 'eval_steps_per_second': 7.93, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Construction\\checkpoint-260\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Construction\\checkpoint-260\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6627, 'learning_rate': 4.786324786324787e-05, 'epoch': 2.08}\n",
      "{'loss': 1.4996, 'learning_rate': 4.7578347578347584e-05, 'epoch': 2.15}\n",
      "{'loss': 1.5763, 'learning_rate': 4.72934472934473e-05, 'epoch': 2.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.716, 'learning_rate': 4.700854700854701e-05, 'epoch': 2.31}\n",
      "{'loss': 1.7572, 'learning_rate': 4.672364672364672e-05, 'epoch': 2.38}\n",
      "{'loss': 1.8086, 'learning_rate': 4.643874643874644e-05, 'epoch': 2.46}\n",
      "{'loss': 1.6102, 'learning_rate': 4.615384615384616e-05, 'epoch': 2.54}\n",
      "{'loss': 1.6938, 'learning_rate': 4.586894586894587e-05, 'epoch': 2.61}\n",
      "{'loss': 1.7127, 'learning_rate': 4.558404558404559e-05, 'epoch': 2.69}\n",
      "{'loss': 1.63, 'learning_rate': 4.52991452991453e-05, 'epoch': 2.77}\n",
      "{'loss': 1.3659, 'learning_rate': 4.501424501424502e-05, 'epoch': 2.84}\n",
      "{'loss': 1.6756, 'learning_rate': 4.472934472934473e-05, 'epoch': 2.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.557, 'learning_rate': 4.4444444444444447e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "947ce6b36e89444ab43310c16c382a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Construction\\checkpoint-390\n",
      "Configuration saved in models/ViT_Construction\\checkpoint-390\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8338009119033813, 'eval_accuracy': 0.7515617491590582, 'eval_f1': 0.005172449193600573, 'eval_precision': 0.011202290401075433, 'eval_recall': 0.005260413333388559, 'eval_runtime': 16.5395, 'eval_samples_per_second': 125.82, 'eval_steps_per_second': 7.92, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Construction\\checkpoint-390\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Construction\\checkpoint-390\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4301, 'learning_rate': 4.415954415954416e-05, 'epoch': 3.08}\n",
      "{'loss': 1.4984, 'learning_rate': 4.3874643874643876e-05, 'epoch': 3.15}\n",
      "{'loss': 1.5005, 'learning_rate': 4.358974358974359e-05, 'epoch': 3.23}\n",
      "{'loss': 1.3749, 'learning_rate': 4.3304843304843306e-05, 'epoch': 3.31}\n",
      "{'loss': 1.6756, 'learning_rate': 4.301994301994302e-05, 'epoch': 3.38}\n",
      "{'loss': 1.6404, 'learning_rate': 4.2735042735042735e-05, 'epoch': 3.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4855, 'learning_rate': 4.2450142450142457e-05, 'epoch': 3.54}\n",
      "{'loss': 1.6255, 'learning_rate': 4.216524216524217e-05, 'epoch': 3.61}\n",
      "{'loss': 1.5432, 'learning_rate': 4.1880341880341886e-05, 'epoch': 3.69}\n",
      "{'loss': 1.5604, 'learning_rate': 4.15954415954416e-05, 'epoch': 3.77}\n",
      "{'loss': 1.6706, 'learning_rate': 4.131054131054131e-05, 'epoch': 3.84}\n",
      "{'loss': 1.5546, 'learning_rate': 4.1025641025641023e-05, 'epoch': 3.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.665, 'learning_rate': 4.074074074074074e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4b44f53f354d268d35759fe3d39a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Construction\\checkpoint-520\n",
      "Configuration saved in models/ViT_Construction\\checkpoint-520\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.812620759010315, 'eval_accuracy': 0.7496395963479097, 'eval_f1': 0.005904137483775399, 'eval_precision': 0.006742859895938943, 'eval_recall': 0.00616751257053634, 'eval_runtime': 16.646, 'eval_samples_per_second': 125.015, 'eval_steps_per_second': 7.87, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Construction\\checkpoint-520\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Construction\\checkpoint-520\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.684, 'learning_rate': 4.045584045584046e-05, 'epoch': 4.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3192, 'learning_rate': 4.0170940170940174e-05, 'epoch': 4.15}\n",
      "{'loss': 1.5439, 'learning_rate': 3.988603988603989e-05, 'epoch': 4.23}\n",
      "{'loss': 1.5143, 'learning_rate': 3.9601139601139604e-05, 'epoch': 4.31}\n",
      "{'loss': 1.3726, 'learning_rate': 3.931623931623932e-05, 'epoch': 4.38}\n",
      "{'loss': 1.4216, 'learning_rate': 3.903133903133903e-05, 'epoch': 4.46}\n",
      "{'loss': 1.3106, 'learning_rate': 3.874643874643875e-05, 'epoch': 4.54}\n",
      "{'loss': 1.5293, 'learning_rate': 3.846153846153846e-05, 'epoch': 4.61}\n",
      "{'loss': 1.5522, 'learning_rate': 3.817663817663818e-05, 'epoch': 4.69}\n",
      "{'loss': 1.4787, 'learning_rate': 3.789173789173789e-05, 'epoch': 4.77}\n",
      "{'loss': 1.5619, 'learning_rate': 3.760683760683761e-05, 'epoch': 4.84}\n",
      "{'loss': 1.3376, 'learning_rate': 3.732193732193732e-05, 'epoch': 4.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4699, 'learning_rate': 3.7037037037037037e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a4a19a4b1640f797916861b0ca1856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Construction\\checkpoint-650\n",
      "Configuration saved in models/ViT_Construction\\checkpoint-650\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8057796955108643, 'eval_accuracy': 0.7477174435367612, 'eval_f1': 0.006618091723819763, 'eval_precision': 0.007476823529682664, 'eval_recall': 0.006499711381260567, 'eval_runtime': 16.612, 'eval_samples_per_second': 125.271, 'eval_steps_per_second': 7.886, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Construction\\checkpoint-650\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Construction\\checkpoint-650\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.551, 'learning_rate': 3.675213675213676e-05, 'epoch': 5.08}\n",
      "{'loss': 1.4756, 'learning_rate': 3.646723646723647e-05, 'epoch': 5.15}\n",
      "{'loss': 1.2462, 'learning_rate': 3.618233618233619e-05, 'epoch': 5.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6876, 'learning_rate': 3.58974358974359e-05, 'epoch': 5.31}\n",
      "{'loss': 1.3281, 'learning_rate': 3.561253561253561e-05, 'epoch': 5.38}\n",
      "{'loss': 1.1317, 'learning_rate': 3.5327635327635325e-05, 'epoch': 5.46}\n",
      "{'loss': 1.4921, 'learning_rate': 3.504273504273504e-05, 'epoch': 5.54}\n",
      "{'loss': 1.4216, 'learning_rate': 3.475783475783476e-05, 'epoch': 5.61}\n",
      "{'loss': 1.4003, 'learning_rate': 3.4472934472934476e-05, 'epoch': 5.69}\n",
      "{'loss': 1.4349, 'learning_rate': 3.418803418803419e-05, 'epoch': 5.77}\n",
      "{'loss': 1.2924, 'learning_rate': 3.3903133903133905e-05, 'epoch': 5.84}\n",
      "{'loss': 1.3082, 'learning_rate': 3.361823361823362e-05, 'epoch': 5.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.245, 'learning_rate': 3.3333333333333335e-05, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e20b24504be4aef856746dd5ccc1d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Construction\\checkpoint-780\n",
      "Configuration saved in models/ViT_Construction\\checkpoint-780\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7938517332077026, 'eval_accuracy': 0.7530033637674195, 'eval_f1': 0.005962824698589304, 'eval_precision': 0.008221552999215325, 'eval_recall': 0.005801002846015479, 'eval_runtime': 16.5933, 'eval_samples_per_second': 125.412, 'eval_steps_per_second': 7.895, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Construction\\checkpoint-780\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Construction\\checkpoint-780\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3594, 'learning_rate': 3.304843304843305e-05, 'epoch': 6.08}\n",
      "{'loss': 1.2599, 'learning_rate': 3.2763532763532764e-05, 'epoch': 6.15}\n",
      "{'loss': 1.1772, 'learning_rate': 3.247863247863248e-05, 'epoch': 6.23}\n",
      "{'loss': 1.437, 'learning_rate': 3.2193732193732194e-05, 'epoch': 6.31}\n",
      "{'loss': 1.1696, 'learning_rate': 3.190883190883191e-05, 'epoch': 6.38}\n",
      "{'loss': 1.1533, 'learning_rate': 3.162393162393162e-05, 'epoch': 6.46}\n",
      "{'loss': 1.2292, 'learning_rate': 3.133903133903134e-05, 'epoch': 6.54}\n",
      "{'loss': 1.2854, 'learning_rate': 3.105413105413106e-05, 'epoch': 6.61}\n",
      "{'loss': 1.3202, 'learning_rate': 3.0769230769230774e-05, 'epoch': 6.69}\n",
      "{'loss': 1.3654, 'learning_rate': 3.0484330484330486e-05, 'epoch': 6.77}\n",
      "{'loss': 1.3715, 'learning_rate': 3.01994301994302e-05, 'epoch': 6.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3422, 'learning_rate': 2.9914529914529915e-05, 'epoch': 6.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3926, 'learning_rate': 2.962962962962963e-05, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc41d537bb04437b32c1f8c4f36ff1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Construction\\checkpoint-910\n",
      "Configuration saved in models/ViT_Construction\\checkpoint-910\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7998414039611816, 'eval_accuracy': 0.7443536761172513, 'eval_f1': 0.0069500006154569515, 'eval_precision': 0.006556785810684278, 'eval_recall': 0.0075614613616756445, 'eval_runtime': 16.2925, 'eval_samples_per_second': 127.727, 'eval_steps_per_second': 8.04, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Construction\\checkpoint-910\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Construction\\checkpoint-910\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1899, 'learning_rate': 2.9344729344729345e-05, 'epoch': 7.08}\n",
      "{'loss': 1.3122, 'learning_rate': 2.9059829059829063e-05, 'epoch': 7.15}\n",
      "{'loss': 1.2603, 'learning_rate': 2.8774928774928778e-05, 'epoch': 7.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2607, 'learning_rate': 2.8490028490028492e-05, 'epoch': 7.31}\n",
      "{'loss': 1.0844, 'learning_rate': 2.8205128205128207e-05, 'epoch': 7.38}\n",
      "{'loss': 1.2249, 'learning_rate': 2.7920227920227922e-05, 'epoch': 7.46}\n",
      "{'loss': 1.1411, 'learning_rate': 2.7635327635327633e-05, 'epoch': 7.54}\n",
      "{'loss': 1.3028, 'learning_rate': 2.7350427350427355e-05, 'epoch': 7.61}\n",
      "{'loss': 1.2637, 'learning_rate': 2.706552706552707e-05, 'epoch': 7.69}\n",
      "{'loss': 1.0935, 'learning_rate': 2.6780626780626784e-05, 'epoch': 7.77}\n",
      "{'loss': 1.2422, 'learning_rate': 2.64957264957265e-05, 'epoch': 7.84}\n",
      "{'loss': 1.2603, 'learning_rate': 2.621082621082621e-05, 'epoch': 7.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2379, 'learning_rate': 2.5925925925925925e-05, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a85029079db24cc6837a1c0e4fde967c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Construction\\checkpoint-1040\n",
      "Configuration saved in models/ViT_Construction\\checkpoint-1040\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7978088855743408, 'eval_accuracy': 0.7453147525228255, 'eval_f1': 0.010811897568940146, 'eval_precision': 0.011074170723404398, 'eval_recall': 0.011226399388923695, 'eval_runtime': 16.24, 'eval_samples_per_second': 128.14, 'eval_steps_per_second': 8.067, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Construction\\checkpoint-1040\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Construction\\checkpoint-1040\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1595, 'learning_rate': 2.564102564102564e-05, 'epoch': 8.08}\n",
      "{'loss': 1.1144, 'learning_rate': 2.535612535612536e-05, 'epoch': 8.15}\n",
      "{'loss': 1.2499, 'learning_rate': 2.5071225071225073e-05, 'epoch': 8.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0923, 'learning_rate': 2.4786324786324787e-05, 'epoch': 8.31}\n",
      "{'loss': 1.2286, 'learning_rate': 2.4501424501424502e-05, 'epoch': 8.38}\n",
      "{'loss': 1.1765, 'learning_rate': 2.4216524216524217e-05, 'epoch': 8.46}\n",
      "{'loss': 1.1049, 'learning_rate': 2.3931623931623935e-05, 'epoch': 8.54}\n",
      "{'loss': 1.0929, 'learning_rate': 2.364672364672365e-05, 'epoch': 8.61}\n",
      "{'loss': 1.1823, 'learning_rate': 2.336182336182336e-05, 'epoch': 8.69}\n",
      "{'loss': 1.2495, 'learning_rate': 2.307692307692308e-05, 'epoch': 8.77}\n",
      "{'loss': 1.1202, 'learning_rate': 2.2792022792022794e-05, 'epoch': 8.84}\n",
      "{'loss': 1.1113, 'learning_rate': 2.250712250712251e-05, 'epoch': 8.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0985, 'learning_rate': 2.2222222222222223e-05, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23ef8cb4985460481aabe2869da50f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Construction\\checkpoint-1170\n",
      "Configuration saved in models/ViT_Construction\\checkpoint-1170\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.79225754737854, 'eval_accuracy': 0.7525228255646323, 'eval_f1': 0.011957362191399378, 'eval_precision': 0.01643150525535779, 'eval_recall': 0.010695960705618394, 'eval_runtime': 16.5483, 'eval_samples_per_second': 125.753, 'eval_steps_per_second': 7.916, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Construction\\checkpoint-1170\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Construction\\checkpoint-1170\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0586, 'learning_rate': 2.1937321937321938e-05, 'epoch': 9.08}\n",
      "{'loss': 0.986, 'learning_rate': 2.1652421652421653e-05, 'epoch': 9.15}\n",
      "{'loss': 1.0899, 'learning_rate': 2.1367521367521368e-05, 'epoch': 9.23}\n",
      "{'loss': 1.0325, 'learning_rate': 2.1082621082621086e-05, 'epoch': 9.31}\n",
      "{'loss': 1.0852, 'learning_rate': 2.07977207977208e-05, 'epoch': 9.38}\n",
      "{'loss': 1.0132, 'learning_rate': 2.0512820512820512e-05, 'epoch': 9.46}\n",
      "{'loss': 1.2488, 'learning_rate': 2.022792022792023e-05, 'epoch': 9.54}\n",
      "{'loss': 1.0819, 'learning_rate': 1.9943019943019945e-05, 'epoch': 9.61}\n",
      "{'loss': 1.0588, 'learning_rate': 1.965811965811966e-05, 'epoch': 9.69}\n",
      "{'loss': 1.2334, 'learning_rate': 1.9373219373219374e-05, 'epoch': 9.77}\n",
      "{'loss': 1.0164, 'learning_rate': 1.908831908831909e-05, 'epoch': 9.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2119, 'learning_rate': 1.8803418803418804e-05, 'epoch': 9.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0605, 'learning_rate': 1.8518518518518518e-05, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5109c99571b64d29a63f703a79c2b97e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Construction\\checkpoint-1300\n",
      "Configuration saved in models/ViT_Construction\\checkpoint-1300\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8010756969451904, 'eval_accuracy': 0.751081210956271, 'eval_f1': 0.007548557038986061, 'eval_precision': 0.011068991971629385, 'eval_recall': 0.007595178821848093, 'eval_runtime': 16.5435, 'eval_samples_per_second': 125.79, 'eval_steps_per_second': 7.919, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Construction\\checkpoint-1300\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Construction\\checkpoint-1300\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0455, 'learning_rate': 1.8233618233618236e-05, 'epoch': 10.08}\n",
      "{'loss': 0.9807, 'learning_rate': 1.794871794871795e-05, 'epoch': 10.15}\n",
      "{'loss': 0.9042, 'learning_rate': 1.7663817663817662e-05, 'epoch': 10.23}\n",
      "{'loss': 1.1045, 'learning_rate': 1.737891737891738e-05, 'epoch': 10.31}\n",
      "{'loss': 1.0222, 'learning_rate': 1.7094017094017095e-05, 'epoch': 10.38}\n",
      "{'loss': 1.0518, 'learning_rate': 1.680911680911681e-05, 'epoch': 10.46}\n",
      "{'loss': 0.9951, 'learning_rate': 1.6524216524216525e-05, 'epoch': 10.54}\n",
      "{'loss': 1.2091, 'learning_rate': 1.623931623931624e-05, 'epoch': 10.61}\n",
      "{'loss': 0.9436, 'learning_rate': 1.5954415954415954e-05, 'epoch': 10.69}\n",
      "{'loss': 1.1668, 'learning_rate': 1.566951566951567e-05, 'epoch': 10.77}\n",
      "{'loss': 0.9785, 'learning_rate': 1.5384615384615387e-05, 'epoch': 10.84}\n",
      "{'loss': 1.0469, 'learning_rate': 1.50997150997151e-05, 'epoch': 10.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9621, 'learning_rate': 1.4814814814814815e-05, 'epoch': 11.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851bd6d51b964e439919dd979ce53a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Construction\\checkpoint-1430\n",
      "Configuration saved in models/ViT_Construction\\checkpoint-1430\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8261151313781738, 'eval_accuracy': 0.7501201345506968, 'eval_f1': 0.01379535054469459, 'eval_precision': 0.017583885742915653, 'eval_recall': 0.01393129897290935, 'eval_runtime': 16.6014, 'eval_samples_per_second': 125.35, 'eval_steps_per_second': 7.891, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Construction\\checkpoint-1430\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Construction\\checkpoint-1430\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0962, 'learning_rate': 1.4529914529914531e-05, 'epoch': 11.08}\n",
      "{'loss': 0.9458, 'learning_rate': 1.4245014245014246e-05, 'epoch': 11.15}\n",
      "{'loss': 0.9693, 'learning_rate': 1.3960113960113961e-05, 'epoch': 11.23}\n",
      "{'loss': 1.0564, 'learning_rate': 1.3675213675213677e-05, 'epoch': 11.31}\n",
      "{'loss': 0.9155, 'learning_rate': 1.3390313390313392e-05, 'epoch': 11.38}\n",
      "{'loss': 0.9679, 'learning_rate': 1.3105413105413105e-05, 'epoch': 11.46}\n",
      "{'loss': 0.9802, 'learning_rate': 1.282051282051282e-05, 'epoch': 11.54}\n",
      "{'loss': 0.9779, 'learning_rate': 1.2535612535612536e-05, 'epoch': 11.61}\n",
      "{'loss': 0.9171, 'learning_rate': 1.2250712250712251e-05, 'epoch': 11.69}\n",
      "{'loss': 0.9649, 'learning_rate': 1.1965811965811967e-05, 'epoch': 11.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9614, 'learning_rate': 1.168091168091168e-05, 'epoch': 11.84}\n",
      "{'loss': 1.1155, 'learning_rate': 1.1396011396011397e-05, 'epoch': 11.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0586, 'learning_rate': 1.1111111111111112e-05, 'epoch': 12.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5651942ff24c6f814fed669cff9209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Construction\\checkpoint-1560\n",
      "Configuration saved in models/ViT_Construction\\checkpoint-1560\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8461637496948242, 'eval_accuracy': 0.7448342143200385, 'eval_f1': 0.011451203301264685, 'eval_precision': 0.01637120234193977, 'eval_recall': 0.010132706324009795, 'eval_runtime': 16.6549, 'eval_samples_per_second': 124.948, 'eval_steps_per_second': 7.866, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Construction\\checkpoint-1560\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Construction\\checkpoint-1560\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0095, 'learning_rate': 1.0826210826210826e-05, 'epoch': 12.08}\n",
      "{'loss': 0.9637, 'learning_rate': 1.0541310541310543e-05, 'epoch': 12.15}\n",
      "{'loss': 0.9661, 'learning_rate': 1.0256410256410256e-05, 'epoch': 12.23}\n",
      "{'loss': 0.9762, 'learning_rate': 9.971509971509972e-06, 'epoch': 12.31}\n",
      "{'loss': 0.9458, 'learning_rate': 9.686609686609687e-06, 'epoch': 12.38}\n",
      "{'loss': 0.9133, 'learning_rate': 9.401709401709402e-06, 'epoch': 12.46}\n",
      "{'loss': 0.862, 'learning_rate': 9.116809116809118e-06, 'epoch': 12.54}\n",
      "{'loss': 0.8871, 'learning_rate': 8.831908831908831e-06, 'epoch': 12.61}\n",
      "{'loss': 0.9442, 'learning_rate': 8.547008547008548e-06, 'epoch': 12.69}\n",
      "{'loss': 1.0016, 'learning_rate': 8.262108262108262e-06, 'epoch': 12.77}\n",
      "{'loss': 0.9388, 'learning_rate': 7.977207977207977e-06, 'epoch': 12.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9818, 'learning_rate': 7.692307692307694e-06, 'epoch': 12.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0435, 'learning_rate': 7.4074074074074075e-06, 'epoch': 13.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f722b713c03847199fed8d240eb109db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Construction\\checkpoint-1690\n",
      "Configuration saved in models/ViT_Construction\\checkpoint-1690\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8227145671844482, 'eval_accuracy': 0.7414704469005285, 'eval_f1': 0.011974251310646736, 'eval_precision': 0.01637709370883365, 'eval_recall': 0.011255695994460973, 'eval_runtime': 16.569, 'eval_samples_per_second': 125.596, 'eval_steps_per_second': 7.906, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Construction\\checkpoint-1690\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Construction\\checkpoint-1690\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0617, 'learning_rate': 7.122507122507123e-06, 'epoch': 13.08}\n",
      "{'loss': 0.9468, 'learning_rate': 6.837606837606839e-06, 'epoch': 13.15}\n",
      "{'loss': 0.8691, 'learning_rate': 6.5527065527065525e-06, 'epoch': 13.23}\n",
      "{'loss': 0.9026, 'learning_rate': 6.267806267806268e-06, 'epoch': 13.31}\n",
      "{'loss': 0.9025, 'learning_rate': 5.982905982905984e-06, 'epoch': 13.38}\n",
      "{'loss': 0.9927, 'learning_rate': 5.6980056980056985e-06, 'epoch': 13.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0118, 'learning_rate': 5.413105413105413e-06, 'epoch': 13.54}\n",
      "{'loss': 1.0708, 'learning_rate': 5.128205128205128e-06, 'epoch': 13.61}\n",
      "{'loss': 0.8447, 'learning_rate': 4.8433048433048435e-06, 'epoch': 13.69}\n",
      "{'loss': 0.9057, 'learning_rate': 4.558404558404559e-06, 'epoch': 13.77}\n",
      "{'loss': 0.9399, 'learning_rate': 4.273504273504274e-06, 'epoch': 13.84}\n",
      "{'loss': 0.874, 'learning_rate': 3.988603988603989e-06, 'epoch': 13.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8002, 'learning_rate': 3.7037037037037037e-06, 'epoch': 14.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06dc9c0483484799b9c008c19ff71c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Construction\\checkpoint-1820\n",
      "Configuration saved in models/ViT_Construction\\checkpoint-1820\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.835974097251892, 'eval_accuracy': 0.7481979817395483, 'eval_f1': 0.01095424460312751, 'eval_precision': 0.013290508465344866, 'eval_recall': 0.010057911884422463, 'eval_runtime': 16.5825, 'eval_samples_per_second': 125.494, 'eval_steps_per_second': 7.9, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Construction\\checkpoint-1820\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Construction\\checkpoint-1820\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8886, 'learning_rate': 3.4188034188034193e-06, 'epoch': 14.08}\n",
      "{'loss': 0.9372, 'learning_rate': 3.133903133903134e-06, 'epoch': 14.15}\n",
      "{'loss': 0.8552, 'learning_rate': 2.8490028490028492e-06, 'epoch': 14.23}\n",
      "{'loss': 0.9174, 'learning_rate': 2.564102564102564e-06, 'epoch': 14.31}\n",
      "{'loss': 0.8753, 'learning_rate': 2.2792022792022796e-06, 'epoch': 14.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9387, 'learning_rate': 1.9943019943019943e-06, 'epoch': 14.46}\n",
      "{'loss': 0.8006, 'learning_rate': 1.7094017094017097e-06, 'epoch': 14.54}\n",
      "{'loss': 0.9114, 'learning_rate': 1.4245014245014246e-06, 'epoch': 14.61}\n",
      "{'loss': 0.8629, 'learning_rate': 1.1396011396011398e-06, 'epoch': 14.69}\n",
      "{'loss': 0.9279, 'learning_rate': 8.547008547008548e-07, 'epoch': 14.77}\n",
      "{'loss': 0.9149, 'learning_rate': 5.698005698005699e-07, 'epoch': 14.84}\n",
      "{'loss': 0.9665, 'learning_rate': 2.8490028490028494e-07, 'epoch': 14.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.982, 'learning_rate': 0.0, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a848e2043174640b37a50f1c01ed254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Construction\\checkpoint-1950\n",
      "Configuration saved in models/ViT_Construction\\checkpoint-1950\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8446953296661377, 'eval_accuracy': 0.7481979817395483, 'eval_f1': 0.009258634951371587, 'eval_precision': 0.009442448424214949, 'eval_recall': 0.009439064816367708, 'eval_runtime': 16.5198, 'eval_samples_per_second': 125.97, 'eval_steps_per_second': 7.93, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Construction\\checkpoint-1950\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Construction\\checkpoint-1950\\preprocessor_config.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from models/ViT_Construction\\checkpoint-1430 (score: 0.01379535054469459).\n",
      "Setting `WANDB_LOG_MODEL` from true to `end` instead\n",
      "Saving model checkpoint to C:\\Users\\chris\\AppData\\Local\\Temp\\tmpmtik4qqz\n",
      "Configuration saved in C:\\Users\\chris\\AppData\\Local\\Temp\\tmpmtik4qqz\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 2244.9293, 'train_samples_per_second': 55.612, 'train_steps_per_second': 0.869, 'train_loss': 1.364447204883282, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in C:\\Users\\chris\\AppData\\Local\\Temp\\tmpmtik4qqz\\pytorch_model.bin\n",
      "Image processor saved in C:\\Users\\chris\\AppData\\Local\\Temp\\tmpmtik4qqz\\preprocessor_config.json\n",
      "Logging model artifacts. ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▅▅▇▆▅█▃▃█▇▆▃▁▅▅</td></tr><tr><td>eval/f1</td><td>▁▁▂▂▃▃▃▆▇▄█▆▇▆▅</td></tr><tr><td>eval/loss</td><td>█▆▄▃▂▁▂▁▁▂▄▅▃▄▅</td></tr><tr><td>eval/precision</td><td>▁▃▅▃▃▃▃▅▇▅█▇▇▆▄</td></tr><tr><td>eval/recall</td><td>▁▁▂▂▃▂▃▆▆▃█▅▆▅▅</td></tr><tr><td>eval/runtime</td><td>▁▆▆█▇▇▂▁▆▆▇█▇▇▆</td></tr><tr><td>eval/samples_per_second</td><td>█▃▃▁▂▂▇█▃▃▂▁▂▂▃</td></tr><tr><td>eval/steps_per_second</td><td>█▃▃▁▂▂▇█▃▃▂▁▂▂▃</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>▂▃▅▇███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.7482</td></tr><tr><td>eval/f1</td><td>0.00926</td></tr><tr><td>eval/loss</td><td>1.8447</td></tr><tr><td>eval/precision</td><td>0.00944</td></tr><tr><td>eval/recall</td><td>0.00944</td></tr><tr><td>eval/runtime</td><td>16.5198</td></tr><tr><td>eval/samples_per_second</td><td>125.97</td></tr><tr><td>eval/steps_per_second</td><td>7.93</td></tr><tr><td>train/epoch</td><td>15.0</td></tr><tr><td>train/global_step</td><td>1950</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.982</td></tr><tr><td>train/total_flos</td><td>9.729314094888751e+18</td></tr><tr><td>train/train_loss</td><td>1.36445</td></tr><tr><td>train/train_runtime</td><td>2244.9293</td></tr><tr><td>train/train_samples_per_second</td><td>55.612</td></tr><tr><td>train/train_steps_per_second</td><td>0.869</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ViT_Construction</strong>: <a href=\"https://wandb.ai/cringgaard/Sailboat%20FGVC/runs/3n2xd9ga\" target=\"_blank\">https://wandb.ai/cringgaard/Sailboat%20FGVC/runs/3n2xd9ga</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230323_141907-3n2xd9ga\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8887bfb7e4fb4bfdb1b873bd4de37b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\chris\\OneDrive\\Dokumenter\\GitHub\\SailFGVC\\wandb\\run-20230323_145715-3pds0bos</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cringgaard/Sailboat%20FGVC/runs/3pds0bos\" target=\"_blank\">ViT_Ballast Type</a></strong> to <a href=\"https://wandb.ai/cringgaard/Sailboat%20FGVC\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\\cache-dd4e4efd60e5a362.arrow and C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\\cache-5ba6bd0f06b77e36.arrow\n",
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\\cache-a018fc98cfdb169d.arrow\n",
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\\cache-4ebb0ed8bf80df99.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]\n",
      "[0, 1, 2, 4, 5, 6, 7, 9, 11, 15, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 34, 37, 44, 45, 49, 53, 56, 57, 58, 59, 60, 61, 69, 76, 81, 82, 83, 85, 89, 90]\n",
      "[81, 56, 85, 30, 23]\n",
      "['Lead', 'Iron', 'NaN', 'Lead + Water', 'Iron or Lead', 'Lead/Water', 'Lead (internal)', 'Lead or Iron', 'Aluminum Centerboard', 'Cast iron', 'Cement and Ferrous material', 'lead', 'Lead/Iron', 'Lead bulb with cast iron fin', 'Optional sand bags', 'Steel fin / lead bulb', 'Blade: cast iron; Bulb: lead', 'Keel blade cast iron; bulb lead', 'Steel fin with lead bulb', 'Cast Iron', 'Galvanized and polyester shot', 'iron', 'Iron/Lead', 'Lead w/ steel cb', 'Galvanized iron', 'Water', 'Steel centerboard', 'Concrete', 'Lead bulb', 'Cast iron with lead fill', 'Lead and water', 'Steel', 'Lead; galvanized steel center plate', 'Iron /Lead', 'Lead/ Iron', 'Cast iron (standard keel)', 'Gal. steel', 'Lead Bulb', 'Lea', 'Case iron', 'Aluminum centerboard', 'cast iron', '1994.0', 'Iron / Steel', 'Cast iron keel with mixed cast iron/lead ballast', 'water + iron', 'Cast iron with lead bulb', 'Iron keel with lead bulb', 'Keel built in lead, iron and epoxy GRP', 'Cast iron fin with lead bulb', 'Steel and Lead', 'Iron fin with lead bulb', 'Cast iron + lead', 'Cast iron fin with head bulb', 'Lead ballast', 'Incapsulated steel', 'Galv. steel', 'Lead and iron', 'Iron or lead', 'Cast iron fin / lead bulb', 'Stone', 'Lead internal', 'Iron/lead', 'Stainless steel fin / lead bulb', '2000.0', 'lead/iron', 'Cast iron centerboard', 'Cast iron keel', 'Galvanized steel centerboard', 'Internal: cast iron; Centerboard: galvanized steel', 'Cast iron and galvanized steel', 'Cast iron and lead', 'Lead,water', 'Concrete*', 'Lead/water', 'Cast', 'Cast lead', 'Iron.', 'Lead on Iron', 'Cast steel and/pr lead', 'Cast steel and/or lead', 'Cast iron and/or lead', 'Cast iron fin/lead bulb', 'Cast iron fin; lead bulb', 'Iron/SS', 'lead/concrete', 'Iron (lead optional)', 'Cast iron shot', 'Anything', 'Iron and steel', 'Varies', 'Cast iron swing keel', 'Stainless steel', '87.5% cast iron, 12.5% lead', 'Lead + iron', 'Water Ballast']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\chris/.cache\\huggingface\\hub\\models--google--vit-base-patch16-224\\snapshots\\2ddc9d4e473d7ba52128f0df4723e478fa14fb80\\config.json\n",
      "Model config ViTConfig {\n",
      "  \"_name_or_path\": \"google/vit-base-patch16-224\",\n",
      "  \"architectures\": [\n",
      "    \"ViTForImageClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\",\n",
      "    \"59\": \"LABEL_59\",\n",
      "    \"60\": \"LABEL_60\",\n",
      "    \"61\": \"LABEL_61\",\n",
      "    \"62\": \"LABEL_62\",\n",
      "    \"63\": \"LABEL_63\",\n",
      "    \"64\": \"LABEL_64\",\n",
      "    \"65\": \"LABEL_65\",\n",
      "    \"66\": \"LABEL_66\",\n",
      "    \"67\": \"LABEL_67\",\n",
      "    \"68\": \"LABEL_68\",\n",
      "    \"69\": \"LABEL_69\",\n",
      "    \"70\": \"LABEL_70\",\n",
      "    \"71\": \"LABEL_71\",\n",
      "    \"72\": \"LABEL_72\",\n",
      "    \"73\": \"LABEL_73\",\n",
      "    \"74\": \"LABEL_74\",\n",
      "    \"75\": \"LABEL_75\",\n",
      "    \"76\": \"LABEL_76\",\n",
      "    \"77\": \"LABEL_77\",\n",
      "    \"78\": \"LABEL_78\",\n",
      "    \"79\": \"LABEL_79\",\n",
      "    \"80\": \"LABEL_80\",\n",
      "    \"81\": \"LABEL_81\",\n",
      "    \"82\": \"LABEL_82\",\n",
      "    \"83\": \"LABEL_83\",\n",
      "    \"84\": \"LABEL_84\",\n",
      "    \"85\": \"LABEL_85\",\n",
      "    \"86\": \"LABEL_86\",\n",
      "    \"87\": \"LABEL_87\",\n",
      "    \"88\": \"LABEL_88\",\n",
      "    \"89\": \"LABEL_89\",\n",
      "    \"90\": \"LABEL_90\",\n",
      "    \"91\": \"LABEL_91\",\n",
      "    \"92\": \"LABEL_92\",\n",
      "    \"93\": \"LABEL_93\",\n",
      "    \"94\": \"LABEL_94\",\n",
      "    \"95\": \"LABEL_95\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_59\": 59,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_60\": 60,\n",
      "    \"LABEL_61\": 61,\n",
      "    \"LABEL_62\": 62,\n",
      "    \"LABEL_63\": 63,\n",
      "    \"LABEL_64\": 64,\n",
      "    \"LABEL_65\": 65,\n",
      "    \"LABEL_66\": 66,\n",
      "    \"LABEL_67\": 67,\n",
      "    \"LABEL_68\": 68,\n",
      "    \"LABEL_69\": 69,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_70\": 70,\n",
      "    \"LABEL_71\": 71,\n",
      "    \"LABEL_72\": 72,\n",
      "    \"LABEL_73\": 73,\n",
      "    \"LABEL_74\": 74,\n",
      "    \"LABEL_75\": 75,\n",
      "    \"LABEL_76\": 76,\n",
      "    \"LABEL_77\": 77,\n",
      "    \"LABEL_78\": 78,\n",
      "    \"LABEL_79\": 79,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_80\": 80,\n",
      "    \"LABEL_81\": 81,\n",
      "    \"LABEL_82\": 82,\n",
      "    \"LABEL_83\": 83,\n",
      "    \"LABEL_84\": 84,\n",
      "    \"LABEL_85\": 85,\n",
      "    \"LABEL_86\": 86,\n",
      "    \"LABEL_87\": 87,\n",
      "    \"LABEL_88\": 88,\n",
      "    \"LABEL_89\": 89,\n",
      "    \"LABEL_9\": 9,\n",
      "    \"LABEL_90\": 90,\n",
      "    \"LABEL_91\": 91,\n",
      "    \"LABEL_92\": 92,\n",
      "    \"LABEL_93\": 93,\n",
      "    \"LABEL_94\": 94,\n",
      "    \"LABEL_95\": 95\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": true,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\chris/.cache\\huggingface\\hub\\models--google--vit-base-patch16-224\\snapshots\\2ddc9d4e473d7ba52128f0df4723e478fa14fb80\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing ViTForImageClassification.\n",
      "\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([96, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([96]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "Setting `WANDB_LOG_MODEL` from true to `end` instead\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8323\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 1950\n",
      "  Number of trainable parameters = 85872480\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5048b842916749ec948981fbfa7d848c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.4648, 'learning_rate': 2.564102564102564e-06, 'epoch': 0.08}\n",
      "{'loss': 4.1479, 'learning_rate': 5.128205128205128e-06, 'epoch': 0.15}\n",
      "{'loss': 3.563, 'learning_rate': 7.692307692307694e-06, 'epoch': 0.23}\n",
      "{'loss': 2.794, 'learning_rate': 1.0256410256410256e-05, 'epoch': 0.31}\n",
      "{'loss': 2.1619, 'learning_rate': 1.282051282051282e-05, 'epoch': 0.38}\n",
      "{'loss': 1.528, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.46}\n",
      "{'loss': 1.2714, 'learning_rate': 1.794871794871795e-05, 'epoch': 0.54}\n",
      "{'loss': 1.1861, 'learning_rate': 2.0512820512820512e-05, 'epoch': 0.61}\n",
      "{'loss': 1.1525, 'learning_rate': 2.307692307692308e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.252, 'learning_rate': 2.564102564102564e-05, 'epoch': 0.77}\n",
      "{'loss': 1.0867, 'learning_rate': 2.8205128205128207e-05, 'epoch': 0.84}\n",
      "{'loss': 1.2508, 'learning_rate': 3.0769230769230774e-05, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0987, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b18df377e38743dca468ff88f435004b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Ballast Type\\checkpoint-130\n",
      "Configuration saved in models/ViT_Ballast Type\\checkpoint-130\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2063839435577393, 'eval_accuracy': 0.493993272465161, 'eval_f1': 0.024508849075309633, 'eval_precision': 0.02416026415949095, 'eval_recall': 0.028471782771941876, 'eval_runtime': 16.4075, 'eval_samples_per_second': 126.832, 'eval_steps_per_second': 7.984, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Ballast Type\\checkpoint-130\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Ballast Type\\checkpoint-130\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.235, 'learning_rate': 3.58974358974359e-05, 'epoch': 1.08}\n",
      "{'loss': 1.1624, 'learning_rate': 3.846153846153846e-05, 'epoch': 1.15}\n",
      "{'loss': 1.1094, 'learning_rate': 4.1025641025641023e-05, 'epoch': 1.23}\n",
      "{'loss': 1.1454, 'learning_rate': 4.358974358974359e-05, 'epoch': 1.31}\n",
      "{'loss': 1.117, 'learning_rate': 4.615384615384616e-05, 'epoch': 1.38}\n",
      "{'loss': 1.1547, 'learning_rate': 4.871794871794872e-05, 'epoch': 1.46}\n",
      "{'loss': 1.0886, 'learning_rate': 4.985754985754986e-05, 'epoch': 1.54}\n",
      "{'loss': 1.1708, 'learning_rate': 4.9572649572649575e-05, 'epoch': 1.61}\n",
      "{'loss': 1.057, 'learning_rate': 4.928774928774929e-05, 'epoch': 1.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1725, 'learning_rate': 4.9002849002849004e-05, 'epoch': 1.77}\n",
      "{'loss': 1.0539, 'learning_rate': 4.871794871794872e-05, 'epoch': 1.84}\n",
      "{'loss': 1.1275, 'learning_rate': 4.8433048433048433e-05, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1206, 'learning_rate': 4.814814814814815e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92845634a0245a4890dbb601d018ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Ballast Type\\checkpoint-260\n",
      "Configuration saved in models/ViT_Ballast Type\\checkpoint-260\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0888159275054932, 'eval_accuracy': 0.6444017299375301, 'eval_f1': 0.02399299648122908, 'eval_precision': 0.02621802309573087, 'eval_recall': 0.026373231903186342, 'eval_runtime': 16.5528, 'eval_samples_per_second': 125.719, 'eval_steps_per_second': 7.914, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Ballast Type\\checkpoint-260\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Ballast Type\\checkpoint-260\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1236, 'learning_rate': 4.786324786324787e-05, 'epoch': 2.08}\n",
      "{'loss': 1.2023, 'learning_rate': 4.7578347578347584e-05, 'epoch': 2.15}\n",
      "{'loss': 1.084, 'learning_rate': 4.72934472934473e-05, 'epoch': 2.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0048, 'learning_rate': 4.700854700854701e-05, 'epoch': 2.31}\n",
      "{'loss': 1.0436, 'learning_rate': 4.672364672364672e-05, 'epoch': 2.38}\n",
      "{'loss': 1.1604, 'learning_rate': 4.643874643874644e-05, 'epoch': 2.46}\n",
      "{'loss': 1.0482, 'learning_rate': 4.615384615384616e-05, 'epoch': 2.54}\n",
      "{'loss': 1.0724, 'learning_rate': 4.586894586894587e-05, 'epoch': 2.61}\n",
      "{'loss': 1.1059, 'learning_rate': 4.558404558404559e-05, 'epoch': 2.69}\n",
      "{'loss': 1.1369, 'learning_rate': 4.52991452991453e-05, 'epoch': 2.77}\n",
      "{'loss': 1.0975, 'learning_rate': 4.501424501424502e-05, 'epoch': 2.84}\n",
      "{'loss': 1.0709, 'learning_rate': 4.472934472934473e-05, 'epoch': 2.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0188, 'learning_rate': 4.4444444444444447e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2871efa0061b44499de4a1417ffe640f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Ballast Type\\checkpoint-390\n",
      "Configuration saved in models/ViT_Ballast Type\\checkpoint-390\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0679458379745483, 'eval_accuracy': 0.6376741950985103, 'eval_f1': 0.028119371252089118, 'eval_precision': 0.05114729173265758, 'eval_recall': 0.029058735341865805, 'eval_runtime': 16.2147, 'eval_samples_per_second': 128.34, 'eval_steps_per_second': 8.079, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Ballast Type\\checkpoint-390\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Ballast Type\\checkpoint-390\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0288, 'learning_rate': 4.415954415954416e-05, 'epoch': 3.08}\n",
      "{'loss': 1.0274, 'learning_rate': 4.3874643874643876e-05, 'epoch': 3.15}\n",
      "{'loss': 1.1033, 'learning_rate': 4.358974358974359e-05, 'epoch': 3.23}\n",
      "{'loss': 0.9999, 'learning_rate': 4.3304843304843306e-05, 'epoch': 3.31}\n",
      "{'loss': 1.0461, 'learning_rate': 4.301994301994302e-05, 'epoch': 3.38}\n",
      "{'loss': 1.0642, 'learning_rate': 4.2735042735042735e-05, 'epoch': 3.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9846, 'learning_rate': 4.2450142450142457e-05, 'epoch': 3.54}\n",
      "{'loss': 0.9901, 'learning_rate': 4.216524216524217e-05, 'epoch': 3.61}\n",
      "{'loss': 1.0149, 'learning_rate': 4.1880341880341886e-05, 'epoch': 3.69}\n",
      "{'loss': 0.9877, 'learning_rate': 4.15954415954416e-05, 'epoch': 3.77}\n",
      "{'loss': 1.0388, 'learning_rate': 4.131054131054131e-05, 'epoch': 3.84}\n",
      "{'loss': 1.1039, 'learning_rate': 4.1025641025641023e-05, 'epoch': 3.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0583, 'learning_rate': 4.074074074074074e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6eb891d5377460490c307fe38ab9c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Ballast Type\\checkpoint-520\n",
      "Configuration saved in models/ViT_Ballast Type\\checkpoint-520\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0645204782485962, 'eval_accuracy': 0.6554541086016338, 'eval_f1': 0.024584315336753943, 'eval_precision': 0.0650682801921954, 'eval_recall': 0.026863008272700415, 'eval_runtime': 16.2171, 'eval_samples_per_second': 128.322, 'eval_steps_per_second': 8.078, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Ballast Type\\checkpoint-520\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Ballast Type\\checkpoint-520\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.019, 'learning_rate': 4.045584045584046e-05, 'epoch': 4.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.955, 'learning_rate': 4.0170940170940174e-05, 'epoch': 4.15}\n",
      "{'loss': 0.9901, 'learning_rate': 3.988603988603989e-05, 'epoch': 4.23}\n",
      "{'loss': 0.9779, 'learning_rate': 3.9601139601139604e-05, 'epoch': 4.31}\n",
      "{'loss': 1.0169, 'learning_rate': 3.931623931623932e-05, 'epoch': 4.38}\n",
      "{'loss': 0.9127, 'learning_rate': 3.903133903133903e-05, 'epoch': 4.46}\n",
      "{'loss': 0.9444, 'learning_rate': 3.874643874643875e-05, 'epoch': 4.54}\n",
      "{'loss': 0.9575, 'learning_rate': 3.846153846153846e-05, 'epoch': 4.61}\n",
      "{'loss': 1.0836, 'learning_rate': 3.817663817663818e-05, 'epoch': 4.69}\n",
      "{'loss': 1.059, 'learning_rate': 3.789173789173789e-05, 'epoch': 4.77}\n",
      "{'loss': 0.9125, 'learning_rate': 3.760683760683761e-05, 'epoch': 4.84}\n",
      "{'loss': 1.0467, 'learning_rate': 3.732193732193732e-05, 'epoch': 4.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0983, 'learning_rate': 3.7037037037037037e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91fd6865bf5a4df89101398164280aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Ballast Type\\checkpoint-650\n",
      "Configuration saved in models/ViT_Ballast Type\\checkpoint-650\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.061731219291687, 'eval_accuracy': 0.6352715040845748, 'eval_f1': 0.028684363767474328, 'eval_precision': 0.040800221341048486, 'eval_recall': 0.029205928828545866, 'eval_runtime': 16.2702, 'eval_samples_per_second': 127.902, 'eval_steps_per_second': 8.052, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Ballast Type\\checkpoint-650\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Ballast Type\\checkpoint-650\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9569, 'learning_rate': 3.675213675213676e-05, 'epoch': 5.08}\n",
      "{'loss': 0.8866, 'learning_rate': 3.646723646723647e-05, 'epoch': 5.15}\n",
      "{'loss': 0.8978, 'learning_rate': 3.618233618233619e-05, 'epoch': 5.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.916, 'learning_rate': 3.58974358974359e-05, 'epoch': 5.31}\n",
      "{'loss': 1.0011, 'learning_rate': 3.561253561253561e-05, 'epoch': 5.38}\n",
      "{'loss': 0.9227, 'learning_rate': 3.5327635327635325e-05, 'epoch': 5.46}\n",
      "{'loss': 1.0336, 'learning_rate': 3.504273504273504e-05, 'epoch': 5.54}\n",
      "{'loss': 0.9649, 'learning_rate': 3.475783475783476e-05, 'epoch': 5.61}\n",
      "{'loss': 0.979, 'learning_rate': 3.4472934472934476e-05, 'epoch': 5.69}\n",
      "{'loss': 0.9508, 'learning_rate': 3.418803418803419e-05, 'epoch': 5.77}\n",
      "{'loss': 0.9463, 'learning_rate': 3.3903133903133905e-05, 'epoch': 5.84}\n",
      "{'loss': 0.931, 'learning_rate': 3.361823361823362e-05, 'epoch': 5.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9446, 'learning_rate': 3.3333333333333335e-05, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5339ec98ed4c4da4b511741043b3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Ballast Type\\checkpoint-780\n",
      "Configuration saved in models/ViT_Ballast Type\\checkpoint-780\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0987049341201782, 'eval_accuracy': 0.6093224411340702, 'eval_f1': 0.02863480292318366, 'eval_precision': 0.05008236821086262, 'eval_recall': 0.029709892745992887, 'eval_runtime': 16.5525, 'eval_samples_per_second': 125.721, 'eval_steps_per_second': 7.914, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Ballast Type\\checkpoint-780\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Ballast Type\\checkpoint-780\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9247, 'learning_rate': 3.304843304843305e-05, 'epoch': 6.08}\n",
      "{'loss': 0.9066, 'learning_rate': 3.2763532763532764e-05, 'epoch': 6.15}\n",
      "{'loss': 0.8671, 'learning_rate': 3.247863247863248e-05, 'epoch': 6.23}\n",
      "{'loss': 0.8084, 'learning_rate': 3.2193732193732194e-05, 'epoch': 6.31}\n",
      "{'loss': 0.928, 'learning_rate': 3.190883190883191e-05, 'epoch': 6.38}\n",
      "{'loss': 0.8764, 'learning_rate': 3.162393162393162e-05, 'epoch': 6.46}\n",
      "{'loss': 0.8774, 'learning_rate': 3.133903133903134e-05, 'epoch': 6.54}\n",
      "{'loss': 0.8797, 'learning_rate': 3.105413105413106e-05, 'epoch': 6.61}\n",
      "{'loss': 0.921, 'learning_rate': 3.0769230769230774e-05, 'epoch': 6.69}\n",
      "{'loss': 0.8225, 'learning_rate': 3.0484330484330486e-05, 'epoch': 6.77}\n",
      "{'loss': 0.9348, 'learning_rate': 3.01994301994302e-05, 'epoch': 6.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.996, 'learning_rate': 2.9914529914529915e-05, 'epoch': 6.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9003, 'learning_rate': 2.962962962962963e-05, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac00f4616c3c42cd88f41092efe9ff00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Ballast Type\\checkpoint-910\n",
      "Configuration saved in models/ViT_Ballast Type\\checkpoint-910\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0923269987106323, 'eval_accuracy': 0.6429601153291686, 'eval_f1': 0.025110104602217204, 'eval_precision': 0.04066327115988118, 'eval_recall': 0.0268669684153812, 'eval_runtime': 16.4767, 'eval_samples_per_second': 126.299, 'eval_steps_per_second': 7.951, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Ballast Type\\checkpoint-910\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Ballast Type\\checkpoint-910\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8465, 'learning_rate': 2.9344729344729345e-05, 'epoch': 7.08}\n",
      "{'loss': 0.8458, 'learning_rate': 2.9059829059829063e-05, 'epoch': 7.15}\n",
      "{'loss': 0.7959, 'learning_rate': 2.8774928774928778e-05, 'epoch': 7.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9208, 'learning_rate': 2.8490028490028492e-05, 'epoch': 7.31}\n",
      "{'loss': 0.8718, 'learning_rate': 2.8205128205128207e-05, 'epoch': 7.38}\n",
      "{'loss': 0.9049, 'learning_rate': 2.7920227920227922e-05, 'epoch': 7.46}\n",
      "{'loss': 0.8352, 'learning_rate': 2.7635327635327633e-05, 'epoch': 7.54}\n",
      "{'loss': 0.8338, 'learning_rate': 2.7350427350427355e-05, 'epoch': 7.61}\n",
      "{'loss': 0.7971, 'learning_rate': 2.706552706552707e-05, 'epoch': 7.69}\n",
      "{'loss': 0.8909, 'learning_rate': 2.6780626780626784e-05, 'epoch': 7.77}\n",
      "{'loss': 0.8289, 'learning_rate': 2.64957264957265e-05, 'epoch': 7.84}\n",
      "{'loss': 0.8146, 'learning_rate': 2.621082621082621e-05, 'epoch': 7.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8544, 'learning_rate': 2.5925925925925925e-05, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f09fd27cbd4dfe90343b30028753d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Ballast Type\\checkpoint-1040\n",
      "Configuration saved in models/ViT_Ballast Type\\checkpoint-1040\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0934051275253296, 'eval_accuracy': 0.6304661220567035, 'eval_f1': 0.031111995522242954, 'eval_precision': 0.04856835699407761, 'eval_recall': 0.03065328500480986, 'eval_runtime': 16.5397, 'eval_samples_per_second': 125.818, 'eval_steps_per_second': 7.92, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Ballast Type\\checkpoint-1040\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Ballast Type\\checkpoint-1040\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8034, 'learning_rate': 2.564102564102564e-05, 'epoch': 8.08}\n",
      "{'loss': 0.8409, 'learning_rate': 2.535612535612536e-05, 'epoch': 8.15}\n",
      "{'loss': 0.8075, 'learning_rate': 2.5071225071225073e-05, 'epoch': 8.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7607, 'learning_rate': 2.4786324786324787e-05, 'epoch': 8.31}\n",
      "{'loss': 0.7651, 'learning_rate': 2.4501424501424502e-05, 'epoch': 8.38}\n",
      "{'loss': 0.7881, 'learning_rate': 2.4216524216524217e-05, 'epoch': 8.46}\n",
      "{'loss': 0.7854, 'learning_rate': 2.3931623931623935e-05, 'epoch': 8.54}\n",
      "{'loss': 0.7241, 'learning_rate': 2.364672364672365e-05, 'epoch': 8.61}\n",
      "{'loss': 0.7838, 'learning_rate': 2.336182336182336e-05, 'epoch': 8.69}\n",
      "{'loss': 0.8462, 'learning_rate': 2.307692307692308e-05, 'epoch': 8.77}\n",
      "{'loss': 0.817, 'learning_rate': 2.2792022792022794e-05, 'epoch': 8.84}\n",
      "{'loss': 0.7455, 'learning_rate': 2.250712250712251e-05, 'epoch': 8.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7629, 'learning_rate': 2.2222222222222223e-05, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35612969caf409c9bf23e0ed03edbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Ballast Type\\checkpoint-1170\n",
      "Configuration saved in models/ViT_Ballast Type\\checkpoint-1170\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0970001220703125, 'eval_accuracy': 0.6295050456511293, 'eval_f1': 0.03153675549956877, 'eval_precision': 0.047923505513627195, 'eval_recall': 0.030938287384655084, 'eval_runtime': 16.5555, 'eval_samples_per_second': 125.698, 'eval_steps_per_second': 7.913, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Ballast Type\\checkpoint-1170\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Ballast Type\\checkpoint-1170\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7094, 'learning_rate': 2.1937321937321938e-05, 'epoch': 9.08}\n",
      "{'loss': 0.6703, 'learning_rate': 2.1652421652421653e-05, 'epoch': 9.15}\n",
      "{'loss': 0.7258, 'learning_rate': 2.1367521367521368e-05, 'epoch': 9.23}\n",
      "{'loss': 0.8245, 'learning_rate': 2.1082621082621086e-05, 'epoch': 9.31}\n",
      "{'loss': 0.7429, 'learning_rate': 2.07977207977208e-05, 'epoch': 9.38}\n",
      "{'loss': 0.7252, 'learning_rate': 2.0512820512820512e-05, 'epoch': 9.46}\n",
      "{'loss': 0.7694, 'learning_rate': 2.022792022792023e-05, 'epoch': 9.54}\n",
      "{'loss': 0.7918, 'learning_rate': 1.9943019943019945e-05, 'epoch': 9.61}\n",
      "{'loss': 0.6957, 'learning_rate': 1.965811965811966e-05, 'epoch': 9.69}\n",
      "{'loss': 0.7873, 'learning_rate': 1.9373219373219374e-05, 'epoch': 9.77}\n",
      "{'loss': 0.7602, 'learning_rate': 1.908831908831909e-05, 'epoch': 9.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7548, 'learning_rate': 1.8803418803418804e-05, 'epoch': 9.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8106, 'learning_rate': 1.8518518518518518e-05, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35726b3460d54470867f6e094e98b17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Ballast Type\\checkpoint-1300\n",
      "Configuration saved in models/ViT_Ballast Type\\checkpoint-1300\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.093361496925354, 'eval_accuracy': 0.6333493512734263, 'eval_f1': 0.04445896062110183, 'eval_precision': 0.07020817726653096, 'eval_recall': 0.039530723357488695, 'eval_runtime': 16.3828, 'eval_samples_per_second': 127.023, 'eval_steps_per_second': 7.996, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Ballast Type\\checkpoint-1300\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Ballast Type\\checkpoint-1300\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7983, 'learning_rate': 1.8233618233618236e-05, 'epoch': 10.08}\n",
      "{'loss': 0.6873, 'learning_rate': 1.794871794871795e-05, 'epoch': 10.15}\n",
      "{'loss': 0.6279, 'learning_rate': 1.7663817663817662e-05, 'epoch': 10.23}\n",
      "{'loss': 0.6886, 'learning_rate': 1.737891737891738e-05, 'epoch': 10.31}\n",
      "{'loss': 0.75, 'learning_rate': 1.7094017094017095e-05, 'epoch': 10.38}\n",
      "{'loss': 0.6394, 'learning_rate': 1.680911680911681e-05, 'epoch': 10.46}\n",
      "{'loss': 0.6985, 'learning_rate': 1.6524216524216525e-05, 'epoch': 10.54}\n",
      "{'loss': 0.6645, 'learning_rate': 1.623931623931624e-05, 'epoch': 10.61}\n",
      "{'loss': 0.7629, 'learning_rate': 1.5954415954415954e-05, 'epoch': 10.69}\n",
      "{'loss': 0.6918, 'learning_rate': 1.566951566951567e-05, 'epoch': 10.77}\n",
      "{'loss': 0.6625, 'learning_rate': 1.5384615384615387e-05, 'epoch': 10.84}\n",
      "{'loss': 0.7063, 'learning_rate': 1.50997150997151e-05, 'epoch': 10.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6976, 'learning_rate': 1.4814814814814815e-05, 'epoch': 11.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68dfa13fb4eb49d68617bd524982091e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Ballast Type\\checkpoint-1430\n",
      "Configuration saved in models/ViT_Ballast Type\\checkpoint-1430\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1442564725875854, 'eval_accuracy': 0.6290245074483422, 'eval_f1': 0.04561968902732716, 'eval_precision': 0.07076120000164994, 'eval_recall': 0.04072583231862578, 'eval_runtime': 16.5596, 'eval_samples_per_second': 125.668, 'eval_steps_per_second': 7.911, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Ballast Type\\checkpoint-1430\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Ballast Type\\checkpoint-1430\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8309, 'learning_rate': 1.4529914529914531e-05, 'epoch': 11.08}\n",
      "{'loss': 0.6986, 'learning_rate': 1.4245014245014246e-05, 'epoch': 11.15}\n",
      "{'loss': 0.657, 'learning_rate': 1.3960113960113961e-05, 'epoch': 11.23}\n",
      "{'loss': 0.6095, 'learning_rate': 1.3675213675213677e-05, 'epoch': 11.31}\n",
      "{'loss': 0.5791, 'learning_rate': 1.3390313390313392e-05, 'epoch': 11.38}\n",
      "{'loss': 0.6662, 'learning_rate': 1.3105413105413105e-05, 'epoch': 11.46}\n",
      "{'loss': 0.7619, 'learning_rate': 1.282051282051282e-05, 'epoch': 11.54}\n",
      "{'loss': 0.6232, 'learning_rate': 1.2535612535612536e-05, 'epoch': 11.61}\n",
      "{'loss': 0.6472, 'learning_rate': 1.2250712250712251e-05, 'epoch': 11.69}\n",
      "{'loss': 0.6102, 'learning_rate': 1.1965811965811967e-05, 'epoch': 11.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6568, 'learning_rate': 1.168091168091168e-05, 'epoch': 11.84}\n",
      "{'loss': 0.7364, 'learning_rate': 1.1396011396011397e-05, 'epoch': 11.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6871, 'learning_rate': 1.1111111111111112e-05, 'epoch': 12.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed9d2c9266b4a25a14ab8d0f603a53c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Ballast Type\\checkpoint-1560\n",
      "Configuration saved in models/ViT_Ballast Type\\checkpoint-1560\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1720362901687622, 'eval_accuracy': 0.6131667467563672, 'eval_f1': 0.043554137025880416, 'eval_precision': 0.061817215043021505, 'eval_recall': 0.03912179090842873, 'eval_runtime': 16.6014, 'eval_samples_per_second': 125.351, 'eval_steps_per_second': 7.891, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Ballast Type\\checkpoint-1560\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Ballast Type\\checkpoint-1560\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6488, 'learning_rate': 1.0826210826210826e-05, 'epoch': 12.08}\n",
      "{'loss': 0.6037, 'learning_rate': 1.0541310541310543e-05, 'epoch': 12.15}\n",
      "{'loss': 0.6385, 'learning_rate': 1.0256410256410256e-05, 'epoch': 12.23}\n",
      "{'loss': 0.6154, 'learning_rate': 9.971509971509972e-06, 'epoch': 12.31}\n",
      "{'loss': 0.707, 'learning_rate': 9.686609686609687e-06, 'epoch': 12.38}\n",
      "{'loss': 0.6379, 'learning_rate': 9.401709401709402e-06, 'epoch': 12.46}\n",
      "{'loss': 0.685, 'learning_rate': 9.116809116809118e-06, 'epoch': 12.54}\n",
      "{'loss': 0.6557, 'learning_rate': 8.831908831908831e-06, 'epoch': 12.61}\n",
      "{'loss': 0.7028, 'learning_rate': 8.547008547008548e-06, 'epoch': 12.69}\n",
      "{'loss': 0.6709, 'learning_rate': 8.262108262108262e-06, 'epoch': 12.77}\n",
      "{'loss': 0.6163, 'learning_rate': 7.977207977207977e-06, 'epoch': 12.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6075, 'learning_rate': 7.692307692307694e-06, 'epoch': 12.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5957, 'learning_rate': 7.4074074074074075e-06, 'epoch': 13.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec77269cf144407ea5baf8498041e4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Ballast Type\\checkpoint-1690\n",
      "Configuration saved in models/ViT_Ballast Type\\checkpoint-1690\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1857186555862427, 'eval_accuracy': 0.5992311388755406, 'eval_f1': 0.043839084873603267, 'eval_precision': 0.06405776233314778, 'eval_recall': 0.03933337247498869, 'eval_runtime': 16.5575, 'eval_samples_per_second': 125.683, 'eval_steps_per_second': 7.912, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Ballast Type\\checkpoint-1690\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Ballast Type\\checkpoint-1690\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5967, 'learning_rate': 7.122507122507123e-06, 'epoch': 13.08}\n",
      "{'loss': 0.6986, 'learning_rate': 6.837606837606839e-06, 'epoch': 13.15}\n",
      "{'loss': 0.6177, 'learning_rate': 6.5527065527065525e-06, 'epoch': 13.23}\n",
      "{'loss': 0.6863, 'learning_rate': 6.267806267806268e-06, 'epoch': 13.31}\n",
      "{'loss': 0.6566, 'learning_rate': 5.982905982905984e-06, 'epoch': 13.38}\n",
      "{'loss': 0.5966, 'learning_rate': 5.6980056980056985e-06, 'epoch': 13.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5886, 'learning_rate': 5.413105413105413e-06, 'epoch': 13.54}\n",
      "{'loss': 0.582, 'learning_rate': 5.128205128205128e-06, 'epoch': 13.61}\n",
      "{'loss': 0.6247, 'learning_rate': 4.8433048433048435e-06, 'epoch': 13.69}\n",
      "{'loss': 0.5862, 'learning_rate': 4.558404558404559e-06, 'epoch': 13.77}\n",
      "{'loss': 0.5996, 'learning_rate': 4.273504273504274e-06, 'epoch': 13.84}\n",
      "{'loss': 0.5939, 'learning_rate': 3.988603988603989e-06, 'epoch': 13.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5841, 'learning_rate': 3.7037037037037037e-06, 'epoch': 14.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ad469796964b2a8feb3272ea259bb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Ballast Type\\checkpoint-1820\n",
      "Configuration saved in models/ViT_Ballast Type\\checkpoint-1820\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1992911100387573, 'eval_accuracy': 0.6367131186929361, 'eval_f1': 0.035194939133085405, 'eval_precision': 0.045009121075805916, 'eval_recall': 0.03360126903000671, 'eval_runtime': 16.4461, 'eval_samples_per_second': 126.535, 'eval_steps_per_second': 7.965, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Ballast Type\\checkpoint-1820\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Ballast Type\\checkpoint-1820\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6042, 'learning_rate': 3.4188034188034193e-06, 'epoch': 14.08}\n",
      "{'loss': 0.5977, 'learning_rate': 3.133903133903134e-06, 'epoch': 14.15}\n",
      "{'loss': 0.6307, 'learning_rate': 2.8490028490028492e-06, 'epoch': 14.23}\n",
      "{'loss': 0.6, 'learning_rate': 2.564102564102564e-06, 'epoch': 14.31}\n",
      "{'loss': 0.5787, 'learning_rate': 2.2792022792022796e-06, 'epoch': 14.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6067, 'learning_rate': 1.9943019943019943e-06, 'epoch': 14.46}\n",
      "{'loss': 0.5968, 'learning_rate': 1.7094017094017097e-06, 'epoch': 14.54}\n",
      "{'loss': 0.5956, 'learning_rate': 1.4245014245014246e-06, 'epoch': 14.61}\n",
      "{'loss': 0.599, 'learning_rate': 1.1396011396011398e-06, 'epoch': 14.69}\n",
      "{'loss': 0.6236, 'learning_rate': 8.547008547008548e-07, 'epoch': 14.77}\n",
      "{'loss': 0.5586, 'learning_rate': 5.698005698005699e-07, 'epoch': 14.84}\n",
      "{'loss': 0.6105, 'learning_rate': 2.8490028490028494e-07, 'epoch': 14.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5881, 'learning_rate': 0.0, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f4febdfb09342069993d9c0e110eda5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Ballast Type\\checkpoint-1950\n",
      "Configuration saved in models/ViT_Ballast Type\\checkpoint-1950\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1776914596557617, 'eval_accuracy': 0.6256607400288323, 'eval_f1': 0.052768981508568125, 'eval_precision': 0.06709322744864389, 'eval_recall': 0.048300375845500766, 'eval_runtime': 16.5044, 'eval_samples_per_second': 126.088, 'eval_steps_per_second': 7.937, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Ballast Type\\checkpoint-1950\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Ballast Type\\checkpoint-1950\\preprocessor_config.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from models/ViT_Ballast Type\\checkpoint-1950 (score: 0.052768981508568125).\n",
      "Setting `WANDB_LOG_MODEL` from true to `end` instead\n",
      "Saving model checkpoint to C:\\Users\\chris\\AppData\\Local\\Temp\\tmpj0qyc2az\n",
      "Configuration saved in C:\\Users\\chris\\AppData\\Local\\Temp\\tmpj0qyc2az\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 2239.7427, 'train_samples_per_second': 55.741, 'train_steps_per_second': 0.871, 'train_loss': 0.9195040499858367, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in C:\\Users\\chris\\AppData\\Local\\Temp\\tmpj0qyc2az\\pytorch_model.bin\n",
      "Image processor saved in C:\\Users\\chris\\AppData\\Local\\Temp\\tmpj0qyc2az\\preprocessor_config.json\n",
      "Logging model artifacts. ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁█▇█▇▆▇▇▇▇▇▆▆▇▇</td></tr><tr><td>eval/f1</td><td>▁▁▂▁▂▂▁▃▃▆▆▆▆▄█</td></tr><tr><td>eval/loss</td><td>█▂▁▁▁▃▂▃▃▃▅▆▇█▇</td></tr><tr><td>eval/precision</td><td>▁▁▅▇▃▅▃▅▅██▇▇▄▇</td></tr><tr><td>eval/recall</td><td>▂▁▂▁▂▂▁▂▂▅▆▅▅▃█</td></tr><tr><td>eval/runtime</td><td>▄▇▁▁▂▇▆▇▇▄▇█▇▅▆</td></tr><tr><td>eval/samples_per_second</td><td>▄▂██▇▂▃▂▂▅▂▁▂▄▃</td></tr><tr><td>eval/steps_per_second</td><td>▄▂██▇▂▃▂▂▅▂▁▂▄▃</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>▂▃▅▇███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.62566</td></tr><tr><td>eval/f1</td><td>0.05277</td></tr><tr><td>eval/loss</td><td>1.17769</td></tr><tr><td>eval/precision</td><td>0.06709</td></tr><tr><td>eval/recall</td><td>0.0483</td></tr><tr><td>eval/runtime</td><td>16.5044</td></tr><tr><td>eval/samples_per_second</td><td>126.088</td></tr><tr><td>eval/steps_per_second</td><td>7.937</td></tr><tr><td>train/epoch</td><td>15.0</td></tr><tr><td>train/global_step</td><td>1950</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.5881</td></tr><tr><td>train/total_flos</td><td>9.68240545246937e+18</td></tr><tr><td>train/train_loss</td><td>0.9195</td></tr><tr><td>train/train_runtime</td><td>2239.7427</td></tr><tr><td>train/train_samples_per_second</td><td>55.741</td></tr><tr><td>train/train_steps_per_second</td><td>0.871</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ViT_Ballast Type</strong>: <a href=\"https://wandb.ai/cringgaard/Sailboat%20FGVC/runs/3pds0bos\" target=\"_blank\">https://wandb.ai/cringgaard/Sailboat%20FGVC/runs/3pds0bos</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230323_145715-3pds0bos\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300b30990c934a63a3c7a32415680ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\chris\\OneDrive\\Dokumenter\\GitHub\\SailFGVC\\wandb\\run-20230323_153516-1cpiz4bg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cringgaard/Sailboat%20FGVC/runs/1cpiz4bg\" target=\"_blank\">ViT_Designer</a></strong> to <a href=\"https://wandb.ai/cringgaard/Sailboat%20FGVC\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\\cache-2a585625075c0e2e.arrow and C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\\cache-b6892114b627658b.arrow\n",
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\\cache-775a837c5a184365.arrow\n",
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\\cache-e5d91e7463cbb9af.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 168, 169, 170, 171, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 266, 267, 268, 269, 270, 272, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 289, 290, 291, 292, 293, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 440, 441, 442, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 482, 483, 484, 485, 486, 487, 488, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 510, 512, 513, 514, 515, 517, 518, 519, 520, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 548, 549, 550, 551, 552, 553, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 569, 570, 572, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 659, 660, 661, 662, 663, 664, 666, 667, 668, 669, 670, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 702, 703, 704, 706, 707, 708, 709, 711, 712, 714, 715, 716, 717, 718, 719, 720, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 736, 737, 738, 739, 740, 741, 742, 743, 744, 746, 747, 748, 750, 751, 752, 753, 754, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 777, 778, 779, 780, 781, 783, 784, 785, 786, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 835, 837, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 858, 860, 862, 863, 864, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 895, 896, 897, 898, 899, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 966, 967, 968, 969, 970, 971, 972, 973, 975, 976, 977, 978, 979, 980, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1003, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1030, 1031, 1032, 1033, 1035, 1036, 1037, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1105, 1106, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1183, 1184, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1251, 1252, 1254, 1256, 1257, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1273, 1274, 1275, 1276, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1315, 1316, 1317, 1318, 1319, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1336, 1337, 1338, 1339, 1341, 1342, 1344, 1345, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1399, 1400, 1401, 1402, 1403, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1436, 1437, 1438, 1439, 1440, 1441, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1504, 1505, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1529, 1530, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1542, 1543, 1545, 1546, 1547, 1548, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1572, 1573, 1574, 1575, 1577, 1578, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1598, 1599, 1600, 1601, 1602, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1652, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1663, 1664, 1666, 1667, 1668, 1669, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1765, 1766, 1767, 1768, 1769, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1802, 1804, 1805, 1806, 1807, 1808, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1818, 1819, 1820, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1836, 1837, 1838, 1839, 1841, 1842, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880, 1881, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1904, 1905, 1906, 1907, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1922, 1923, 1924, 1925, 1926, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1968, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2010, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2037, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2080, 2081, 2082, 2083, 2084, 2086, 2087, 2088, 2089, 2090, 2091, 2092, 2093, 2094, 2095, 2096, 2097, 2098, 2099, 2100, 2101, 2102, 2103, 2104, 2105, 2106, 2107, 2108, 2109, 2110, 2111, 2112, 2113, 2114, 2115, 2116, 2117, 2118, 2119, 2120, 2121, 2122, 2123, 2125, 2126, 2127, 2128, 2129, 2130, 2131, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2141, 2142, 2143, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2151, 2152, 2153, 2154, 2155, 2156, 2157, 2158, 2159, 2160, 2161, 2162, 2163, 2164, 2166, 2167, 2168, 2169, 2170, 2171, 2172, 2173, 2174, 2176, 2177, 2178, 2179, 2180, 2182, 2183, 2184, 2185, 2186, 2187, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2196, 2197, 2199, 2200, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2208, 2209, 2210, 2211, 2212, 2213, 2214, 2215, 2216, 2217, 2218, 2219, 2220, 2221, 2222, 2223, 2224, 2225, 2226, 2227, 2228, 2229, 2230, 2231, 2232, 2233, 2234, 2235, 2236, 2237, 2238, 2239, 2240, 2241, 2242, 2243, 2244, 2245, 2246, 2247, 2248, 2249, 2252, 2253, 2254, 2255, 2257, 2258, 2259, 2260, 2261, 2262, 2263, 2264, 2265, 2266, 2267, 2269, 2271, 2272, 2273, 2274, 2275, 2276, 2277, 2278, 2279, 2281, 2282, 2283, 2284, 2285, 2287, 2288, 2289, 2290, 2291, 2295, 2296, 2297, 2298, 2299, 2300, 2301, 2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2310, 2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2330, 2331, 2332, 2334, 2335, 2336, 2337, 2338, 2339, 2340]\n",
      "[1, 6, 7, 8, 9, 10, 12, 13, 15, 16, 18, 19, 21, 22, 23, 29, 31, 32, 33, 36, 37, 40, 41, 44, 46, 47, 49, 50, 51, 54, 56, 57, 61, 62, 63, 64, 65, 70, 71, 72, 73, 76, 77, 79, 80, 82, 83, 87, 89, 94, 95, 96, 98, 99, 100, 102, 104, 105, 106, 107, 108, 109, 112, 113, 115, 116, 117, 119, 123, 125, 128, 130, 131, 132, 133, 136, 137, 141, 142, 143, 144, 145, 146, 147, 149, 150, 151, 153, 159, 160, 161, 163, 164, 167, 168, 170, 172, 174, 176, 177, 178, 179, 180, 181, 182, 183, 190, 191, 192, 194, 195, 197, 198, 199, 201, 204, 207, 211, 212, 213, 214, 216, 220, 221, 222, 224, 225, 226, 228, 230, 231, 233, 239, 243, 244, 245, 246, 248, 249, 251, 252, 253, 254, 255, 256, 259, 261, 262, 264, 265, 267, 271, 273, 274, 276, 278, 279, 282, 284, 285, 286, 288, 291, 293, 295, 299, 300, 301, 304, 306, 307, 308, 312, 313, 314, 317, 322, 326, 327, 328, 329, 331, 333, 336, 337, 340, 343, 345, 346, 347, 349, 353, 358, 360, 362, 367, 368, 369, 370, 371, 373, 374, 375, 378, 381, 382, 384, 386, 387, 388, 392, 393, 395, 396, 397, 405, 408, 410, 411, 415, 420, 421, 422, 423, 424, 429, 430, 431, 432, 436, 438, 439, 440, 442, 443, 444, 445, 453, 455, 462, 463, 466, 471, 472, 474, 476, 478, 479, 480, 481, 483, 485, 487, 488, 489, 490, 491, 493, 496, 500, 502, 506, 509, 510, 511, 512, 514, 515, 516, 520, 521, 522, 523, 524, 529, 531, 533, 536, 537, 540, 541, 542, 545, 546, 549, 550, 551, 552, 554, 555, 557, 559, 564, 565, 566, 567, 568, 569, 571, 572, 573, 574, 578, 583, 586, 587, 590, 592, 594, 598, 599, 600, 601, 604, 608, 609, 610, 613, 616, 617, 623, 624, 625, 628, 630, 632, 638, 640, 642, 643, 653, 654, 656, 658, 660, 662, 663, 664, 666, 669, 670, 671, 673, 677, 680, 681, 683, 685, 687, 689, 698, 699, 701, 703, 704, 705, 709, 710, 711, 713, 714, 715, 717, 720, 721, 722, 723, 728, 729, 730, 731, 734, 735, 736, 738, 744, 745, 746, 747, 749, 752, 753, 754, 755, 756, 757, 761, 762, 763, 765, 767, 768, 772, 776, 779, 780, 782, 784, 786, 787, 794, 795, 796, 797, 799, 800, 801, 802, 803, 805, 806, 808, 809, 812, 818, 819, 823, 824, 826, 827, 829, 834, 836, 838, 841, 848, 853, 855, 857, 859, 861, 862, 865, 867, 869, 870, 872, 876, 877, 879, 883, 887, 890, 891, 892, 894, 897, 898, 900, 901, 902, 903, 905, 906, 911, 912, 913, 917, 920, 922, 924, 932, 937, 938, 941, 948, 949, 950, 964, 965, 966, 970, 971, 973, 974, 977, 981, 984, 987, 990, 991, 993, 994, 999, 1001, 1002, 1003, 1004, 1011, 1012, 1013, 1016, 1018, 1019, 1023, 1024, 1032, 1033, 1034, 1038, 1042, 1043, 1047, 1048, 1049, 1050, 1055, 1056, 1058, 1060, 1062, 1063, 1064, 1065, 1066, 1071, 1074, 1075, 1081, 1082, 1083, 1088, 1089, 1091, 1095, 1100, 1101, 1102, 1103, 1104, 1106, 1107, 1108, 1110, 1112, 1116, 1118, 1122, 1125, 1126, 1128, 1131, 1132, 1140, 1141, 1144, 1145, 1148, 1149, 1150, 1158, 1159, 1160, 1166, 1172, 1179, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1193, 1197, 1198, 1199, 1205, 1212, 1213, 1215, 1217, 1226, 1229, 1231, 1232, 1233, 1234, 1235, 1239, 1240, 1241, 1243, 1247, 1250, 1252, 1253, 1255, 1257, 1258, 1265, 1266, 1268, 1272, 1274, 1276, 1277, 1278, 1284, 1286, 1287, 1292, 1294, 1299, 1301, 1307, 1308, 1310, 1311, 1314, 1320, 1327, 1330, 1331, 1334, 1335, 1336, 1338, 1339, 1340, 1343, 1346, 1347, 1352, 1354, 1358, 1359, 1363, 1365, 1367, 1368, 1370, 1371, 1373, 1377, 1379, 1382, 1384, 1385, 1386, 1387, 1391, 1393, 1395, 1398, 1402, 1404, 1407, 1408, 1409, 1410, 1414, 1415, 1416, 1417, 1420, 1421, 1422, 1423, 1431, 1435, 1437, 1441, 1442, 1448, 1449, 1452, 1453, 1458, 1460, 1463, 1464, 1465, 1467, 1474, 1476, 1477, 1482, 1483, 1484, 1485, 1487, 1488, 1495, 1500, 1501, 1503, 1505, 1506, 1514, 1517, 1519, 1521, 1524, 1528, 1529, 1531, 1541, 1542, 1544, 1545, 1548, 1549, 1552, 1555, 1556, 1563, 1569, 1571, 1575, 1576, 1579, 1585, 1586, 1589, 1590, 1593, 1597, 1598, 1599, 1600, 1603, 1609, 1612, 1616, 1618, 1624, 1625, 1630, 1631, 1633, 1636, 1643, 1644, 1647, 1650, 1651, 1652, 1653, 1657, 1662, 1665, 1668, 1669, 1670, 1671, 1672, 1674, 1675, 1676, 1679, 1685, 1689, 1696, 1697, 1700, 1706, 1715, 1730, 1732, 1738, 1741, 1743, 1748, 1752, 1754, 1757, 1758, 1759, 1764, 1765, 1766, 1769, 1770, 1773, 1774, 1775, 1778, 1783, 1787, 1788, 1792, 1798, 1801, 1803, 1807, 1808, 1809, 1817, 1818, 1821, 1824, 1827, 1835, 1840, 1843, 1844, 1845, 1846, 1851, 1852, 1853, 1855, 1857, 1858, 1866, 1868, 1875, 1877, 1880, 1882, 1883, 1886, 1892, 1896, 1897, 1901, 1902, 1903, 1907, 1908, 1909, 1921, 1927, 1928, 1932, 1936, 1937, 1940, 1944, 1945, 1953, 1959, 1961, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1972, 1976, 1981, 1984, 1990, 1991, 1996, 2000, 2003, 2009, 2011, 2014, 2020, 2021, 2022, 2023, 2025, 2035, 2036, 2043, 2047, 2049, 2062, 2072, 2073, 2074, 2076, 2079, 2081, 2085, 2087, 2089, 2091, 2095, 2097, 2104, 2105, 2106, 2107, 2111, 2124, 2128, 2129, 2137, 2138, 2139, 2140, 2145, 2150, 2151, 2152, 2156, 2157, 2165, 2168, 2173, 2175, 2190, 2192, 2193, 2195, 2198, 2199, 2200, 2201, 2203, 2207, 2211, 2221, 2223, 2230, 2233, 2235, 2239, 2240, 2243, 2247, 2250, 2251, 2256, 2257, 2259, 2263, 2266, 2268, 2270, 2278, 2280, 2281, 2284, 2286, 2288, 2292, 2293, 2294, 2295, 2303, 2304, 2308, 2309, 2311, 2313, 2318, 2320, 2329, 2333, 2334]\n",
      "[568, 749, 2175, 573, 1346, 1817, 533, 99, 1857, 965, 1314, 1801, 2124, 1487, 1435, 1840, 776, 1038, 1650, 61, 1048, 244, 1809, 1653, 1442, 1370, 423, 1966, 271, 787, 1034, 1903, 1185, 950, 2251, 894, 1358, 259, 1103, 174, 1597, 1371, 1927, 1902, 1277, 489, 2256, 1579, 1122, 1969, 191, 1764, 15, 1172, 1474, 1095, 600, 1670, 1343, 554, 1921, 721, 1544, 172, 1631, 2270, 782, 521, 1488, 1272, 1452, 1255, 151, 481, 381, 859, 422, 900, 1803, 1335, 349, 865, 1253, 1706, 1603, 1258, 1571, 224, 745, 2292, 317, 981, 1404, 1576, 1665, 1981, 1770, 571, 1908, 701, 838, 671, 1065, 861, 2329, 1787, 2165, 163, 2333, 2011, 801, 2250, 1531, 1752, 1696, 1506, 511, 713, 658, 1835, 1250, 1528, 1843, 1821, 883, 1004, 710, 1541, 2293, 808, 705, 1882, 755, 1967, 912, 2036, 145, 1002, 2079, 1662, 735, 2268, 288, 2195, 1883, 857, 2085, 1340, 1715, 2198, 131, 1549, 1788, 439, 265, 2294, 1159, 62, 1198, 214, 1398, 1083, 1107, 509, 1197, 1320, 273, 1503, 836, 1651, 1386, 683, 516, 445, 834, 2280, 1012, 116, 1182, 2286, 1104, 974, 2009, 2022]\n",
      "['Ron Holland & Rolf Gyhlenius', 'C. Raymond Hunt', 'Krogen Brothers', 'Simon Grieg', 'Nelson/Marek', 'Reichel Pugh Yacht Design', 'NaN', 'Various', 'Julian Bethwaite', 'Bruce Farr', 'Christian Maury', 'Chris Benedict', 'André Cornu', 'John Westell/Austin Farrar ', 'Maury/Sergent', 'Bethwaite Design/Frank Bethwaite', 'Anton Miglitsch', 'Wilson-Marquinez (ARG)', 'Gösta & Gunnar Edwardsson', 'David Thomas', 'J&J Yacht Design/Doug Peterson', 'Joubert - Nivelt', 'Joubert-Nivelt', 'John O. Johnson', 'Jerry and David Hubbard', 'Ian Proctor /Abbott', 'Bill Abbott Sr.', 'Jan Larsen/Abbott', 'W. R. Loughlin', 'Chuck Paine', 'Oracle Racing Team', 'G. William McVay', 'Ted Carpentier', 'Peter Norlin', 'Chris Mitchell', 'Oliver Lee /Chris Butler', 'Chris Butler', 'Lars Olof Norlin', 'Joe Adams', 'Adams', 'Doug Peterson', 'Angelo Lavranos', 'John Swarbrick', 'Biscontini Yacht Design/Nauta Yachts', 'Reichel/Pugh', 'Walter Schutz', 'Gary Mull', 'Groupe Finot', 'Rodger Martin and Steve Koopman', 'Rodger Martin', 'Larl Linblöm', 'Simonis Voogd Design', 'Oliver Lee', 'C&C', 'Marc Lombard', 'Peter Stevenson', 'Frank V. Butler', 'Raymond Richards', 'Colin Archer/William Atkin', 'Uffa Fox/Greg Gregory', 'Dieter Hänsel', 'Dieter Hä&#776;nsel', 'Roberto Rovere', 'German Frers', 'Carl Alberg', 'Rolf Magnusson', 'W. Tripp/A. Lecomte', 'W. Tripp/Dolf Lecomte', 'S&S/D. Le Compte', 'A. E. Luders/Le Comte', 'Hans Starreveld', 'John G. Alden & Co.', 'Niels Helleberg', 'Alden Associates/Nils Helleberg', 'Alden Yachts', 'Alden', 'John Alden', 'Berret Racoupeau Yacht Design', 'Nathanael Herreshoff', 'Herreshoff', 'Halsey Herreshoff', 'Alerion Yachts', 'Gary Hoyt', 'Carl Schumacher', 'John Letcher', 'Loc Goepfert', 'Henri Amel', 'E. G van de Stadt', 'Fred Bingham/Bruce Bingham', 'John Westell', 'George Owens/Robert Harris', 'Walter Scott & T. R. Allmand', 'W. H. Scott', 'W.H. Scott/T.R. Allmand', 'Berret/Racoupeau', 'Berret-Racoupeau', 'Berret-Racoupeau/Darnet', 'Berret-Racoupeau / Franck Darnet', 'Alf Ortang', 'Jan Bjerke/Alf Ortang', \"J.M. L'Hermenier\", 'J. Faroux', 'Frans Maas', \"J. M. L'Hermenier\", 'Ted Brewer', 'Robert Perry', 'Brewer/Walstrom', 'Ron Holland', 'Mark Ellis', 'Ted Brewer/Robert Walstrom', 'Danilo Cattadori', 'Sparkman $ Stephens', 'Sparkman & Stephens', 'E. G. van de Stadt', 'Alpa', 'John H. Illingworth', 'Anselmi Boretti/Illingsworth', 'Illingworth & Associates', 'D.Cattadori', 'Roberto Róvere', 'Tom Roland', 'Tanguy Le Bihan', 'Mike Arnold/Rondar', 'P. Briand', 'Grahame Shannon', 'Amel', 'Amel/Berret-Racoupeau', 'Ron Bertholf', 'Arthur S. Henry', 'Arthur S Henry', 'Francis Sweisguth', 'Henri Garreta', 'Ted Hood', 'Carl Andersson', 'Cyrus Hamlin, Farham Butler', 'Cyrus Hamlin, F. Butler', 'Donald Pye', 'Holman & Pye', \"Wilf O'Kell\", 'Bruce Binham', 'Hans Denhertog', 'Alan Andrews', 'Bruce Bingham', 'John Holmes', 'Philip Rhodes', 'A. E. Luders/Robert Henry Jr.', 'Ocke Mannerfelt', 'Ted Clements', 'Dominique Presle', 'Peter Schmitt', 'Charles Morgan', 'Adam & Michael Orych', 'Michal & Adam Orych', 'Jim Antrim', 'J. R. Macalpine-Downie', 'Paul Elvstrom/Jan Kjaerulff ', 'Carl Beyer', 'Carl Bayer', 'Jan Kjaerulff', 'Judel/Vrolijk & Co.', 'Bruce Kirby', 'Neil Coster', 'Arthur Javes', 'Peter Barrett ', 'Peter Barrett / Stan Miller', 'Frank Parish', 'P.Harlé', 'Harry Becker', 'Neil Fowler', 'Roberts/Haberman', 'Tony Castro', 'Wirth Munroe', 'Stefan Qviberg/Torgny Jansson', 'Stefan Qviberg', 'Tommy Stål', 'Stefan Quiberg', 'Dudley Dix', 'Ian Howlett/Rob White', 'Dick Newick', 'Thomas Gillmer', 'Olle Enderlein', 'P. Harle', 'Jacek Centkowski', 'Michel Dufour', 'A. M. Deering', 'Neil Fowler & Roy Martin', 'Schionning Design', 'Rhodes', 'Robert L. Taber', 'Hans Groop', 'Jean-Jacques Herbulot', 'Herbulot', 'Ettore Santarelli', 'Stéphan Vallet', 'VPLP Design', 'Perspective Yacht Design', 'Eric Hanseval', 'Uffa Fox', 'Maurice Griffiths', 'Håkan Södergren', 'Flahault/Nivelt', 'CSJ Roy', 'John Bennet & Associates', 'Georges Auzepy-Brenneur', 'W. Starling Burgess', 'Walter F. Rayner', 'Chris White', 'J & J Design', 'Yannis Raptis', 'D. Martin', 'Bowes & Mower', 'Roberto Barros', 'Philippe Briand', 'Laurent Giles', 'Mark Ellis/Hinterhoeller', 'Graham Johnston', 'Jack Drew', 'Laurent Giles/Pininfarina', 'Rod Macalipe-Downie', 'Giovanni Ceccarelli', 'Ceccarelli Yacht Design', 'Rob Humphreys', 'Hakan Sodergren', 'Leif Beiley', 'Lief Beiley', 'David & Jerry Hubbard', 'Luca Brenta', 'Luca Brenta Yacht Design', 'Eric Maizey', 'Knud H Reimers', 'J. H. McGlasson', 'Joseph McGlasson', 'Bob Finch', 'Harlé', 'Du Toit Yacht Design', 'Roger Hill/Phillip Berman', 'Anton du Toit', 'Phillip Berman/Anton du Toit', 'Gunnar Cardell', 'W. Shad Turner', 'Lyle C. Hess/Richard Arthur', 'Shad Turner/William Downing', 'Lyle C. Hess', 'Lyle Hess', 'Joubert', 'Xavier Faÿ', 'Xavier Faÿ; Olivier Poncin', 'Xavier Fay/Poncin/Couedel', 'Xavier Faÿ; Lasta design Studios (interior)', 'Xavier Faÿ; Lasta Design Studio (interior)', 'Lasta Design STUDIO', 'Robert Tucker', 'Wojciech Spisak', 'C&C Design Group', 'Judel/Vrolijk', 'C&C Design', 'Tripp Design', 'C & C Design Group', 'Knud Olsen', 'Rod Macalpine-Downie / Dick Gibbs', 'Andrew Stewart', 'Pierre Rolland', 'Dick Lefeber', 'I. Neilson', 'Niels Jeppesen', 'Richard L. Reid', 'M. S. Redman', 'Jack Laurent Giles', 'Gordon Saunders & Dick Medve', 'John G. Alden/Cifford Swaine', 'Howard Siddons', 'James E. Graves', 'Sweisguth/Mower', 'J. Howard Perrine', 'John Barnett', 'Ron & Gerry Hedlund', 'Andre Beneteau', 'Gus Linell', 'Axel Mohnhaupt', 'J&J Design', 'Kurt W. Schroter', 'Kurt W. Schröter', 'Farr Yacht Design', 'B. Farr', 'Doug Peterson/J&J Design', 'Reuben Trane', 'Ted Gozzard', 'Haydn Gozzard', 'Winthrop L. Warner', 'Børresen Brothers', 'Borge Bringsvaerd', 'Walter Scott', 'Manuel Nunes & Sons', 'Bernt Andersson', 'Bill Sauerbrey', 'John Beetle', 'William Fife Jr.', 'Fife', 'Linton Hope,', 'Peter A. Ibold', 'Peter Ibold/Vicente Belliure', 'Peter Ibold', 'Peter Pfab', 'Eugène Cornu', 'Charles Nicholson', 'Jean Beret/J. Fauroux/Group Finot', 'Finot / Conq Assoc.', 'Berret - Racoupeau', 'Bruce Farr & Armel Briand', 'Farr Yacht Design/Armel Briand ', 'judel/vrolijk & co', 'William Tripp, Jr.', 'William Tripp Jr.', 'Dykstra Naval Architects', 'Richard Wrighton', 'Richard Wrighton,', 'Vincent Lebailly', 'Wrighton', 'Jan Kjærulff', 'Elvstrøm & Kjærulff ', 'Elvstrom & Kjaerulff', 'Svend Aage Christensen', 'Elvstrøm & Kjærulff', 'Bjorn Jensen', 'Gilles Costantini', 'David Binks', 'Fred C.Brewer / Alden & Associates', 'Phil Bolger/Peter Duff', 'Jan Becker', 'Alan Hill', 'N. G. Herreshoff', 'Van de Stadt', 'Daniel Webb', 'Norman Blanchard Sr./Ben Seaborn ', 'Norman Blanchard Sr.', 'Ian Howlett/John Craig', 'William Tripp Jr,', 'Christian Bolinger.', 'Christian Bolinger', 'Sidney Herreshoff', 'Harry R. Sindle', 'Phillippe Briand', 'Tim Jackett w/Bob Johnson', 'Drake Sparkman/Sparkman & Stephens', 'Ken Watts', 'Cuthbertson & Cassian', 'William Garden', 'W. J. Roué', 'Camper & Nicholson', 'Bill Dizon', 'Per Qvist', 'Jacques Deperon', 'Ker Yacht Design', 'Robert Finch', 'DeClercq', 'Walter H. Scott', 'Paul Cronin', 'Mario Cossutti', 'Francois Sergent', 'Clive Jeffries', 'Alan Buchanan', 'John G. Alden & Assoc,', 'John G. Alden & Associates', 'Geerd N. Hendel', 'Jacek Wasowski', 'Andreas Wozniak', 'Philippe Briand /Hugon Couëdel', 'Jean-François Delvoye', 'Ian Howlett', 'Bruno Boström/Grandinsson', 'Bruno Boström', 'Ian Proctor', 'Jean-Jacques Hurbulot', 'C. W. Paine', 'Peter Cole', 'Philip Rhodes/William Garden', 'Ian L. Anderson', 'C.W. Paine Yacht Design Inc.', 'Holman and Pye', 'Alan H. Buchanan', 'P. E. Ferguson', 'Sergio Abrami', 'Dick Koopmans', 'Dick Koopmans Sr..', 'Simonis-Voogd', 'D. Koopmans Sr..', 'Simonis Voogd', 'van de Stadt', 'Mark Bremer', 'Joel White', 'Robert Stone', 'Finot / Harle', 'Philippe Harlé', 'Finot', 'Paul Coble', 'Carl Alberg ', 'Dieter Empacher', 'Ted Hood / Dieter Empacher', 'Halsey C. Herreshoff', 'Deiter Empacher ', 'Clifford P. Swain /John G. Alden Assoc.', 'Ted Hood/Dieter Empacher', 'Ted Hood / D. Empacher', 'Simon Davidson and Robert Underwood', 'Linton Hope', 'Mark Ellis Design', 'Doug Zurn', 'Starling Burgess', 'Rod Macalpine-Downie/Dick Gibbs', 'G. William McVay/Bayliner', 'Alan Payne/Bayliner', 'Lock Crowther', 'Gary Mull/Bayliner', 'Bob Neck & Clark Scarboro', 'D. Peterson (unauthorized)', 'Doug Peterson (unauthorized)', 'D. Peterson (unauthorized)/Bayliner', 'Bill Buchan Sr. & John Buchan', 'Bob Mayo', 'Greg Young (NZ)', 'Peter Milne', 'Chuck Burns', 'R. T. Miller', 'L. F.  Herreshoff', 'Nathaniel Herreshoff', 'Ian Bruce', 'J.O. Johnson', 'Chris Hood/David Robison', 'Bill Symons', 'Don Clark', 'Greg Goodall', 'Cossutti Yacht Design', 'W.I.B. Crealock', 'W.I.B. Crealock/Dennis Garrett', 'W.I.B. Crealock ', 'Chuck Paine/Ed Joy', 'William Crealock', 'Beneteau', 'Jack Holt', 'Judel/Vrolijk & Co', 'Henry Martinak/IME Yachting (FRA)', 'C. William Lapworth ', 'C. William Lapworth', 'William Lapworth', 'C. R. Hunt  Assoc.', 'Bill Lapworth', 'C. Raymond Hunt  & Assoc.', 'C. W. Lapworth', 'C. Raymond Hunt & Assoc.', 'Lapworth', 'P. Boyce (Hunt Assoc.)', 'Raymond Hunt & Assoc.', 'C. William Lapworth/Calgan', 'Michael McCreary', 'Nicholas Potter', 'André Bénéteau', 'A. Beneteau', 'Wendell H. Calkins', 'C. Gilbert', 'David Walters', 'Winthrop Warner', 'Crowninshield/R. N. Burbank', 'Bernt Lindquist', 'Andrea Vallicelli', 'E. Cornu', 'Victor. Brix', 'Edward S. Brewer', 'Hervé Nollet and Clément Salzes', 'Charles Whittholz', 'Charles S. Gurney', 'Andrew C. Vavolotis ', 'George Stadel', 'Clive M. Dent', 'Marek', 'William Atkin/Ed Monk', 'William Atkin/Cecil Lange', 'Lehman/W. D. Schock', 'Ted Carpentier/Frank Butler', 'Frank Butler', 'Frank Butler/Gerry Douglas', 'Gary Mull / Frank Butler', 'F. Butler', 'Nelson Marek/Gerry Douglas', 'Yves Mareschal', 'Martin Fischer, Greg Goodall', 'Escape Sailboat Co.', 'O. H. Rodgers/Scott', 'David Cheverton', 'Leonardo da Costa Sayago', 'Alden Assoc.', 'Tim Kernan', 'Alan Warwick', 'John Duncanson/David Rose', 'Alan Gurney', 'Günther Thomat', 'Carkeek Design Partners.', 'Richard Carlson', 'Ron Swanson', 'Rob Carpenter', 'Dieter Blank', 'Dick Carter', 'Jerry Cartwright', 'Robert Smith', 'Robert A. Smith', 'Steven Douglas', 'J. Winterbotom/Tom & Mary Lack', 'Tom Lack/J. Winterbotom', 'Tom Lack', 'J. Winterbotham/T.M. Lack', 'John Winterbotom', 'Winterbotom/Lack/Duff', 'Carpentier/Butler', 'Catalina Yachts', 'Frank Butler/ Bob Finch', 'Gerry Douglas', 'Gerry Douglass', 'Sparkman & Stephens / Butler', 'G. Douglas / Catalina', 'Frank Douglas/Gerry Douglas', 'Nelson/Marek / Catalina', 'Seymour Paul', 'Lock Crowther /C. Barreau', 'Christophe Barreau', 'Lock Crowther / Christophe Barreau', 'Bureau d’études Catana', 'Christophestophe Barreau', 'Bureau d’études Catana/Marc Lombard', 'George W. Patterson', 'Wyatt and Freeman/Terry Compton', 'Terry Compton', 'Peterson/Salthouse', 'Laurie Davidson', 'Bob Salthouse/Laurie Davidson', 'Bob Salthouse', 'Stan Evanson/Johann Wester', 'Brewer/Fuhriman', 'Bryce Fuhriman', 'Leif Ängermark', 'Ängermark/Qviberg', 'Kim Holman', 'Dubois', 'Ed Dubois', 'Edward Dubois', 'Albert Sedlmayer', 'Gaudry', 'F. S. Ford', 'Alex McGruer', 'Hector Ballester', 'Angus Primrose ', 'Howard Stern', 'John G. Alden', 'Jaques Gaubert', 'Jacques Gaubert', 'A. Mauric - J. Gaubert', 'McCune', 'Britton Chance', 'David Thomas/Ken Freivokh', 'Julian Everitt', 'Angelo Lavranos.', 'Michel Joubert', 'Gilbert Caroff', 'Kingdon Watt Jr.', 'Edwin Monk Jr,', 'Bob Ames', 'Robert B. Harris', 'Ray Richards', 'Robert H. Perry', 'Rod Macalpine-Downie', 'Development Clas', 'John E. Cherubini', 'Ernest H. Hartge', 'Frank Meldau', 'Frederick Geiger', 'S. C. Huntingford', 'Scott Kaufman', 'Scott Sprague', 'Halsey Hereshoff', 'Michel Pocock', 'John Butler', 'Ian Proctor / Graham Dodd / George Blanchard', 'Bruce Fairlie', 'Janusz Maderski', 'W. Shad Turner ', 'Peter Van Dine', 'John C. Harris', 'Craig Walters', 'Andrzej Skrzat', 'A. E. Luders', 'A. E. Luders, Jr.', 'Adrian Keough/Scott Jutson', 'Scott Jutson', 'Juan Kouyoumdjian', 'Alfred Mylne', 'Nelson/Merek', 'Farr Yacht Design, Ltd.', 'Jay R. Benford', 'Philippe Briand/Jean-Marc Platon', 'Bruce Roberts/Grahame Shannon', 'William Shaw', 'Alan F. Hill', 'Don Karmin', 'David Feltham', 'Peter Fletcher', 'Harlé - Mortain', 'Andrej Justin', 'Andre Cornu', 'P. Harlé', 'P. Cole & Assoc.', 'Jim Taylor', 'Alan Payne', 'J. McGlasson', 'Columbia/McGlasson', 'Columbia Yachts', 'William H. Tripp Jr.', 'Wirth Monroe /Richard Valdez', 'William Tripp Sr.', 'William Tripp Jr./ B.  Seeley', 'William Tripp', 'William Tripp Jr', 'Sigurd Herburn/Columbia Yachts', 'William H. Tripp Jr. ', 'Joseph M. Dyer', 'John Bennet & Assoc.', 'Clark Mills', 'Bob Johnson', 'C. Mills/Com-Pac', 'Hutchins Group', 'Hutchins', 'Vallicelli', 'Finot - Fauroux ', 'Group Finot', 'van de Stadt/Group Finot', 'Sergio Lupoli', 'A. Vallicelli', 'Valicelli', 'Groupe Finot/D. Peterson', 'Van De Stadt/Finot', 'Andrew Simmons', 'C. Lowndes Johnson', 'Kenneth Albinsson', 'Edwin Monk Sr.', 'Ingemar Boding', 'Thomas Bern', 'Ian Farrier', 'Knud E. Hansen & Jan Kjærulff', 'Charles Ludwig', 'Aborn Smith', 'Gunter Heuchmer & Don Lees', 'Claude Allen Smith', 'Culler/Hunt/Howland', 'C. Raymond Hunt, Waldo Howland', 'Mick Price', 'Daniele Buizza', 'Helmut Stöberl', 'Alberg/Karl-Heinrich Lehmann/Klaus Felz/Uli Labor', 'John Conser', 'Johann Tanzer', 'Brewer & Wallstrom', 'Ben Lexcen', 'David Sadler', 'Arthur Edmunds', 'David Alan-Williams', 'G. Luyten', 'Dick Zaal', 'Jac. de Ridder', 'Uus van Essen', 'U. van Essen', 'U. Van Essen/Dick Zaal', 'D. Zaal', 'Dick Zaal ', 'Georg Nissen', 'Dick Zaal / Georg Nissen', 'Dick Zaal / Doug Peterson', 'Cole Beadon', 'C. Hamlin/Butler', 'E. Farnham Butler', 'W. .H Rowlands', 'Stan Huntingford', 'Rod McAlpine-Downie/Dick Gibbs', 'Marius Corbin', 'Robert Dufour/Marius Corbin', 'John Corby', 'Corby', 'B&B Yacht Designs', 'C. A. Martzoucos', 'Ted Irwin', 'William Fife III', 'Roger Dongray', 'Eric Bruneel/Gildas Cornic', 'Andrew Wolstenholme', 'Ed Edgar/Frank Butler', 'Finch  & Butler', 'J. Brooke', 'Corsair/Farrier', 'Corsair Marine', 'Corsair Design Team', 'François PERUS', 'Robert F. Matteson', 'Stanley Butler/Edwin Mairs', 'Prout', 'Ian Anderson', 'Roger Dongay', 'Michael Henderson', 'Ray Creekmore', 'Lee Creekmore', 'Richard C. Hill', 'C.T. Allen', 'Wyatt & Freeman', 'C. William Lapworth/A. Nairne', 'Hein Driehuyzen', 'Jules Fleder', 'Bill Luders', 'Ian Farrier/Corsair Design Team', 'Barry Moore', 'Raymond Wall', 'Frank Hamlin/Peter Schmitt', 'Lazzara', 'Johan Valentijen', 'C. S. Chen', 'Ta Chaio', 'Yves-Marie Tanton', 'Kauffman & Ladd', 'Kaufmann & Ladd', 'E. G. Van de Stadt', 'Hugh Rossiter', 'Eric White & Alan Hill', 'Alan Pape', 'Berret-Racoupeau.', 'George Hinterhoeller', 'Phil Morrison', 'C. John Thorpe', 'Jack Köper', 'Rod Macalpine-Downey / Dick Gibbs', 'Eldredge McGinnis', 'Artù Chiggiato', 'Arthur Robb ', 'Olin Stephens', 'Rodney March', 'Yves Loday ', 'Yves Loday/Reg White', 'Willem de Vries-Lentsch', 'Farrier/Corsair', \"Uffa Fox/O'Day\", 'Graal', 'E. G. van de Stadt/Cees van Tongeren', 'Georges Silvant/Jacques Lebrun', 'MacLear & Harris', 'Peter Dean', 'Torild Larsson', 'Guy Tyrwhitt-Drake', 'Sebschmidt Architecte Naval Sàrl', 'André Herskovits and Philippe Thomé', 'Peter Brett', 'Jacques Gaubert/André Mauric', 'Talman Bigelow/Robert Baker', 'Eva M. Hollman', 'Risto Kristeri / Seppo Mäkelä.', 'Häkan Södergren', 'E. G. van de Stadt ', 'Simonis & Voogd', 'Van De Stadt', 'judel/vrolijk & co.', 'Judel / Vrolijk', 'McGlasson', 'William Crealock/Edward DeLong', 'Andre Mauric', 'U. van Essen / Charles Teeter', 'Charles Whittolz', 'Michael Quick', 'B. Desjoyeaux', 'Ted E. Graves', 'Ernest Tucker', 'George Hazen', 'Kaufman & Assoc.', 'Wallstrom, Watkins & Assoc', 'Joseph V. Puccia', 'E. Dubois', 'Hatfield & Palmer', 'Peter Hatfield', 'Oscar Mayr Design', 'Bill Dixon', 'Bernt Lindquist/Peter Ståhle', 'Pierre Rolland/Pierre Delion', 'F. Sergent', 'Mills Design', 'Archie Arroll', 'Glenn & Murray Corcoran', 'Glen & Murray Corcoran', 'Jack A. Helms', 'John Sharp', 'Philipe Pouvreau', 'John G. Alden Assoc.', 'Peter Bosgraaf', 'Phil Bolger', 'Bob Poole', 'Henry Morschladt and Bob Poole', 'Gert Gerlach', 'Johann Anker', 'Borge Quorning', 'Børge Quorning', 'Jens Quorning and Steen Olsen', 'Jens Quorning', 'Borge Quorning/Jens Quorning', \"George O'Brien Kennedy\", 'Prof. Ir. W. Draijer', 'Umberto Felci', 'John Watkinson', 'John L. Watkinson', 'John Hanna/W.I.B. Crealock', 'Michael Schallmann', 'Leen Hoogmoed', 'Jacob Vierø', 'G. Diller & H. Schwill', 'Diller & Schwill', 'Massimo Paperini', 'Thorkild Lind', 'Dufour', 'Michel Dufour ', 'Jacques Fauroux', 'Felci Yacht Design', 'Olivier Poncin/J&J Design/Dufour', 'Michael Dufour', 'Umberto Felci / Patrick Roséo', 'Umberto Felci/Patrick Roséo', 'Mortain & Mavrikios', 'Umberto Felci & Patrick Roséo', 'Jean Berret', 'Johan Valentijn', 'P. Harle/A. Mortain', 'J. Valentijn', 'J & J Designs', 'Yann Chabaud / Olivier Poncin', 'J & J Design / Olivier Poncin ', 'J & J Designs/Olivier Poncin', 'O.Poncin/Berret', 'Laurent Cordelle', 'Jean-Louis Noir', 'Duncanson', 'Allen Blackburne', 'Alois Roland', 'Philippe Costard', 'Stephen Seaton', 'Durbeck', 'John C.  Alden', 'Charles Street', 'Philip Rhodes / Charles Wittholz/Dyer', 'Rhodes/Tanton', 'Rhodes/Dyer', 'Joubert/Nivelt', 'Arnold Meyer Sr', 'Parsak & Wurmfeld', 'Maclear & Harris', 'Gaastmeer/Terpstra Design', 'Hoek Design', 'Mike Brennan', 'Claude A. Smith', 'Eliot Spalding', 'Eldridge/McInnis', 'Eldredge-McInnis', 'Olle Blomqvist', 'Peter Snell', 'Epaminonda Ceccarelli', 'Maurice Edel', 'Edel', 'Sylvestre Langevin', 'Yvonne Faulconnier', 'Strahlmann', 'Charles McGregor', 'Jacobin Design', 'Robert Humphreys', 'Humphreys Yacht Design', 'Humphreys Yachts Design', 'Berret-Racoupeau Design', 'Philippe Harle', 'Phillipe Harle', 'P. Harle / A. Mortain', 'Harle & Mortain', 'Gilles Vaton', 'C. R. Holman', 'Greg Elliott', 'Elliott', 'Paul Elvstrom', 'R. Gardner/L. Hedges/J. Bott', 'Reg Gardner', 'Reg Gardner/Endeavour Yachts', 'Graham Tilley/Marine Reasearch pty.', 'Ted Irwin / Dennis Robbins', 'Bruce Kelley', 'Dennis Robbins/Creekmore', 'Endeavour/Creekmore', 'Johan Valentijn ', 'Robert Johnson', 'R. C. Lazzarra', 'Norman Newell', 'Endeavour/Cortland Steck', 'Endeavour', 'Marc Laurent', 'William Atkin', 'Bruce King', 'W. I. B.Crealock', 'Carl Alberg/Bruce King', 'Jeanneau', 'Phillipe Briand', 'Morgan-Giles', 'Mortain-Mavrikios', 'Jacques de Ridder', 'Jacques De Ridder', 'M.O. von Ahlen', 'Von Ahlen Yacht Design/Stile Bertone', 'Jac. de Ridder ', 'Marc-Oliver v.Ahlen', 'Harlé-Mortain-Mavrikios', 'J&J Design/Etap Yachting', 'Von Ahlen Yacht Design / Stile Bertone (interior)', 'von Ahlen Yacht Design/Stile Bertone', 'E. W. Etchells', 'Pierre Marique/Alois Roland', 'Bob Evelyn', 'Pas & Razinger', 'E. G. Van De Stadt', 'Lucien Gourmez', 'Carlo Bertorello', 'Hoyt', 'Ted Hood/Gary Hoyt', 'Steve Killing', 'Yves Loday', 'Torsten Gustavsson', 'Ivar Åkesson', 'Farrier', 'Charles Currey', 'John Morris/Alan Burnard/Charles Currey', 'Harry Dennis', 'William Crealock/Charles F. Street', 'Charles Street/Alden', 'Rodney Warington Smyth', 'Uwe Mares and Hubert Raudaschl', 'H. Amel/J. Carteau', 'Tim Jackett', 'Knut Jacobsson', 'Philippe H. Harlé', 'Stephens Brothers', 'Simonis Voogt', 'Simonis - Voogd', 'Alan Adler', 'John Gross', 'Rajan Naidu', 'Angelo Lavranos/Gideon Goudsmit', 'Simonis Voogd Yacht Design', 'Niels Peter Faurby', 'Alain Jezequel', 'Eva Hollmann', 'Gilles Vaton/Patrick Roseo', 'Michel Joubert/Patrick Roseo', 'Vaton & Cadro', 'Alain Mortain / Yiannis Mavrikios', 'Alliaura Marine', 'Joubert / Nivelt ', 'Gebr de Kloet', 'Michel Castillo', 'Jacques (Koos) de Ridder', 'Riccardo Baffigo', 'Joubert-Nivelt/Olivier Flahault', 'W. & R.B. Fife', 'Michel  Joubert', 'VPLP design', 'J. J. Herbulot', 'Groupe Finot/Jean Beret', 'Alan Platt / Laurie Harbotell', 'Alan Platt', 'Knud Riemers', 'Richard Sarby', 'Eivind Still', 'Eivind Still/Hans Johansson', 'Karl-Johan Stråhlmann', 'Turun Veneveistramo', 'Karl Strahlmann', 'Hakan Södergren', 'Angus Primrose', 'Turien Veneveistramo', 'Oy Fiskars', 'Hary Becker', 'Elvind Still', 'Martyn Smith', 'John Spencer/Peter Tait', 'Farr Design', 'Samuel Manuard', 'Sam Manuard', 'Jean-Marie Finot', 'Finot / Conq', 'André Mauric', 'J.M. Finot', 'Jean Berret/ Philippe Starck ', 'Jean Berret ', 'Berret', 'Jean Berret/Phillippe Starck', 'Farr Yacht Design Ltd.', 'Bruce Farr/Pininfarina', 'Groupe Finot/Jacques Fauroux', 'Jean-Marie Finot ', 'Jean-Marie Finot / Jacques Fauroux ', 'Jacques Fauroux/Jean-Marie Finot', 'Biscontini Yacht Design', 'Rathbone DeBuys', 'Wyatt and Freeman', 'Gordon R. Wyatt', 'S. Herreshoff', 'Charles Mower', 'Eivind Amble/Geir Grung', 'Eivind Amble', 'Herreshoff/Joel White', 'Alan Eckford', 'Carter Pyle/Joe Quigg', 'Peer Bruun', 'AMF Alcort', 'S. Langevin', 'John Spencer', 'Heribert Streuer', 'Uus Van Essen/Conrad Gulcher', 'Eva Hollman', 'E. Maxwell Smith/John McKellar', 'Martin Fischer', 'Gonzalo Redondo', 'Gordon K. Douglass', 'E.G. van de Stadt', 'Jerzy Piesniewski', 'Steve Clark/Dave Clark', 'F. Parker', 'C.J. Johnson', 'Fred Scott,  Jack Evans', 'Kurt A. H. Oehlmann', 'Hugo Samuelsson', 'Ron Amy', 'Claude Puvieux', 'Stephen Jones', 'Brett Bakewell-White', 'R. Freeman', 'Tony Dixon', 'William Tripp III', 'James Williams', 'Gary Hoyt/Jay Paris ', 'Freedom Yachts', 'J. Paris/Gary Hoyt', 'David Pedrick', 'Ron Holland/Gary Hoyt', 'Hoyt/Herreshoff', 'Gary Hoyt/H. Herreshoff', 'Charles Davies/Robert Perry', 'Studio Lostuzzi', 'Halverson Bros.', 'A.H. Meijer', 'Koos de Ridder', 'Jac. de Ridder/Dick Koopmans Sr.', 'E.G. Van de Stadt', 'Tord Sunden/Cheoy Lee', 'Bill Spencer', 'C. Oberly', 'John G. Alden Inc.', 'John G Alden Inc.', 'Joubert & Nivelt ', 'Dubois/Joubert-Nivelt', 'Alberto Cabal', 'Charles D. Mower', 'Hans Geissler', 'Van de Stadt Design', 'John Kaiser Sr.', 'Steven DiLeo', 'Ian Haney', 'D. Presles', 'Jan H. Linge', 'C&C design group', 'Dr Martin Fischer', 'L. E Ted Geary', 'Magnus Öster/Bo Jonsson', 'Rob Humphries', 'Tony Smith', 'George Larsen', 'Greg Gregory', 'H. Lemstra (NL)', 'Dr. Jüs Segger', 'Laurent Giles/Chris Hawkins', 'Mike Pocock', 'Horst Glacer', 'Donald Pye (Holman & Pye)', 'Herreshoff/Harold Glander', 'Garden/Perry', 'Harry Sindle', 'Stuart Windley', 'P. Jouët & Cie', 'Jan Gougeon', 'Donovan', 'Gustavo Rodriguez', 'Dick Wyche', 'R. van der Staad', 'George Cuthbertson', 'Rolf van der Sleen', 'Charles Angle/Axel Schmidt', 'Jørn Hansen', 'Kristian Rode', 'Skyron srl', 'Alexandro Vismara', 'Claudio Maletto', 'Matteo Polli', 'Marco Lostuzzi', 'Judel/Vrolijk - Felci', 'Botin & Partners', 'Luca Brenta & Co.', 'Joubert & Nivelt', 'J. Taylor', 'E. Selman Graves', 'John R. Brophy', 'Malcolm Tennant', 'Steven A. George', 'Aage Utzon/Klaus Baess', 'Bill Cook Yacht Design', 'Mark Ellis/Rob Maza', 'William H. Short', 'George Stadel Jr.', 'Laurent Giles & Partners', 'W. Jenneskens', 'Peter Bruun', 'Sergent/Herbulot', 'German Frers Sr.', 'William H. Shaw', 'Cockburn/Jones', 'Capital Yachts', 'Martin Bludworth', 'Martin Bludworth ', 'Richard Lazzarra/ David Jones', 'Richard C. Lazzara', 'Vince Lazzara', 'Richard Lazzara', 'Lazarra', 'Vince Lazarra', 'Gulfstar/V. Lazzara', 'V. Lazarra', 'V. S. Lazzara', 'Ole Enderlain', 'Morelli & Melvin (USA)', 'Nigel Irens', 'Herb Stewart', 'Guy-Christer Lönngren', 'L. Francis Herreshoff', 'Glen Trustwell/Dan Holman', 'Janusz Konkol', 'Janusz Konkol/Henryk Brylski', 'Nick Hake', 'Taylor Newell', 'Olle Enderlein / Christoph Rassy', 'Germán Frers', 'Christoph Rassy and Olle Enderlein', 'Christoph Rassy / Olle Enderlein', 'Christoph Rassy/Olle Enderlein', 'Harry Hallberg', 'Michael Volmer', 'John B Sharp', 'A. R. Luke', 'Vincent Serio', 'Merle Hallett', 'Harwood Ives', 'Henry Rasmussen', 'Yachtzentrum Greifswald', 'Willy Asmus', 'Gösta Edwardsson & Erik Hansson', 'Wegu', 'Klaus Fahrenkroog', 'Lehman/Schock', 'Steven Schock', 'Chris Bjerregaard', 'Keith Callaghan', 'Richard Hartley', 'R. T. Hartley', 'Lars Oudrup', 'Lage Eklund', 'Chris Hawkins', 'T. Wylie', 'Van de Stadt ', 'Horst E. Glacer', 'Percey Dalton', 'Pat Patterson', 'Berret Racoupeau', 'G. Moreau', 'Lothar Koehler', 'J. \"Jopie\" Helsen', 'Johannes Helsen', 'Glenn Henderson', 'Andrew Davidhazy', 'McCurdy & Rhodes', 'Richard Ketcham', 'Charles Wittholz', 'Charles Purbrook', 'H. Herreshoff', 'Judel / Vrolijk & Co./SDK Structures', 'James Hakes', 'Morrelli & Melvin', 'J. de Ridder', 'Sandy Douglas', 'D. Bruce Connolly', 'Carl Alberg/Alden', 'H. Hinckley III/Owens', 'H. Hinckley', 'William H. Tripp', 'Chris Hammond', 'Richard C. Lazarra', 'Morgan', 'P. Milne', 'Hobie Alter', 'John Wake', 'Hobie Alter & Phil Edwards', 'Hobie Cat', 'Hobie Europe', 'Hobiecat Europe', 'Nils Bunkenburg', 'Hobie Cat Europe', 'Ian Murray & Associates', 'Jack Groeneveld', 'Ron Holder', 'Greg Ketterman', 'Morrelli, Melvin & Hobie Design Team', 'Hobie Cat Europe Design Team', 'Ron Holder/Dave Ulmann', 'A. Lavranos', 'A. K. Balfour', 'Warwick Hood', 'H.Herreshoff', 'Helmut Hatecke', 'Doug Hemphill', 'John Welsford', 'S&S', 'W. Herbert Boyd', 'Howard Hughes', 'Gary Mull/Jim Donovan ', 'Hunter Design Team', 'Chuck Burns/Hunter Design Team', 'Hunter Design', 'Cortland Steck', 'Hunter Design Group', 'Hunter Marine', 'John Cherubini/Bob Seidelmann', 'Rob Mazza', 'Rob Mazza/Hunter Design Team', 'John Cherubini', 'Hunter Design Team/R. Mazza', 'Steven Jones', 'Cherubini', 'Glen Henderson', 'Warren Luhrs', 'Henderson/Hunter Design Team', 'Glenn Henderson/Hunter Design Team', 'W. Luhrs /J. Cherubini/C. Steck', 'G.K. Collyer', 'Reg & Rob White', 'Donald Pye/Holman & Pye', 'Dick Koopmans Sr.', 'Paul Hutton', 'Skorski/Jusis', 'Mike West', 'Heinz-Jurgen Sass', 'Sparkman and Stephens', 'Johnstone', 'Henry Bateson', 'Clinton Crane', 'Alf Harvey/John Spencer', 'Jo Richards & Neil Graham', 'E. Bjørn Jensen', 'D. Peterson', 'L. Wakefield', 'William Cook', 'Arthur Caldwell', 'John G. Alden/Sam Crocker', 'Melges', 'George Cockshott', 'Helsen', 'Farr', 'Robert G. Henry Jr.', 'Pelle Petterson', 'Van Essen/Gulcher', 'Tord Sundén', 'Bjarn Aas', 'McCurdy and Rhodes', 'Jim Kyle/Rolf van der Sleen', 'Kevin Shepherd', 'Ted Irwin ', 'John R. Van Ost', 'Irwin/Rogers', 'Berret-Racoupeau Yacht Design', 'Walter Scott/Bob Johnson', 'Walter Scott & Robert Johnson', 'Robert K. Johnson', 'Hugh Angleman', 'William Hardin', 'Floyd Ayers', 'A.S. Pendell', 'J.H.McGlasson', 'McGlasson/Islander', 'Alan P. Gurney', 'Charles Davies ', 'Guido Politi', 'Fontana Maletto Navone', 'Pérus. Scolari. Hertwig. Yacht Design Collective', 'Maurizio Cossutti', 'Maurizio Cossutti Yacht Design', 'G. Drummond-Bayne', 'Flamme Yacht Design', 'John Mullins', 'Finch/Butler/Milne', 'Fred R. Parker', 'William H. Tripp, Jr.', 'Development Class', 'Daniel Andrieu', 'Briand Yacht Design', 'Philippe Briand Yacht Design', 'Philippe Briand/Andrew Winch', 'George Olson/Ron Moore', 'Jack Butte', 'Howard Siddons/Uffa Fox', 'Uwe Mares & Hubert Raudaschl', 'Jack Riggleman', 'Skip Johnson', 'JP Villenave', 'Charles A. Nicholson', 'Ken Broyles', 'Peter Sijm / De Vries Lentsch', 'Doug Peterson/Peter Sijm', 'Jorma Nyman/Strahlman', 'Jorma Nyman ', 'Jorma Nyman/Karl-Johan Stråhlmann', 'Jorma Nyman/ Karl/Johan Stråhlmann', 'Daniel Tortarolo', 'Paul Elvström', 'Yves Marechal', 'Jacques Valer', 'Knud Reimers /Peter Norlin', \"Bill O'Brien\", 'Eric Salander', 'Arne Borghegn', 'Sigurd Fr. Herbern', 'Rod Johnstone', 'Murray Wright', 'Paul Handley', 'James S. Krogen', 'John R.Kaiser Sr.', 'Kaiser', 'McInnis', 'Michel Bigoin/Jacques Duvergie', 'M. Kaufmann', 'Paul A. Lindh', 'Aborn Smith/Kells Corp.', 'D.Peterson', 'Gilles Ollier', 'Phillipe Harlé', 'William Atkin/William Crealock', 'M. Bigoin', 'Jason Ker', \"George O'Brian Kennedy\", 'Paul Kettenburg', 'Paul Kettenberg', 'Ernst Lehfeld', 'Armin Philips', 'Wayne Vetterlein', 'R.A.G. Nierop', 'R. A. G. Nierop', 'Philip L. Rhodes', 'H. Amel', 'Carter Pyle', 'John Winslow', 'O. H. Rodgers', 'Bakewell-White Yacht Design', 'Erling Kristoffersen', 'Robert Clark', 'G. Pfeiffer', 'Klaus Scheeberger', 'Lock Crowther/John Hitch', 'Kevin Dibley', 'Richard Lefeber', 'Lars Olsen', 'Henri Copponex', 'Bolger', 'Morrelli and Melvin', 'Van Peteghem/Lauriot-Prevost', 'Van Petheghem/Lauriot-Prévost', 'Van Peteghem/Lauriot Prévost', 'Van Peteghem-Lauriot Prévost', 'Van Peteghem & Lauriot Prévost', 'Van Peteghem & Prevost/Nauta Design', 'Shad Turner', 'Herb David', 'Bill Lee/Bruce King', 'Bill Lee', 'Ken Rusinek', 'Steve Dalzell', 'M.Mills', 'Willliam Gardner', 'A Van Gool,', 'Hans Åge Larsen', 'F. Bethwaite/I. Bruce', 'Jo Richards', 'Arvid Laurin', 'O. Flahault Design /Joubert - Nivelt', 'J. G. Pollard', 'Luger', 'Barney Lehman', 'Lehman', 'Arhur C. Howard', 'Simon Cory', 'Graham Craddick/Frank Pryor', 'Frank Pryor', 'Byan Lello', 'Morelli & Melvin', 'Joe Fennell', 'Peter Hoyt/D. Peterson', 'Barney Lehman/W.D. Schock', 'Mark Giles', 'Paul Lindenberg', 'Jan Gustafsson', 'Mats Gustafsson', 'Linjett Design Team, inc.; Oscar Södergren', 'Arthur Robb', 'Howard Lippincott Jr.', 'Dieter Gade', 'Karl & Klaus Feltz', 'Robert H. Baker', 'Palle Mortensen', 'Bent Juul Andersen', 'Stuart Windley/Harry Sindle', 'Sidney Blinder', 'James Croll', 'Maurice  Griffiths', 'Thomas Faul & Charles Wittholz ', 'T. L. Foul & C. Wittholz', 'Loren Hart/Tommy Chen', 'Loren Hart/Admiralty Design', 'Alan Wright', 'M. Joubert/ B. Nivelt', 'Bossuet/Meyney/Salmoiraghi', 'Berret-Raccoupeau Yacht Design', 'André Herskovits & Philippe Thomé', 'Oluf Jørgensen', 'Olef Jorgensen/Bent Juul Andersen', 'Joergensen', 'E. Van De Stadt', 'Costantini', 'Ole Jensen/Christian Madsen', 'Percy Blandford', 'Johnson/Melges Boat Works', 'H. Melges Jr./H. Melges Sr.', 'Goran Marström/Kare Ljung', 'Joubert/Nivelt/Mercier', 'McClintock-Dubdam', 'Roger Macgregor', 'Roger MacGregor', 'Tim Kings', 'C.S.J.Roy', 'Eldredge & McInnis', 'Illingworth & Primrose', 'D. Newick/M. Raymond', 'Dick Vermuelen', 'Leszec Gomciarz', 'Julien Marin', 'IDBMarine (FRA)', 'Heraldo Ruesch', 'Javier Soto Acebal', 'Pablo Mastracchio', 'M. Joubert/B. Nivelt', 'Warren Seaman', 'Olsöner', 'Olsöners Båtbyggen', 'Bo Olsson', 'Leif Angermark', 'Olsoner Batbyggen', 'Jan & Harry Becker', 'Bengt Karlsson', 'H. Amel & J. Carteau', 'Cesare Sangermani', 'Ralph Tobias', 'LeRouge', 'Andrzej Arminski', 'Henry Amel & J. Carteau', 'Jean Jacques Herbulot', 'Aborn Smith Jr.', 'Henry Morschadt', 'Alan Mayer/Claude McCullock', 'Lars-Olof Norlin', 'Olle Enderlain', 'Günter Thomat', 'Eskil Haldin', 'Åke Sandström', 'Peter Canning', 'Clair Oberly', 'Clair Oberly/William Garden', 'Clair Oberly/W. Garden', 'Eric White & Arthur Berry', 'C. Oberly/W. Garden', 'George Stadel III', 'John S. Letcher Jr.', 'Jean Beret /Olivier Racoupeau', 'Breckenridge Marshall', 'Reichel-Pugh', 'Don Martin', 'Al Mason', 'Al Mason/Jeff Leishman', 'Mason', 'Bruce Roberts', 'Phil Southwell', 'Pelle Peterson', 'Maxi Dolphin', 'Jacek Daszkiewicz', 'Hugh Angelman/Charles Davies', 'John V. Kelley', 'Melges/Johnson', 'Harry Dunning', 'Botin Partners', 'William Ashcraft', 'Charles Hunt Jr./Charles Morgan', 'Andre  Mauric/Gilles Vaton', 'R. Crawford/Trad.', 'Tony Robinson', 'W.H. Rowland', 'Menger', 'Menger/Sweisguth', 'William Tripp Jr..', 'Ernest Nunes', 'Paul Yates', 'Sture Sunden', 'Nestor Völker', 'A.E. Luders', 'Michel Bigoin', 'Bob Smith', 'Norbert Patalas', 'André Gallois', 'Martin Horak', 'Rex Fettel', 'G. William McVay Sr.', 'Bruce Kelly', 'Feltham/Thames Marine', 'Philip Harle', 'Phillippe Harle', 'Ken Fickett', 'Bucknell & Holt', 'Olle Enderlein (SWE)', 'Oswald Berkemeyer', 'Roger Moorman', 'Paul Molich', 'Heribert Streuer & Horst Schlichting', 'Ronald Petralito', 'Ed Monk Sr.', 'Jerry Montgomery', 'Lyle Hess/Gerry Montgomery', 'Bill Dixon/Angus Primrose', 'Dixon Yacht Design', 'Laurent Giles & Partners Ltd.', 'George Olson, Ron Moore', 'Jean Beret', 'Briand', 'Morgan Yachts', 'George McVay', 'Ted Brewer/Jack Corey', 'Charles Morgan/Jack Corey', 'Charles Morgan/Henry Scheel', 'Nelson Marek', 'Henry Scheel', 'Jack Cory/Charles Morgan', 'Kenneth Collyer', \"Jean-Yves Manac'h\", 'Chuck Paine & Associates', 'Paine', 'Open', 'Matti Pulli', 'I. Anderson & Chris Baker', 'Van Peteghem Lauriot Prévost', 'J. R. Macalpine-Downie / Dick Gibbs', 'Joachim Harpprecht', 'Vlad Murnikov', 'Mylius Yachts', 'Fred Parker', 'Robert Clark/Austin Farrer', 'Peter Legnos', 'Axel Debeaufort/Alexis Muratet', 'Gino Morrelli/Pete Melvin', 'Tom Roland/Ross Guinea', 'Roscoe Guinea', 'Roscoe Guinea/NACRA', 'Roy Seaman', 'Tom Roland/NACRA Design Group', 'Tom Rolland/NACRA Design Group/Roy Seaman', 'NACRA Design Group', 'Morelli & Melvin / Vink, Larsen, Young', 'Thorwald Karlsson', 'O. Enderlien', 'Judel/ Vrolijk', 'Najad', 'judel/vrolijk and Eric Segerlind', 'Peter Cole & Associates', 'McCullough/Violette', 'Wilbur Ketcham ', 'Hughes/Nash', 'Joe Nash', 'William F. Crosby', 'Charles Morgan/Roger Warren', 'W. Aarnipalo', 'Kaj Gustafsson ', 'Kaj Gustafsson', 'Henri Adriaanse/Henk Zwart', 'Henry Adriaanse', 'Henri Adriaanse', 'Pablo A Cibert', 'Mortain & Mavrikios ', 'Alain Mortain & Yannis Mavrikios', 'Olivier Poncin/Alain Mortain & Yiannis Mavrikios', 'Marc Lombard/Chedal Anglay', 'Marc Lombard/Roseo Design', 'Mortain/Mavrikios', 'J. Pierrejean', 'Marc Lombard Yacht Design', 'Nelson', 'Lothar Leichtfuß', 'C. William Lapworth/Capital Yachts Inc.', 'Capital Yachts Inc.', 'Sam Crocker', 'Nathanael G. Herreshoff', 'N. Herreshoff', 'G. Taylor Newell', 'Harry R. Sindle ', 'Ackerman', 'Mark Ellis Design/Hinterhoeller', 'Camper & Nicholson/Raymond Wall', 'Camper & Nicholson/R. Wall', 'Charles A. Nicholson / Peter Nicholson', 'Ray Wall/Camper & Nicholson', 'Charles A. Nicholson/ Peter Nicholson', 'John Alden & Assoc.', 'Camper & Nicholson/Ray Wall', 'Tom Wylie', 'Kaufman & Ladd', 'Ray Greene', 'Dick Slates', 'Alex Trethewey/Noel Honey', 'Noel Honey/Alex Trethewey/Steve Marten', 'Geoffrey Prindle', 'Robert Ames/Steve Clark', 'Siddons & Sindle', 'Dennis Rayner', 'Mark Ellis Design/Gordon Fisher', 'Moedt', 'Peter Roos', 'Holger B. Jensen', 'Robert van Dam', 'Elvstrøm, Kjærulff, Rögeberg', 'Jac Iversen & Tor Sunden/Scandinavian Yacht Racing', 'Ole Jensen', 'Malta-Muller', 'Kjærulff/Elvström', 'Elvstrom/Kjaeralf/Buchwald', 'Buchwald & Borghegn', 'Nordship', 'Elvström/Kjærulff', 'John Leather', 'Peter Norlin ', 'Gary Grant', 'Alexander Simonis', 'Frans Cobelens NBJA', 'Sparkman & Stephens ', 'Marcelo Penna', 'Bob Ball', 'Hank Kaufman', 'Gary Lundy', 'Ted Moreau', 'Michele Ansaloni', 'Helmut Stauch', 'Hank Hinckley', 'W. H Tripp Jr.', 'Jack Savage', 'Finot-Conq', 'Finot-Conq/Nauta Design', 'FINOT-CONQ', 'Berret Racoupeau /Nauta Design', 'Berret Racoupeau Design', 'Berret Racoupeau/Nauta Design', 'Berret-Racoupeau/P. Andreani', 'J. J. Hurbulot', 'Hurbulot', 'Volker and Gerda Lamprecht', 'Etienne Bertrand', 'A.E. Luders ', 'Neil Parmentier/Sieg Brunnenkant', 'Herreshoff/Cheoy Lee Shipyard', 'Maurice DeClercq', 'Tanton', 'Alden & Assoc.', 'A. E  Luders', 'Einar Ohlson', 'George Olson', 'George Olsen', 'Derek Angus', 'Gaston Grenier', 'Peter Ståhle', 'Yanni Triatafilopolous', 'George Cuthbertson ', 'Henry Mohrschladt', 'Alvin Mason', 'Barreau / Neuman', 'Barreau/Neuman', 'Barreau & Neuman', 'Géaed Danson', 'VPLP', 'Marc Van Peteghem/ Michel Desjoyeaux', 'Louis Vallé', 'Mortain/Mavrikios and CBA design offices', 'Norman G. Owens', 'C. Schumacher', 'Hollman & Pyle', 'Holman  & Pye', 'Homann & Pyle', 'Holman  & Pyle', 'Rob Humphreys & Oyster Design', 'Chappelle', 'Harry Highet', 'Denis Ganley', 'Alex Simonis/Maarten Voogd', 'Jaudenes/Theys', 'Simonis Voogd Designs', 'George W. McVay', 'Bela Molnar', 'William Tritt', 'Nestor Volker', 'Ron Given', 'Parker', 'Tony Castro / B & W Parker', 'Castro', 'Richardson', 'George Kettenburg Jr.', 'George W. Kettenburg Jr.', 'William H. Shaw ', 'William Shaw/W. G. Richards', 'Bill Shaw', 'John Bennet', 'Gordon V. Harris', 'A.K. Carter', 'Dominique Presles', 'Laurent Giles ', 'Perry/Huntingford', 'Jack Howie', 'heribert Streuer', 'Nick Shein', 'Paul Wright & Brian Taylor', 'Phileas Boats', 'Wojcioch Spisak', 'Philippe Staempfli', 'Nils Lucander', 'Des Townson', 'Cyrus Hamlin', 'Mark Leonard', 'Van der Rest', 'Aage Nielsen/S&S', 'Talman Bigelow/R. Baker', 'Rolf Eliason', 'Sparkman & Stephens/Francis S. Kinney', 'David Boyd', 'Carl Martens', 'Aldo Renai', 'Finot-Conq ', 'Edson I. Schock', 'M. Joubert', 'R. Holland', 'Robert Perry (unauthorized)', 'CSK/Rudy Choy', 'Pierre Deschamps', 'Per Brohall', 'George S. Hawn, Jr', 'Steve Seaton', 'Jim Taylor ', 'G. Plessis & J. Marin', 'Botin & Carkeek', 'John Lucke', 'Geoff Prindle', 'Richard Loutek', 'Prindle', 'Norman Howard', 'Eric LeFevre', 'Guy Ribadeau Dumas', 'Marc Lombard/Franck Darnet Design', 'Marc Lombard/Diedre Design', 'Stephen Thomas', 'Ernesto Quaranta', 'Christian Stimson', 'Robert Underwood/David Feltham', 'Robert Derecktor', 'Fred Scott', 'Sciomachen', 'Chris Boyd', 'C. Raymond Hunt Assoc./John Deknatel', 'C. Raymond Hunt Assoc.(John Deknatel) ', 'Ray Wall', 'Roger Martin', 'Michael Price', 'Fred Goeller', 'Hubert Weber', 'John Drawe', 'John Drawe/Dave Ellis', 'Raymond H. Richards', 'Gary Mull ', 'C. Raymond Hunt Assoc.', 'Broadblue Catamarans', 'Roger McAleer', 'Owen Woolley', 'Ben Seaborn', 'Rajen Naidu', 'Bill Roberts', 'Paul Whiting', 'Ray Greene/Alvin Youngquist', 'Ford', 'Mark Mills.', 'G. de Vries Lentsch Jr.', 'P. Jouet & Cie', 'Arthur S. Henry ', 'Kurt Reinke', 'Steve Killing ', 'Pierre Meunier', 'Elmer Millenbach', 'Brian Amato', 'Gunnar L. Stenbäck', 'Herbert Klein', 'Randy Reynolds', 'Rolf Jacobssen', 'Peter Barrett', 'Rob Legg', 'Lombard', 'Bernt Lindquist / Peter Ståhle / S. Jardine', 'Gary Mull/Don Martin', 'Rodgers', 'Murray Ross', 'William J. Roué', 'Norman Dallimore', 'H.C. Smith', 'Reichel/Pugh Yacht Design', 'Richards/Whitehouse/RS Sailing', 'Jo Richards/RS Sailing', 'Phil Morrison/RS Sailing', 'Clive Everest', 'Phil Morisson', 'Clive Everest and Nick Peters', 'Nick Peters/Alex Southon', 'David Boyd/Rustler', 'Knud Reimers', 'Robert Slater', 'Graham & Schlageter', 'Don Wennersten/Graham & Schlageter', 'Don Wennersten', 'Arthur Edmonds/Don Wennersten', 'Arthur Edmunds/Leon Slikkers', 'Edmunds', 'Alan Scott', 'Roger Hewson/Sabre', 'Sabre Design Team', 'R.Hewson/Sabre', 'Jim Taylor/Hewson/Sabre', 'Roger Hewson', 'Rex Fettell', 'David & Martin Sadler', 'Klaus Grohnert', 'Aage Utzon', 'Arthur Berry', 'Tom Manders', 'J&J / Salona Design', 'J&J Design /Ker', 'Ker design', 'Michel Bigoin/Daniel Duvergie', 'David M. Cannell', 'L. Francis Herreshoff/Eldredge-McGinnis', 'B.Kirby/Clark', 'Hein Driehuyzen/Don Clark', 'Arnold/Breck Marshall', 'Breck Marshall', 'Leonardo da Costa Sayago ', 'Bill Lee/Bob Smith', 'Steven Schock/Shad Turner', 'Gary Mull / Shad Turner', 'H. Amel  & J. Carteau', 'Axel de la Hidalga', 'Saffier Yachts', 'Richard Hennevanger', 'Dean Hennevanger', 'Jan Larsen', 'Wojciech Spinsak', 'Marc Oliver van Ahlen', 'Nils-Eric Olafsson', 'Nils-Eric Olofsson', 'Peter Norlin/Bernt Lindquist', 'John Scarano', 'Oscar Schelin', 'Steven Schock/Reijo Salminen', 'Nelson/Marek ', 'DynaYacht', 'William E. Cook ', 'Bruce Marek', 'Carlo Sciarrelli', 'Robb Ladd', 'Taprell Dorling', 'M. Kaufman/M. Perkins', 'Saffier', 'Frederick W. Goeller, Jr', 'Charles Mower/Thomas F. Day/L.D. Huntington', 'Harden/Huntingford', 'Huntingford/Hardin/Cooper', 'Oliver F. Seabrook/Henry Sheel', 'Allan J. Arnold', 'L. F. Herreshoff/Ron Johnson', 'Ron Johnson', 'Kenneth Evans', 'Wirth Monroe', 'Edwin Monk', 'Kirke Leonard', 'Gordon Fowler/Harry Feltham', 'Hugh Angelman', 'William Garden/W.Hardin', 'Herbert Baggs/W. Scott Hayward', 'Reg Freeman', 'A. Sidney DeWolf Herreshoff', 'S. J. Herbert/J. V. Kelley', 'John Vincent Kelley/Stan Herbert', 'C. S. J. Roy', 'John A. Bennet', 'Ralston', 'Nigel Irens/Phil Medley', 'Ed Monk Jr.', 'Ed Monk', 'L. H. James', 'Jim Brown', 'Samual Manuard', 'Alfred Westmacott', 'G. A. Feltham', 'W. B. Stearns', 'N.G.Herreshoff', 'Cox & Stevens', 'Richard Ward', 'Seawind Catamarans', 'Francois Perus', 'Leszek Gonciarz', 'Gerhard Gilgenast', 'Craig V. Walters', 'Bob Seidelmann/Bruce Kirby/W. Ross', 'Bob Seidelmann', 'Glander', 'Berret Racoupeau/Nauta', 'Yves Loday and Reg White', 'Walter Shultz', 'G, H. Stadel & Son/Schultz & Assoc.', 'G, H. Stadel & Son', 'Walter Schulz & Assoc.', 'Dick Gibbs/J.R. MacAlpine-Downie', 'Henri Amel/J. Carteau', 'Rob Shaw', 'Francis & Roland Prout', 'Philippe Harlè', 'Fontana/Maletto/Navone', 'Delio Barberis/Lanfranco Soma', 'A.Jèzèquel', 'Fontana, Maletto & Navone', 'A Vallicelli', 'J. R. Macalpine-Downie/Dick Gibbs', 'Håkan Södergren ', 'Ray Kaufmann', 'Chantiers Gouteron', 'Carkeek & Botin', 'Per Brohäll', 'Hubert Vandestadt', 'Hakan Sodergren ', 'Dave Pedrick', 'K. Schröter Travenünde', 'H. Streuer', 'J. Berret/Vandestadt & McGruer', 'Hubert Van de stadt', 'Peter Schmidt', 'Marc-Oliver von Ahlen', 'Streuer/Schmidt', 'Jack Herrick/Vince Minter/Jeffkins', 'Jac. M. Iversen/Gusta Erikson', 'Reuel Parker', 'J.T.Lockley', 'Pyle/Moorman/Sindle', 'Julian Bethwaite & Chris Mitchell', 'Morrelli & Melvin/Labek/Ridley/Sanderson', 'Robin Chadworth-Musters/Alan Gurney', 'Stan Hundtingford', 'PELLE PETTERSSON', 'Thames Structural Plastics/Thames Marine', 'Thames Marine', 'David Feltham/Thames Marine', 'William Crosby', 'Willis Reid/Schock', 'Chris McLellan and Terry Steller', 'Gene Vernon', 'Lostuzzi', 'H. W. White', 'Jan Linge', 'John & Laurie Converse/J. Lange', 'Bjarne Marcussen', 'Jim Voysey', \"Joseph D'Alessio\", 'Carl Schumacher ', 'George H. Stadel Jr.', 'Alberg/South Coast', 'Iain Murray', 'Warren Metcalf', 'Bruce Roberts/Rudy Waalkens', 'Jim Monroe', 'Carter/Northshore', 'D. Carter/Rob Humphreys/Northshore Design Team', 'John Bennett', 'Stephen Jones/Southerly Design', 'Ken Upham/Mike Price', 'Luger Industries', 'Sovereign Design Group ', 'Arthur Edmunds/Sovereign', 'Sovereign Design Group', 'Mark Soverel', 'Daniel McCarthy/Waltman Walters', 'Daniel McCarthy/W.Walters', 'Bill Soverel, Walt Walters', 'Bill Soverel/Mark Soverel', 'Bill Soverel', 'Soverel/Walters', 'Kim Swarbrick', 'K. T. Swarbrick', 'Myron Spaulding', 'Frank Spears', 'John Brandlmayr', 'Gunter Hoechmer', 'Charles E. Morgan', 'Ron Hillier/D. Peterson (unauthorized)', 'Robert Finch/Earl Blackwell', 'J. De Ridder', 'Reg White/Yves Loday', 'Robert N. Stone', 'Herbert McWilliams', 'Howard Chapelle', 'G. Henderson', 'Benjamin Hallock', 'Luca Taddei', 'Franz Maas', 'Ed Dubois/Frans Maas', 'W.Gardner/F.Sweisguth ', 'John P. Fillip', 'James H. Kyle', 'Peter Wormwood', 'Bill Higgins/Don Ansley', 'Bill Higgins', 'Janne Jacobsson', 'S. S. Crocker 1931', 'Lindblom', 'Colin Archer type', 'Alex Stuart', 'L. Francis Herreshoff/Bill Harding', 'Edson Schock', 'Seth Persson', 'Olivier Petit/Jeanneau', 'Monk/Perry', 'Jacques Faroux', 'J&J Design/D. Andrieu', 'Philippe Briand / Jeanneau Design ', 'Daniel Andrieu / Guillaume Verdier', 'Andrieu Yacht Design', 'Jeanneau Design', 'M. Lombard', 'M. Lombard / V. Garroni', 'P. Briand/Franck Darnet/Flahault Design', 'Marc Lombard/Piaton Design', 'Briand/Darnet/Flahault/Jeanneau', 'Philippe Briand/Piaton Bonet Yacht Design', 'Philippe Briand /Jeanneau', 'Garonni / Briand', 'Bruce Farr/J&J Design', 'Fauroux & Garroni', 'Manfred Schöchl', 'Georg Nissen/Schöchl', 'Schöchl', 'Schoechl', 'J&J Design / Gerald Kiska', 'Miglitsch/Schoechl', 'J&J', 'J & J Design ', 'Fred Scott, Jack Evans', 'J. B. Brooke', 'John Brooke', 'E. A. Brown', 'Dashew', 'Alexander Bryan/Cortland Heyniger/Carl Meinart', 'John B. Brooke', 'Arthur Howard', 'Leslie H. James', 'Colin Mudie', 'E. Monk/R. Perry', 'Ulf Røgeberg', 'Mauric / Gaubert', 'Jean Pierre Magnum', 'Sergent/Amel', 'Alex Bryan/Cortland Heyniger', 'George Marzin', 'Steve Edmunds/Bill Roberts', 'Ib Pors Nielsen', 'Richard and Jay McFarlane', 'Tom Thornycroft', 'George L. Chaisson', 'German Frers/A. Winch', 'Norlin/Ostmann', 'Peter Norlin / Jens Östmann', 'Peter Norlin/Jens Östmann', 'Peter Norlin and Jens Ostmann', 'Charles Teeter', 'G. Prout & Sons', 'Colin Silvester', 'Bram Dally', 'Murray Burns Dovell', 'I Murray', 'Murray, Burns & Dovell', 'Fairways Marine (UK)', 'Lostuzzi Yacht Design', 'Pierre Gutelle', 'Roberto Barras', 'John G. Hanna', 'Bergstrom/Ridder', 'Newell', 'Greg Goodall/Jim Boyer', 'David Cannell', 'Dick Carter/Johann Tanzer', 'Tom McNeill/Tim Jackett', 'Tom Norton', 'Frank Bethwaite/Ian Bruce', 'Harold S. Glander', 'Robert Perry ', 'Peter Beeldsnijder', 'Robert Ladd', 'Hendricks Bulthuis', 'MIT/George Owen', 'Ian Procter', 'Burgess, Rigg and Morgan', 'Dave Westphal', 'Tomasz Siwik', 'Sandy Douglass', 'Guy Thompson', 'Steve Thompson', 'William Gardner', 'Collin', 'Mark E. Swanson', 'L. H. Walker', 'Paul R. Kotzebue', 'William B. Harris', 'James Wharram', 'James Wharram/Hanneke Boon', 'Colin Thorne', 'Ernesto & Mario Quaranta', 'Marion Excoffon', 'Joubert-Nivelt/Flahault', 'Merle/Joubert', 'Michele Molino', 'Ted Strain', 'Whistance', 'Yves Loday /Rob White', 'Bernd Breymann/Klaus Enzmann', 'Bert Keeble', 'D.Koopmans Sr.', 'F. Butler / A. Garest', 'R. March/T. Pearce/R. White', 'Fragniere & Naverraz', 'Pert M. Lowell', 'Tony Allen', 'Richard & Jay McFarlane', 'Steve Nichols', 'Dave Hubbard', 'John Rock', 'George Llwewllyn', 'George Duke', 'Robert Humphries', 'Richard Newick', 'Charles Angle', 'D. Tortarolo', 'Ribadeau Dumas', 'E.G. van der Stadt', 'Hans Blomstergren', 'Bill Tripp III', 'William Tripp, III', 'William Tripp, III ', 'Jean Pierre Brouns', 'Lars Hedberg', 'Doug Peterson (hull/unauthorized)', 'Iannis Triantafilopoulos', 'Reimers', 'G. Verdier', 'Ted Tyler', 'Reg White/Derek Kelsall', 'Sierp de Vries', 'Jeff Canepa/Jim Antrim', 'John Mazzotti', 'Doug Peterson (unauthorized)/Daryl Watson', 'Douglas Peterson/Daryl Watson', 'Alden Associates / Carl Alberg', 'Ralph Kuppersmith/C. Mills', 'George H. Stadel III', 'Artu Chiggiato', 'Tom Cox', 'Bob Perry', 'Robert B Harris', 'Robert Harris', 'Tony Taylore', 'Tony Taylor', 'Harken/Vanguard', 'Duncan Stuart', 'Bob Ames / Steve Clark', 'Antonio José Ferrer', 'Hobie Cat Europe/Philéas', 'MacGregor', 'Emre Karamanci', 'D. Koopmans Sr.', 'D. Koopmans Jr.', 'Dick Koopmans Jr.', 'Andre Hoek', 'John A Bennett', 'John A Bennett & Assoc.', 'C.W. Paine', 'A. Westmacott/S. Graham', 'Bill Hephurn', 'E G van de Stadt', 'Bjarne Aas', 'André Koschel', 'Erling Viksund', 'Jan Bjerke', 'John H. Lindblom', 'Carl Andersson & John H. Lindblom', 'Erford W. Burt', 'Thomas Hale & Son', 'T. M. Hale & Assoc.', 'Brian Bennett', 'Thompson Design', 'Roy Lunney', 'James Turner', 'Peter Stevenson/D.C. Pollard', 'Alan Hill/D. Pollard', 'Alan  Hill', 'Herb Stewart/International Marine', 'Daniel Avoures', 'Edwin Monk Associates/ Eric White', 'K. Kremer', 'Arthur Peltzer', 'K.T. Kremer', 'Arthur Pelzer', 'William Loughlin', 'Farr/Bassani', 'J. Laurent-Giles', 'J. Segger', 'John Conser/Vince Bartolone', 'Angus Primrose/Bill Dixon', 'Harry Becker/Leif Ängermark', 'Andrew McDougall', 'Nathaniel Herreshoff/Sidney Herreshoff', 'Thomas B. Middleton/J. E. Doyle', 'Watkins', 'Helsen/Watkins', 'Walter Scott/Watkins', 'W. Tripp/Watkins Yachts', 'Tripp/Watkins', 'G. L. Watson & Co. Ltd.', 'Palmer Scott  Co.', 'Thomas D. Scott', 'Arne Wiklund', 'Bill Wellington', 'Kenneth Collyer/Morgan-Giles', 'H. G. May', 'Stanley T. Smith', 'Stanley T. Smith/Herb. Stewart', 'Stanley T. Smith/H. Stewart', 'West Wight Sailing Club (UK)', 'Denys Rayner', 'Denis Rayner', 'Denys A. Rayner', 'John A. Butler', 'David Westphal', 'William Crealock/W. Atkin', 'George Stadell III', 'Tim Clissold/Roger and Chris Kitchen', 'T. Wheeler', 'Macalpine-Downie', 'Sears Design Team', 'F. S. Ford Jr.', 'H. Manley Crosby', 'C.S.J. Roy', 'Terry Lamb', 'Bergström & Ridder ', 'Mark Balogh/Windrider', 'Jim Brown/Windrider', 'S. Bradfield/T. Haman/M.McGarry', 'Shad Truner', 'Cmdr. Denys A. Rayner', 'Leo Bruckner', 'Trevor Kirby', 'Colin Mudie/Van de Stadt', 'Prins', 'Rolf Eliasson', 'Cees van Tongeren', 'Cees van Tongeren/Van de Stadt Design', 'Ralph E. Winslow', 'Ralph Winslow', 'Burgess & Packard', 'Dr. Walter Radcliffe', 'Bud Taplin', 'Arthur Edmunds/Sparkman & Stephens', 'Thomas Wylie', 'Thomas Wylie ', 'Niels Jeppessen', 'Jochum Bierma', 'Lutra Design', 'Thomas Mielec and X-Yachts Design Team', 'X-Yachts design team', 'Jeppesen', 'Ian Howlett and Rob White', 'Rudolf Jonker', 'Alvin Youngquist', 'Rod MacAlpine-Downie', 'G O’Brien Kennedy', 'Jack Hold;', 'Yamaha Design Group', 'Yamaha/Ichiro Yokoyama', 'Yamaha Design Team', 'Yamaha/Norlin', 'Yamaha', 'Yamaha Design team', 'Ernest Woods', 'Henry Longmore', 'J. Everitt', 'Leslie Landamore', 'Jan  Linge', 'Harrison Butler', 'J. S. Helyer', 'H. McCune', 'Jim Young', 'Charles & Lindsay Cunningham', 'Michel Nivelt/Lucien Gourmez', 'Ed Thrall & Jack Freitag', 'Steve Clark', 'Harold Brainard', 'Henrik Segercrantz', 'Gary Grossman/Steve Nichols', 'John Corby / David Harte']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\chris/.cache\\huggingface\\hub\\models--google--vit-base-patch16-224\\snapshots\\2ddc9d4e473d7ba52128f0df4723e478fa14fb80\\config.json\n",
      "Model config ViTConfig {\n",
      "  \"_name_or_path\": \"google/vit-base-patch16-224\",\n",
      "  \"architectures\": [\n",
      "    \"ViTForImageClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\",\n",
      "    \"59\": \"LABEL_59\",\n",
      "    \"60\": \"LABEL_60\",\n",
      "    \"61\": \"LABEL_61\",\n",
      "    \"62\": \"LABEL_62\",\n",
      "    \"63\": \"LABEL_63\",\n",
      "    \"64\": \"LABEL_64\",\n",
      "    \"65\": \"LABEL_65\",\n",
      "    \"66\": \"LABEL_66\",\n",
      "    \"67\": \"LABEL_67\",\n",
      "    \"68\": \"LABEL_68\",\n",
      "    \"69\": \"LABEL_69\",\n",
      "    \"70\": \"LABEL_70\",\n",
      "    \"71\": \"LABEL_71\",\n",
      "    \"72\": \"LABEL_72\",\n",
      "    \"73\": \"LABEL_73\",\n",
      "    \"74\": \"LABEL_74\",\n",
      "    \"75\": \"LABEL_75\",\n",
      "    \"76\": \"LABEL_76\",\n",
      "    \"77\": \"LABEL_77\",\n",
      "    \"78\": \"LABEL_78\",\n",
      "    \"79\": \"LABEL_79\",\n",
      "    \"80\": \"LABEL_80\",\n",
      "    \"81\": \"LABEL_81\",\n",
      "    \"82\": \"LABEL_82\",\n",
      "    \"83\": \"LABEL_83\",\n",
      "    \"84\": \"LABEL_84\",\n",
      "    \"85\": \"LABEL_85\",\n",
      "    \"86\": \"LABEL_86\",\n",
      "    \"87\": \"LABEL_87\",\n",
      "    \"88\": \"LABEL_88\",\n",
      "    \"89\": \"LABEL_89\",\n",
      "    \"90\": \"LABEL_90\",\n",
      "    \"91\": \"LABEL_91\",\n",
      "    \"92\": \"LABEL_92\",\n",
      "    \"93\": \"LABEL_93\",\n",
      "    \"94\": \"LABEL_94\",\n",
      "    \"95\": \"LABEL_95\",\n",
      "    \"96\": \"LABEL_96\",\n",
      "    \"97\": \"LABEL_97\",\n",
      "    \"98\": \"LABEL_98\",\n",
      "    \"99\": \"LABEL_99\",\n",
      "    \"100\": \"LABEL_100\",\n",
      "    \"101\": \"LABEL_101\",\n",
      "    \"102\": \"LABEL_102\",\n",
      "    \"103\": \"LABEL_103\",\n",
      "    \"104\": \"LABEL_104\",\n",
      "    \"105\": \"LABEL_105\",\n",
      "    \"106\": \"LABEL_106\",\n",
      "    \"107\": \"LABEL_107\",\n",
      "    \"108\": \"LABEL_108\",\n",
      "    \"109\": \"LABEL_109\",\n",
      "    \"110\": \"LABEL_110\",\n",
      "    \"111\": \"LABEL_111\",\n",
      "    \"112\": \"LABEL_112\",\n",
      "    \"113\": \"LABEL_113\",\n",
      "    \"114\": \"LABEL_114\",\n",
      "    \"115\": \"LABEL_115\",\n",
      "    \"116\": \"LABEL_116\",\n",
      "    \"117\": \"LABEL_117\",\n",
      "    \"118\": \"LABEL_118\",\n",
      "    \"119\": \"LABEL_119\",\n",
      "    \"120\": \"LABEL_120\",\n",
      "    \"121\": \"LABEL_121\",\n",
      "    \"122\": \"LABEL_122\",\n",
      "    \"123\": \"LABEL_123\",\n",
      "    \"124\": \"LABEL_124\",\n",
      "    \"125\": \"LABEL_125\",\n",
      "    \"126\": \"LABEL_126\",\n",
      "    \"127\": \"LABEL_127\",\n",
      "    \"128\": \"LABEL_128\",\n",
      "    \"129\": \"LABEL_129\",\n",
      "    \"130\": \"LABEL_130\",\n",
      "    \"131\": \"LABEL_131\",\n",
      "    \"132\": \"LABEL_132\",\n",
      "    \"133\": \"LABEL_133\",\n",
      "    \"134\": \"LABEL_134\",\n",
      "    \"135\": \"LABEL_135\",\n",
      "    \"136\": \"LABEL_136\",\n",
      "    \"137\": \"LABEL_137\",\n",
      "    \"138\": \"LABEL_138\",\n",
      "    \"139\": \"LABEL_139\",\n",
      "    \"140\": \"LABEL_140\",\n",
      "    \"141\": \"LABEL_141\",\n",
      "    \"142\": \"LABEL_142\",\n",
      "    \"143\": \"LABEL_143\",\n",
      "    \"144\": \"LABEL_144\",\n",
      "    \"145\": \"LABEL_145\",\n",
      "    \"146\": \"LABEL_146\",\n",
      "    \"147\": \"LABEL_147\",\n",
      "    \"148\": \"LABEL_148\",\n",
      "    \"149\": \"LABEL_149\",\n",
      "    \"150\": \"LABEL_150\",\n",
      "    \"151\": \"LABEL_151\",\n",
      "    \"152\": \"LABEL_152\",\n",
      "    \"153\": \"LABEL_153\",\n",
      "    \"154\": \"LABEL_154\",\n",
      "    \"155\": \"LABEL_155\",\n",
      "    \"156\": \"LABEL_156\",\n",
      "    \"157\": \"LABEL_157\",\n",
      "    \"158\": \"LABEL_158\",\n",
      "    \"159\": \"LABEL_159\",\n",
      "    \"160\": \"LABEL_160\",\n",
      "    \"161\": \"LABEL_161\",\n",
      "    \"162\": \"LABEL_162\",\n",
      "    \"163\": \"LABEL_163\",\n",
      "    \"164\": \"LABEL_164\",\n",
      "    \"165\": \"LABEL_165\",\n",
      "    \"166\": \"LABEL_166\",\n",
      "    \"167\": \"LABEL_167\",\n",
      "    \"168\": \"LABEL_168\",\n",
      "    \"169\": \"LABEL_169\",\n",
      "    \"170\": \"LABEL_170\",\n",
      "    \"171\": \"LABEL_171\",\n",
      "    \"172\": \"LABEL_172\",\n",
      "    \"173\": \"LABEL_173\",\n",
      "    \"174\": \"LABEL_174\",\n",
      "    \"175\": \"LABEL_175\",\n",
      "    \"176\": \"LABEL_176\",\n",
      "    \"177\": \"LABEL_177\",\n",
      "    \"178\": \"LABEL_178\",\n",
      "    \"179\": \"LABEL_179\",\n",
      "    \"180\": \"LABEL_180\",\n",
      "    \"181\": \"LABEL_181\",\n",
      "    \"182\": \"LABEL_182\",\n",
      "    \"183\": \"LABEL_183\",\n",
      "    \"184\": \"LABEL_184\",\n",
      "    \"185\": \"LABEL_185\",\n",
      "    \"186\": \"LABEL_186\",\n",
      "    \"187\": \"LABEL_187\",\n",
      "    \"188\": \"LABEL_188\",\n",
      "    \"189\": \"LABEL_189\",\n",
      "    \"190\": \"LABEL_190\",\n",
      "    \"191\": \"LABEL_191\",\n",
      "    \"192\": \"LABEL_192\",\n",
      "    \"193\": \"LABEL_193\",\n",
      "    \"194\": \"LABEL_194\",\n",
      "    \"195\": \"LABEL_195\",\n",
      "    \"196\": \"LABEL_196\",\n",
      "    \"197\": \"LABEL_197\",\n",
      "    \"198\": \"LABEL_198\",\n",
      "    \"199\": \"LABEL_199\",\n",
      "    \"200\": \"LABEL_200\",\n",
      "    \"201\": \"LABEL_201\",\n",
      "    \"202\": \"LABEL_202\",\n",
      "    \"203\": \"LABEL_203\",\n",
      "    \"204\": \"LABEL_204\",\n",
      "    \"205\": \"LABEL_205\",\n",
      "    \"206\": \"LABEL_206\",\n",
      "    \"207\": \"LABEL_207\",\n",
      "    \"208\": \"LABEL_208\",\n",
      "    \"209\": \"LABEL_209\",\n",
      "    \"210\": \"LABEL_210\",\n",
      "    \"211\": \"LABEL_211\",\n",
      "    \"212\": \"LABEL_212\",\n",
      "    \"213\": \"LABEL_213\",\n",
      "    \"214\": \"LABEL_214\",\n",
      "    \"215\": \"LABEL_215\",\n",
      "    \"216\": \"LABEL_216\",\n",
      "    \"217\": \"LABEL_217\",\n",
      "    \"218\": \"LABEL_218\",\n",
      "    \"219\": \"LABEL_219\",\n",
      "    \"220\": \"LABEL_220\",\n",
      "    \"221\": \"LABEL_221\",\n",
      "    \"222\": \"LABEL_222\",\n",
      "    \"223\": \"LABEL_223\",\n",
      "    \"224\": \"LABEL_224\",\n",
      "    \"225\": \"LABEL_225\",\n",
      "    \"226\": \"LABEL_226\",\n",
      "    \"227\": \"LABEL_227\",\n",
      "    \"228\": \"LABEL_228\",\n",
      "    \"229\": \"LABEL_229\",\n",
      "    \"230\": \"LABEL_230\",\n",
      "    \"231\": \"LABEL_231\",\n",
      "    \"232\": \"LABEL_232\",\n",
      "    \"233\": \"LABEL_233\",\n",
      "    \"234\": \"LABEL_234\",\n",
      "    \"235\": \"LABEL_235\",\n",
      "    \"236\": \"LABEL_236\",\n",
      "    \"237\": \"LABEL_237\",\n",
      "    \"238\": \"LABEL_238\",\n",
      "    \"239\": \"LABEL_239\",\n",
      "    \"240\": \"LABEL_240\",\n",
      "    \"241\": \"LABEL_241\",\n",
      "    \"242\": \"LABEL_242\",\n",
      "    \"243\": \"LABEL_243\",\n",
      "    \"244\": \"LABEL_244\",\n",
      "    \"245\": \"LABEL_245\",\n",
      "    \"246\": \"LABEL_246\",\n",
      "    \"247\": \"LABEL_247\",\n",
      "    \"248\": \"LABEL_248\",\n",
      "    \"249\": \"LABEL_249\",\n",
      "    \"250\": \"LABEL_250\",\n",
      "    \"251\": \"LABEL_251\",\n",
      "    \"252\": \"LABEL_252\",\n",
      "    \"253\": \"LABEL_253\",\n",
      "    \"254\": \"LABEL_254\",\n",
      "    \"255\": \"LABEL_255\",\n",
      "    \"256\": \"LABEL_256\",\n",
      "    \"257\": \"LABEL_257\",\n",
      "    \"258\": \"LABEL_258\",\n",
      "    \"259\": \"LABEL_259\",\n",
      "    \"260\": \"LABEL_260\",\n",
      "    \"261\": \"LABEL_261\",\n",
      "    \"262\": \"LABEL_262\",\n",
      "    \"263\": \"LABEL_263\",\n",
      "    \"264\": \"LABEL_264\",\n",
      "    \"265\": \"LABEL_265\",\n",
      "    \"266\": \"LABEL_266\",\n",
      "    \"267\": \"LABEL_267\",\n",
      "    \"268\": \"LABEL_268\",\n",
      "    \"269\": \"LABEL_269\",\n",
      "    \"270\": \"LABEL_270\",\n",
      "    \"271\": \"LABEL_271\",\n",
      "    \"272\": \"LABEL_272\",\n",
      "    \"273\": \"LABEL_273\",\n",
      "    \"274\": \"LABEL_274\",\n",
      "    \"275\": \"LABEL_275\",\n",
      "    \"276\": \"LABEL_276\",\n",
      "    \"277\": \"LABEL_277\",\n",
      "    \"278\": \"LABEL_278\",\n",
      "    \"279\": \"LABEL_279\",\n",
      "    \"280\": \"LABEL_280\",\n",
      "    \"281\": \"LABEL_281\",\n",
      "    \"282\": \"LABEL_282\",\n",
      "    \"283\": \"LABEL_283\",\n",
      "    \"284\": \"LABEL_284\",\n",
      "    \"285\": \"LABEL_285\",\n",
      "    \"286\": \"LABEL_286\",\n",
      "    \"287\": \"LABEL_287\",\n",
      "    \"288\": \"LABEL_288\",\n",
      "    \"289\": \"LABEL_289\",\n",
      "    \"290\": \"LABEL_290\",\n",
      "    \"291\": \"LABEL_291\",\n",
      "    \"292\": \"LABEL_292\",\n",
      "    \"293\": \"LABEL_293\",\n",
      "    \"294\": \"LABEL_294\",\n",
      "    \"295\": \"LABEL_295\",\n",
      "    \"296\": \"LABEL_296\",\n",
      "    \"297\": \"LABEL_297\",\n",
      "    \"298\": \"LABEL_298\",\n",
      "    \"299\": \"LABEL_299\",\n",
      "    \"300\": \"LABEL_300\",\n",
      "    \"301\": \"LABEL_301\",\n",
      "    \"302\": \"LABEL_302\",\n",
      "    \"303\": \"LABEL_303\",\n",
      "    \"304\": \"LABEL_304\",\n",
      "    \"305\": \"LABEL_305\",\n",
      "    \"306\": \"LABEL_306\",\n",
      "    \"307\": \"LABEL_307\",\n",
      "    \"308\": \"LABEL_308\",\n",
      "    \"309\": \"LABEL_309\",\n",
      "    \"310\": \"LABEL_310\",\n",
      "    \"311\": \"LABEL_311\",\n",
      "    \"312\": \"LABEL_312\",\n",
      "    \"313\": \"LABEL_313\",\n",
      "    \"314\": \"LABEL_314\",\n",
      "    \"315\": \"LABEL_315\",\n",
      "    \"316\": \"LABEL_316\",\n",
      "    \"317\": \"LABEL_317\",\n",
      "    \"318\": \"LABEL_318\",\n",
      "    \"319\": \"LABEL_319\",\n",
      "    \"320\": \"LABEL_320\",\n",
      "    \"321\": \"LABEL_321\",\n",
      "    \"322\": \"LABEL_322\",\n",
      "    \"323\": \"LABEL_323\",\n",
      "    \"324\": \"LABEL_324\",\n",
      "    \"325\": \"LABEL_325\",\n",
      "    \"326\": \"LABEL_326\",\n",
      "    \"327\": \"LABEL_327\",\n",
      "    \"328\": \"LABEL_328\",\n",
      "    \"329\": \"LABEL_329\",\n",
      "    \"330\": \"LABEL_330\",\n",
      "    \"331\": \"LABEL_331\",\n",
      "    \"332\": \"LABEL_332\",\n",
      "    \"333\": \"LABEL_333\",\n",
      "    \"334\": \"LABEL_334\",\n",
      "    \"335\": \"LABEL_335\",\n",
      "    \"336\": \"LABEL_336\",\n",
      "    \"337\": \"LABEL_337\",\n",
      "    \"338\": \"LABEL_338\",\n",
      "    \"339\": \"LABEL_339\",\n",
      "    \"340\": \"LABEL_340\",\n",
      "    \"341\": \"LABEL_341\",\n",
      "    \"342\": \"LABEL_342\",\n",
      "    \"343\": \"LABEL_343\",\n",
      "    \"344\": \"LABEL_344\",\n",
      "    \"345\": \"LABEL_345\",\n",
      "    \"346\": \"LABEL_346\",\n",
      "    \"347\": \"LABEL_347\",\n",
      "    \"348\": \"LABEL_348\",\n",
      "    \"349\": \"LABEL_349\",\n",
      "    \"350\": \"LABEL_350\",\n",
      "    \"351\": \"LABEL_351\",\n",
      "    \"352\": \"LABEL_352\",\n",
      "    \"353\": \"LABEL_353\",\n",
      "    \"354\": \"LABEL_354\",\n",
      "    \"355\": \"LABEL_355\",\n",
      "    \"356\": \"LABEL_356\",\n",
      "    \"357\": \"LABEL_357\",\n",
      "    \"358\": \"LABEL_358\",\n",
      "    \"359\": \"LABEL_359\",\n",
      "    \"360\": \"LABEL_360\",\n",
      "    \"361\": \"LABEL_361\",\n",
      "    \"362\": \"LABEL_362\",\n",
      "    \"363\": \"LABEL_363\",\n",
      "    \"364\": \"LABEL_364\",\n",
      "    \"365\": \"LABEL_365\",\n",
      "    \"366\": \"LABEL_366\",\n",
      "    \"367\": \"LABEL_367\",\n",
      "    \"368\": \"LABEL_368\",\n",
      "    \"369\": \"LABEL_369\",\n",
      "    \"370\": \"LABEL_370\",\n",
      "    \"371\": \"LABEL_371\",\n",
      "    \"372\": \"LABEL_372\",\n",
      "    \"373\": \"LABEL_373\",\n",
      "    \"374\": \"LABEL_374\",\n",
      "    \"375\": \"LABEL_375\",\n",
      "    \"376\": \"LABEL_376\",\n",
      "    \"377\": \"LABEL_377\",\n",
      "    \"378\": \"LABEL_378\",\n",
      "    \"379\": \"LABEL_379\",\n",
      "    \"380\": \"LABEL_380\",\n",
      "    \"381\": \"LABEL_381\",\n",
      "    \"382\": \"LABEL_382\",\n",
      "    \"383\": \"LABEL_383\",\n",
      "    \"384\": \"LABEL_384\",\n",
      "    \"385\": \"LABEL_385\",\n",
      "    \"386\": \"LABEL_386\",\n",
      "    \"387\": \"LABEL_387\",\n",
      "    \"388\": \"LABEL_388\",\n",
      "    \"389\": \"LABEL_389\",\n",
      "    \"390\": \"LABEL_390\",\n",
      "    \"391\": \"LABEL_391\",\n",
      "    \"392\": \"LABEL_392\",\n",
      "    \"393\": \"LABEL_393\",\n",
      "    \"394\": \"LABEL_394\",\n",
      "    \"395\": \"LABEL_395\",\n",
      "    \"396\": \"LABEL_396\",\n",
      "    \"397\": \"LABEL_397\",\n",
      "    \"398\": \"LABEL_398\",\n",
      "    \"399\": \"LABEL_399\",\n",
      "    \"400\": \"LABEL_400\",\n",
      "    \"401\": \"LABEL_401\",\n",
      "    \"402\": \"LABEL_402\",\n",
      "    \"403\": \"LABEL_403\",\n",
      "    \"404\": \"LABEL_404\",\n",
      "    \"405\": \"LABEL_405\",\n",
      "    \"406\": \"LABEL_406\",\n",
      "    \"407\": \"LABEL_407\",\n",
      "    \"408\": \"LABEL_408\",\n",
      "    \"409\": \"LABEL_409\",\n",
      "    \"410\": \"LABEL_410\",\n",
      "    \"411\": \"LABEL_411\",\n",
      "    \"412\": \"LABEL_412\",\n",
      "    \"413\": \"LABEL_413\",\n",
      "    \"414\": \"LABEL_414\",\n",
      "    \"415\": \"LABEL_415\",\n",
      "    \"416\": \"LABEL_416\",\n",
      "    \"417\": \"LABEL_417\",\n",
      "    \"418\": \"LABEL_418\",\n",
      "    \"419\": \"LABEL_419\",\n",
      "    \"420\": \"LABEL_420\",\n",
      "    \"421\": \"LABEL_421\",\n",
      "    \"422\": \"LABEL_422\",\n",
      "    \"423\": \"LABEL_423\",\n",
      "    \"424\": \"LABEL_424\",\n",
      "    \"425\": \"LABEL_425\",\n",
      "    \"426\": \"LABEL_426\",\n",
      "    \"427\": \"LABEL_427\",\n",
      "    \"428\": \"LABEL_428\",\n",
      "    \"429\": \"LABEL_429\",\n",
      "    \"430\": \"LABEL_430\",\n",
      "    \"431\": \"LABEL_431\",\n",
      "    \"432\": \"LABEL_432\",\n",
      "    \"433\": \"LABEL_433\",\n",
      "    \"434\": \"LABEL_434\",\n",
      "    \"435\": \"LABEL_435\",\n",
      "    \"436\": \"LABEL_436\",\n",
      "    \"437\": \"LABEL_437\",\n",
      "    \"438\": \"LABEL_438\",\n",
      "    \"439\": \"LABEL_439\",\n",
      "    \"440\": \"LABEL_440\",\n",
      "    \"441\": \"LABEL_441\",\n",
      "    \"442\": \"LABEL_442\",\n",
      "    \"443\": \"LABEL_443\",\n",
      "    \"444\": \"LABEL_444\",\n",
      "    \"445\": \"LABEL_445\",\n",
      "    \"446\": \"LABEL_446\",\n",
      "    \"447\": \"LABEL_447\",\n",
      "    \"448\": \"LABEL_448\",\n",
      "    \"449\": \"LABEL_449\",\n",
      "    \"450\": \"LABEL_450\",\n",
      "    \"451\": \"LABEL_451\",\n",
      "    \"452\": \"LABEL_452\",\n",
      "    \"453\": \"LABEL_453\",\n",
      "    \"454\": \"LABEL_454\",\n",
      "    \"455\": \"LABEL_455\",\n",
      "    \"456\": \"LABEL_456\",\n",
      "    \"457\": \"LABEL_457\",\n",
      "    \"458\": \"LABEL_458\",\n",
      "    \"459\": \"LABEL_459\",\n",
      "    \"460\": \"LABEL_460\",\n",
      "    \"461\": \"LABEL_461\",\n",
      "    \"462\": \"LABEL_462\",\n",
      "    \"463\": \"LABEL_463\",\n",
      "    \"464\": \"LABEL_464\",\n",
      "    \"465\": \"LABEL_465\",\n",
      "    \"466\": \"LABEL_466\",\n",
      "    \"467\": \"LABEL_467\",\n",
      "    \"468\": \"LABEL_468\",\n",
      "    \"469\": \"LABEL_469\",\n",
      "    \"470\": \"LABEL_470\",\n",
      "    \"471\": \"LABEL_471\",\n",
      "    \"472\": \"LABEL_472\",\n",
      "    \"473\": \"LABEL_473\",\n",
      "    \"474\": \"LABEL_474\",\n",
      "    \"475\": \"LABEL_475\",\n",
      "    \"476\": \"LABEL_476\",\n",
      "    \"477\": \"LABEL_477\",\n",
      "    \"478\": \"LABEL_478\",\n",
      "    \"479\": \"LABEL_479\",\n",
      "    \"480\": \"LABEL_480\",\n",
      "    \"481\": \"LABEL_481\",\n",
      "    \"482\": \"LABEL_482\",\n",
      "    \"483\": \"LABEL_483\",\n",
      "    \"484\": \"LABEL_484\",\n",
      "    \"485\": \"LABEL_485\",\n",
      "    \"486\": \"LABEL_486\",\n",
      "    \"487\": \"LABEL_487\",\n",
      "    \"488\": \"LABEL_488\",\n",
      "    \"489\": \"LABEL_489\",\n",
      "    \"490\": \"LABEL_490\",\n",
      "    \"491\": \"LABEL_491\",\n",
      "    \"492\": \"LABEL_492\",\n",
      "    \"493\": \"LABEL_493\",\n",
      "    \"494\": \"LABEL_494\",\n",
      "    \"495\": \"LABEL_495\",\n",
      "    \"496\": \"LABEL_496\",\n",
      "    \"497\": \"LABEL_497\",\n",
      "    \"498\": \"LABEL_498\",\n",
      "    \"499\": \"LABEL_499\",\n",
      "    \"500\": \"LABEL_500\",\n",
      "    \"501\": \"LABEL_501\",\n",
      "    \"502\": \"LABEL_502\",\n",
      "    \"503\": \"LABEL_503\",\n",
      "    \"504\": \"LABEL_504\",\n",
      "    \"505\": \"LABEL_505\",\n",
      "    \"506\": \"LABEL_506\",\n",
      "    \"507\": \"LABEL_507\",\n",
      "    \"508\": \"LABEL_508\",\n",
      "    \"509\": \"LABEL_509\",\n",
      "    \"510\": \"LABEL_510\",\n",
      "    \"511\": \"LABEL_511\",\n",
      "    \"512\": \"LABEL_512\",\n",
      "    \"513\": \"LABEL_513\",\n",
      "    \"514\": \"LABEL_514\",\n",
      "    \"515\": \"LABEL_515\",\n",
      "    \"516\": \"LABEL_516\",\n",
      "    \"517\": \"LABEL_517\",\n",
      "    \"518\": \"LABEL_518\",\n",
      "    \"519\": \"LABEL_519\",\n",
      "    \"520\": \"LABEL_520\",\n",
      "    \"521\": \"LABEL_521\",\n",
      "    \"522\": \"LABEL_522\",\n",
      "    \"523\": \"LABEL_523\",\n",
      "    \"524\": \"LABEL_524\",\n",
      "    \"525\": \"LABEL_525\",\n",
      "    \"526\": \"LABEL_526\",\n",
      "    \"527\": \"LABEL_527\",\n",
      "    \"528\": \"LABEL_528\",\n",
      "    \"529\": \"LABEL_529\",\n",
      "    \"530\": \"LABEL_530\",\n",
      "    \"531\": \"LABEL_531\",\n",
      "    \"532\": \"LABEL_532\",\n",
      "    \"533\": \"LABEL_533\",\n",
      "    \"534\": \"LABEL_534\",\n",
      "    \"535\": \"LABEL_535\",\n",
      "    \"536\": \"LABEL_536\",\n",
      "    \"537\": \"LABEL_537\",\n",
      "    \"538\": \"LABEL_538\",\n",
      "    \"539\": \"LABEL_539\",\n",
      "    \"540\": \"LABEL_540\",\n",
      "    \"541\": \"LABEL_541\",\n",
      "    \"542\": \"LABEL_542\",\n",
      "    \"543\": \"LABEL_543\",\n",
      "    \"544\": \"LABEL_544\",\n",
      "    \"545\": \"LABEL_545\",\n",
      "    \"546\": \"LABEL_546\",\n",
      "    \"547\": \"LABEL_547\",\n",
      "    \"548\": \"LABEL_548\",\n",
      "    \"549\": \"LABEL_549\",\n",
      "    \"550\": \"LABEL_550\",\n",
      "    \"551\": \"LABEL_551\",\n",
      "    \"552\": \"LABEL_552\",\n",
      "    \"553\": \"LABEL_553\",\n",
      "    \"554\": \"LABEL_554\",\n",
      "    \"555\": \"LABEL_555\",\n",
      "    \"556\": \"LABEL_556\",\n",
      "    \"557\": \"LABEL_557\",\n",
      "    \"558\": \"LABEL_558\",\n",
      "    \"559\": \"LABEL_559\",\n",
      "    \"560\": \"LABEL_560\",\n",
      "    \"561\": \"LABEL_561\",\n",
      "    \"562\": \"LABEL_562\",\n",
      "    \"563\": \"LABEL_563\",\n",
      "    \"564\": \"LABEL_564\",\n",
      "    \"565\": \"LABEL_565\",\n",
      "    \"566\": \"LABEL_566\",\n",
      "    \"567\": \"LABEL_567\",\n",
      "    \"568\": \"LABEL_568\",\n",
      "    \"569\": \"LABEL_569\",\n",
      "    \"570\": \"LABEL_570\",\n",
      "    \"571\": \"LABEL_571\",\n",
      "    \"572\": \"LABEL_572\",\n",
      "    \"573\": \"LABEL_573\",\n",
      "    \"574\": \"LABEL_574\",\n",
      "    \"575\": \"LABEL_575\",\n",
      "    \"576\": \"LABEL_576\",\n",
      "    \"577\": \"LABEL_577\",\n",
      "    \"578\": \"LABEL_578\",\n",
      "    \"579\": \"LABEL_579\",\n",
      "    \"580\": \"LABEL_580\",\n",
      "    \"581\": \"LABEL_581\",\n",
      "    \"582\": \"LABEL_582\",\n",
      "    \"583\": \"LABEL_583\",\n",
      "    \"584\": \"LABEL_584\",\n",
      "    \"585\": \"LABEL_585\",\n",
      "    \"586\": \"LABEL_586\",\n",
      "    \"587\": \"LABEL_587\",\n",
      "    \"588\": \"LABEL_588\",\n",
      "    \"589\": \"LABEL_589\",\n",
      "    \"590\": \"LABEL_590\",\n",
      "    \"591\": \"LABEL_591\",\n",
      "    \"592\": \"LABEL_592\",\n",
      "    \"593\": \"LABEL_593\",\n",
      "    \"594\": \"LABEL_594\",\n",
      "    \"595\": \"LABEL_595\",\n",
      "    \"596\": \"LABEL_596\",\n",
      "    \"597\": \"LABEL_597\",\n",
      "    \"598\": \"LABEL_598\",\n",
      "    \"599\": \"LABEL_599\",\n",
      "    \"600\": \"LABEL_600\",\n",
      "    \"601\": \"LABEL_601\",\n",
      "    \"602\": \"LABEL_602\",\n",
      "    \"603\": \"LABEL_603\",\n",
      "    \"604\": \"LABEL_604\",\n",
      "    \"605\": \"LABEL_605\",\n",
      "    \"606\": \"LABEL_606\",\n",
      "    \"607\": \"LABEL_607\",\n",
      "    \"608\": \"LABEL_608\",\n",
      "    \"609\": \"LABEL_609\",\n",
      "    \"610\": \"LABEL_610\",\n",
      "    \"611\": \"LABEL_611\",\n",
      "    \"612\": \"LABEL_612\",\n",
      "    \"613\": \"LABEL_613\",\n",
      "    \"614\": \"LABEL_614\",\n",
      "    \"615\": \"LABEL_615\",\n",
      "    \"616\": \"LABEL_616\",\n",
      "    \"617\": \"LABEL_617\",\n",
      "    \"618\": \"LABEL_618\",\n",
      "    \"619\": \"LABEL_619\",\n",
      "    \"620\": \"LABEL_620\",\n",
      "    \"621\": \"LABEL_621\",\n",
      "    \"622\": \"LABEL_622\",\n",
      "    \"623\": \"LABEL_623\",\n",
      "    \"624\": \"LABEL_624\",\n",
      "    \"625\": \"LABEL_625\",\n",
      "    \"626\": \"LABEL_626\",\n",
      "    \"627\": \"LABEL_627\",\n",
      "    \"628\": \"LABEL_628\",\n",
      "    \"629\": \"LABEL_629\",\n",
      "    \"630\": \"LABEL_630\",\n",
      "    \"631\": \"LABEL_631\",\n",
      "    \"632\": \"LABEL_632\",\n",
      "    \"633\": \"LABEL_633\",\n",
      "    \"634\": \"LABEL_634\",\n",
      "    \"635\": \"LABEL_635\",\n",
      "    \"636\": \"LABEL_636\",\n",
      "    \"637\": \"LABEL_637\",\n",
      "    \"638\": \"LABEL_638\",\n",
      "    \"639\": \"LABEL_639\",\n",
      "    \"640\": \"LABEL_640\",\n",
      "    \"641\": \"LABEL_641\",\n",
      "    \"642\": \"LABEL_642\",\n",
      "    \"643\": \"LABEL_643\",\n",
      "    \"644\": \"LABEL_644\",\n",
      "    \"645\": \"LABEL_645\",\n",
      "    \"646\": \"LABEL_646\",\n",
      "    \"647\": \"LABEL_647\",\n",
      "    \"648\": \"LABEL_648\",\n",
      "    \"649\": \"LABEL_649\",\n",
      "    \"650\": \"LABEL_650\",\n",
      "    \"651\": \"LABEL_651\",\n",
      "    \"652\": \"LABEL_652\",\n",
      "    \"653\": \"LABEL_653\",\n",
      "    \"654\": \"LABEL_654\",\n",
      "    \"655\": \"LABEL_655\",\n",
      "    \"656\": \"LABEL_656\",\n",
      "    \"657\": \"LABEL_657\",\n",
      "    \"658\": \"LABEL_658\",\n",
      "    \"659\": \"LABEL_659\",\n",
      "    \"660\": \"LABEL_660\",\n",
      "    \"661\": \"LABEL_661\",\n",
      "    \"662\": \"LABEL_662\",\n",
      "    \"663\": \"LABEL_663\",\n",
      "    \"664\": \"LABEL_664\",\n",
      "    \"665\": \"LABEL_665\",\n",
      "    \"666\": \"LABEL_666\",\n",
      "    \"667\": \"LABEL_667\",\n",
      "    \"668\": \"LABEL_668\",\n",
      "    \"669\": \"LABEL_669\",\n",
      "    \"670\": \"LABEL_670\",\n",
      "    \"671\": \"LABEL_671\",\n",
      "    \"672\": \"LABEL_672\",\n",
      "    \"673\": \"LABEL_673\",\n",
      "    \"674\": \"LABEL_674\",\n",
      "    \"675\": \"LABEL_675\",\n",
      "    \"676\": \"LABEL_676\",\n",
      "    \"677\": \"LABEL_677\",\n",
      "    \"678\": \"LABEL_678\",\n",
      "    \"679\": \"LABEL_679\",\n",
      "    \"680\": \"LABEL_680\",\n",
      "    \"681\": \"LABEL_681\",\n",
      "    \"682\": \"LABEL_682\",\n",
      "    \"683\": \"LABEL_683\",\n",
      "    \"684\": \"LABEL_684\",\n",
      "    \"685\": \"LABEL_685\",\n",
      "    \"686\": \"LABEL_686\",\n",
      "    \"687\": \"LABEL_687\",\n",
      "    \"688\": \"LABEL_688\",\n",
      "    \"689\": \"LABEL_689\",\n",
      "    \"690\": \"LABEL_690\",\n",
      "    \"691\": \"LABEL_691\",\n",
      "    \"692\": \"LABEL_692\",\n",
      "    \"693\": \"LABEL_693\",\n",
      "    \"694\": \"LABEL_694\",\n",
      "    \"695\": \"LABEL_695\",\n",
      "    \"696\": \"LABEL_696\",\n",
      "    \"697\": \"LABEL_697\",\n",
      "    \"698\": \"LABEL_698\",\n",
      "    \"699\": \"LABEL_699\",\n",
      "    \"700\": \"LABEL_700\",\n",
      "    \"701\": \"LABEL_701\",\n",
      "    \"702\": \"LABEL_702\",\n",
      "    \"703\": \"LABEL_703\",\n",
      "    \"704\": \"LABEL_704\",\n",
      "    \"705\": \"LABEL_705\",\n",
      "    \"706\": \"LABEL_706\",\n",
      "    \"707\": \"LABEL_707\",\n",
      "    \"708\": \"LABEL_708\",\n",
      "    \"709\": \"LABEL_709\",\n",
      "    \"710\": \"LABEL_710\",\n",
      "    \"711\": \"LABEL_711\",\n",
      "    \"712\": \"LABEL_712\",\n",
      "    \"713\": \"LABEL_713\",\n",
      "    \"714\": \"LABEL_714\",\n",
      "    \"715\": \"LABEL_715\",\n",
      "    \"716\": \"LABEL_716\",\n",
      "    \"717\": \"LABEL_717\",\n",
      "    \"718\": \"LABEL_718\",\n",
      "    \"719\": \"LABEL_719\",\n",
      "    \"720\": \"LABEL_720\",\n",
      "    \"721\": \"LABEL_721\",\n",
      "    \"722\": \"LABEL_722\",\n",
      "    \"723\": \"LABEL_723\",\n",
      "    \"724\": \"LABEL_724\",\n",
      "    \"725\": \"LABEL_725\",\n",
      "    \"726\": \"LABEL_726\",\n",
      "    \"727\": \"LABEL_727\",\n",
      "    \"728\": \"LABEL_728\",\n",
      "    \"729\": \"LABEL_729\",\n",
      "    \"730\": \"LABEL_730\",\n",
      "    \"731\": \"LABEL_731\",\n",
      "    \"732\": \"LABEL_732\",\n",
      "    \"733\": \"LABEL_733\",\n",
      "    \"734\": \"LABEL_734\",\n",
      "    \"735\": \"LABEL_735\",\n",
      "    \"736\": \"LABEL_736\",\n",
      "    \"737\": \"LABEL_737\",\n",
      "    \"738\": \"LABEL_738\",\n",
      "    \"739\": \"LABEL_739\",\n",
      "    \"740\": \"LABEL_740\",\n",
      "    \"741\": \"LABEL_741\",\n",
      "    \"742\": \"LABEL_742\",\n",
      "    \"743\": \"LABEL_743\",\n",
      "    \"744\": \"LABEL_744\",\n",
      "    \"745\": \"LABEL_745\",\n",
      "    \"746\": \"LABEL_746\",\n",
      "    \"747\": \"LABEL_747\",\n",
      "    \"748\": \"LABEL_748\",\n",
      "    \"749\": \"LABEL_749\",\n",
      "    \"750\": \"LABEL_750\",\n",
      "    \"751\": \"LABEL_751\",\n",
      "    \"752\": \"LABEL_752\",\n",
      "    \"753\": \"LABEL_753\",\n",
      "    \"754\": \"LABEL_754\",\n",
      "    \"755\": \"LABEL_755\",\n",
      "    \"756\": \"LABEL_756\",\n",
      "    \"757\": \"LABEL_757\",\n",
      "    \"758\": \"LABEL_758\",\n",
      "    \"759\": \"LABEL_759\",\n",
      "    \"760\": \"LABEL_760\",\n",
      "    \"761\": \"LABEL_761\",\n",
      "    \"762\": \"LABEL_762\",\n",
      "    \"763\": \"LABEL_763\",\n",
      "    \"764\": \"LABEL_764\",\n",
      "    \"765\": \"LABEL_765\",\n",
      "    \"766\": \"LABEL_766\",\n",
      "    \"767\": \"LABEL_767\",\n",
      "    \"768\": \"LABEL_768\",\n",
      "    \"769\": \"LABEL_769\",\n",
      "    \"770\": \"LABEL_770\",\n",
      "    \"771\": \"LABEL_771\",\n",
      "    \"772\": \"LABEL_772\",\n",
      "    \"773\": \"LABEL_773\",\n",
      "    \"774\": \"LABEL_774\",\n",
      "    \"775\": \"LABEL_775\",\n",
      "    \"776\": \"LABEL_776\",\n",
      "    \"777\": \"LABEL_777\",\n",
      "    \"778\": \"LABEL_778\",\n",
      "    \"779\": \"LABEL_779\",\n",
      "    \"780\": \"LABEL_780\",\n",
      "    \"781\": \"LABEL_781\",\n",
      "    \"782\": \"LABEL_782\",\n",
      "    \"783\": \"LABEL_783\",\n",
      "    \"784\": \"LABEL_784\",\n",
      "    \"785\": \"LABEL_785\",\n",
      "    \"786\": \"LABEL_786\",\n",
      "    \"787\": \"LABEL_787\",\n",
      "    \"788\": \"LABEL_788\",\n",
      "    \"789\": \"LABEL_789\",\n",
      "    \"790\": \"LABEL_790\",\n",
      "    \"791\": \"LABEL_791\",\n",
      "    \"792\": \"LABEL_792\",\n",
      "    \"793\": \"LABEL_793\",\n",
      "    \"794\": \"LABEL_794\",\n",
      "    \"795\": \"LABEL_795\",\n",
      "    \"796\": \"LABEL_796\",\n",
      "    \"797\": \"LABEL_797\",\n",
      "    \"798\": \"LABEL_798\",\n",
      "    \"799\": \"LABEL_799\",\n",
      "    \"800\": \"LABEL_800\",\n",
      "    \"801\": \"LABEL_801\",\n",
      "    \"802\": \"LABEL_802\",\n",
      "    \"803\": \"LABEL_803\",\n",
      "    \"804\": \"LABEL_804\",\n",
      "    \"805\": \"LABEL_805\",\n",
      "    \"806\": \"LABEL_806\",\n",
      "    \"807\": \"LABEL_807\",\n",
      "    \"808\": \"LABEL_808\",\n",
      "    \"809\": \"LABEL_809\",\n",
      "    \"810\": \"LABEL_810\",\n",
      "    \"811\": \"LABEL_811\",\n",
      "    \"812\": \"LABEL_812\",\n",
      "    \"813\": \"LABEL_813\",\n",
      "    \"814\": \"LABEL_814\",\n",
      "    \"815\": \"LABEL_815\",\n",
      "    \"816\": \"LABEL_816\",\n",
      "    \"817\": \"LABEL_817\",\n",
      "    \"818\": \"LABEL_818\",\n",
      "    \"819\": \"LABEL_819\",\n",
      "    \"820\": \"LABEL_820\",\n",
      "    \"821\": \"LABEL_821\",\n",
      "    \"822\": \"LABEL_822\",\n",
      "    \"823\": \"LABEL_823\",\n",
      "    \"824\": \"LABEL_824\",\n",
      "    \"825\": \"LABEL_825\",\n",
      "    \"826\": \"LABEL_826\",\n",
      "    \"827\": \"LABEL_827\",\n",
      "    \"828\": \"LABEL_828\",\n",
      "    \"829\": \"LABEL_829\",\n",
      "    \"830\": \"LABEL_830\",\n",
      "    \"831\": \"LABEL_831\",\n",
      "    \"832\": \"LABEL_832\",\n",
      "    \"833\": \"LABEL_833\",\n",
      "    \"834\": \"LABEL_834\",\n",
      "    \"835\": \"LABEL_835\",\n",
      "    \"836\": \"LABEL_836\",\n",
      "    \"837\": \"LABEL_837\",\n",
      "    \"838\": \"LABEL_838\",\n",
      "    \"839\": \"LABEL_839\",\n",
      "    \"840\": \"LABEL_840\",\n",
      "    \"841\": \"LABEL_841\",\n",
      "    \"842\": \"LABEL_842\",\n",
      "    \"843\": \"LABEL_843\",\n",
      "    \"844\": \"LABEL_844\",\n",
      "    \"845\": \"LABEL_845\",\n",
      "    \"846\": \"LABEL_846\",\n",
      "    \"847\": \"LABEL_847\",\n",
      "    \"848\": \"LABEL_848\",\n",
      "    \"849\": \"LABEL_849\",\n",
      "    \"850\": \"LABEL_850\",\n",
      "    \"851\": \"LABEL_851\",\n",
      "    \"852\": \"LABEL_852\",\n",
      "    \"853\": \"LABEL_853\",\n",
      "    \"854\": \"LABEL_854\",\n",
      "    \"855\": \"LABEL_855\",\n",
      "    \"856\": \"LABEL_856\",\n",
      "    \"857\": \"LABEL_857\",\n",
      "    \"858\": \"LABEL_858\",\n",
      "    \"859\": \"LABEL_859\",\n",
      "    \"860\": \"LABEL_860\",\n",
      "    \"861\": \"LABEL_861\",\n",
      "    \"862\": \"LABEL_862\",\n",
      "    \"863\": \"LABEL_863\",\n",
      "    \"864\": \"LABEL_864\",\n",
      "    \"865\": \"LABEL_865\",\n",
      "    \"866\": \"LABEL_866\",\n",
      "    \"867\": \"LABEL_867\",\n",
      "    \"868\": \"LABEL_868\",\n",
      "    \"869\": \"LABEL_869\",\n",
      "    \"870\": \"LABEL_870\",\n",
      "    \"871\": \"LABEL_871\",\n",
      "    \"872\": \"LABEL_872\",\n",
      "    \"873\": \"LABEL_873\",\n",
      "    \"874\": \"LABEL_874\",\n",
      "    \"875\": \"LABEL_875\",\n",
      "    \"876\": \"LABEL_876\",\n",
      "    \"877\": \"LABEL_877\",\n",
      "    \"878\": \"LABEL_878\",\n",
      "    \"879\": \"LABEL_879\",\n",
      "    \"880\": \"LABEL_880\",\n",
      "    \"881\": \"LABEL_881\",\n",
      "    \"882\": \"LABEL_882\",\n",
      "    \"883\": \"LABEL_883\",\n",
      "    \"884\": \"LABEL_884\",\n",
      "    \"885\": \"LABEL_885\",\n",
      "    \"886\": \"LABEL_886\",\n",
      "    \"887\": \"LABEL_887\",\n",
      "    \"888\": \"LABEL_888\",\n",
      "    \"889\": \"LABEL_889\",\n",
      "    \"890\": \"LABEL_890\",\n",
      "    \"891\": \"LABEL_891\",\n",
      "    \"892\": \"LABEL_892\",\n",
      "    \"893\": \"LABEL_893\",\n",
      "    \"894\": \"LABEL_894\",\n",
      "    \"895\": \"LABEL_895\",\n",
      "    \"896\": \"LABEL_896\",\n",
      "    \"897\": \"LABEL_897\",\n",
      "    \"898\": \"LABEL_898\",\n",
      "    \"899\": \"LABEL_899\",\n",
      "    \"900\": \"LABEL_900\",\n",
      "    \"901\": \"LABEL_901\",\n",
      "    \"902\": \"LABEL_902\",\n",
      "    \"903\": \"LABEL_903\",\n",
      "    \"904\": \"LABEL_904\",\n",
      "    \"905\": \"LABEL_905\",\n",
      "    \"906\": \"LABEL_906\",\n",
      "    \"907\": \"LABEL_907\",\n",
      "    \"908\": \"LABEL_908\",\n",
      "    \"909\": \"LABEL_909\",\n",
      "    \"910\": \"LABEL_910\",\n",
      "    \"911\": \"LABEL_911\",\n",
      "    \"912\": \"LABEL_912\",\n",
      "    \"913\": \"LABEL_913\",\n",
      "    \"914\": \"LABEL_914\",\n",
      "    \"915\": \"LABEL_915\",\n",
      "    \"916\": \"LABEL_916\",\n",
      "    \"917\": \"LABEL_917\",\n",
      "    \"918\": \"LABEL_918\",\n",
      "    \"919\": \"LABEL_919\",\n",
      "    \"920\": \"LABEL_920\",\n",
      "    \"921\": \"LABEL_921\",\n",
      "    \"922\": \"LABEL_922\",\n",
      "    \"923\": \"LABEL_923\",\n",
      "    \"924\": \"LABEL_924\",\n",
      "    \"925\": \"LABEL_925\",\n",
      "    \"926\": \"LABEL_926\",\n",
      "    \"927\": \"LABEL_927\",\n",
      "    \"928\": \"LABEL_928\",\n",
      "    \"929\": \"LABEL_929\",\n",
      "    \"930\": \"LABEL_930\",\n",
      "    \"931\": \"LABEL_931\",\n",
      "    \"932\": \"LABEL_932\",\n",
      "    \"933\": \"LABEL_933\",\n",
      "    \"934\": \"LABEL_934\",\n",
      "    \"935\": \"LABEL_935\",\n",
      "    \"936\": \"LABEL_936\",\n",
      "    \"937\": \"LABEL_937\",\n",
      "    \"938\": \"LABEL_938\",\n",
      "    \"939\": \"LABEL_939\",\n",
      "    \"940\": \"LABEL_940\",\n",
      "    \"941\": \"LABEL_941\",\n",
      "    \"942\": \"LABEL_942\",\n",
      "    \"943\": \"LABEL_943\",\n",
      "    \"944\": \"LABEL_944\",\n",
      "    \"945\": \"LABEL_945\",\n",
      "    \"946\": \"LABEL_946\",\n",
      "    \"947\": \"LABEL_947\",\n",
      "    \"948\": \"LABEL_948\",\n",
      "    \"949\": \"LABEL_949\",\n",
      "    \"950\": \"LABEL_950\",\n",
      "    \"951\": \"LABEL_951\",\n",
      "    \"952\": \"LABEL_952\",\n",
      "    \"953\": \"LABEL_953\",\n",
      "    \"954\": \"LABEL_954\",\n",
      "    \"955\": \"LABEL_955\",\n",
      "    \"956\": \"LABEL_956\",\n",
      "    \"957\": \"LABEL_957\",\n",
      "    \"958\": \"LABEL_958\",\n",
      "    \"959\": \"LABEL_959\",\n",
      "    \"960\": \"LABEL_960\",\n",
      "    \"961\": \"LABEL_961\",\n",
      "    \"962\": \"LABEL_962\",\n",
      "    \"963\": \"LABEL_963\",\n",
      "    \"964\": \"LABEL_964\",\n",
      "    \"965\": \"LABEL_965\",\n",
      "    \"966\": \"LABEL_966\",\n",
      "    \"967\": \"LABEL_967\",\n",
      "    \"968\": \"LABEL_968\",\n",
      "    \"969\": \"LABEL_969\",\n",
      "    \"970\": \"LABEL_970\",\n",
      "    \"971\": \"LABEL_971\",\n",
      "    \"972\": \"LABEL_972\",\n",
      "    \"973\": \"LABEL_973\",\n",
      "    \"974\": \"LABEL_974\",\n",
      "    \"975\": \"LABEL_975\",\n",
      "    \"976\": \"LABEL_976\",\n",
      "    \"977\": \"LABEL_977\",\n",
      "    \"978\": \"LABEL_978\",\n",
      "    \"979\": \"LABEL_979\",\n",
      "    \"980\": \"LABEL_980\",\n",
      "    \"981\": \"LABEL_981\",\n",
      "    \"982\": \"LABEL_982\",\n",
      "    \"983\": \"LABEL_983\",\n",
      "    \"984\": \"LABEL_984\",\n",
      "    \"985\": \"LABEL_985\",\n",
      "    \"986\": \"LABEL_986\",\n",
      "    \"987\": \"LABEL_987\",\n",
      "    \"988\": \"LABEL_988\",\n",
      "    \"989\": \"LABEL_989\",\n",
      "    \"990\": \"LABEL_990\",\n",
      "    \"991\": \"LABEL_991\",\n",
      "    \"992\": \"LABEL_992\",\n",
      "    \"993\": \"LABEL_993\",\n",
      "    \"994\": \"LABEL_994\",\n",
      "    \"995\": \"LABEL_995\",\n",
      "    \"996\": \"LABEL_996\",\n",
      "    \"997\": \"LABEL_997\",\n",
      "    \"998\": \"LABEL_998\",\n",
      "    \"999\": \"LABEL_999\",\n",
      "    \"1000\": \"LABEL_1000\",\n",
      "    \"1001\": \"LABEL_1001\",\n",
      "    \"1002\": \"LABEL_1002\",\n",
      "    \"1003\": \"LABEL_1003\",\n",
      "    \"1004\": \"LABEL_1004\",\n",
      "    \"1005\": \"LABEL_1005\",\n",
      "    \"1006\": \"LABEL_1006\",\n",
      "    \"1007\": \"LABEL_1007\",\n",
      "    \"1008\": \"LABEL_1008\",\n",
      "    \"1009\": \"LABEL_1009\",\n",
      "    \"1010\": \"LABEL_1010\",\n",
      "    \"1011\": \"LABEL_1011\",\n",
      "    \"1012\": \"LABEL_1012\",\n",
      "    \"1013\": \"LABEL_1013\",\n",
      "    \"1014\": \"LABEL_1014\",\n",
      "    \"1015\": \"LABEL_1015\",\n",
      "    \"1016\": \"LABEL_1016\",\n",
      "    \"1017\": \"LABEL_1017\",\n",
      "    \"1018\": \"LABEL_1018\",\n",
      "    \"1019\": \"LABEL_1019\",\n",
      "    \"1020\": \"LABEL_1020\",\n",
      "    \"1021\": \"LABEL_1021\",\n",
      "    \"1022\": \"LABEL_1022\",\n",
      "    \"1023\": \"LABEL_1023\",\n",
      "    \"1024\": \"LABEL_1024\",\n",
      "    \"1025\": \"LABEL_1025\",\n",
      "    \"1026\": \"LABEL_1026\",\n",
      "    \"1027\": \"LABEL_1027\",\n",
      "    \"1028\": \"LABEL_1028\",\n",
      "    \"1029\": \"LABEL_1029\",\n",
      "    \"1030\": \"LABEL_1030\",\n",
      "    \"1031\": \"LABEL_1031\",\n",
      "    \"1032\": \"LABEL_1032\",\n",
      "    \"1033\": \"LABEL_1033\",\n",
      "    \"1034\": \"LABEL_1034\",\n",
      "    \"1035\": \"LABEL_1035\",\n",
      "    \"1036\": \"LABEL_1036\",\n",
      "    \"1037\": \"LABEL_1037\",\n",
      "    \"1038\": \"LABEL_1038\",\n",
      "    \"1039\": \"LABEL_1039\",\n",
      "    \"1040\": \"LABEL_1040\",\n",
      "    \"1041\": \"LABEL_1041\",\n",
      "    \"1042\": \"LABEL_1042\",\n",
      "    \"1043\": \"LABEL_1043\",\n",
      "    \"1044\": \"LABEL_1044\",\n",
      "    \"1045\": \"LABEL_1045\",\n",
      "    \"1046\": \"LABEL_1046\",\n",
      "    \"1047\": \"LABEL_1047\",\n",
      "    \"1048\": \"LABEL_1048\",\n",
      "    \"1049\": \"LABEL_1049\",\n",
      "    \"1050\": \"LABEL_1050\",\n",
      "    \"1051\": \"LABEL_1051\",\n",
      "    \"1052\": \"LABEL_1052\",\n",
      "    \"1053\": \"LABEL_1053\",\n",
      "    \"1054\": \"LABEL_1054\",\n",
      "    \"1055\": \"LABEL_1055\",\n",
      "    \"1056\": \"LABEL_1056\",\n",
      "    \"1057\": \"LABEL_1057\",\n",
      "    \"1058\": \"LABEL_1058\",\n",
      "    \"1059\": \"LABEL_1059\",\n",
      "    \"1060\": \"LABEL_1060\",\n",
      "    \"1061\": \"LABEL_1061\",\n",
      "    \"1062\": \"LABEL_1062\",\n",
      "    \"1063\": \"LABEL_1063\",\n",
      "    \"1064\": \"LABEL_1064\",\n",
      "    \"1065\": \"LABEL_1065\",\n",
      "    \"1066\": \"LABEL_1066\",\n",
      "    \"1067\": \"LABEL_1067\",\n",
      "    \"1068\": \"LABEL_1068\",\n",
      "    \"1069\": \"LABEL_1069\",\n",
      "    \"1070\": \"LABEL_1070\",\n",
      "    \"1071\": \"LABEL_1071\",\n",
      "    \"1072\": \"LABEL_1072\",\n",
      "    \"1073\": \"LABEL_1073\",\n",
      "    \"1074\": \"LABEL_1074\",\n",
      "    \"1075\": \"LABEL_1075\",\n",
      "    \"1076\": \"LABEL_1076\",\n",
      "    \"1077\": \"LABEL_1077\",\n",
      "    \"1078\": \"LABEL_1078\",\n",
      "    \"1079\": \"LABEL_1079\",\n",
      "    \"1080\": \"LABEL_1080\",\n",
      "    \"1081\": \"LABEL_1081\",\n",
      "    \"1082\": \"LABEL_1082\",\n",
      "    \"1083\": \"LABEL_1083\",\n",
      "    \"1084\": \"LABEL_1084\",\n",
      "    \"1085\": \"LABEL_1085\",\n",
      "    \"1086\": \"LABEL_1086\",\n",
      "    \"1087\": \"LABEL_1087\",\n",
      "    \"1088\": \"LABEL_1088\",\n",
      "    \"1089\": \"LABEL_1089\",\n",
      "    \"1090\": \"LABEL_1090\",\n",
      "    \"1091\": \"LABEL_1091\",\n",
      "    \"1092\": \"LABEL_1092\",\n",
      "    \"1093\": \"LABEL_1093\",\n",
      "    \"1094\": \"LABEL_1094\",\n",
      "    \"1095\": \"LABEL_1095\",\n",
      "    \"1096\": \"LABEL_1096\",\n",
      "    \"1097\": \"LABEL_1097\",\n",
      "    \"1098\": \"LABEL_1098\",\n",
      "    \"1099\": \"LABEL_1099\",\n",
      "    \"1100\": \"LABEL_1100\",\n",
      "    \"1101\": \"LABEL_1101\",\n",
      "    \"1102\": \"LABEL_1102\",\n",
      "    \"1103\": \"LABEL_1103\",\n",
      "    \"1104\": \"LABEL_1104\",\n",
      "    \"1105\": \"LABEL_1105\",\n",
      "    \"1106\": \"LABEL_1106\",\n",
      "    \"1107\": \"LABEL_1107\",\n",
      "    \"1108\": \"LABEL_1108\",\n",
      "    \"1109\": \"LABEL_1109\",\n",
      "    \"1110\": \"LABEL_1110\",\n",
      "    \"1111\": \"LABEL_1111\",\n",
      "    \"1112\": \"LABEL_1112\",\n",
      "    \"1113\": \"LABEL_1113\",\n",
      "    \"1114\": \"LABEL_1114\",\n",
      "    \"1115\": \"LABEL_1115\",\n",
      "    \"1116\": \"LABEL_1116\",\n",
      "    \"1117\": \"LABEL_1117\",\n",
      "    \"1118\": \"LABEL_1118\",\n",
      "    \"1119\": \"LABEL_1119\",\n",
      "    \"1120\": \"LABEL_1120\",\n",
      "    \"1121\": \"LABEL_1121\",\n",
      "    \"1122\": \"LABEL_1122\",\n",
      "    \"1123\": \"LABEL_1123\",\n",
      "    \"1124\": \"LABEL_1124\",\n",
      "    \"1125\": \"LABEL_1125\",\n",
      "    \"1126\": \"LABEL_1126\",\n",
      "    \"1127\": \"LABEL_1127\",\n",
      "    \"1128\": \"LABEL_1128\",\n",
      "    \"1129\": \"LABEL_1129\",\n",
      "    \"1130\": \"LABEL_1130\",\n",
      "    \"1131\": \"LABEL_1131\",\n",
      "    \"1132\": \"LABEL_1132\",\n",
      "    \"1133\": \"LABEL_1133\",\n",
      "    \"1134\": \"LABEL_1134\",\n",
      "    \"1135\": \"LABEL_1135\",\n",
      "    \"1136\": \"LABEL_1136\",\n",
      "    \"1137\": \"LABEL_1137\",\n",
      "    \"1138\": \"LABEL_1138\",\n",
      "    \"1139\": \"LABEL_1139\",\n",
      "    \"1140\": \"LABEL_1140\",\n",
      "    \"1141\": \"LABEL_1141\",\n",
      "    \"1142\": \"LABEL_1142\",\n",
      "    \"1143\": \"LABEL_1143\",\n",
      "    \"1144\": \"LABEL_1144\",\n",
      "    \"1145\": \"LABEL_1145\",\n",
      "    \"1146\": \"LABEL_1146\",\n",
      "    \"1147\": \"LABEL_1147\",\n",
      "    \"1148\": \"LABEL_1148\",\n",
      "    \"1149\": \"LABEL_1149\",\n",
      "    \"1150\": \"LABEL_1150\",\n",
      "    \"1151\": \"LABEL_1151\",\n",
      "    \"1152\": \"LABEL_1152\",\n",
      "    \"1153\": \"LABEL_1153\",\n",
      "    \"1154\": \"LABEL_1154\",\n",
      "    \"1155\": \"LABEL_1155\",\n",
      "    \"1156\": \"LABEL_1156\",\n",
      "    \"1157\": \"LABEL_1157\",\n",
      "    \"1158\": \"LABEL_1158\",\n",
      "    \"1159\": \"LABEL_1159\",\n",
      "    \"1160\": \"LABEL_1160\",\n",
      "    \"1161\": \"LABEL_1161\",\n",
      "    \"1162\": \"LABEL_1162\",\n",
      "    \"1163\": \"LABEL_1163\",\n",
      "    \"1164\": \"LABEL_1164\",\n",
      "    \"1165\": \"LABEL_1165\",\n",
      "    \"1166\": \"LABEL_1166\",\n",
      "    \"1167\": \"LABEL_1167\",\n",
      "    \"1168\": \"LABEL_1168\",\n",
      "    \"1169\": \"LABEL_1169\",\n",
      "    \"1170\": \"LABEL_1170\",\n",
      "    \"1171\": \"LABEL_1171\",\n",
      "    \"1172\": \"LABEL_1172\",\n",
      "    \"1173\": \"LABEL_1173\",\n",
      "    \"1174\": \"LABEL_1174\",\n",
      "    \"1175\": \"LABEL_1175\",\n",
      "    \"1176\": \"LABEL_1176\",\n",
      "    \"1177\": \"LABEL_1177\",\n",
      "    \"1178\": \"LABEL_1178\",\n",
      "    \"1179\": \"LABEL_1179\",\n",
      "    \"1180\": \"LABEL_1180\",\n",
      "    \"1181\": \"LABEL_1181\",\n",
      "    \"1182\": \"LABEL_1182\",\n",
      "    \"1183\": \"LABEL_1183\",\n",
      "    \"1184\": \"LABEL_1184\",\n",
      "    \"1185\": \"LABEL_1185\",\n",
      "    \"1186\": \"LABEL_1186\",\n",
      "    \"1187\": \"LABEL_1187\",\n",
      "    \"1188\": \"LABEL_1188\",\n",
      "    \"1189\": \"LABEL_1189\",\n",
      "    \"1190\": \"LABEL_1190\",\n",
      "    \"1191\": \"LABEL_1191\",\n",
      "    \"1192\": \"LABEL_1192\",\n",
      "    \"1193\": \"LABEL_1193\",\n",
      "    \"1194\": \"LABEL_1194\",\n",
      "    \"1195\": \"LABEL_1195\",\n",
      "    \"1196\": \"LABEL_1196\",\n",
      "    \"1197\": \"LABEL_1197\",\n",
      "    \"1198\": \"LABEL_1198\",\n",
      "    \"1199\": \"LABEL_1199\",\n",
      "    \"1200\": \"LABEL_1200\",\n",
      "    \"1201\": \"LABEL_1201\",\n",
      "    \"1202\": \"LABEL_1202\",\n",
      "    \"1203\": \"LABEL_1203\",\n",
      "    \"1204\": \"LABEL_1204\",\n",
      "    \"1205\": \"LABEL_1205\",\n",
      "    \"1206\": \"LABEL_1206\",\n",
      "    \"1207\": \"LABEL_1207\",\n",
      "    \"1208\": \"LABEL_1208\",\n",
      "    \"1209\": \"LABEL_1209\",\n",
      "    \"1210\": \"LABEL_1210\",\n",
      "    \"1211\": \"LABEL_1211\",\n",
      "    \"1212\": \"LABEL_1212\",\n",
      "    \"1213\": \"LABEL_1213\",\n",
      "    \"1214\": \"LABEL_1214\",\n",
      "    \"1215\": \"LABEL_1215\",\n",
      "    \"1216\": \"LABEL_1216\",\n",
      "    \"1217\": \"LABEL_1217\",\n",
      "    \"1218\": \"LABEL_1218\",\n",
      "    \"1219\": \"LABEL_1219\",\n",
      "    \"1220\": \"LABEL_1220\",\n",
      "    \"1221\": \"LABEL_1221\",\n",
      "    \"1222\": \"LABEL_1222\",\n",
      "    \"1223\": \"LABEL_1223\",\n",
      "    \"1224\": \"LABEL_1224\",\n",
      "    \"1225\": \"LABEL_1225\",\n",
      "    \"1226\": \"LABEL_1226\",\n",
      "    \"1227\": \"LABEL_1227\",\n",
      "    \"1228\": \"LABEL_1228\",\n",
      "    \"1229\": \"LABEL_1229\",\n",
      "    \"1230\": \"LABEL_1230\",\n",
      "    \"1231\": \"LABEL_1231\",\n",
      "    \"1232\": \"LABEL_1232\",\n",
      "    \"1233\": \"LABEL_1233\",\n",
      "    \"1234\": \"LABEL_1234\",\n",
      "    \"1235\": \"LABEL_1235\",\n",
      "    \"1236\": \"LABEL_1236\",\n",
      "    \"1237\": \"LABEL_1237\",\n",
      "    \"1238\": \"LABEL_1238\",\n",
      "    \"1239\": \"LABEL_1239\",\n",
      "    \"1240\": \"LABEL_1240\",\n",
      "    \"1241\": \"LABEL_1241\",\n",
      "    \"1242\": \"LABEL_1242\",\n",
      "    \"1243\": \"LABEL_1243\",\n",
      "    \"1244\": \"LABEL_1244\",\n",
      "    \"1245\": \"LABEL_1245\",\n",
      "    \"1246\": \"LABEL_1246\",\n",
      "    \"1247\": \"LABEL_1247\",\n",
      "    \"1248\": \"LABEL_1248\",\n",
      "    \"1249\": \"LABEL_1249\",\n",
      "    \"1250\": \"LABEL_1250\",\n",
      "    \"1251\": \"LABEL_1251\",\n",
      "    \"1252\": \"LABEL_1252\",\n",
      "    \"1253\": \"LABEL_1253\",\n",
      "    \"1254\": \"LABEL_1254\",\n",
      "    \"1255\": \"LABEL_1255\",\n",
      "    \"1256\": \"LABEL_1256\",\n",
      "    \"1257\": \"LABEL_1257\",\n",
      "    \"1258\": \"LABEL_1258\",\n",
      "    \"1259\": \"LABEL_1259\",\n",
      "    \"1260\": \"LABEL_1260\",\n",
      "    \"1261\": \"LABEL_1261\",\n",
      "    \"1262\": \"LABEL_1262\",\n",
      "    \"1263\": \"LABEL_1263\",\n",
      "    \"1264\": \"LABEL_1264\",\n",
      "    \"1265\": \"LABEL_1265\",\n",
      "    \"1266\": \"LABEL_1266\",\n",
      "    \"1267\": \"LABEL_1267\",\n",
      "    \"1268\": \"LABEL_1268\",\n",
      "    \"1269\": \"LABEL_1269\",\n",
      "    \"1270\": \"LABEL_1270\",\n",
      "    \"1271\": \"LABEL_1271\",\n",
      "    \"1272\": \"LABEL_1272\",\n",
      "    \"1273\": \"LABEL_1273\",\n",
      "    \"1274\": \"LABEL_1274\",\n",
      "    \"1275\": \"LABEL_1275\",\n",
      "    \"1276\": \"LABEL_1276\",\n",
      "    \"1277\": \"LABEL_1277\",\n",
      "    \"1278\": \"LABEL_1278\",\n",
      "    \"1279\": \"LABEL_1279\",\n",
      "    \"1280\": \"LABEL_1280\",\n",
      "    \"1281\": \"LABEL_1281\",\n",
      "    \"1282\": \"LABEL_1282\",\n",
      "    \"1283\": \"LABEL_1283\",\n",
      "    \"1284\": \"LABEL_1284\",\n",
      "    \"1285\": \"LABEL_1285\",\n",
      "    \"1286\": \"LABEL_1286\",\n",
      "    \"1287\": \"LABEL_1287\",\n",
      "    \"1288\": \"LABEL_1288\",\n",
      "    \"1289\": \"LABEL_1289\",\n",
      "    \"1290\": \"LABEL_1290\",\n",
      "    \"1291\": \"LABEL_1291\",\n",
      "    \"1292\": \"LABEL_1292\",\n",
      "    \"1293\": \"LABEL_1293\",\n",
      "    \"1294\": \"LABEL_1294\",\n",
      "    \"1295\": \"LABEL_1295\",\n",
      "    \"1296\": \"LABEL_1296\",\n",
      "    \"1297\": \"LABEL_1297\",\n",
      "    \"1298\": \"LABEL_1298\",\n",
      "    \"1299\": \"LABEL_1299\",\n",
      "    \"1300\": \"LABEL_1300\",\n",
      "    \"1301\": \"LABEL_1301\",\n",
      "    \"1302\": \"LABEL_1302\",\n",
      "    \"1303\": \"LABEL_1303\",\n",
      "    \"1304\": \"LABEL_1304\",\n",
      "    \"1305\": \"LABEL_1305\",\n",
      "    \"1306\": \"LABEL_1306\",\n",
      "    \"1307\": \"LABEL_1307\",\n",
      "    \"1308\": \"LABEL_1308\",\n",
      "    \"1309\": \"LABEL_1309\",\n",
      "    \"1310\": \"LABEL_1310\",\n",
      "    \"1311\": \"LABEL_1311\",\n",
      "    \"1312\": \"LABEL_1312\",\n",
      "    \"1313\": \"LABEL_1313\",\n",
      "    \"1314\": \"LABEL_1314\",\n",
      "    \"1315\": \"LABEL_1315\",\n",
      "    \"1316\": \"LABEL_1316\",\n",
      "    \"1317\": \"LABEL_1317\",\n",
      "    \"1318\": \"LABEL_1318\",\n",
      "    \"1319\": \"LABEL_1319\",\n",
      "    \"1320\": \"LABEL_1320\",\n",
      "    \"1321\": \"LABEL_1321\",\n",
      "    \"1322\": \"LABEL_1322\",\n",
      "    \"1323\": \"LABEL_1323\",\n",
      "    \"1324\": \"LABEL_1324\",\n",
      "    \"1325\": \"LABEL_1325\",\n",
      "    \"1326\": \"LABEL_1326\",\n",
      "    \"1327\": \"LABEL_1327\",\n",
      "    \"1328\": \"LABEL_1328\",\n",
      "    \"1329\": \"LABEL_1329\",\n",
      "    \"1330\": \"LABEL_1330\",\n",
      "    \"1331\": \"LABEL_1331\",\n",
      "    \"1332\": \"LABEL_1332\",\n",
      "    \"1333\": \"LABEL_1333\",\n",
      "    \"1334\": \"LABEL_1334\",\n",
      "    \"1335\": \"LABEL_1335\",\n",
      "    \"1336\": \"LABEL_1336\",\n",
      "    \"1337\": \"LABEL_1337\",\n",
      "    \"1338\": \"LABEL_1338\",\n",
      "    \"1339\": \"LABEL_1339\",\n",
      "    \"1340\": \"LABEL_1340\",\n",
      "    \"1341\": \"LABEL_1341\",\n",
      "    \"1342\": \"LABEL_1342\",\n",
      "    \"1343\": \"LABEL_1343\",\n",
      "    \"1344\": \"LABEL_1344\",\n",
      "    \"1345\": \"LABEL_1345\",\n",
      "    \"1346\": \"LABEL_1346\",\n",
      "    \"1347\": \"LABEL_1347\",\n",
      "    \"1348\": \"LABEL_1348\",\n",
      "    \"1349\": \"LABEL_1349\",\n",
      "    \"1350\": \"LABEL_1350\",\n",
      "    \"1351\": \"LABEL_1351\",\n",
      "    \"1352\": \"LABEL_1352\",\n",
      "    \"1353\": \"LABEL_1353\",\n",
      "    \"1354\": \"LABEL_1354\",\n",
      "    \"1355\": \"LABEL_1355\",\n",
      "    \"1356\": \"LABEL_1356\",\n",
      "    \"1357\": \"LABEL_1357\",\n",
      "    \"1358\": \"LABEL_1358\",\n",
      "    \"1359\": \"LABEL_1359\",\n",
      "    \"1360\": \"LABEL_1360\",\n",
      "    \"1361\": \"LABEL_1361\",\n",
      "    \"1362\": \"LABEL_1362\",\n",
      "    \"1363\": \"LABEL_1363\",\n",
      "    \"1364\": \"LABEL_1364\",\n",
      "    \"1365\": \"LABEL_1365\",\n",
      "    \"1366\": \"LABEL_1366\",\n",
      "    \"1367\": \"LABEL_1367\",\n",
      "    \"1368\": \"LABEL_1368\",\n",
      "    \"1369\": \"LABEL_1369\",\n",
      "    \"1370\": \"LABEL_1370\",\n",
      "    \"1371\": \"LABEL_1371\",\n",
      "    \"1372\": \"LABEL_1372\",\n",
      "    \"1373\": \"LABEL_1373\",\n",
      "    \"1374\": \"LABEL_1374\",\n",
      "    \"1375\": \"LABEL_1375\",\n",
      "    \"1376\": \"LABEL_1376\",\n",
      "    \"1377\": \"LABEL_1377\",\n",
      "    \"1378\": \"LABEL_1378\",\n",
      "    \"1379\": \"LABEL_1379\",\n",
      "    \"1380\": \"LABEL_1380\",\n",
      "    \"1381\": \"LABEL_1381\",\n",
      "    \"1382\": \"LABEL_1382\",\n",
      "    \"1383\": \"LABEL_1383\",\n",
      "    \"1384\": \"LABEL_1384\",\n",
      "    \"1385\": \"LABEL_1385\",\n",
      "    \"1386\": \"LABEL_1386\",\n",
      "    \"1387\": \"LABEL_1387\",\n",
      "    \"1388\": \"LABEL_1388\",\n",
      "    \"1389\": \"LABEL_1389\",\n",
      "    \"1390\": \"LABEL_1390\",\n",
      "    \"1391\": \"LABEL_1391\",\n",
      "    \"1392\": \"LABEL_1392\",\n",
      "    \"1393\": \"LABEL_1393\",\n",
      "    \"1394\": \"LABEL_1394\",\n",
      "    \"1395\": \"LABEL_1395\",\n",
      "    \"1396\": \"LABEL_1396\",\n",
      "    \"1397\": \"LABEL_1397\",\n",
      "    \"1398\": \"LABEL_1398\",\n",
      "    \"1399\": \"LABEL_1399\",\n",
      "    \"1400\": \"LABEL_1400\",\n",
      "    \"1401\": \"LABEL_1401\",\n",
      "    \"1402\": \"LABEL_1402\",\n",
      "    \"1403\": \"LABEL_1403\",\n",
      "    \"1404\": \"LABEL_1404\",\n",
      "    \"1405\": \"LABEL_1405\",\n",
      "    \"1406\": \"LABEL_1406\",\n",
      "    \"1407\": \"LABEL_1407\",\n",
      "    \"1408\": \"LABEL_1408\",\n",
      "    \"1409\": \"LABEL_1409\",\n",
      "    \"1410\": \"LABEL_1410\",\n",
      "    \"1411\": \"LABEL_1411\",\n",
      "    \"1412\": \"LABEL_1412\",\n",
      "    \"1413\": \"LABEL_1413\",\n",
      "    \"1414\": \"LABEL_1414\",\n",
      "    \"1415\": \"LABEL_1415\",\n",
      "    \"1416\": \"LABEL_1416\",\n",
      "    \"1417\": \"LABEL_1417\",\n",
      "    \"1418\": \"LABEL_1418\",\n",
      "    \"1419\": \"LABEL_1419\",\n",
      "    \"1420\": \"LABEL_1420\",\n",
      "    \"1421\": \"LABEL_1421\",\n",
      "    \"1422\": \"LABEL_1422\",\n",
      "    \"1423\": \"LABEL_1423\",\n",
      "    \"1424\": \"LABEL_1424\",\n",
      "    \"1425\": \"LABEL_1425\",\n",
      "    \"1426\": \"LABEL_1426\",\n",
      "    \"1427\": \"LABEL_1427\",\n",
      "    \"1428\": \"LABEL_1428\",\n",
      "    \"1429\": \"LABEL_1429\",\n",
      "    \"1430\": \"LABEL_1430\",\n",
      "    \"1431\": \"LABEL_1431\",\n",
      "    \"1432\": \"LABEL_1432\",\n",
      "    \"1433\": \"LABEL_1433\",\n",
      "    \"1434\": \"LABEL_1434\",\n",
      "    \"1435\": \"LABEL_1435\",\n",
      "    \"1436\": \"LABEL_1436\",\n",
      "    \"1437\": \"LABEL_1437\",\n",
      "    \"1438\": \"LABEL_1438\",\n",
      "    \"1439\": \"LABEL_1439\",\n",
      "    \"1440\": \"LABEL_1440\",\n",
      "    \"1441\": \"LABEL_1441\",\n",
      "    \"1442\": \"LABEL_1442\",\n",
      "    \"1443\": \"LABEL_1443\",\n",
      "    \"1444\": \"LABEL_1444\",\n",
      "    \"1445\": \"LABEL_1445\",\n",
      "    \"1446\": \"LABEL_1446\",\n",
      "    \"1447\": \"LABEL_1447\",\n",
      "    \"1448\": \"LABEL_1448\",\n",
      "    \"1449\": \"LABEL_1449\",\n",
      "    \"1450\": \"LABEL_1450\",\n",
      "    \"1451\": \"LABEL_1451\",\n",
      "    \"1452\": \"LABEL_1452\",\n",
      "    \"1453\": \"LABEL_1453\",\n",
      "    \"1454\": \"LABEL_1454\",\n",
      "    \"1455\": \"LABEL_1455\",\n",
      "    \"1456\": \"LABEL_1456\",\n",
      "    \"1457\": \"LABEL_1457\",\n",
      "    \"1458\": \"LABEL_1458\",\n",
      "    \"1459\": \"LABEL_1459\",\n",
      "    \"1460\": \"LABEL_1460\",\n",
      "    \"1461\": \"LABEL_1461\",\n",
      "    \"1462\": \"LABEL_1462\",\n",
      "    \"1463\": \"LABEL_1463\",\n",
      "    \"1464\": \"LABEL_1464\",\n",
      "    \"1465\": \"LABEL_1465\",\n",
      "    \"1466\": \"LABEL_1466\",\n",
      "    \"1467\": \"LABEL_1467\",\n",
      "    \"1468\": \"LABEL_1468\",\n",
      "    \"1469\": \"LABEL_1469\",\n",
      "    \"1470\": \"LABEL_1470\",\n",
      "    \"1471\": \"LABEL_1471\",\n",
      "    \"1472\": \"LABEL_1472\",\n",
      "    \"1473\": \"LABEL_1473\",\n",
      "    \"1474\": \"LABEL_1474\",\n",
      "    \"1475\": \"LABEL_1475\",\n",
      "    \"1476\": \"LABEL_1476\",\n",
      "    \"1477\": \"LABEL_1477\",\n",
      "    \"1478\": \"LABEL_1478\",\n",
      "    \"1479\": \"LABEL_1479\",\n",
      "    \"1480\": \"LABEL_1480\",\n",
      "    \"1481\": \"LABEL_1481\",\n",
      "    \"1482\": \"LABEL_1482\",\n",
      "    \"1483\": \"LABEL_1483\",\n",
      "    \"1484\": \"LABEL_1484\",\n",
      "    \"1485\": \"LABEL_1485\",\n",
      "    \"1486\": \"LABEL_1486\",\n",
      "    \"1487\": \"LABEL_1487\",\n",
      "    \"1488\": \"LABEL_1488\",\n",
      "    \"1489\": \"LABEL_1489\",\n",
      "    \"1490\": \"LABEL_1490\",\n",
      "    \"1491\": \"LABEL_1491\",\n",
      "    \"1492\": \"LABEL_1492\",\n",
      "    \"1493\": \"LABEL_1493\",\n",
      "    \"1494\": \"LABEL_1494\",\n",
      "    \"1495\": \"LABEL_1495\",\n",
      "    \"1496\": \"LABEL_1496\",\n",
      "    \"1497\": \"LABEL_1497\",\n",
      "    \"1498\": \"LABEL_1498\",\n",
      "    \"1499\": \"LABEL_1499\",\n",
      "    \"1500\": \"LABEL_1500\",\n",
      "    \"1501\": \"LABEL_1501\",\n",
      "    \"1502\": \"LABEL_1502\",\n",
      "    \"1503\": \"LABEL_1503\",\n",
      "    \"1504\": \"LABEL_1504\",\n",
      "    \"1505\": \"LABEL_1505\",\n",
      "    \"1506\": \"LABEL_1506\",\n",
      "    \"1507\": \"LABEL_1507\",\n",
      "    \"1508\": \"LABEL_1508\",\n",
      "    \"1509\": \"LABEL_1509\",\n",
      "    \"1510\": \"LABEL_1510\",\n",
      "    \"1511\": \"LABEL_1511\",\n",
      "    \"1512\": \"LABEL_1512\",\n",
      "    \"1513\": \"LABEL_1513\",\n",
      "    \"1514\": \"LABEL_1514\",\n",
      "    \"1515\": \"LABEL_1515\",\n",
      "    \"1516\": \"LABEL_1516\",\n",
      "    \"1517\": \"LABEL_1517\",\n",
      "    \"1518\": \"LABEL_1518\",\n",
      "    \"1519\": \"LABEL_1519\",\n",
      "    \"1520\": \"LABEL_1520\",\n",
      "    \"1521\": \"LABEL_1521\",\n",
      "    \"1522\": \"LABEL_1522\",\n",
      "    \"1523\": \"LABEL_1523\",\n",
      "    \"1524\": \"LABEL_1524\",\n",
      "    \"1525\": \"LABEL_1525\",\n",
      "    \"1526\": \"LABEL_1526\",\n",
      "    \"1527\": \"LABEL_1527\",\n",
      "    \"1528\": \"LABEL_1528\",\n",
      "    \"1529\": \"LABEL_1529\",\n",
      "    \"1530\": \"LABEL_1530\",\n",
      "    \"1531\": \"LABEL_1531\",\n",
      "    \"1532\": \"LABEL_1532\",\n",
      "    \"1533\": \"LABEL_1533\",\n",
      "    \"1534\": \"LABEL_1534\",\n",
      "    \"1535\": \"LABEL_1535\",\n",
      "    \"1536\": \"LABEL_1536\",\n",
      "    \"1537\": \"LABEL_1537\",\n",
      "    \"1538\": \"LABEL_1538\",\n",
      "    \"1539\": \"LABEL_1539\",\n",
      "    \"1540\": \"LABEL_1540\",\n",
      "    \"1541\": \"LABEL_1541\",\n",
      "    \"1542\": \"LABEL_1542\",\n",
      "    \"1543\": \"LABEL_1543\",\n",
      "    \"1544\": \"LABEL_1544\",\n",
      "    \"1545\": \"LABEL_1545\",\n",
      "    \"1546\": \"LABEL_1546\",\n",
      "    \"1547\": \"LABEL_1547\",\n",
      "    \"1548\": \"LABEL_1548\",\n",
      "    \"1549\": \"LABEL_1549\",\n",
      "    \"1550\": \"LABEL_1550\",\n",
      "    \"1551\": \"LABEL_1551\",\n",
      "    \"1552\": \"LABEL_1552\",\n",
      "    \"1553\": \"LABEL_1553\",\n",
      "    \"1554\": \"LABEL_1554\",\n",
      "    \"1555\": \"LABEL_1555\",\n",
      "    \"1556\": \"LABEL_1556\",\n",
      "    \"1557\": \"LABEL_1557\",\n",
      "    \"1558\": \"LABEL_1558\",\n",
      "    \"1559\": \"LABEL_1559\",\n",
      "    \"1560\": \"LABEL_1560\",\n",
      "    \"1561\": \"LABEL_1561\",\n",
      "    \"1562\": \"LABEL_1562\",\n",
      "    \"1563\": \"LABEL_1563\",\n",
      "    \"1564\": \"LABEL_1564\",\n",
      "    \"1565\": \"LABEL_1565\",\n",
      "    \"1566\": \"LABEL_1566\",\n",
      "    \"1567\": \"LABEL_1567\",\n",
      "    \"1568\": \"LABEL_1568\",\n",
      "    \"1569\": \"LABEL_1569\",\n",
      "    \"1570\": \"LABEL_1570\",\n",
      "    \"1571\": \"LABEL_1571\",\n",
      "    \"1572\": \"LABEL_1572\",\n",
      "    \"1573\": \"LABEL_1573\",\n",
      "    \"1574\": \"LABEL_1574\",\n",
      "    \"1575\": \"LABEL_1575\",\n",
      "    \"1576\": \"LABEL_1576\",\n",
      "    \"1577\": \"LABEL_1577\",\n",
      "    \"1578\": \"LABEL_1578\",\n",
      "    \"1579\": \"LABEL_1579\",\n",
      "    \"1580\": \"LABEL_1580\",\n",
      "    \"1581\": \"LABEL_1581\",\n",
      "    \"1582\": \"LABEL_1582\",\n",
      "    \"1583\": \"LABEL_1583\",\n",
      "    \"1584\": \"LABEL_1584\",\n",
      "    \"1585\": \"LABEL_1585\",\n",
      "    \"1586\": \"LABEL_1586\",\n",
      "    \"1587\": \"LABEL_1587\",\n",
      "    \"1588\": \"LABEL_1588\",\n",
      "    \"1589\": \"LABEL_1589\",\n",
      "    \"1590\": \"LABEL_1590\",\n",
      "    \"1591\": \"LABEL_1591\",\n",
      "    \"1592\": \"LABEL_1592\",\n",
      "    \"1593\": \"LABEL_1593\",\n",
      "    \"1594\": \"LABEL_1594\",\n",
      "    \"1595\": \"LABEL_1595\",\n",
      "    \"1596\": \"LABEL_1596\",\n",
      "    \"1597\": \"LABEL_1597\",\n",
      "    \"1598\": \"LABEL_1598\",\n",
      "    \"1599\": \"LABEL_1599\",\n",
      "    \"1600\": \"LABEL_1600\",\n",
      "    \"1601\": \"LABEL_1601\",\n",
      "    \"1602\": \"LABEL_1602\",\n",
      "    \"1603\": \"LABEL_1603\",\n",
      "    \"1604\": \"LABEL_1604\",\n",
      "    \"1605\": \"LABEL_1605\",\n",
      "    \"1606\": \"LABEL_1606\",\n",
      "    \"1607\": \"LABEL_1607\",\n",
      "    \"1608\": \"LABEL_1608\",\n",
      "    \"1609\": \"LABEL_1609\",\n",
      "    \"1610\": \"LABEL_1610\",\n",
      "    \"1611\": \"LABEL_1611\",\n",
      "    \"1612\": \"LABEL_1612\",\n",
      "    \"1613\": \"LABEL_1613\",\n",
      "    \"1614\": \"LABEL_1614\",\n",
      "    \"1615\": \"LABEL_1615\",\n",
      "    \"1616\": \"LABEL_1616\",\n",
      "    \"1617\": \"LABEL_1617\",\n",
      "    \"1618\": \"LABEL_1618\",\n",
      "    \"1619\": \"LABEL_1619\",\n",
      "    \"1620\": \"LABEL_1620\",\n",
      "    \"1621\": \"LABEL_1621\",\n",
      "    \"1622\": \"LABEL_1622\",\n",
      "    \"1623\": \"LABEL_1623\",\n",
      "    \"1624\": \"LABEL_1624\",\n",
      "    \"1625\": \"LABEL_1625\",\n",
      "    \"1626\": \"LABEL_1626\",\n",
      "    \"1627\": \"LABEL_1627\",\n",
      "    \"1628\": \"LABEL_1628\",\n",
      "    \"1629\": \"LABEL_1629\",\n",
      "    \"1630\": \"LABEL_1630\",\n",
      "    \"1631\": \"LABEL_1631\",\n",
      "    \"1632\": \"LABEL_1632\",\n",
      "    \"1633\": \"LABEL_1633\",\n",
      "    \"1634\": \"LABEL_1634\",\n",
      "    \"1635\": \"LABEL_1635\",\n",
      "    \"1636\": \"LABEL_1636\",\n",
      "    \"1637\": \"LABEL_1637\",\n",
      "    \"1638\": \"LABEL_1638\",\n",
      "    \"1639\": \"LABEL_1639\",\n",
      "    \"1640\": \"LABEL_1640\",\n",
      "    \"1641\": \"LABEL_1641\",\n",
      "    \"1642\": \"LABEL_1642\",\n",
      "    \"1643\": \"LABEL_1643\",\n",
      "    \"1644\": \"LABEL_1644\",\n",
      "    \"1645\": \"LABEL_1645\",\n",
      "    \"1646\": \"LABEL_1646\",\n",
      "    \"1647\": \"LABEL_1647\",\n",
      "    \"1648\": \"LABEL_1648\",\n",
      "    \"1649\": \"LABEL_1649\",\n",
      "    \"1650\": \"LABEL_1650\",\n",
      "    \"1651\": \"LABEL_1651\",\n",
      "    \"1652\": \"LABEL_1652\",\n",
      "    \"1653\": \"LABEL_1653\",\n",
      "    \"1654\": \"LABEL_1654\",\n",
      "    \"1655\": \"LABEL_1655\",\n",
      "    \"1656\": \"LABEL_1656\",\n",
      "    \"1657\": \"LABEL_1657\",\n",
      "    \"1658\": \"LABEL_1658\",\n",
      "    \"1659\": \"LABEL_1659\",\n",
      "    \"1660\": \"LABEL_1660\",\n",
      "    \"1661\": \"LABEL_1661\",\n",
      "    \"1662\": \"LABEL_1662\",\n",
      "    \"1663\": \"LABEL_1663\",\n",
      "    \"1664\": \"LABEL_1664\",\n",
      "    \"1665\": \"LABEL_1665\",\n",
      "    \"1666\": \"LABEL_1666\",\n",
      "    \"1667\": \"LABEL_1667\",\n",
      "    \"1668\": \"LABEL_1668\",\n",
      "    \"1669\": \"LABEL_1669\",\n",
      "    \"1670\": \"LABEL_1670\",\n",
      "    \"1671\": \"LABEL_1671\",\n",
      "    \"1672\": \"LABEL_1672\",\n",
      "    \"1673\": \"LABEL_1673\",\n",
      "    \"1674\": \"LABEL_1674\",\n",
      "    \"1675\": \"LABEL_1675\",\n",
      "    \"1676\": \"LABEL_1676\",\n",
      "    \"1677\": \"LABEL_1677\",\n",
      "    \"1678\": \"LABEL_1678\",\n",
      "    \"1679\": \"LABEL_1679\",\n",
      "    \"1680\": \"LABEL_1680\",\n",
      "    \"1681\": \"LABEL_1681\",\n",
      "    \"1682\": \"LABEL_1682\",\n",
      "    \"1683\": \"LABEL_1683\",\n",
      "    \"1684\": \"LABEL_1684\",\n",
      "    \"1685\": \"LABEL_1685\",\n",
      "    \"1686\": \"LABEL_1686\",\n",
      "    \"1687\": \"LABEL_1687\",\n",
      "    \"1688\": \"LABEL_1688\",\n",
      "    \"1689\": \"LABEL_1689\",\n",
      "    \"1690\": \"LABEL_1690\",\n",
      "    \"1691\": \"LABEL_1691\",\n",
      "    \"1692\": \"LABEL_1692\",\n",
      "    \"1693\": \"LABEL_1693\",\n",
      "    \"1694\": \"LABEL_1694\",\n",
      "    \"1695\": \"LABEL_1695\",\n",
      "    \"1696\": \"LABEL_1696\",\n",
      "    \"1697\": \"LABEL_1697\",\n",
      "    \"1698\": \"LABEL_1698\",\n",
      "    \"1699\": \"LABEL_1699\",\n",
      "    \"1700\": \"LABEL_1700\",\n",
      "    \"1701\": \"LABEL_1701\",\n",
      "    \"1702\": \"LABEL_1702\",\n",
      "    \"1703\": \"LABEL_1703\",\n",
      "    \"1704\": \"LABEL_1704\",\n",
      "    \"1705\": \"LABEL_1705\",\n",
      "    \"1706\": \"LABEL_1706\",\n",
      "    \"1707\": \"LABEL_1707\",\n",
      "    \"1708\": \"LABEL_1708\",\n",
      "    \"1709\": \"LABEL_1709\",\n",
      "    \"1710\": \"LABEL_1710\",\n",
      "    \"1711\": \"LABEL_1711\",\n",
      "    \"1712\": \"LABEL_1712\",\n",
      "    \"1713\": \"LABEL_1713\",\n",
      "    \"1714\": \"LABEL_1714\",\n",
      "    \"1715\": \"LABEL_1715\",\n",
      "    \"1716\": \"LABEL_1716\",\n",
      "    \"1717\": \"LABEL_1717\",\n",
      "    \"1718\": \"LABEL_1718\",\n",
      "    \"1719\": \"LABEL_1719\",\n",
      "    \"1720\": \"LABEL_1720\",\n",
      "    \"1721\": \"LABEL_1721\",\n",
      "    \"1722\": \"LABEL_1722\",\n",
      "    \"1723\": \"LABEL_1723\",\n",
      "    \"1724\": \"LABEL_1724\",\n",
      "    \"1725\": \"LABEL_1725\",\n",
      "    \"1726\": \"LABEL_1726\",\n",
      "    \"1727\": \"LABEL_1727\",\n",
      "    \"1728\": \"LABEL_1728\",\n",
      "    \"1729\": \"LABEL_1729\",\n",
      "    \"1730\": \"LABEL_1730\",\n",
      "    \"1731\": \"LABEL_1731\",\n",
      "    \"1732\": \"LABEL_1732\",\n",
      "    \"1733\": \"LABEL_1733\",\n",
      "    \"1734\": \"LABEL_1734\",\n",
      "    \"1735\": \"LABEL_1735\",\n",
      "    \"1736\": \"LABEL_1736\",\n",
      "    \"1737\": \"LABEL_1737\",\n",
      "    \"1738\": \"LABEL_1738\",\n",
      "    \"1739\": \"LABEL_1739\",\n",
      "    \"1740\": \"LABEL_1740\",\n",
      "    \"1741\": \"LABEL_1741\",\n",
      "    \"1742\": \"LABEL_1742\",\n",
      "    \"1743\": \"LABEL_1743\",\n",
      "    \"1744\": \"LABEL_1744\",\n",
      "    \"1745\": \"LABEL_1745\",\n",
      "    \"1746\": \"LABEL_1746\",\n",
      "    \"1747\": \"LABEL_1747\",\n",
      "    \"1748\": \"LABEL_1748\",\n",
      "    \"1749\": \"LABEL_1749\",\n",
      "    \"1750\": \"LABEL_1750\",\n",
      "    \"1751\": \"LABEL_1751\",\n",
      "    \"1752\": \"LABEL_1752\",\n",
      "    \"1753\": \"LABEL_1753\",\n",
      "    \"1754\": \"LABEL_1754\",\n",
      "    \"1755\": \"LABEL_1755\",\n",
      "    \"1756\": \"LABEL_1756\",\n",
      "    \"1757\": \"LABEL_1757\",\n",
      "    \"1758\": \"LABEL_1758\",\n",
      "    \"1759\": \"LABEL_1759\",\n",
      "    \"1760\": \"LABEL_1760\",\n",
      "    \"1761\": \"LABEL_1761\",\n",
      "    \"1762\": \"LABEL_1762\",\n",
      "    \"1763\": \"LABEL_1763\",\n",
      "    \"1764\": \"LABEL_1764\",\n",
      "    \"1765\": \"LABEL_1765\",\n",
      "    \"1766\": \"LABEL_1766\",\n",
      "    \"1767\": \"LABEL_1767\",\n",
      "    \"1768\": \"LABEL_1768\",\n",
      "    \"1769\": \"LABEL_1769\",\n",
      "    \"1770\": \"LABEL_1770\",\n",
      "    \"1771\": \"LABEL_1771\",\n",
      "    \"1772\": \"LABEL_1772\",\n",
      "    \"1773\": \"LABEL_1773\",\n",
      "    \"1774\": \"LABEL_1774\",\n",
      "    \"1775\": \"LABEL_1775\",\n",
      "    \"1776\": \"LABEL_1776\",\n",
      "    \"1777\": \"LABEL_1777\",\n",
      "    \"1778\": \"LABEL_1778\",\n",
      "    \"1779\": \"LABEL_1779\",\n",
      "    \"1780\": \"LABEL_1780\",\n",
      "    \"1781\": \"LABEL_1781\",\n",
      "    \"1782\": \"LABEL_1782\",\n",
      "    \"1783\": \"LABEL_1783\",\n",
      "    \"1784\": \"LABEL_1784\",\n",
      "    \"1785\": \"LABEL_1785\",\n",
      "    \"1786\": \"LABEL_1786\",\n",
      "    \"1787\": \"LABEL_1787\",\n",
      "    \"1788\": \"LABEL_1788\",\n",
      "    \"1789\": \"LABEL_1789\",\n",
      "    \"1790\": \"LABEL_1790\",\n",
      "    \"1791\": \"LABEL_1791\",\n",
      "    \"1792\": \"LABEL_1792\",\n",
      "    \"1793\": \"LABEL_1793\",\n",
      "    \"1794\": \"LABEL_1794\",\n",
      "    \"1795\": \"LABEL_1795\",\n",
      "    \"1796\": \"LABEL_1796\",\n",
      "    \"1797\": \"LABEL_1797\",\n",
      "    \"1798\": \"LABEL_1798\",\n",
      "    \"1799\": \"LABEL_1799\",\n",
      "    \"1800\": \"LABEL_1800\",\n",
      "    \"1801\": \"LABEL_1801\",\n",
      "    \"1802\": \"LABEL_1802\",\n",
      "    \"1803\": \"LABEL_1803\",\n",
      "    \"1804\": \"LABEL_1804\",\n",
      "    \"1805\": \"LABEL_1805\",\n",
      "    \"1806\": \"LABEL_1806\",\n",
      "    \"1807\": \"LABEL_1807\",\n",
      "    \"1808\": \"LABEL_1808\",\n",
      "    \"1809\": \"LABEL_1809\",\n",
      "    \"1810\": \"LABEL_1810\",\n",
      "    \"1811\": \"LABEL_1811\",\n",
      "    \"1812\": \"LABEL_1812\",\n",
      "    \"1813\": \"LABEL_1813\",\n",
      "    \"1814\": \"LABEL_1814\",\n",
      "    \"1815\": \"LABEL_1815\",\n",
      "    \"1816\": \"LABEL_1816\",\n",
      "    \"1817\": \"LABEL_1817\",\n",
      "    \"1818\": \"LABEL_1818\",\n",
      "    \"1819\": \"LABEL_1819\",\n",
      "    \"1820\": \"LABEL_1820\",\n",
      "    \"1821\": \"LABEL_1821\",\n",
      "    \"1822\": \"LABEL_1822\",\n",
      "    \"1823\": \"LABEL_1823\",\n",
      "    \"1824\": \"LABEL_1824\",\n",
      "    \"1825\": \"LABEL_1825\",\n",
      "    \"1826\": \"LABEL_1826\",\n",
      "    \"1827\": \"LABEL_1827\",\n",
      "    \"1828\": \"LABEL_1828\",\n",
      "    \"1829\": \"LABEL_1829\",\n",
      "    \"1830\": \"LABEL_1830\",\n",
      "    \"1831\": \"LABEL_1831\",\n",
      "    \"1832\": \"LABEL_1832\",\n",
      "    \"1833\": \"LABEL_1833\",\n",
      "    \"1834\": \"LABEL_1834\",\n",
      "    \"1835\": \"LABEL_1835\",\n",
      "    \"1836\": \"LABEL_1836\",\n",
      "    \"1837\": \"LABEL_1837\",\n",
      "    \"1838\": \"LABEL_1838\",\n",
      "    \"1839\": \"LABEL_1839\",\n",
      "    \"1840\": \"LABEL_1840\",\n",
      "    \"1841\": \"LABEL_1841\",\n",
      "    \"1842\": \"LABEL_1842\",\n",
      "    \"1843\": \"LABEL_1843\",\n",
      "    \"1844\": \"LABEL_1844\",\n",
      "    \"1845\": \"LABEL_1845\",\n",
      "    \"1846\": \"LABEL_1846\",\n",
      "    \"1847\": \"LABEL_1847\",\n",
      "    \"1848\": \"LABEL_1848\",\n",
      "    \"1849\": \"LABEL_1849\",\n",
      "    \"1850\": \"LABEL_1850\",\n",
      "    \"1851\": \"LABEL_1851\",\n",
      "    \"1852\": \"LABEL_1852\",\n",
      "    \"1853\": \"LABEL_1853\",\n",
      "    \"1854\": \"LABEL_1854\",\n",
      "    \"1855\": \"LABEL_1855\",\n",
      "    \"1856\": \"LABEL_1856\",\n",
      "    \"1857\": \"LABEL_1857\",\n",
      "    \"1858\": \"LABEL_1858\",\n",
      "    \"1859\": \"LABEL_1859\",\n",
      "    \"1860\": \"LABEL_1860\",\n",
      "    \"1861\": \"LABEL_1861\",\n",
      "    \"1862\": \"LABEL_1862\",\n",
      "    \"1863\": \"LABEL_1863\",\n",
      "    \"1864\": \"LABEL_1864\",\n",
      "    \"1865\": \"LABEL_1865\",\n",
      "    \"1866\": \"LABEL_1866\",\n",
      "    \"1867\": \"LABEL_1867\",\n",
      "    \"1868\": \"LABEL_1868\",\n",
      "    \"1869\": \"LABEL_1869\",\n",
      "    \"1870\": \"LABEL_1870\",\n",
      "    \"1871\": \"LABEL_1871\",\n",
      "    \"1872\": \"LABEL_1872\",\n",
      "    \"1873\": \"LABEL_1873\",\n",
      "    \"1874\": \"LABEL_1874\",\n",
      "    \"1875\": \"LABEL_1875\",\n",
      "    \"1876\": \"LABEL_1876\",\n",
      "    \"1877\": \"LABEL_1877\",\n",
      "    \"1878\": \"LABEL_1878\",\n",
      "    \"1879\": \"LABEL_1879\",\n",
      "    \"1880\": \"LABEL_1880\",\n",
      "    \"1881\": \"LABEL_1881\",\n",
      "    \"1882\": \"LABEL_1882\",\n",
      "    \"1883\": \"LABEL_1883\",\n",
      "    \"1884\": \"LABEL_1884\",\n",
      "    \"1885\": \"LABEL_1885\",\n",
      "    \"1886\": \"LABEL_1886\",\n",
      "    \"1887\": \"LABEL_1887\",\n",
      "    \"1888\": \"LABEL_1888\",\n",
      "    \"1889\": \"LABEL_1889\",\n",
      "    \"1890\": \"LABEL_1890\",\n",
      "    \"1891\": \"LABEL_1891\",\n",
      "    \"1892\": \"LABEL_1892\",\n",
      "    \"1893\": \"LABEL_1893\",\n",
      "    \"1894\": \"LABEL_1894\",\n",
      "    \"1895\": \"LABEL_1895\",\n",
      "    \"1896\": \"LABEL_1896\",\n",
      "    \"1897\": \"LABEL_1897\",\n",
      "    \"1898\": \"LABEL_1898\",\n",
      "    \"1899\": \"LABEL_1899\",\n",
      "    \"1900\": \"LABEL_1900\",\n",
      "    \"1901\": \"LABEL_1901\",\n",
      "    \"1902\": \"LABEL_1902\",\n",
      "    \"1903\": \"LABEL_1903\",\n",
      "    \"1904\": \"LABEL_1904\",\n",
      "    \"1905\": \"LABEL_1905\",\n",
      "    \"1906\": \"LABEL_1906\",\n",
      "    \"1907\": \"LABEL_1907\",\n",
      "    \"1908\": \"LABEL_1908\",\n",
      "    \"1909\": \"LABEL_1909\",\n",
      "    \"1910\": \"LABEL_1910\",\n",
      "    \"1911\": \"LABEL_1911\",\n",
      "    \"1912\": \"LABEL_1912\",\n",
      "    \"1913\": \"LABEL_1913\",\n",
      "    \"1914\": \"LABEL_1914\",\n",
      "    \"1915\": \"LABEL_1915\",\n",
      "    \"1916\": \"LABEL_1916\",\n",
      "    \"1917\": \"LABEL_1917\",\n",
      "    \"1918\": \"LABEL_1918\",\n",
      "    \"1919\": \"LABEL_1919\",\n",
      "    \"1920\": \"LABEL_1920\",\n",
      "    \"1921\": \"LABEL_1921\",\n",
      "    \"1922\": \"LABEL_1922\",\n",
      "    \"1923\": \"LABEL_1923\",\n",
      "    \"1924\": \"LABEL_1924\",\n",
      "    \"1925\": \"LABEL_1925\",\n",
      "    \"1926\": \"LABEL_1926\",\n",
      "    \"1927\": \"LABEL_1927\",\n",
      "    \"1928\": \"LABEL_1928\",\n",
      "    \"1929\": \"LABEL_1929\",\n",
      "    \"1930\": \"LABEL_1930\",\n",
      "    \"1931\": \"LABEL_1931\",\n",
      "    \"1932\": \"LABEL_1932\",\n",
      "    \"1933\": \"LABEL_1933\",\n",
      "    \"1934\": \"LABEL_1934\",\n",
      "    \"1935\": \"LABEL_1935\",\n",
      "    \"1936\": \"LABEL_1936\",\n",
      "    \"1937\": \"LABEL_1937\",\n",
      "    \"1938\": \"LABEL_1938\",\n",
      "    \"1939\": \"LABEL_1939\",\n",
      "    \"1940\": \"LABEL_1940\",\n",
      "    \"1941\": \"LABEL_1941\",\n",
      "    \"1942\": \"LABEL_1942\",\n",
      "    \"1943\": \"LABEL_1943\",\n",
      "    \"1944\": \"LABEL_1944\",\n",
      "    \"1945\": \"LABEL_1945\",\n",
      "    \"1946\": \"LABEL_1946\",\n",
      "    \"1947\": \"LABEL_1947\",\n",
      "    \"1948\": \"LABEL_1948\",\n",
      "    \"1949\": \"LABEL_1949\",\n",
      "    \"1950\": \"LABEL_1950\",\n",
      "    \"1951\": \"LABEL_1951\",\n",
      "    \"1952\": \"LABEL_1952\",\n",
      "    \"1953\": \"LABEL_1953\",\n",
      "    \"1954\": \"LABEL_1954\",\n",
      "    \"1955\": \"LABEL_1955\",\n",
      "    \"1956\": \"LABEL_1956\",\n",
      "    \"1957\": \"LABEL_1957\",\n",
      "    \"1958\": \"LABEL_1958\",\n",
      "    \"1959\": \"LABEL_1959\",\n",
      "    \"1960\": \"LABEL_1960\",\n",
      "    \"1961\": \"LABEL_1961\",\n",
      "    \"1962\": \"LABEL_1962\",\n",
      "    \"1963\": \"LABEL_1963\",\n",
      "    \"1964\": \"LABEL_1964\",\n",
      "    \"1965\": \"LABEL_1965\",\n",
      "    \"1966\": \"LABEL_1966\",\n",
      "    \"1967\": \"LABEL_1967\",\n",
      "    \"1968\": \"LABEL_1968\",\n",
      "    \"1969\": \"LABEL_1969\",\n",
      "    \"1970\": \"LABEL_1970\",\n",
      "    \"1971\": \"LABEL_1971\",\n",
      "    \"1972\": \"LABEL_1972\",\n",
      "    \"1973\": \"LABEL_1973\",\n",
      "    \"1974\": \"LABEL_1974\",\n",
      "    \"1975\": \"LABEL_1975\",\n",
      "    \"1976\": \"LABEL_1976\",\n",
      "    \"1977\": \"LABEL_1977\",\n",
      "    \"1978\": \"LABEL_1978\",\n",
      "    \"1979\": \"LABEL_1979\",\n",
      "    \"1980\": \"LABEL_1980\",\n",
      "    \"1981\": \"LABEL_1981\",\n",
      "    \"1982\": \"LABEL_1982\",\n",
      "    \"1983\": \"LABEL_1983\",\n",
      "    \"1984\": \"LABEL_1984\",\n",
      "    \"1985\": \"LABEL_1985\",\n",
      "    \"1986\": \"LABEL_1986\",\n",
      "    \"1987\": \"LABEL_1987\",\n",
      "    \"1988\": \"LABEL_1988\",\n",
      "    \"1989\": \"LABEL_1989\",\n",
      "    \"1990\": \"LABEL_1990\",\n",
      "    \"1991\": \"LABEL_1991\",\n",
      "    \"1992\": \"LABEL_1992\",\n",
      "    \"1993\": \"LABEL_1993\",\n",
      "    \"1994\": \"LABEL_1994\",\n",
      "    \"1995\": \"LABEL_1995\",\n",
      "    \"1996\": \"LABEL_1996\",\n",
      "    \"1997\": \"LABEL_1997\",\n",
      "    \"1998\": \"LABEL_1998\",\n",
      "    \"1999\": \"LABEL_1999\",\n",
      "    \"2000\": \"LABEL_2000\",\n",
      "    \"2001\": \"LABEL_2001\",\n",
      "    \"2002\": \"LABEL_2002\",\n",
      "    \"2003\": \"LABEL_2003\",\n",
      "    \"2004\": \"LABEL_2004\",\n",
      "    \"2005\": \"LABEL_2005\",\n",
      "    \"2006\": \"LABEL_2006\",\n",
      "    \"2007\": \"LABEL_2007\",\n",
      "    \"2008\": \"LABEL_2008\",\n",
      "    \"2009\": \"LABEL_2009\",\n",
      "    \"2010\": \"LABEL_2010\",\n",
      "    \"2011\": \"LABEL_2011\",\n",
      "    \"2012\": \"LABEL_2012\",\n",
      "    \"2013\": \"LABEL_2013\",\n",
      "    \"2014\": \"LABEL_2014\",\n",
      "    \"2015\": \"LABEL_2015\",\n",
      "    \"2016\": \"LABEL_2016\",\n",
      "    \"2017\": \"LABEL_2017\",\n",
      "    \"2018\": \"LABEL_2018\",\n",
      "    \"2019\": \"LABEL_2019\",\n",
      "    \"2020\": \"LABEL_2020\",\n",
      "    \"2021\": \"LABEL_2021\",\n",
      "    \"2022\": \"LABEL_2022\",\n",
      "    \"2023\": \"LABEL_2023\",\n",
      "    \"2024\": \"LABEL_2024\",\n",
      "    \"2025\": \"LABEL_2025\",\n",
      "    \"2026\": \"LABEL_2026\",\n",
      "    \"2027\": \"LABEL_2027\",\n",
      "    \"2028\": \"LABEL_2028\",\n",
      "    \"2029\": \"LABEL_2029\",\n",
      "    \"2030\": \"LABEL_2030\",\n",
      "    \"2031\": \"LABEL_2031\",\n",
      "    \"2032\": \"LABEL_2032\",\n",
      "    \"2033\": \"LABEL_2033\",\n",
      "    \"2034\": \"LABEL_2034\",\n",
      "    \"2035\": \"LABEL_2035\",\n",
      "    \"2036\": \"LABEL_2036\",\n",
      "    \"2037\": \"LABEL_2037\",\n",
      "    \"2038\": \"LABEL_2038\",\n",
      "    \"2039\": \"LABEL_2039\",\n",
      "    \"2040\": \"LABEL_2040\",\n",
      "    \"2041\": \"LABEL_2041\",\n",
      "    \"2042\": \"LABEL_2042\",\n",
      "    \"2043\": \"LABEL_2043\",\n",
      "    \"2044\": \"LABEL_2044\",\n",
      "    \"2045\": \"LABEL_2045\",\n",
      "    \"2046\": \"LABEL_2046\",\n",
      "    \"2047\": \"LABEL_2047\",\n",
      "    \"2048\": \"LABEL_2048\",\n",
      "    \"2049\": \"LABEL_2049\",\n",
      "    \"2050\": \"LABEL_2050\",\n",
      "    \"2051\": \"LABEL_2051\",\n",
      "    \"2052\": \"LABEL_2052\",\n",
      "    \"2053\": \"LABEL_2053\",\n",
      "    \"2054\": \"LABEL_2054\",\n",
      "    \"2055\": \"LABEL_2055\",\n",
      "    \"2056\": \"LABEL_2056\",\n",
      "    \"2057\": \"LABEL_2057\",\n",
      "    \"2058\": \"LABEL_2058\",\n",
      "    \"2059\": \"LABEL_2059\",\n",
      "    \"2060\": \"LABEL_2060\",\n",
      "    \"2061\": \"LABEL_2061\",\n",
      "    \"2062\": \"LABEL_2062\",\n",
      "    \"2063\": \"LABEL_2063\",\n",
      "    \"2064\": \"LABEL_2064\",\n",
      "    \"2065\": \"LABEL_2065\",\n",
      "    \"2066\": \"LABEL_2066\",\n",
      "    \"2067\": \"LABEL_2067\",\n",
      "    \"2068\": \"LABEL_2068\",\n",
      "    \"2069\": \"LABEL_2069\",\n",
      "    \"2070\": \"LABEL_2070\",\n",
      "    \"2071\": \"LABEL_2071\",\n",
      "    \"2072\": \"LABEL_2072\",\n",
      "    \"2073\": \"LABEL_2073\",\n",
      "    \"2074\": \"LABEL_2074\",\n",
      "    \"2075\": \"LABEL_2075\",\n",
      "    \"2076\": \"LABEL_2076\",\n",
      "    \"2077\": \"LABEL_2077\",\n",
      "    \"2078\": \"LABEL_2078\",\n",
      "    \"2079\": \"LABEL_2079\",\n",
      "    \"2080\": \"LABEL_2080\",\n",
      "    \"2081\": \"LABEL_2081\",\n",
      "    \"2082\": \"LABEL_2082\",\n",
      "    \"2083\": \"LABEL_2083\",\n",
      "    \"2084\": \"LABEL_2084\",\n",
      "    \"2085\": \"LABEL_2085\",\n",
      "    \"2086\": \"LABEL_2086\",\n",
      "    \"2087\": \"LABEL_2087\",\n",
      "    \"2088\": \"LABEL_2088\",\n",
      "    \"2089\": \"LABEL_2089\",\n",
      "    \"2090\": \"LABEL_2090\",\n",
      "    \"2091\": \"LABEL_2091\",\n",
      "    \"2092\": \"LABEL_2092\",\n",
      "    \"2093\": \"LABEL_2093\",\n",
      "    \"2094\": \"LABEL_2094\",\n",
      "    \"2095\": \"LABEL_2095\",\n",
      "    \"2096\": \"LABEL_2096\",\n",
      "    \"2097\": \"LABEL_2097\",\n",
      "    \"2098\": \"LABEL_2098\",\n",
      "    \"2099\": \"LABEL_2099\",\n",
      "    \"2100\": \"LABEL_2100\",\n",
      "    \"2101\": \"LABEL_2101\",\n",
      "    \"2102\": \"LABEL_2102\",\n",
      "    \"2103\": \"LABEL_2103\",\n",
      "    \"2104\": \"LABEL_2104\",\n",
      "    \"2105\": \"LABEL_2105\",\n",
      "    \"2106\": \"LABEL_2106\",\n",
      "    \"2107\": \"LABEL_2107\",\n",
      "    \"2108\": \"LABEL_2108\",\n",
      "    \"2109\": \"LABEL_2109\",\n",
      "    \"2110\": \"LABEL_2110\",\n",
      "    \"2111\": \"LABEL_2111\",\n",
      "    \"2112\": \"LABEL_2112\",\n",
      "    \"2113\": \"LABEL_2113\",\n",
      "    \"2114\": \"LABEL_2114\",\n",
      "    \"2115\": \"LABEL_2115\",\n",
      "    \"2116\": \"LABEL_2116\",\n",
      "    \"2117\": \"LABEL_2117\",\n",
      "    \"2118\": \"LABEL_2118\",\n",
      "    \"2119\": \"LABEL_2119\",\n",
      "    \"2120\": \"LABEL_2120\",\n",
      "    \"2121\": \"LABEL_2121\",\n",
      "    \"2122\": \"LABEL_2122\",\n",
      "    \"2123\": \"LABEL_2123\",\n",
      "    \"2124\": \"LABEL_2124\",\n",
      "    \"2125\": \"LABEL_2125\",\n",
      "    \"2126\": \"LABEL_2126\",\n",
      "    \"2127\": \"LABEL_2127\",\n",
      "    \"2128\": \"LABEL_2128\",\n",
      "    \"2129\": \"LABEL_2129\",\n",
      "    \"2130\": \"LABEL_2130\",\n",
      "    \"2131\": \"LABEL_2131\",\n",
      "    \"2132\": \"LABEL_2132\",\n",
      "    \"2133\": \"LABEL_2133\",\n",
      "    \"2134\": \"LABEL_2134\",\n",
      "    \"2135\": \"LABEL_2135\",\n",
      "    \"2136\": \"LABEL_2136\",\n",
      "    \"2137\": \"LABEL_2137\",\n",
      "    \"2138\": \"LABEL_2138\",\n",
      "    \"2139\": \"LABEL_2139\",\n",
      "    \"2140\": \"LABEL_2140\",\n",
      "    \"2141\": \"LABEL_2141\",\n",
      "    \"2142\": \"LABEL_2142\",\n",
      "    \"2143\": \"LABEL_2143\",\n",
      "    \"2144\": \"LABEL_2144\",\n",
      "    \"2145\": \"LABEL_2145\",\n",
      "    \"2146\": \"LABEL_2146\",\n",
      "    \"2147\": \"LABEL_2147\",\n",
      "    \"2148\": \"LABEL_2148\",\n",
      "    \"2149\": \"LABEL_2149\",\n",
      "    \"2150\": \"LABEL_2150\",\n",
      "    \"2151\": \"LABEL_2151\",\n",
      "    \"2152\": \"LABEL_2152\",\n",
      "    \"2153\": \"LABEL_2153\",\n",
      "    \"2154\": \"LABEL_2154\",\n",
      "    \"2155\": \"LABEL_2155\",\n",
      "    \"2156\": \"LABEL_2156\",\n",
      "    \"2157\": \"LABEL_2157\",\n",
      "    \"2158\": \"LABEL_2158\",\n",
      "    \"2159\": \"LABEL_2159\",\n",
      "    \"2160\": \"LABEL_2160\",\n",
      "    \"2161\": \"LABEL_2161\",\n",
      "    \"2162\": \"LABEL_2162\",\n",
      "    \"2163\": \"LABEL_2163\",\n",
      "    \"2164\": \"LABEL_2164\",\n",
      "    \"2165\": \"LABEL_2165\",\n",
      "    \"2166\": \"LABEL_2166\",\n",
      "    \"2167\": \"LABEL_2167\",\n",
      "    \"2168\": \"LABEL_2168\",\n",
      "    \"2169\": \"LABEL_2169\",\n",
      "    \"2170\": \"LABEL_2170\",\n",
      "    \"2171\": \"LABEL_2171\",\n",
      "    \"2172\": \"LABEL_2172\",\n",
      "    \"2173\": \"LABEL_2173\",\n",
      "    \"2174\": \"LABEL_2174\",\n",
      "    \"2175\": \"LABEL_2175\",\n",
      "    \"2176\": \"LABEL_2176\",\n",
      "    \"2177\": \"LABEL_2177\",\n",
      "    \"2178\": \"LABEL_2178\",\n",
      "    \"2179\": \"LABEL_2179\",\n",
      "    \"2180\": \"LABEL_2180\",\n",
      "    \"2181\": \"LABEL_2181\",\n",
      "    \"2182\": \"LABEL_2182\",\n",
      "    \"2183\": \"LABEL_2183\",\n",
      "    \"2184\": \"LABEL_2184\",\n",
      "    \"2185\": \"LABEL_2185\",\n",
      "    \"2186\": \"LABEL_2186\",\n",
      "    \"2187\": \"LABEL_2187\",\n",
      "    \"2188\": \"LABEL_2188\",\n",
      "    \"2189\": \"LABEL_2189\",\n",
      "    \"2190\": \"LABEL_2190\",\n",
      "    \"2191\": \"LABEL_2191\",\n",
      "    \"2192\": \"LABEL_2192\",\n",
      "    \"2193\": \"LABEL_2193\",\n",
      "    \"2194\": \"LABEL_2194\",\n",
      "    \"2195\": \"LABEL_2195\",\n",
      "    \"2196\": \"LABEL_2196\",\n",
      "    \"2197\": \"LABEL_2197\",\n",
      "    \"2198\": \"LABEL_2198\",\n",
      "    \"2199\": \"LABEL_2199\",\n",
      "    \"2200\": \"LABEL_2200\",\n",
      "    \"2201\": \"LABEL_2201\",\n",
      "    \"2202\": \"LABEL_2202\",\n",
      "    \"2203\": \"LABEL_2203\",\n",
      "    \"2204\": \"LABEL_2204\",\n",
      "    \"2205\": \"LABEL_2205\",\n",
      "    \"2206\": \"LABEL_2206\",\n",
      "    \"2207\": \"LABEL_2207\",\n",
      "    \"2208\": \"LABEL_2208\",\n",
      "    \"2209\": \"LABEL_2209\",\n",
      "    \"2210\": \"LABEL_2210\",\n",
      "    \"2211\": \"LABEL_2211\",\n",
      "    \"2212\": \"LABEL_2212\",\n",
      "    \"2213\": \"LABEL_2213\",\n",
      "    \"2214\": \"LABEL_2214\",\n",
      "    \"2215\": \"LABEL_2215\",\n",
      "    \"2216\": \"LABEL_2216\",\n",
      "    \"2217\": \"LABEL_2217\",\n",
      "    \"2218\": \"LABEL_2218\",\n",
      "    \"2219\": \"LABEL_2219\",\n",
      "    \"2220\": \"LABEL_2220\",\n",
      "    \"2221\": \"LABEL_2221\",\n",
      "    \"2222\": \"LABEL_2222\",\n",
      "    \"2223\": \"LABEL_2223\",\n",
      "    \"2224\": \"LABEL_2224\",\n",
      "    \"2225\": \"LABEL_2225\",\n",
      "    \"2226\": \"LABEL_2226\",\n",
      "    \"2227\": \"LABEL_2227\",\n",
      "    \"2228\": \"LABEL_2228\",\n",
      "    \"2229\": \"LABEL_2229\",\n",
      "    \"2230\": \"LABEL_2230\",\n",
      "    \"2231\": \"LABEL_2231\",\n",
      "    \"2232\": \"LABEL_2232\",\n",
      "    \"2233\": \"LABEL_2233\",\n",
      "    \"2234\": \"LABEL_2234\",\n",
      "    \"2235\": \"LABEL_2235\",\n",
      "    \"2236\": \"LABEL_2236\",\n",
      "    \"2237\": \"LABEL_2237\",\n",
      "    \"2238\": \"LABEL_2238\",\n",
      "    \"2239\": \"LABEL_2239\",\n",
      "    \"2240\": \"LABEL_2240\",\n",
      "    \"2241\": \"LABEL_2241\",\n",
      "    \"2242\": \"LABEL_2242\",\n",
      "    \"2243\": \"LABEL_2243\",\n",
      "    \"2244\": \"LABEL_2244\",\n",
      "    \"2245\": \"LABEL_2245\",\n",
      "    \"2246\": \"LABEL_2246\",\n",
      "    \"2247\": \"LABEL_2247\",\n",
      "    \"2248\": \"LABEL_2248\",\n",
      "    \"2249\": \"LABEL_2249\",\n",
      "    \"2250\": \"LABEL_2250\",\n",
      "    \"2251\": \"LABEL_2251\",\n",
      "    \"2252\": \"LABEL_2252\",\n",
      "    \"2253\": \"LABEL_2253\",\n",
      "    \"2254\": \"LABEL_2254\",\n",
      "    \"2255\": \"LABEL_2255\",\n",
      "    \"2256\": \"LABEL_2256\",\n",
      "    \"2257\": \"LABEL_2257\",\n",
      "    \"2258\": \"LABEL_2258\",\n",
      "    \"2259\": \"LABEL_2259\",\n",
      "    \"2260\": \"LABEL_2260\",\n",
      "    \"2261\": \"LABEL_2261\",\n",
      "    \"2262\": \"LABEL_2262\",\n",
      "    \"2263\": \"LABEL_2263\",\n",
      "    \"2264\": \"LABEL_2264\",\n",
      "    \"2265\": \"LABEL_2265\",\n",
      "    \"2266\": \"LABEL_2266\",\n",
      "    \"2267\": \"LABEL_2267\",\n",
      "    \"2268\": \"LABEL_2268\",\n",
      "    \"2269\": \"LABEL_2269\",\n",
      "    \"2270\": \"LABEL_2270\",\n",
      "    \"2271\": \"LABEL_2271\",\n",
      "    \"2272\": \"LABEL_2272\",\n",
      "    \"2273\": \"LABEL_2273\",\n",
      "    \"2274\": \"LABEL_2274\",\n",
      "    \"2275\": \"LABEL_2275\",\n",
      "    \"2276\": \"LABEL_2276\",\n",
      "    \"2277\": \"LABEL_2277\",\n",
      "    \"2278\": \"LABEL_2278\",\n",
      "    \"2279\": \"LABEL_2279\",\n",
      "    \"2280\": \"LABEL_2280\",\n",
      "    \"2281\": \"LABEL_2281\",\n",
      "    \"2282\": \"LABEL_2282\",\n",
      "    \"2283\": \"LABEL_2283\",\n",
      "    \"2284\": \"LABEL_2284\",\n",
      "    \"2285\": \"LABEL_2285\",\n",
      "    \"2286\": \"LABEL_2286\",\n",
      "    \"2287\": \"LABEL_2287\",\n",
      "    \"2288\": \"LABEL_2288\",\n",
      "    \"2289\": \"LABEL_2289\",\n",
      "    \"2290\": \"LABEL_2290\",\n",
      "    \"2291\": \"LABEL_2291\",\n",
      "    \"2292\": \"LABEL_2292\",\n",
      "    \"2293\": \"LABEL_2293\",\n",
      "    \"2294\": \"LABEL_2294\",\n",
      "    \"2295\": \"LABEL_2295\",\n",
      "    \"2296\": \"LABEL_2296\",\n",
      "    \"2297\": \"LABEL_2297\",\n",
      "    \"2298\": \"LABEL_2298\",\n",
      "    \"2299\": \"LABEL_2299\",\n",
      "    \"2300\": \"LABEL_2300\",\n",
      "    \"2301\": \"LABEL_2301\",\n",
      "    \"2302\": \"LABEL_2302\",\n",
      "    \"2303\": \"LABEL_2303\",\n",
      "    \"2304\": \"LABEL_2304\",\n",
      "    \"2305\": \"LABEL_2305\",\n",
      "    \"2306\": \"LABEL_2306\",\n",
      "    \"2307\": \"LABEL_2307\",\n",
      "    \"2308\": \"LABEL_2308\",\n",
      "    \"2309\": \"LABEL_2309\",\n",
      "    \"2310\": \"LABEL_2310\",\n",
      "    \"2311\": \"LABEL_2311\",\n",
      "    \"2312\": \"LABEL_2312\",\n",
      "    \"2313\": \"LABEL_2313\",\n",
      "    \"2314\": \"LABEL_2314\",\n",
      "    \"2315\": \"LABEL_2315\",\n",
      "    \"2316\": \"LABEL_2316\",\n",
      "    \"2317\": \"LABEL_2317\",\n",
      "    \"2318\": \"LABEL_2318\",\n",
      "    \"2319\": \"LABEL_2319\",\n",
      "    \"2320\": \"LABEL_2320\",\n",
      "    \"2321\": \"LABEL_2321\",\n",
      "    \"2322\": \"LABEL_2322\",\n",
      "    \"2323\": \"LABEL_2323\",\n",
      "    \"2324\": \"LABEL_2324\",\n",
      "    \"2325\": \"LABEL_2325\",\n",
      "    \"2326\": \"LABEL_2326\",\n",
      "    \"2327\": \"LABEL_2327\",\n",
      "    \"2328\": \"LABEL_2328\",\n",
      "    \"2329\": \"LABEL_2329\",\n",
      "    \"2330\": \"LABEL_2330\",\n",
      "    \"2331\": \"LABEL_2331\",\n",
      "    \"2332\": \"LABEL_2332\",\n",
      "    \"2333\": \"LABEL_2333\",\n",
      "    \"2334\": \"LABEL_2334\",\n",
      "    \"2335\": \"LABEL_2335\",\n",
      "    \"2336\": \"LABEL_2336\",\n",
      "    \"2337\": \"LABEL_2337\",\n",
      "    \"2338\": \"LABEL_2338\",\n",
      "    \"2339\": \"LABEL_2339\",\n",
      "    \"2340\": \"LABEL_2340\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_100\": 100,\n",
      "    \"LABEL_1000\": 1000,\n",
      "    \"LABEL_1001\": 1001,\n",
      "    \"LABEL_1002\": 1002,\n",
      "    \"LABEL_1003\": 1003,\n",
      "    \"LABEL_1004\": 1004,\n",
      "    \"LABEL_1005\": 1005,\n",
      "    \"LABEL_1006\": 1006,\n",
      "    \"LABEL_1007\": 1007,\n",
      "    \"LABEL_1008\": 1008,\n",
      "    \"LABEL_1009\": 1009,\n",
      "    \"LABEL_101\": 101,\n",
      "    \"LABEL_1010\": 1010,\n",
      "    \"LABEL_1011\": 1011,\n",
      "    \"LABEL_1012\": 1012,\n",
      "    \"LABEL_1013\": 1013,\n",
      "    \"LABEL_1014\": 1014,\n",
      "    \"LABEL_1015\": 1015,\n",
      "    \"LABEL_1016\": 1016,\n",
      "    \"LABEL_1017\": 1017,\n",
      "    \"LABEL_1018\": 1018,\n",
      "    \"LABEL_1019\": 1019,\n",
      "    \"LABEL_102\": 102,\n",
      "    \"LABEL_1020\": 1020,\n",
      "    \"LABEL_1021\": 1021,\n",
      "    \"LABEL_1022\": 1022,\n",
      "    \"LABEL_1023\": 1023,\n",
      "    \"LABEL_1024\": 1024,\n",
      "    \"LABEL_1025\": 1025,\n",
      "    \"LABEL_1026\": 1026,\n",
      "    \"LABEL_1027\": 1027,\n",
      "    \"LABEL_1028\": 1028,\n",
      "    \"LABEL_1029\": 1029,\n",
      "    \"LABEL_103\": 103,\n",
      "    \"LABEL_1030\": 1030,\n",
      "    \"LABEL_1031\": 1031,\n",
      "    \"LABEL_1032\": 1032,\n",
      "    \"LABEL_1033\": 1033,\n",
      "    \"LABEL_1034\": 1034,\n",
      "    \"LABEL_1035\": 1035,\n",
      "    \"LABEL_1036\": 1036,\n",
      "    \"LABEL_1037\": 1037,\n",
      "    \"LABEL_1038\": 1038,\n",
      "    \"LABEL_1039\": 1039,\n",
      "    \"LABEL_104\": 104,\n",
      "    \"LABEL_1040\": 1040,\n",
      "    \"LABEL_1041\": 1041,\n",
      "    \"LABEL_1042\": 1042,\n",
      "    \"LABEL_1043\": 1043,\n",
      "    \"LABEL_1044\": 1044,\n",
      "    \"LABEL_1045\": 1045,\n",
      "    \"LABEL_1046\": 1046,\n",
      "    \"LABEL_1047\": 1047,\n",
      "    \"LABEL_1048\": 1048,\n",
      "    \"LABEL_1049\": 1049,\n",
      "    \"LABEL_105\": 105,\n",
      "    \"LABEL_1050\": 1050,\n",
      "    \"LABEL_1051\": 1051,\n",
      "    \"LABEL_1052\": 1052,\n",
      "    \"LABEL_1053\": 1053,\n",
      "    \"LABEL_1054\": 1054,\n",
      "    \"LABEL_1055\": 1055,\n",
      "    \"LABEL_1056\": 1056,\n",
      "    \"LABEL_1057\": 1057,\n",
      "    \"LABEL_1058\": 1058,\n",
      "    \"LABEL_1059\": 1059,\n",
      "    \"LABEL_106\": 106,\n",
      "    \"LABEL_1060\": 1060,\n",
      "    \"LABEL_1061\": 1061,\n",
      "    \"LABEL_1062\": 1062,\n",
      "    \"LABEL_1063\": 1063,\n",
      "    \"LABEL_1064\": 1064,\n",
      "    \"LABEL_1065\": 1065,\n",
      "    \"LABEL_1066\": 1066,\n",
      "    \"LABEL_1067\": 1067,\n",
      "    \"LABEL_1068\": 1068,\n",
      "    \"LABEL_1069\": 1069,\n",
      "    \"LABEL_107\": 107,\n",
      "    \"LABEL_1070\": 1070,\n",
      "    \"LABEL_1071\": 1071,\n",
      "    \"LABEL_1072\": 1072,\n",
      "    \"LABEL_1073\": 1073,\n",
      "    \"LABEL_1074\": 1074,\n",
      "    \"LABEL_1075\": 1075,\n",
      "    \"LABEL_1076\": 1076,\n",
      "    \"LABEL_1077\": 1077,\n",
      "    \"LABEL_1078\": 1078,\n",
      "    \"LABEL_1079\": 1079,\n",
      "    \"LABEL_108\": 108,\n",
      "    \"LABEL_1080\": 1080,\n",
      "    \"LABEL_1081\": 1081,\n",
      "    \"LABEL_1082\": 1082,\n",
      "    \"LABEL_1083\": 1083,\n",
      "    \"LABEL_1084\": 1084,\n",
      "    \"LABEL_1085\": 1085,\n",
      "    \"LABEL_1086\": 1086,\n",
      "    \"LABEL_1087\": 1087,\n",
      "    \"LABEL_1088\": 1088,\n",
      "    \"LABEL_1089\": 1089,\n",
      "    \"LABEL_109\": 109,\n",
      "    \"LABEL_1090\": 1090,\n",
      "    \"LABEL_1091\": 1091,\n",
      "    \"LABEL_1092\": 1092,\n",
      "    \"LABEL_1093\": 1093,\n",
      "    \"LABEL_1094\": 1094,\n",
      "    \"LABEL_1095\": 1095,\n",
      "    \"LABEL_1096\": 1096,\n",
      "    \"LABEL_1097\": 1097,\n",
      "    \"LABEL_1098\": 1098,\n",
      "    \"LABEL_1099\": 1099,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_110\": 110,\n",
      "    \"LABEL_1100\": 1100,\n",
      "    \"LABEL_1101\": 1101,\n",
      "    \"LABEL_1102\": 1102,\n",
      "    \"LABEL_1103\": 1103,\n",
      "    \"LABEL_1104\": 1104,\n",
      "    \"LABEL_1105\": 1105,\n",
      "    \"LABEL_1106\": 1106,\n",
      "    \"LABEL_1107\": 1107,\n",
      "    \"LABEL_1108\": 1108,\n",
      "    \"LABEL_1109\": 1109,\n",
      "    \"LABEL_111\": 111,\n",
      "    \"LABEL_1110\": 1110,\n",
      "    \"LABEL_1111\": 1111,\n",
      "    \"LABEL_1112\": 1112,\n",
      "    \"LABEL_1113\": 1113,\n",
      "    \"LABEL_1114\": 1114,\n",
      "    \"LABEL_1115\": 1115,\n",
      "    \"LABEL_1116\": 1116,\n",
      "    \"LABEL_1117\": 1117,\n",
      "    \"LABEL_1118\": 1118,\n",
      "    \"LABEL_1119\": 1119,\n",
      "    \"LABEL_112\": 112,\n",
      "    \"LABEL_1120\": 1120,\n",
      "    \"LABEL_1121\": 1121,\n",
      "    \"LABEL_1122\": 1122,\n",
      "    \"LABEL_1123\": 1123,\n",
      "    \"LABEL_1124\": 1124,\n",
      "    \"LABEL_1125\": 1125,\n",
      "    \"LABEL_1126\": 1126,\n",
      "    \"LABEL_1127\": 1127,\n",
      "    \"LABEL_1128\": 1128,\n",
      "    \"LABEL_1129\": 1129,\n",
      "    \"LABEL_113\": 113,\n",
      "    \"LABEL_1130\": 1130,\n",
      "    \"LABEL_1131\": 1131,\n",
      "    \"LABEL_1132\": 1132,\n",
      "    \"LABEL_1133\": 1133,\n",
      "    \"LABEL_1134\": 1134,\n",
      "    \"LABEL_1135\": 1135,\n",
      "    \"LABEL_1136\": 1136,\n",
      "    \"LABEL_1137\": 1137,\n",
      "    \"LABEL_1138\": 1138,\n",
      "    \"LABEL_1139\": 1139,\n",
      "    \"LABEL_114\": 114,\n",
      "    \"LABEL_1140\": 1140,\n",
      "    \"LABEL_1141\": 1141,\n",
      "    \"LABEL_1142\": 1142,\n",
      "    \"LABEL_1143\": 1143,\n",
      "    \"LABEL_1144\": 1144,\n",
      "    \"LABEL_1145\": 1145,\n",
      "    \"LABEL_1146\": 1146,\n",
      "    \"LABEL_1147\": 1147,\n",
      "    \"LABEL_1148\": 1148,\n",
      "    \"LABEL_1149\": 1149,\n",
      "    \"LABEL_115\": 115,\n",
      "    \"LABEL_1150\": 1150,\n",
      "    \"LABEL_1151\": 1151,\n",
      "    \"LABEL_1152\": 1152,\n",
      "    \"LABEL_1153\": 1153,\n",
      "    \"LABEL_1154\": 1154,\n",
      "    \"LABEL_1155\": 1155,\n",
      "    \"LABEL_1156\": 1156,\n",
      "    \"LABEL_1157\": 1157,\n",
      "    \"LABEL_1158\": 1158,\n",
      "    \"LABEL_1159\": 1159,\n",
      "    \"LABEL_116\": 116,\n",
      "    \"LABEL_1160\": 1160,\n",
      "    \"LABEL_1161\": 1161,\n",
      "    \"LABEL_1162\": 1162,\n",
      "    \"LABEL_1163\": 1163,\n",
      "    \"LABEL_1164\": 1164,\n",
      "    \"LABEL_1165\": 1165,\n",
      "    \"LABEL_1166\": 1166,\n",
      "    \"LABEL_1167\": 1167,\n",
      "    \"LABEL_1168\": 1168,\n",
      "    \"LABEL_1169\": 1169,\n",
      "    \"LABEL_117\": 117,\n",
      "    \"LABEL_1170\": 1170,\n",
      "    \"LABEL_1171\": 1171,\n",
      "    \"LABEL_1172\": 1172,\n",
      "    \"LABEL_1173\": 1173,\n",
      "    \"LABEL_1174\": 1174,\n",
      "    \"LABEL_1175\": 1175,\n",
      "    \"LABEL_1176\": 1176,\n",
      "    \"LABEL_1177\": 1177,\n",
      "    \"LABEL_1178\": 1178,\n",
      "    \"LABEL_1179\": 1179,\n",
      "    \"LABEL_118\": 118,\n",
      "    \"LABEL_1180\": 1180,\n",
      "    \"LABEL_1181\": 1181,\n",
      "    \"LABEL_1182\": 1182,\n",
      "    \"LABEL_1183\": 1183,\n",
      "    \"LABEL_1184\": 1184,\n",
      "    \"LABEL_1185\": 1185,\n",
      "    \"LABEL_1186\": 1186,\n",
      "    \"LABEL_1187\": 1187,\n",
      "    \"LABEL_1188\": 1188,\n",
      "    \"LABEL_1189\": 1189,\n",
      "    \"LABEL_119\": 119,\n",
      "    \"LABEL_1190\": 1190,\n",
      "    \"LABEL_1191\": 1191,\n",
      "    \"LABEL_1192\": 1192,\n",
      "    \"LABEL_1193\": 1193,\n",
      "    \"LABEL_1194\": 1194,\n",
      "    \"LABEL_1195\": 1195,\n",
      "    \"LABEL_1196\": 1196,\n",
      "    \"LABEL_1197\": 1197,\n",
      "    \"LABEL_1198\": 1198,\n",
      "    \"LABEL_1199\": 1199,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_120\": 120,\n",
      "    \"LABEL_1200\": 1200,\n",
      "    \"LABEL_1201\": 1201,\n",
      "    \"LABEL_1202\": 1202,\n",
      "    \"LABEL_1203\": 1203,\n",
      "    \"LABEL_1204\": 1204,\n",
      "    \"LABEL_1205\": 1205,\n",
      "    \"LABEL_1206\": 1206,\n",
      "    \"LABEL_1207\": 1207,\n",
      "    \"LABEL_1208\": 1208,\n",
      "    \"LABEL_1209\": 1209,\n",
      "    \"LABEL_121\": 121,\n",
      "    \"LABEL_1210\": 1210,\n",
      "    \"LABEL_1211\": 1211,\n",
      "    \"LABEL_1212\": 1212,\n",
      "    \"LABEL_1213\": 1213,\n",
      "    \"LABEL_1214\": 1214,\n",
      "    \"LABEL_1215\": 1215,\n",
      "    \"LABEL_1216\": 1216,\n",
      "    \"LABEL_1217\": 1217,\n",
      "    \"LABEL_1218\": 1218,\n",
      "    \"LABEL_1219\": 1219,\n",
      "    \"LABEL_122\": 122,\n",
      "    \"LABEL_1220\": 1220,\n",
      "    \"LABEL_1221\": 1221,\n",
      "    \"LABEL_1222\": 1222,\n",
      "    \"LABEL_1223\": 1223,\n",
      "    \"LABEL_1224\": 1224,\n",
      "    \"LABEL_1225\": 1225,\n",
      "    \"LABEL_1226\": 1226,\n",
      "    \"LABEL_1227\": 1227,\n",
      "    \"LABEL_1228\": 1228,\n",
      "    \"LABEL_1229\": 1229,\n",
      "    \"LABEL_123\": 123,\n",
      "    \"LABEL_1230\": 1230,\n",
      "    \"LABEL_1231\": 1231,\n",
      "    \"LABEL_1232\": 1232,\n",
      "    \"LABEL_1233\": 1233,\n",
      "    \"LABEL_1234\": 1234,\n",
      "    \"LABEL_1235\": 1235,\n",
      "    \"LABEL_1236\": 1236,\n",
      "    \"LABEL_1237\": 1237,\n",
      "    \"LABEL_1238\": 1238,\n",
      "    \"LABEL_1239\": 1239,\n",
      "    \"LABEL_124\": 124,\n",
      "    \"LABEL_1240\": 1240,\n",
      "    \"LABEL_1241\": 1241,\n",
      "    \"LABEL_1242\": 1242,\n",
      "    \"LABEL_1243\": 1243,\n",
      "    \"LABEL_1244\": 1244,\n",
      "    \"LABEL_1245\": 1245,\n",
      "    \"LABEL_1246\": 1246,\n",
      "    \"LABEL_1247\": 1247,\n",
      "    \"LABEL_1248\": 1248,\n",
      "    \"LABEL_1249\": 1249,\n",
      "    \"LABEL_125\": 125,\n",
      "    \"LABEL_1250\": 1250,\n",
      "    \"LABEL_1251\": 1251,\n",
      "    \"LABEL_1252\": 1252,\n",
      "    \"LABEL_1253\": 1253,\n",
      "    \"LABEL_1254\": 1254,\n",
      "    \"LABEL_1255\": 1255,\n",
      "    \"LABEL_1256\": 1256,\n",
      "    \"LABEL_1257\": 1257,\n",
      "    \"LABEL_1258\": 1258,\n",
      "    \"LABEL_1259\": 1259,\n",
      "    \"LABEL_126\": 126,\n",
      "    \"LABEL_1260\": 1260,\n",
      "    \"LABEL_1261\": 1261,\n",
      "    \"LABEL_1262\": 1262,\n",
      "    \"LABEL_1263\": 1263,\n",
      "    \"LABEL_1264\": 1264,\n",
      "    \"LABEL_1265\": 1265,\n",
      "    \"LABEL_1266\": 1266,\n",
      "    \"LABEL_1267\": 1267,\n",
      "    \"LABEL_1268\": 1268,\n",
      "    \"LABEL_1269\": 1269,\n",
      "    \"LABEL_127\": 127,\n",
      "    \"LABEL_1270\": 1270,\n",
      "    \"LABEL_1271\": 1271,\n",
      "    \"LABEL_1272\": 1272,\n",
      "    \"LABEL_1273\": 1273,\n",
      "    \"LABEL_1274\": 1274,\n",
      "    \"LABEL_1275\": 1275,\n",
      "    \"LABEL_1276\": 1276,\n",
      "    \"LABEL_1277\": 1277,\n",
      "    \"LABEL_1278\": 1278,\n",
      "    \"LABEL_1279\": 1279,\n",
      "    \"LABEL_128\": 128,\n",
      "    \"LABEL_1280\": 1280,\n",
      "    \"LABEL_1281\": 1281,\n",
      "    \"LABEL_1282\": 1282,\n",
      "    \"LABEL_1283\": 1283,\n",
      "    \"LABEL_1284\": 1284,\n",
      "    \"LABEL_1285\": 1285,\n",
      "    \"LABEL_1286\": 1286,\n",
      "    \"LABEL_1287\": 1287,\n",
      "    \"LABEL_1288\": 1288,\n",
      "    \"LABEL_1289\": 1289,\n",
      "    \"LABEL_129\": 129,\n",
      "    \"LABEL_1290\": 1290,\n",
      "    \"LABEL_1291\": 1291,\n",
      "    \"LABEL_1292\": 1292,\n",
      "    \"LABEL_1293\": 1293,\n",
      "    \"LABEL_1294\": 1294,\n",
      "    \"LABEL_1295\": 1295,\n",
      "    \"LABEL_1296\": 1296,\n",
      "    \"LABEL_1297\": 1297,\n",
      "    \"LABEL_1298\": 1298,\n",
      "    \"LABEL_1299\": 1299,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_130\": 130,\n",
      "    \"LABEL_1300\": 1300,\n",
      "    \"LABEL_1301\": 1301,\n",
      "    \"LABEL_1302\": 1302,\n",
      "    \"LABEL_1303\": 1303,\n",
      "    \"LABEL_1304\": 1304,\n",
      "    \"LABEL_1305\": 1305,\n",
      "    \"LABEL_1306\": 1306,\n",
      "    \"LABEL_1307\": 1307,\n",
      "    \"LABEL_1308\": 1308,\n",
      "    \"LABEL_1309\": 1309,\n",
      "    \"LABEL_131\": 131,\n",
      "    \"LABEL_1310\": 1310,\n",
      "    \"LABEL_1311\": 1311,\n",
      "    \"LABEL_1312\": 1312,\n",
      "    \"LABEL_1313\": 1313,\n",
      "    \"LABEL_1314\": 1314,\n",
      "    \"LABEL_1315\": 1315,\n",
      "    \"LABEL_1316\": 1316,\n",
      "    \"LABEL_1317\": 1317,\n",
      "    \"LABEL_1318\": 1318,\n",
      "    \"LABEL_1319\": 1319,\n",
      "    \"LABEL_132\": 132,\n",
      "    \"LABEL_1320\": 1320,\n",
      "    \"LABEL_1321\": 1321,\n",
      "    \"LABEL_1322\": 1322,\n",
      "    \"LABEL_1323\": 1323,\n",
      "    \"LABEL_1324\": 1324,\n",
      "    \"LABEL_1325\": 1325,\n",
      "    \"LABEL_1326\": 1326,\n",
      "    \"LABEL_1327\": 1327,\n",
      "    \"LABEL_1328\": 1328,\n",
      "    \"LABEL_1329\": 1329,\n",
      "    \"LABEL_133\": 133,\n",
      "    \"LABEL_1330\": 1330,\n",
      "    \"LABEL_1331\": 1331,\n",
      "    \"LABEL_1332\": 1332,\n",
      "    \"LABEL_1333\": 1333,\n",
      "    \"LABEL_1334\": 1334,\n",
      "    \"LABEL_1335\": 1335,\n",
      "    \"LABEL_1336\": 1336,\n",
      "    \"LABEL_1337\": 1337,\n",
      "    \"LABEL_1338\": 1338,\n",
      "    \"LABEL_1339\": 1339,\n",
      "    \"LABEL_134\": 134,\n",
      "    \"LABEL_1340\": 1340,\n",
      "    \"LABEL_1341\": 1341,\n",
      "    \"LABEL_1342\": 1342,\n",
      "    \"LABEL_1343\": 1343,\n",
      "    \"LABEL_1344\": 1344,\n",
      "    \"LABEL_1345\": 1345,\n",
      "    \"LABEL_1346\": 1346,\n",
      "    \"LABEL_1347\": 1347,\n",
      "    \"LABEL_1348\": 1348,\n",
      "    \"LABEL_1349\": 1349,\n",
      "    \"LABEL_135\": 135,\n",
      "    \"LABEL_1350\": 1350,\n",
      "    \"LABEL_1351\": 1351,\n",
      "    \"LABEL_1352\": 1352,\n",
      "    \"LABEL_1353\": 1353,\n",
      "    \"LABEL_1354\": 1354,\n",
      "    \"LABEL_1355\": 1355,\n",
      "    \"LABEL_1356\": 1356,\n",
      "    \"LABEL_1357\": 1357,\n",
      "    \"LABEL_1358\": 1358,\n",
      "    \"LABEL_1359\": 1359,\n",
      "    \"LABEL_136\": 136,\n",
      "    \"LABEL_1360\": 1360,\n",
      "    \"LABEL_1361\": 1361,\n",
      "    \"LABEL_1362\": 1362,\n",
      "    \"LABEL_1363\": 1363,\n",
      "    \"LABEL_1364\": 1364,\n",
      "    \"LABEL_1365\": 1365,\n",
      "    \"LABEL_1366\": 1366,\n",
      "    \"LABEL_1367\": 1367,\n",
      "    \"LABEL_1368\": 1368,\n",
      "    \"LABEL_1369\": 1369,\n",
      "    \"LABEL_137\": 137,\n",
      "    \"LABEL_1370\": 1370,\n",
      "    \"LABEL_1371\": 1371,\n",
      "    \"LABEL_1372\": 1372,\n",
      "    \"LABEL_1373\": 1373,\n",
      "    \"LABEL_1374\": 1374,\n",
      "    \"LABEL_1375\": 1375,\n",
      "    \"LABEL_1376\": 1376,\n",
      "    \"LABEL_1377\": 1377,\n",
      "    \"LABEL_1378\": 1378,\n",
      "    \"LABEL_1379\": 1379,\n",
      "    \"LABEL_138\": 138,\n",
      "    \"LABEL_1380\": 1380,\n",
      "    \"LABEL_1381\": 1381,\n",
      "    \"LABEL_1382\": 1382,\n",
      "    \"LABEL_1383\": 1383,\n",
      "    \"LABEL_1384\": 1384,\n",
      "    \"LABEL_1385\": 1385,\n",
      "    \"LABEL_1386\": 1386,\n",
      "    \"LABEL_1387\": 1387,\n",
      "    \"LABEL_1388\": 1388,\n",
      "    \"LABEL_1389\": 1389,\n",
      "    \"LABEL_139\": 139,\n",
      "    \"LABEL_1390\": 1390,\n",
      "    \"LABEL_1391\": 1391,\n",
      "    \"LABEL_1392\": 1392,\n",
      "    \"LABEL_1393\": 1393,\n",
      "    \"LABEL_1394\": 1394,\n",
      "    \"LABEL_1395\": 1395,\n",
      "    \"LABEL_1396\": 1396,\n",
      "    \"LABEL_1397\": 1397,\n",
      "    \"LABEL_1398\": 1398,\n",
      "    \"LABEL_1399\": 1399,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_140\": 140,\n",
      "    \"LABEL_1400\": 1400,\n",
      "    \"LABEL_1401\": 1401,\n",
      "    \"LABEL_1402\": 1402,\n",
      "    \"LABEL_1403\": 1403,\n",
      "    \"LABEL_1404\": 1404,\n",
      "    \"LABEL_1405\": 1405,\n",
      "    \"LABEL_1406\": 1406,\n",
      "    \"LABEL_1407\": 1407,\n",
      "    \"LABEL_1408\": 1408,\n",
      "    \"LABEL_1409\": 1409,\n",
      "    \"LABEL_141\": 141,\n",
      "    \"LABEL_1410\": 1410,\n",
      "    \"LABEL_1411\": 1411,\n",
      "    \"LABEL_1412\": 1412,\n",
      "    \"LABEL_1413\": 1413,\n",
      "    \"LABEL_1414\": 1414,\n",
      "    \"LABEL_1415\": 1415,\n",
      "    \"LABEL_1416\": 1416,\n",
      "    \"LABEL_1417\": 1417,\n",
      "    \"LABEL_1418\": 1418,\n",
      "    \"LABEL_1419\": 1419,\n",
      "    \"LABEL_142\": 142,\n",
      "    \"LABEL_1420\": 1420,\n",
      "    \"LABEL_1421\": 1421,\n",
      "    \"LABEL_1422\": 1422,\n",
      "    \"LABEL_1423\": 1423,\n",
      "    \"LABEL_1424\": 1424,\n",
      "    \"LABEL_1425\": 1425,\n",
      "    \"LABEL_1426\": 1426,\n",
      "    \"LABEL_1427\": 1427,\n",
      "    \"LABEL_1428\": 1428,\n",
      "    \"LABEL_1429\": 1429,\n",
      "    \"LABEL_143\": 143,\n",
      "    \"LABEL_1430\": 1430,\n",
      "    \"LABEL_1431\": 1431,\n",
      "    \"LABEL_1432\": 1432,\n",
      "    \"LABEL_1433\": 1433,\n",
      "    \"LABEL_1434\": 1434,\n",
      "    \"LABEL_1435\": 1435,\n",
      "    \"LABEL_1436\": 1436,\n",
      "    \"LABEL_1437\": 1437,\n",
      "    \"LABEL_1438\": 1438,\n",
      "    \"LABEL_1439\": 1439,\n",
      "    \"LABEL_144\": 144,\n",
      "    \"LABEL_1440\": 1440,\n",
      "    \"LABEL_1441\": 1441,\n",
      "    \"LABEL_1442\": 1442,\n",
      "    \"LABEL_1443\": 1443,\n",
      "    \"LABEL_1444\": 1444,\n",
      "    \"LABEL_1445\": 1445,\n",
      "    \"LABEL_1446\": 1446,\n",
      "    \"LABEL_1447\": 1447,\n",
      "    \"LABEL_1448\": 1448,\n",
      "    \"LABEL_1449\": 1449,\n",
      "    \"LABEL_145\": 145,\n",
      "    \"LABEL_1450\": 1450,\n",
      "    \"LABEL_1451\": 1451,\n",
      "    \"LABEL_1452\": 1452,\n",
      "    \"LABEL_1453\": 1453,\n",
      "    \"LABEL_1454\": 1454,\n",
      "    \"LABEL_1455\": 1455,\n",
      "    \"LABEL_1456\": 1456,\n",
      "    \"LABEL_1457\": 1457,\n",
      "    \"LABEL_1458\": 1458,\n",
      "    \"LABEL_1459\": 1459,\n",
      "    \"LABEL_146\": 146,\n",
      "    \"LABEL_1460\": 1460,\n",
      "    \"LABEL_1461\": 1461,\n",
      "    \"LABEL_1462\": 1462,\n",
      "    \"LABEL_1463\": 1463,\n",
      "    \"LABEL_1464\": 1464,\n",
      "    \"LABEL_1465\": 1465,\n",
      "    \"LABEL_1466\": 1466,\n",
      "    \"LABEL_1467\": 1467,\n",
      "    \"LABEL_1468\": 1468,\n",
      "    \"LABEL_1469\": 1469,\n",
      "    \"LABEL_147\": 147,\n",
      "    \"LABEL_1470\": 1470,\n",
      "    \"LABEL_1471\": 1471,\n",
      "    \"LABEL_1472\": 1472,\n",
      "    \"LABEL_1473\": 1473,\n",
      "    \"LABEL_1474\": 1474,\n",
      "    \"LABEL_1475\": 1475,\n",
      "    \"LABEL_1476\": 1476,\n",
      "    \"LABEL_1477\": 1477,\n",
      "    \"LABEL_1478\": 1478,\n",
      "    \"LABEL_1479\": 1479,\n",
      "    \"LABEL_148\": 148,\n",
      "    \"LABEL_1480\": 1480,\n",
      "    \"LABEL_1481\": 1481,\n",
      "    \"LABEL_1482\": 1482,\n",
      "    \"LABEL_1483\": 1483,\n",
      "    \"LABEL_1484\": 1484,\n",
      "    \"LABEL_1485\": 1485,\n",
      "    \"LABEL_1486\": 1486,\n",
      "    \"LABEL_1487\": 1487,\n",
      "    \"LABEL_1488\": 1488,\n",
      "    \"LABEL_1489\": 1489,\n",
      "    \"LABEL_149\": 149,\n",
      "    \"LABEL_1490\": 1490,\n",
      "    \"LABEL_1491\": 1491,\n",
      "    \"LABEL_1492\": 1492,\n",
      "    \"LABEL_1493\": 1493,\n",
      "    \"LABEL_1494\": 1494,\n",
      "    \"LABEL_1495\": 1495,\n",
      "    \"LABEL_1496\": 1496,\n",
      "    \"LABEL_1497\": 1497,\n",
      "    \"LABEL_1498\": 1498,\n",
      "    \"LABEL_1499\": 1499,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_150\": 150,\n",
      "    \"LABEL_1500\": 1500,\n",
      "    \"LABEL_1501\": 1501,\n",
      "    \"LABEL_1502\": 1502,\n",
      "    \"LABEL_1503\": 1503,\n",
      "    \"LABEL_1504\": 1504,\n",
      "    \"LABEL_1505\": 1505,\n",
      "    \"LABEL_1506\": 1506,\n",
      "    \"LABEL_1507\": 1507,\n",
      "    \"LABEL_1508\": 1508,\n",
      "    \"LABEL_1509\": 1509,\n",
      "    \"LABEL_151\": 151,\n",
      "    \"LABEL_1510\": 1510,\n",
      "    \"LABEL_1511\": 1511,\n",
      "    \"LABEL_1512\": 1512,\n",
      "    \"LABEL_1513\": 1513,\n",
      "    \"LABEL_1514\": 1514,\n",
      "    \"LABEL_1515\": 1515,\n",
      "    \"LABEL_1516\": 1516,\n",
      "    \"LABEL_1517\": 1517,\n",
      "    \"LABEL_1518\": 1518,\n",
      "    \"LABEL_1519\": 1519,\n",
      "    \"LABEL_152\": 152,\n",
      "    \"LABEL_1520\": 1520,\n",
      "    \"LABEL_1521\": 1521,\n",
      "    \"LABEL_1522\": 1522,\n",
      "    \"LABEL_1523\": 1523,\n",
      "    \"LABEL_1524\": 1524,\n",
      "    \"LABEL_1525\": 1525,\n",
      "    \"LABEL_1526\": 1526,\n",
      "    \"LABEL_1527\": 1527,\n",
      "    \"LABEL_1528\": 1528,\n",
      "    \"LABEL_1529\": 1529,\n",
      "    \"LABEL_153\": 153,\n",
      "    \"LABEL_1530\": 1530,\n",
      "    \"LABEL_1531\": 1531,\n",
      "    \"LABEL_1532\": 1532,\n",
      "    \"LABEL_1533\": 1533,\n",
      "    \"LABEL_1534\": 1534,\n",
      "    \"LABEL_1535\": 1535,\n",
      "    \"LABEL_1536\": 1536,\n",
      "    \"LABEL_1537\": 1537,\n",
      "    \"LABEL_1538\": 1538,\n",
      "    \"LABEL_1539\": 1539,\n",
      "    \"LABEL_154\": 154,\n",
      "    \"LABEL_1540\": 1540,\n",
      "    \"LABEL_1541\": 1541,\n",
      "    \"LABEL_1542\": 1542,\n",
      "    \"LABEL_1543\": 1543,\n",
      "    \"LABEL_1544\": 1544,\n",
      "    \"LABEL_1545\": 1545,\n",
      "    \"LABEL_1546\": 1546,\n",
      "    \"LABEL_1547\": 1547,\n",
      "    \"LABEL_1548\": 1548,\n",
      "    \"LABEL_1549\": 1549,\n",
      "    \"LABEL_155\": 155,\n",
      "    \"LABEL_1550\": 1550,\n",
      "    \"LABEL_1551\": 1551,\n",
      "    \"LABEL_1552\": 1552,\n",
      "    \"LABEL_1553\": 1553,\n",
      "    \"LABEL_1554\": 1554,\n",
      "    \"LABEL_1555\": 1555,\n",
      "    \"LABEL_1556\": 1556,\n",
      "    \"LABEL_1557\": 1557,\n",
      "    \"LABEL_1558\": 1558,\n",
      "    \"LABEL_1559\": 1559,\n",
      "    \"LABEL_156\": 156,\n",
      "    \"LABEL_1560\": 1560,\n",
      "    \"LABEL_1561\": 1561,\n",
      "    \"LABEL_1562\": 1562,\n",
      "    \"LABEL_1563\": 1563,\n",
      "    \"LABEL_1564\": 1564,\n",
      "    \"LABEL_1565\": 1565,\n",
      "    \"LABEL_1566\": 1566,\n",
      "    \"LABEL_1567\": 1567,\n",
      "    \"LABEL_1568\": 1568,\n",
      "    \"LABEL_1569\": 1569,\n",
      "    \"LABEL_157\": 157,\n",
      "    \"LABEL_1570\": 1570,\n",
      "    \"LABEL_1571\": 1571,\n",
      "    \"LABEL_1572\": 1572,\n",
      "    \"LABEL_1573\": 1573,\n",
      "    \"LABEL_1574\": 1574,\n",
      "    \"LABEL_1575\": 1575,\n",
      "    \"LABEL_1576\": 1576,\n",
      "    \"LABEL_1577\": 1577,\n",
      "    \"LABEL_1578\": 1578,\n",
      "    \"LABEL_1579\": 1579,\n",
      "    \"LABEL_158\": 158,\n",
      "    \"LABEL_1580\": 1580,\n",
      "    \"LABEL_1581\": 1581,\n",
      "    \"LABEL_1582\": 1582,\n",
      "    \"LABEL_1583\": 1583,\n",
      "    \"LABEL_1584\": 1584,\n",
      "    \"LABEL_1585\": 1585,\n",
      "    \"LABEL_1586\": 1586,\n",
      "    \"LABEL_1587\": 1587,\n",
      "    \"LABEL_1588\": 1588,\n",
      "    \"LABEL_1589\": 1589,\n",
      "    \"LABEL_159\": 159,\n",
      "    \"LABEL_1590\": 1590,\n",
      "    \"LABEL_1591\": 1591,\n",
      "    \"LABEL_1592\": 1592,\n",
      "    \"LABEL_1593\": 1593,\n",
      "    \"LABEL_1594\": 1594,\n",
      "    \"LABEL_1595\": 1595,\n",
      "    \"LABEL_1596\": 1596,\n",
      "    \"LABEL_1597\": 1597,\n",
      "    \"LABEL_1598\": 1598,\n",
      "    \"LABEL_1599\": 1599,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_160\": 160,\n",
      "    \"LABEL_1600\": 1600,\n",
      "    \"LABEL_1601\": 1601,\n",
      "    \"LABEL_1602\": 1602,\n",
      "    \"LABEL_1603\": 1603,\n",
      "    \"LABEL_1604\": 1604,\n",
      "    \"LABEL_1605\": 1605,\n",
      "    \"LABEL_1606\": 1606,\n",
      "    \"LABEL_1607\": 1607,\n",
      "    \"LABEL_1608\": 1608,\n",
      "    \"LABEL_1609\": 1609,\n",
      "    \"LABEL_161\": 161,\n",
      "    \"LABEL_1610\": 1610,\n",
      "    \"LABEL_1611\": 1611,\n",
      "    \"LABEL_1612\": 1612,\n",
      "    \"LABEL_1613\": 1613,\n",
      "    \"LABEL_1614\": 1614,\n",
      "    \"LABEL_1615\": 1615,\n",
      "    \"LABEL_1616\": 1616,\n",
      "    \"LABEL_1617\": 1617,\n",
      "    \"LABEL_1618\": 1618,\n",
      "    \"LABEL_1619\": 1619,\n",
      "    \"LABEL_162\": 162,\n",
      "    \"LABEL_1620\": 1620,\n",
      "    \"LABEL_1621\": 1621,\n",
      "    \"LABEL_1622\": 1622,\n",
      "    \"LABEL_1623\": 1623,\n",
      "    \"LABEL_1624\": 1624,\n",
      "    \"LABEL_1625\": 1625,\n",
      "    \"LABEL_1626\": 1626,\n",
      "    \"LABEL_1627\": 1627,\n",
      "    \"LABEL_1628\": 1628,\n",
      "    \"LABEL_1629\": 1629,\n",
      "    \"LABEL_163\": 163,\n",
      "    \"LABEL_1630\": 1630,\n",
      "    \"LABEL_1631\": 1631,\n",
      "    \"LABEL_1632\": 1632,\n",
      "    \"LABEL_1633\": 1633,\n",
      "    \"LABEL_1634\": 1634,\n",
      "    \"LABEL_1635\": 1635,\n",
      "    \"LABEL_1636\": 1636,\n",
      "    \"LABEL_1637\": 1637,\n",
      "    \"LABEL_1638\": 1638,\n",
      "    \"LABEL_1639\": 1639,\n",
      "    \"LABEL_164\": 164,\n",
      "    \"LABEL_1640\": 1640,\n",
      "    \"LABEL_1641\": 1641,\n",
      "    \"LABEL_1642\": 1642,\n",
      "    \"LABEL_1643\": 1643,\n",
      "    \"LABEL_1644\": 1644,\n",
      "    \"LABEL_1645\": 1645,\n",
      "    \"LABEL_1646\": 1646,\n",
      "    \"LABEL_1647\": 1647,\n",
      "    \"LABEL_1648\": 1648,\n",
      "    \"LABEL_1649\": 1649,\n",
      "    \"LABEL_165\": 165,\n",
      "    \"LABEL_1650\": 1650,\n",
      "    \"LABEL_1651\": 1651,\n",
      "    \"LABEL_1652\": 1652,\n",
      "    \"LABEL_1653\": 1653,\n",
      "    \"LABEL_1654\": 1654,\n",
      "    \"LABEL_1655\": 1655,\n",
      "    \"LABEL_1656\": 1656,\n",
      "    \"LABEL_1657\": 1657,\n",
      "    \"LABEL_1658\": 1658,\n",
      "    \"LABEL_1659\": 1659,\n",
      "    \"LABEL_166\": 166,\n",
      "    \"LABEL_1660\": 1660,\n",
      "    \"LABEL_1661\": 1661,\n",
      "    \"LABEL_1662\": 1662,\n",
      "    \"LABEL_1663\": 1663,\n",
      "    \"LABEL_1664\": 1664,\n",
      "    \"LABEL_1665\": 1665,\n",
      "    \"LABEL_1666\": 1666,\n",
      "    \"LABEL_1667\": 1667,\n",
      "    \"LABEL_1668\": 1668,\n",
      "    \"LABEL_1669\": 1669,\n",
      "    \"LABEL_167\": 167,\n",
      "    \"LABEL_1670\": 1670,\n",
      "    \"LABEL_1671\": 1671,\n",
      "    \"LABEL_1672\": 1672,\n",
      "    \"LABEL_1673\": 1673,\n",
      "    \"LABEL_1674\": 1674,\n",
      "    \"LABEL_1675\": 1675,\n",
      "    \"LABEL_1676\": 1676,\n",
      "    \"LABEL_1677\": 1677,\n",
      "    \"LABEL_1678\": 1678,\n",
      "    \"LABEL_1679\": 1679,\n",
      "    \"LABEL_168\": 168,\n",
      "    \"LABEL_1680\": 1680,\n",
      "    \"LABEL_1681\": 1681,\n",
      "    \"LABEL_1682\": 1682,\n",
      "    \"LABEL_1683\": 1683,\n",
      "    \"LABEL_1684\": 1684,\n",
      "    \"LABEL_1685\": 1685,\n",
      "    \"LABEL_1686\": 1686,\n",
      "    \"LABEL_1687\": 1687,\n",
      "    \"LABEL_1688\": 1688,\n",
      "    \"LABEL_1689\": 1689,\n",
      "    \"LABEL_169\": 169,\n",
      "    \"LABEL_1690\": 1690,\n",
      "    \"LABEL_1691\": 1691,\n",
      "    \"LABEL_1692\": 1692,\n",
      "    \"LABEL_1693\": 1693,\n",
      "    \"LABEL_1694\": 1694,\n",
      "    \"LABEL_1695\": 1695,\n",
      "    \"LABEL_1696\": 1696,\n",
      "    \"LABEL_1697\": 1697,\n",
      "    \"LABEL_1698\": 1698,\n",
      "    \"LABEL_1699\": 1699,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_170\": 170,\n",
      "    \"LABEL_1700\": 1700,\n",
      "    \"LABEL_1701\": 1701,\n",
      "    \"LABEL_1702\": 1702,\n",
      "    \"LABEL_1703\": 1703,\n",
      "    \"LABEL_1704\": 1704,\n",
      "    \"LABEL_1705\": 1705,\n",
      "    \"LABEL_1706\": 1706,\n",
      "    \"LABEL_1707\": 1707,\n",
      "    \"LABEL_1708\": 1708,\n",
      "    \"LABEL_1709\": 1709,\n",
      "    \"LABEL_171\": 171,\n",
      "    \"LABEL_1710\": 1710,\n",
      "    \"LABEL_1711\": 1711,\n",
      "    \"LABEL_1712\": 1712,\n",
      "    \"LABEL_1713\": 1713,\n",
      "    \"LABEL_1714\": 1714,\n",
      "    \"LABEL_1715\": 1715,\n",
      "    \"LABEL_1716\": 1716,\n",
      "    \"LABEL_1717\": 1717,\n",
      "    \"LABEL_1718\": 1718,\n",
      "    \"LABEL_1719\": 1719,\n",
      "    \"LABEL_172\": 172,\n",
      "    \"LABEL_1720\": 1720,\n",
      "    \"LABEL_1721\": 1721,\n",
      "    \"LABEL_1722\": 1722,\n",
      "    \"LABEL_1723\": 1723,\n",
      "    \"LABEL_1724\": 1724,\n",
      "    \"LABEL_1725\": 1725,\n",
      "    \"LABEL_1726\": 1726,\n",
      "    \"LABEL_1727\": 1727,\n",
      "    \"LABEL_1728\": 1728,\n",
      "    \"LABEL_1729\": 1729,\n",
      "    \"LABEL_173\": 173,\n",
      "    \"LABEL_1730\": 1730,\n",
      "    \"LABEL_1731\": 1731,\n",
      "    \"LABEL_1732\": 1732,\n",
      "    \"LABEL_1733\": 1733,\n",
      "    \"LABEL_1734\": 1734,\n",
      "    \"LABEL_1735\": 1735,\n",
      "    \"LABEL_1736\": 1736,\n",
      "    \"LABEL_1737\": 1737,\n",
      "    \"LABEL_1738\": 1738,\n",
      "    \"LABEL_1739\": 1739,\n",
      "    \"LABEL_174\": 174,\n",
      "    \"LABEL_1740\": 1740,\n",
      "    \"LABEL_1741\": 1741,\n",
      "    \"LABEL_1742\": 1742,\n",
      "    \"LABEL_1743\": 1743,\n",
      "    \"LABEL_1744\": 1744,\n",
      "    \"LABEL_1745\": 1745,\n",
      "    \"LABEL_1746\": 1746,\n",
      "    \"LABEL_1747\": 1747,\n",
      "    \"LABEL_1748\": 1748,\n",
      "    \"LABEL_1749\": 1749,\n",
      "    \"LABEL_175\": 175,\n",
      "    \"LABEL_1750\": 1750,\n",
      "    \"LABEL_1751\": 1751,\n",
      "    \"LABEL_1752\": 1752,\n",
      "    \"LABEL_1753\": 1753,\n",
      "    \"LABEL_1754\": 1754,\n",
      "    \"LABEL_1755\": 1755,\n",
      "    \"LABEL_1756\": 1756,\n",
      "    \"LABEL_1757\": 1757,\n",
      "    \"LABEL_1758\": 1758,\n",
      "    \"LABEL_1759\": 1759,\n",
      "    \"LABEL_176\": 176,\n",
      "    \"LABEL_1760\": 1760,\n",
      "    \"LABEL_1761\": 1761,\n",
      "    \"LABEL_1762\": 1762,\n",
      "    \"LABEL_1763\": 1763,\n",
      "    \"LABEL_1764\": 1764,\n",
      "    \"LABEL_1765\": 1765,\n",
      "    \"LABEL_1766\": 1766,\n",
      "    \"LABEL_1767\": 1767,\n",
      "    \"LABEL_1768\": 1768,\n",
      "    \"LABEL_1769\": 1769,\n",
      "    \"LABEL_177\": 177,\n",
      "    \"LABEL_1770\": 1770,\n",
      "    \"LABEL_1771\": 1771,\n",
      "    \"LABEL_1772\": 1772,\n",
      "    \"LABEL_1773\": 1773,\n",
      "    \"LABEL_1774\": 1774,\n",
      "    \"LABEL_1775\": 1775,\n",
      "    \"LABEL_1776\": 1776,\n",
      "    \"LABEL_1777\": 1777,\n",
      "    \"LABEL_1778\": 1778,\n",
      "    \"LABEL_1779\": 1779,\n",
      "    \"LABEL_178\": 178,\n",
      "    \"LABEL_1780\": 1780,\n",
      "    \"LABEL_1781\": 1781,\n",
      "    \"LABEL_1782\": 1782,\n",
      "    \"LABEL_1783\": 1783,\n",
      "    \"LABEL_1784\": 1784,\n",
      "    \"LABEL_1785\": 1785,\n",
      "    \"LABEL_1786\": 1786,\n",
      "    \"LABEL_1787\": 1787,\n",
      "    \"LABEL_1788\": 1788,\n",
      "    \"LABEL_1789\": 1789,\n",
      "    \"LABEL_179\": 179,\n",
      "    \"LABEL_1790\": 1790,\n",
      "    \"LABEL_1791\": 1791,\n",
      "    \"LABEL_1792\": 1792,\n",
      "    \"LABEL_1793\": 1793,\n",
      "    \"LABEL_1794\": 1794,\n",
      "    \"LABEL_1795\": 1795,\n",
      "    \"LABEL_1796\": 1796,\n",
      "    \"LABEL_1797\": 1797,\n",
      "    \"LABEL_1798\": 1798,\n",
      "    \"LABEL_1799\": 1799,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_180\": 180,\n",
      "    \"LABEL_1800\": 1800,\n",
      "    \"LABEL_1801\": 1801,\n",
      "    \"LABEL_1802\": 1802,\n",
      "    \"LABEL_1803\": 1803,\n",
      "    \"LABEL_1804\": 1804,\n",
      "    \"LABEL_1805\": 1805,\n",
      "    \"LABEL_1806\": 1806,\n",
      "    \"LABEL_1807\": 1807,\n",
      "    \"LABEL_1808\": 1808,\n",
      "    \"LABEL_1809\": 1809,\n",
      "    \"LABEL_181\": 181,\n",
      "    \"LABEL_1810\": 1810,\n",
      "    \"LABEL_1811\": 1811,\n",
      "    \"LABEL_1812\": 1812,\n",
      "    \"LABEL_1813\": 1813,\n",
      "    \"LABEL_1814\": 1814,\n",
      "    \"LABEL_1815\": 1815,\n",
      "    \"LABEL_1816\": 1816,\n",
      "    \"LABEL_1817\": 1817,\n",
      "    \"LABEL_1818\": 1818,\n",
      "    \"LABEL_1819\": 1819,\n",
      "    \"LABEL_182\": 182,\n",
      "    \"LABEL_1820\": 1820,\n",
      "    \"LABEL_1821\": 1821,\n",
      "    \"LABEL_1822\": 1822,\n",
      "    \"LABEL_1823\": 1823,\n",
      "    \"LABEL_1824\": 1824,\n",
      "    \"LABEL_1825\": 1825,\n",
      "    \"LABEL_1826\": 1826,\n",
      "    \"LABEL_1827\": 1827,\n",
      "    \"LABEL_1828\": 1828,\n",
      "    \"LABEL_1829\": 1829,\n",
      "    \"LABEL_183\": 183,\n",
      "    \"LABEL_1830\": 1830,\n",
      "    \"LABEL_1831\": 1831,\n",
      "    \"LABEL_1832\": 1832,\n",
      "    \"LABEL_1833\": 1833,\n",
      "    \"LABEL_1834\": 1834,\n",
      "    \"LABEL_1835\": 1835,\n",
      "    \"LABEL_1836\": 1836,\n",
      "    \"LABEL_1837\": 1837,\n",
      "    \"LABEL_1838\": 1838,\n",
      "    \"LABEL_1839\": 1839,\n",
      "    \"LABEL_184\": 184,\n",
      "    \"LABEL_1840\": 1840,\n",
      "    \"LABEL_1841\": 1841,\n",
      "    \"LABEL_1842\": 1842,\n",
      "    \"LABEL_1843\": 1843,\n",
      "    \"LABEL_1844\": 1844,\n",
      "    \"LABEL_1845\": 1845,\n",
      "    \"LABEL_1846\": 1846,\n",
      "    \"LABEL_1847\": 1847,\n",
      "    \"LABEL_1848\": 1848,\n",
      "    \"LABEL_1849\": 1849,\n",
      "    \"LABEL_185\": 185,\n",
      "    \"LABEL_1850\": 1850,\n",
      "    \"LABEL_1851\": 1851,\n",
      "    \"LABEL_1852\": 1852,\n",
      "    \"LABEL_1853\": 1853,\n",
      "    \"LABEL_1854\": 1854,\n",
      "    \"LABEL_1855\": 1855,\n",
      "    \"LABEL_1856\": 1856,\n",
      "    \"LABEL_1857\": 1857,\n",
      "    \"LABEL_1858\": 1858,\n",
      "    \"LABEL_1859\": 1859,\n",
      "    \"LABEL_186\": 186,\n",
      "    \"LABEL_1860\": 1860,\n",
      "    \"LABEL_1861\": 1861,\n",
      "    \"LABEL_1862\": 1862,\n",
      "    \"LABEL_1863\": 1863,\n",
      "    \"LABEL_1864\": 1864,\n",
      "    \"LABEL_1865\": 1865,\n",
      "    \"LABEL_1866\": 1866,\n",
      "    \"LABEL_1867\": 1867,\n",
      "    \"LABEL_1868\": 1868,\n",
      "    \"LABEL_1869\": 1869,\n",
      "    \"LABEL_187\": 187,\n",
      "    \"LABEL_1870\": 1870,\n",
      "    \"LABEL_1871\": 1871,\n",
      "    \"LABEL_1872\": 1872,\n",
      "    \"LABEL_1873\": 1873,\n",
      "    \"LABEL_1874\": 1874,\n",
      "    \"LABEL_1875\": 1875,\n",
      "    \"LABEL_1876\": 1876,\n",
      "    \"LABEL_1877\": 1877,\n",
      "    \"LABEL_1878\": 1878,\n",
      "    \"LABEL_1879\": 1879,\n",
      "    \"LABEL_188\": 188,\n",
      "    \"LABEL_1880\": 1880,\n",
      "    \"LABEL_1881\": 1881,\n",
      "    \"LABEL_1882\": 1882,\n",
      "    \"LABEL_1883\": 1883,\n",
      "    \"LABEL_1884\": 1884,\n",
      "    \"LABEL_1885\": 1885,\n",
      "    \"LABEL_1886\": 1886,\n",
      "    \"LABEL_1887\": 1887,\n",
      "    \"LABEL_1888\": 1888,\n",
      "    \"LABEL_1889\": 1889,\n",
      "    \"LABEL_189\": 189,\n",
      "    \"LABEL_1890\": 1890,\n",
      "    \"LABEL_1891\": 1891,\n",
      "    \"LABEL_1892\": 1892,\n",
      "    \"LABEL_1893\": 1893,\n",
      "    \"LABEL_1894\": 1894,\n",
      "    \"LABEL_1895\": 1895,\n",
      "    \"LABEL_1896\": 1896,\n",
      "    \"LABEL_1897\": 1897,\n",
      "    \"LABEL_1898\": 1898,\n",
      "    \"LABEL_1899\": 1899,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_190\": 190,\n",
      "    \"LABEL_1900\": 1900,\n",
      "    \"LABEL_1901\": 1901,\n",
      "    \"LABEL_1902\": 1902,\n",
      "    \"LABEL_1903\": 1903,\n",
      "    \"LABEL_1904\": 1904,\n",
      "    \"LABEL_1905\": 1905,\n",
      "    \"LABEL_1906\": 1906,\n",
      "    \"LABEL_1907\": 1907,\n",
      "    \"LABEL_1908\": 1908,\n",
      "    \"LABEL_1909\": 1909,\n",
      "    \"LABEL_191\": 191,\n",
      "    \"LABEL_1910\": 1910,\n",
      "    \"LABEL_1911\": 1911,\n",
      "    \"LABEL_1912\": 1912,\n",
      "    \"LABEL_1913\": 1913,\n",
      "    \"LABEL_1914\": 1914,\n",
      "    \"LABEL_1915\": 1915,\n",
      "    \"LABEL_1916\": 1916,\n",
      "    \"LABEL_1917\": 1917,\n",
      "    \"LABEL_1918\": 1918,\n",
      "    \"LABEL_1919\": 1919,\n",
      "    \"LABEL_192\": 192,\n",
      "    \"LABEL_1920\": 1920,\n",
      "    \"LABEL_1921\": 1921,\n",
      "    \"LABEL_1922\": 1922,\n",
      "    \"LABEL_1923\": 1923,\n",
      "    \"LABEL_1924\": 1924,\n",
      "    \"LABEL_1925\": 1925,\n",
      "    \"LABEL_1926\": 1926,\n",
      "    \"LABEL_1927\": 1927,\n",
      "    \"LABEL_1928\": 1928,\n",
      "    \"LABEL_1929\": 1929,\n",
      "    \"LABEL_193\": 193,\n",
      "    \"LABEL_1930\": 1930,\n",
      "    \"LABEL_1931\": 1931,\n",
      "    \"LABEL_1932\": 1932,\n",
      "    \"LABEL_1933\": 1933,\n",
      "    \"LABEL_1934\": 1934,\n",
      "    \"LABEL_1935\": 1935,\n",
      "    \"LABEL_1936\": 1936,\n",
      "    \"LABEL_1937\": 1937,\n",
      "    \"LABEL_1938\": 1938,\n",
      "    \"LABEL_1939\": 1939,\n",
      "    \"LABEL_194\": 194,\n",
      "    \"LABEL_1940\": 1940,\n",
      "    \"LABEL_1941\": 1941,\n",
      "    \"LABEL_1942\": 1942,\n",
      "    \"LABEL_1943\": 1943,\n",
      "    \"LABEL_1944\": 1944,\n",
      "    \"LABEL_1945\": 1945,\n",
      "    \"LABEL_1946\": 1946,\n",
      "    \"LABEL_1947\": 1947,\n",
      "    \"LABEL_1948\": 1948,\n",
      "    \"LABEL_1949\": 1949,\n",
      "    \"LABEL_195\": 195,\n",
      "    \"LABEL_1950\": 1950,\n",
      "    \"LABEL_1951\": 1951,\n",
      "    \"LABEL_1952\": 1952,\n",
      "    \"LABEL_1953\": 1953,\n",
      "    \"LABEL_1954\": 1954,\n",
      "    \"LABEL_1955\": 1955,\n",
      "    \"LABEL_1956\": 1956,\n",
      "    \"LABEL_1957\": 1957,\n",
      "    \"LABEL_1958\": 1958,\n",
      "    \"LABEL_1959\": 1959,\n",
      "    \"LABEL_196\": 196,\n",
      "    \"LABEL_1960\": 1960,\n",
      "    \"LABEL_1961\": 1961,\n",
      "    \"LABEL_1962\": 1962,\n",
      "    \"LABEL_1963\": 1963,\n",
      "    \"LABEL_1964\": 1964,\n",
      "    \"LABEL_1965\": 1965,\n",
      "    \"LABEL_1966\": 1966,\n",
      "    \"LABEL_1967\": 1967,\n",
      "    \"LABEL_1968\": 1968,\n",
      "    \"LABEL_1969\": 1969,\n",
      "    \"LABEL_197\": 197,\n",
      "    \"LABEL_1970\": 1970,\n",
      "    \"LABEL_1971\": 1971,\n",
      "    \"LABEL_1972\": 1972,\n",
      "    \"LABEL_1973\": 1973,\n",
      "    \"LABEL_1974\": 1974,\n",
      "    \"LABEL_1975\": 1975,\n",
      "    \"LABEL_1976\": 1976,\n",
      "    \"LABEL_1977\": 1977,\n",
      "    \"LABEL_1978\": 1978,\n",
      "    \"LABEL_1979\": 1979,\n",
      "    \"LABEL_198\": 198,\n",
      "    \"LABEL_1980\": 1980,\n",
      "    \"LABEL_1981\": 1981,\n",
      "    \"LABEL_1982\": 1982,\n",
      "    \"LABEL_1983\": 1983,\n",
      "    \"LABEL_1984\": 1984,\n",
      "    \"LABEL_1985\": 1985,\n",
      "    \"LABEL_1986\": 1986,\n",
      "    \"LABEL_1987\": 1987,\n",
      "    \"LABEL_1988\": 1988,\n",
      "    \"LABEL_1989\": 1989,\n",
      "    \"LABEL_199\": 199,\n",
      "    \"LABEL_1990\": 1990,\n",
      "    \"LABEL_1991\": 1991,\n",
      "    \"LABEL_1992\": 1992,\n",
      "    \"LABEL_1993\": 1993,\n",
      "    \"LABEL_1994\": 1994,\n",
      "    \"LABEL_1995\": 1995,\n",
      "    \"LABEL_1996\": 1996,\n",
      "    \"LABEL_1997\": 1997,\n",
      "    \"LABEL_1998\": 1998,\n",
      "    \"LABEL_1999\": 1999,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_200\": 200,\n",
      "    \"LABEL_2000\": 2000,\n",
      "    \"LABEL_2001\": 2001,\n",
      "    \"LABEL_2002\": 2002,\n",
      "    \"LABEL_2003\": 2003,\n",
      "    \"LABEL_2004\": 2004,\n",
      "    \"LABEL_2005\": 2005,\n",
      "    \"LABEL_2006\": 2006,\n",
      "    \"LABEL_2007\": 2007,\n",
      "    \"LABEL_2008\": 2008,\n",
      "    \"LABEL_2009\": 2009,\n",
      "    \"LABEL_201\": 201,\n",
      "    \"LABEL_2010\": 2010,\n",
      "    \"LABEL_2011\": 2011,\n",
      "    \"LABEL_2012\": 2012,\n",
      "    \"LABEL_2013\": 2013,\n",
      "    \"LABEL_2014\": 2014,\n",
      "    \"LABEL_2015\": 2015,\n",
      "    \"LABEL_2016\": 2016,\n",
      "    \"LABEL_2017\": 2017,\n",
      "    \"LABEL_2018\": 2018,\n",
      "    \"LABEL_2019\": 2019,\n",
      "    \"LABEL_202\": 202,\n",
      "    \"LABEL_2020\": 2020,\n",
      "    \"LABEL_2021\": 2021,\n",
      "    \"LABEL_2022\": 2022,\n",
      "    \"LABEL_2023\": 2023,\n",
      "    \"LABEL_2024\": 2024,\n",
      "    \"LABEL_2025\": 2025,\n",
      "    \"LABEL_2026\": 2026,\n",
      "    \"LABEL_2027\": 2027,\n",
      "    \"LABEL_2028\": 2028,\n",
      "    \"LABEL_2029\": 2029,\n",
      "    \"LABEL_203\": 203,\n",
      "    \"LABEL_2030\": 2030,\n",
      "    \"LABEL_2031\": 2031,\n",
      "    \"LABEL_2032\": 2032,\n",
      "    \"LABEL_2033\": 2033,\n",
      "    \"LABEL_2034\": 2034,\n",
      "    \"LABEL_2035\": 2035,\n",
      "    \"LABEL_2036\": 2036,\n",
      "    \"LABEL_2037\": 2037,\n",
      "    \"LABEL_2038\": 2038,\n",
      "    \"LABEL_2039\": 2039,\n",
      "    \"LABEL_204\": 204,\n",
      "    \"LABEL_2040\": 2040,\n",
      "    \"LABEL_2041\": 2041,\n",
      "    \"LABEL_2042\": 2042,\n",
      "    \"LABEL_2043\": 2043,\n",
      "    \"LABEL_2044\": 2044,\n",
      "    \"LABEL_2045\": 2045,\n",
      "    \"LABEL_2046\": 2046,\n",
      "    \"LABEL_2047\": 2047,\n",
      "    \"LABEL_2048\": 2048,\n",
      "    \"LABEL_2049\": 2049,\n",
      "    \"LABEL_205\": 205,\n",
      "    \"LABEL_2050\": 2050,\n",
      "    \"LABEL_2051\": 2051,\n",
      "    \"LABEL_2052\": 2052,\n",
      "    \"LABEL_2053\": 2053,\n",
      "    \"LABEL_2054\": 2054,\n",
      "    \"LABEL_2055\": 2055,\n",
      "    \"LABEL_2056\": 2056,\n",
      "    \"LABEL_2057\": 2057,\n",
      "    \"LABEL_2058\": 2058,\n",
      "    \"LABEL_2059\": 2059,\n",
      "    \"LABEL_206\": 206,\n",
      "    \"LABEL_2060\": 2060,\n",
      "    \"LABEL_2061\": 2061,\n",
      "    \"LABEL_2062\": 2062,\n",
      "    \"LABEL_2063\": 2063,\n",
      "    \"LABEL_2064\": 2064,\n",
      "    \"LABEL_2065\": 2065,\n",
      "    \"LABEL_2066\": 2066,\n",
      "    \"LABEL_2067\": 2067,\n",
      "    \"LABEL_2068\": 2068,\n",
      "    \"LABEL_2069\": 2069,\n",
      "    \"LABEL_207\": 207,\n",
      "    \"LABEL_2070\": 2070,\n",
      "    \"LABEL_2071\": 2071,\n",
      "    \"LABEL_2072\": 2072,\n",
      "    \"LABEL_2073\": 2073,\n",
      "    \"LABEL_2074\": 2074,\n",
      "    \"LABEL_2075\": 2075,\n",
      "    \"LABEL_2076\": 2076,\n",
      "    \"LABEL_2077\": 2077,\n",
      "    \"LABEL_2078\": 2078,\n",
      "    \"LABEL_2079\": 2079,\n",
      "    \"LABEL_208\": 208,\n",
      "    \"LABEL_2080\": 2080,\n",
      "    \"LABEL_2081\": 2081,\n",
      "    \"LABEL_2082\": 2082,\n",
      "    \"LABEL_2083\": 2083,\n",
      "    \"LABEL_2084\": 2084,\n",
      "    \"LABEL_2085\": 2085,\n",
      "    \"LABEL_2086\": 2086,\n",
      "    \"LABEL_2087\": 2087,\n",
      "    \"LABEL_2088\": 2088,\n",
      "    \"LABEL_2089\": 2089,\n",
      "    \"LABEL_209\": 209,\n",
      "    \"LABEL_2090\": 2090,\n",
      "    \"LABEL_2091\": 2091,\n",
      "    \"LABEL_2092\": 2092,\n",
      "    \"LABEL_2093\": 2093,\n",
      "    \"LABEL_2094\": 2094,\n",
      "    \"LABEL_2095\": 2095,\n",
      "    \"LABEL_2096\": 2096,\n",
      "    \"LABEL_2097\": 2097,\n",
      "    \"LABEL_2098\": 2098,\n",
      "    \"LABEL_2099\": 2099,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_210\": 210,\n",
      "    \"LABEL_2100\": 2100,\n",
      "    \"LABEL_2101\": 2101,\n",
      "    \"LABEL_2102\": 2102,\n",
      "    \"LABEL_2103\": 2103,\n",
      "    \"LABEL_2104\": 2104,\n",
      "    \"LABEL_2105\": 2105,\n",
      "    \"LABEL_2106\": 2106,\n",
      "    \"LABEL_2107\": 2107,\n",
      "    \"LABEL_2108\": 2108,\n",
      "    \"LABEL_2109\": 2109,\n",
      "    \"LABEL_211\": 211,\n",
      "    \"LABEL_2110\": 2110,\n",
      "    \"LABEL_2111\": 2111,\n",
      "    \"LABEL_2112\": 2112,\n",
      "    \"LABEL_2113\": 2113,\n",
      "    \"LABEL_2114\": 2114,\n",
      "    \"LABEL_2115\": 2115,\n",
      "    \"LABEL_2116\": 2116,\n",
      "    \"LABEL_2117\": 2117,\n",
      "    \"LABEL_2118\": 2118,\n",
      "    \"LABEL_2119\": 2119,\n",
      "    \"LABEL_212\": 212,\n",
      "    \"LABEL_2120\": 2120,\n",
      "    \"LABEL_2121\": 2121,\n",
      "    \"LABEL_2122\": 2122,\n",
      "    \"LABEL_2123\": 2123,\n",
      "    \"LABEL_2124\": 2124,\n",
      "    \"LABEL_2125\": 2125,\n",
      "    \"LABEL_2126\": 2126,\n",
      "    \"LABEL_2127\": 2127,\n",
      "    \"LABEL_2128\": 2128,\n",
      "    \"LABEL_2129\": 2129,\n",
      "    \"LABEL_213\": 213,\n",
      "    \"LABEL_2130\": 2130,\n",
      "    \"LABEL_2131\": 2131,\n",
      "    \"LABEL_2132\": 2132,\n",
      "    \"LABEL_2133\": 2133,\n",
      "    \"LABEL_2134\": 2134,\n",
      "    \"LABEL_2135\": 2135,\n",
      "    \"LABEL_2136\": 2136,\n",
      "    \"LABEL_2137\": 2137,\n",
      "    \"LABEL_2138\": 2138,\n",
      "    \"LABEL_2139\": 2139,\n",
      "    \"LABEL_214\": 214,\n",
      "    \"LABEL_2140\": 2140,\n",
      "    \"LABEL_2141\": 2141,\n",
      "    \"LABEL_2142\": 2142,\n",
      "    \"LABEL_2143\": 2143,\n",
      "    \"LABEL_2144\": 2144,\n",
      "    \"LABEL_2145\": 2145,\n",
      "    \"LABEL_2146\": 2146,\n",
      "    \"LABEL_2147\": 2147,\n",
      "    \"LABEL_2148\": 2148,\n",
      "    \"LABEL_2149\": 2149,\n",
      "    \"LABEL_215\": 215,\n",
      "    \"LABEL_2150\": 2150,\n",
      "    \"LABEL_2151\": 2151,\n",
      "    \"LABEL_2152\": 2152,\n",
      "    \"LABEL_2153\": 2153,\n",
      "    \"LABEL_2154\": 2154,\n",
      "    \"LABEL_2155\": 2155,\n",
      "    \"LABEL_2156\": 2156,\n",
      "    \"LABEL_2157\": 2157,\n",
      "    \"LABEL_2158\": 2158,\n",
      "    \"LABEL_2159\": 2159,\n",
      "    \"LABEL_216\": 216,\n",
      "    \"LABEL_2160\": 2160,\n",
      "    \"LABEL_2161\": 2161,\n",
      "    \"LABEL_2162\": 2162,\n",
      "    \"LABEL_2163\": 2163,\n",
      "    \"LABEL_2164\": 2164,\n",
      "    \"LABEL_2165\": 2165,\n",
      "    \"LABEL_2166\": 2166,\n",
      "    \"LABEL_2167\": 2167,\n",
      "    \"LABEL_2168\": 2168,\n",
      "    \"LABEL_2169\": 2169,\n",
      "    \"LABEL_217\": 217,\n",
      "    \"LABEL_2170\": 2170,\n",
      "    \"LABEL_2171\": 2171,\n",
      "    \"LABEL_2172\": 2172,\n",
      "    \"LABEL_2173\": 2173,\n",
      "    \"LABEL_2174\": 2174,\n",
      "    \"LABEL_2175\": 2175,\n",
      "    \"LABEL_2176\": 2176,\n",
      "    \"LABEL_2177\": 2177,\n",
      "    \"LABEL_2178\": 2178,\n",
      "    \"LABEL_2179\": 2179,\n",
      "    \"LABEL_218\": 218,\n",
      "    \"LABEL_2180\": 2180,\n",
      "    \"LABEL_2181\": 2181,\n",
      "    \"LABEL_2182\": 2182,\n",
      "    \"LABEL_2183\": 2183,\n",
      "    \"LABEL_2184\": 2184,\n",
      "    \"LABEL_2185\": 2185,\n",
      "    \"LABEL_2186\": 2186,\n",
      "    \"LABEL_2187\": 2187,\n",
      "    \"LABEL_2188\": 2188,\n",
      "    \"LABEL_2189\": 2189,\n",
      "    \"LABEL_219\": 219,\n",
      "    \"LABEL_2190\": 2190,\n",
      "    \"LABEL_2191\": 2191,\n",
      "    \"LABEL_2192\": 2192,\n",
      "    \"LABEL_2193\": 2193,\n",
      "    \"LABEL_2194\": 2194,\n",
      "    \"LABEL_2195\": 2195,\n",
      "    \"LABEL_2196\": 2196,\n",
      "    \"LABEL_2197\": 2197,\n",
      "    \"LABEL_2198\": 2198,\n",
      "    \"LABEL_2199\": 2199,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_220\": 220,\n",
      "    \"LABEL_2200\": 2200,\n",
      "    \"LABEL_2201\": 2201,\n",
      "    \"LABEL_2202\": 2202,\n",
      "    \"LABEL_2203\": 2203,\n",
      "    \"LABEL_2204\": 2204,\n",
      "    \"LABEL_2205\": 2205,\n",
      "    \"LABEL_2206\": 2206,\n",
      "    \"LABEL_2207\": 2207,\n",
      "    \"LABEL_2208\": 2208,\n",
      "    \"LABEL_2209\": 2209,\n",
      "    \"LABEL_221\": 221,\n",
      "    \"LABEL_2210\": 2210,\n",
      "    \"LABEL_2211\": 2211,\n",
      "    \"LABEL_2212\": 2212,\n",
      "    \"LABEL_2213\": 2213,\n",
      "    \"LABEL_2214\": 2214,\n",
      "    \"LABEL_2215\": 2215,\n",
      "    \"LABEL_2216\": 2216,\n",
      "    \"LABEL_2217\": 2217,\n",
      "    \"LABEL_2218\": 2218,\n",
      "    \"LABEL_2219\": 2219,\n",
      "    \"LABEL_222\": 222,\n",
      "    \"LABEL_2220\": 2220,\n",
      "    \"LABEL_2221\": 2221,\n",
      "    \"LABEL_2222\": 2222,\n",
      "    \"LABEL_2223\": 2223,\n",
      "    \"LABEL_2224\": 2224,\n",
      "    \"LABEL_2225\": 2225,\n",
      "    \"LABEL_2226\": 2226,\n",
      "    \"LABEL_2227\": 2227,\n",
      "    \"LABEL_2228\": 2228,\n",
      "    \"LABEL_2229\": 2229,\n",
      "    \"LABEL_223\": 223,\n",
      "    \"LABEL_2230\": 2230,\n",
      "    \"LABEL_2231\": 2231,\n",
      "    \"LABEL_2232\": 2232,\n",
      "    \"LABEL_2233\": 2233,\n",
      "    \"LABEL_2234\": 2234,\n",
      "    \"LABEL_2235\": 2235,\n",
      "    \"LABEL_2236\": 2236,\n",
      "    \"LABEL_2237\": 2237,\n",
      "    \"LABEL_2238\": 2238,\n",
      "    \"LABEL_2239\": 2239,\n",
      "    \"LABEL_224\": 224,\n",
      "    \"LABEL_2240\": 2240,\n",
      "    \"LABEL_2241\": 2241,\n",
      "    \"LABEL_2242\": 2242,\n",
      "    \"LABEL_2243\": 2243,\n",
      "    \"LABEL_2244\": 2244,\n",
      "    \"LABEL_2245\": 2245,\n",
      "    \"LABEL_2246\": 2246,\n",
      "    \"LABEL_2247\": 2247,\n",
      "    \"LABEL_2248\": 2248,\n",
      "    \"LABEL_2249\": 2249,\n",
      "    \"LABEL_225\": 225,\n",
      "    \"LABEL_2250\": 2250,\n",
      "    \"LABEL_2251\": 2251,\n",
      "    \"LABEL_2252\": 2252,\n",
      "    \"LABEL_2253\": 2253,\n",
      "    \"LABEL_2254\": 2254,\n",
      "    \"LABEL_2255\": 2255,\n",
      "    \"LABEL_2256\": 2256,\n",
      "    \"LABEL_2257\": 2257,\n",
      "    \"LABEL_2258\": 2258,\n",
      "    \"LABEL_2259\": 2259,\n",
      "    \"LABEL_226\": 226,\n",
      "    \"LABEL_2260\": 2260,\n",
      "    \"LABEL_2261\": 2261,\n",
      "    \"LABEL_2262\": 2262,\n",
      "    \"LABEL_2263\": 2263,\n",
      "    \"LABEL_2264\": 2264,\n",
      "    \"LABEL_2265\": 2265,\n",
      "    \"LABEL_2266\": 2266,\n",
      "    \"LABEL_2267\": 2267,\n",
      "    \"LABEL_2268\": 2268,\n",
      "    \"LABEL_2269\": 2269,\n",
      "    \"LABEL_227\": 227,\n",
      "    \"LABEL_2270\": 2270,\n",
      "    \"LABEL_2271\": 2271,\n",
      "    \"LABEL_2272\": 2272,\n",
      "    \"LABEL_2273\": 2273,\n",
      "    \"LABEL_2274\": 2274,\n",
      "    \"LABEL_2275\": 2275,\n",
      "    \"LABEL_2276\": 2276,\n",
      "    \"LABEL_2277\": 2277,\n",
      "    \"LABEL_2278\": 2278,\n",
      "    \"LABEL_2279\": 2279,\n",
      "    \"LABEL_228\": 228,\n",
      "    \"LABEL_2280\": 2280,\n",
      "    \"LABEL_2281\": 2281,\n",
      "    \"LABEL_2282\": 2282,\n",
      "    \"LABEL_2283\": 2283,\n",
      "    \"LABEL_2284\": 2284,\n",
      "    \"LABEL_2285\": 2285,\n",
      "    \"LABEL_2286\": 2286,\n",
      "    \"LABEL_2287\": 2287,\n",
      "    \"LABEL_2288\": 2288,\n",
      "    \"LABEL_2289\": 2289,\n",
      "    \"LABEL_229\": 229,\n",
      "    \"LABEL_2290\": 2290,\n",
      "    \"LABEL_2291\": 2291,\n",
      "    \"LABEL_2292\": 2292,\n",
      "    \"LABEL_2293\": 2293,\n",
      "    \"LABEL_2294\": 2294,\n",
      "    \"LABEL_2295\": 2295,\n",
      "    \"LABEL_2296\": 2296,\n",
      "    \"LABEL_2297\": 2297,\n",
      "    \"LABEL_2298\": 2298,\n",
      "    \"LABEL_2299\": 2299,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_230\": 230,\n",
      "    \"LABEL_2300\": 2300,\n",
      "    \"LABEL_2301\": 2301,\n",
      "    \"LABEL_2302\": 2302,\n",
      "    \"LABEL_2303\": 2303,\n",
      "    \"LABEL_2304\": 2304,\n",
      "    \"LABEL_2305\": 2305,\n",
      "    \"LABEL_2306\": 2306,\n",
      "    \"LABEL_2307\": 2307,\n",
      "    \"LABEL_2308\": 2308,\n",
      "    \"LABEL_2309\": 2309,\n",
      "    \"LABEL_231\": 231,\n",
      "    \"LABEL_2310\": 2310,\n",
      "    \"LABEL_2311\": 2311,\n",
      "    \"LABEL_2312\": 2312,\n",
      "    \"LABEL_2313\": 2313,\n",
      "    \"LABEL_2314\": 2314,\n",
      "    \"LABEL_2315\": 2315,\n",
      "    \"LABEL_2316\": 2316,\n",
      "    \"LABEL_2317\": 2317,\n",
      "    \"LABEL_2318\": 2318,\n",
      "    \"LABEL_2319\": 2319,\n",
      "    \"LABEL_232\": 232,\n",
      "    \"LABEL_2320\": 2320,\n",
      "    \"LABEL_2321\": 2321,\n",
      "    \"LABEL_2322\": 2322,\n",
      "    \"LABEL_2323\": 2323,\n",
      "    \"LABEL_2324\": 2324,\n",
      "    \"LABEL_2325\": 2325,\n",
      "    \"LABEL_2326\": 2326,\n",
      "    \"LABEL_2327\": 2327,\n",
      "    \"LABEL_2328\": 2328,\n",
      "    \"LABEL_2329\": 2329,\n",
      "    \"LABEL_233\": 233,\n",
      "    \"LABEL_2330\": 2330,\n",
      "    \"LABEL_2331\": 2331,\n",
      "    \"LABEL_2332\": 2332,\n",
      "    \"LABEL_2333\": 2333,\n",
      "    \"LABEL_2334\": 2334,\n",
      "    \"LABEL_2335\": 2335,\n",
      "    \"LABEL_2336\": 2336,\n",
      "    \"LABEL_2337\": 2337,\n",
      "    \"LABEL_2338\": 2338,\n",
      "    \"LABEL_2339\": 2339,\n",
      "    \"LABEL_234\": 234,\n",
      "    \"LABEL_2340\": 2340,\n",
      "    \"LABEL_235\": 235,\n",
      "    \"LABEL_236\": 236,\n",
      "    \"LABEL_237\": 237,\n",
      "    \"LABEL_238\": 238,\n",
      "    \"LABEL_239\": 239,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_240\": 240,\n",
      "    \"LABEL_241\": 241,\n",
      "    \"LABEL_242\": 242,\n",
      "    \"LABEL_243\": 243,\n",
      "    \"LABEL_244\": 244,\n",
      "    \"LABEL_245\": 245,\n",
      "    \"LABEL_246\": 246,\n",
      "    \"LABEL_247\": 247,\n",
      "    \"LABEL_248\": 248,\n",
      "    \"LABEL_249\": 249,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_250\": 250,\n",
      "    \"LABEL_251\": 251,\n",
      "    \"LABEL_252\": 252,\n",
      "    \"LABEL_253\": 253,\n",
      "    \"LABEL_254\": 254,\n",
      "    \"LABEL_255\": 255,\n",
      "    \"LABEL_256\": 256,\n",
      "    \"LABEL_257\": 257,\n",
      "    \"LABEL_258\": 258,\n",
      "    \"LABEL_259\": 259,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_260\": 260,\n",
      "    \"LABEL_261\": 261,\n",
      "    \"LABEL_262\": 262,\n",
      "    \"LABEL_263\": 263,\n",
      "    \"LABEL_264\": 264,\n",
      "    \"LABEL_265\": 265,\n",
      "    \"LABEL_266\": 266,\n",
      "    \"LABEL_267\": 267,\n",
      "    \"LABEL_268\": 268,\n",
      "    \"LABEL_269\": 269,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_270\": 270,\n",
      "    \"LABEL_271\": 271,\n",
      "    \"LABEL_272\": 272,\n",
      "    \"LABEL_273\": 273,\n",
      "    \"LABEL_274\": 274,\n",
      "    \"LABEL_275\": 275,\n",
      "    \"LABEL_276\": 276,\n",
      "    \"LABEL_277\": 277,\n",
      "    \"LABEL_278\": 278,\n",
      "    \"LABEL_279\": 279,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_280\": 280,\n",
      "    \"LABEL_281\": 281,\n",
      "    \"LABEL_282\": 282,\n",
      "    \"LABEL_283\": 283,\n",
      "    \"LABEL_284\": 284,\n",
      "    \"LABEL_285\": 285,\n",
      "    \"LABEL_286\": 286,\n",
      "    \"LABEL_287\": 287,\n",
      "    \"LABEL_288\": 288,\n",
      "    \"LABEL_289\": 289,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_290\": 290,\n",
      "    \"LABEL_291\": 291,\n",
      "    \"LABEL_292\": 292,\n",
      "    \"LABEL_293\": 293,\n",
      "    \"LABEL_294\": 294,\n",
      "    \"LABEL_295\": 295,\n",
      "    \"LABEL_296\": 296,\n",
      "    \"LABEL_297\": 297,\n",
      "    \"LABEL_298\": 298,\n",
      "    \"LABEL_299\": 299,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_300\": 300,\n",
      "    \"LABEL_301\": 301,\n",
      "    \"LABEL_302\": 302,\n",
      "    \"LABEL_303\": 303,\n",
      "    \"LABEL_304\": 304,\n",
      "    \"LABEL_305\": 305,\n",
      "    \"LABEL_306\": 306,\n",
      "    \"LABEL_307\": 307,\n",
      "    \"LABEL_308\": 308,\n",
      "    \"LABEL_309\": 309,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_310\": 310,\n",
      "    \"LABEL_311\": 311,\n",
      "    \"LABEL_312\": 312,\n",
      "    \"LABEL_313\": 313,\n",
      "    \"LABEL_314\": 314,\n",
      "    \"LABEL_315\": 315,\n",
      "    \"LABEL_316\": 316,\n",
      "    \"LABEL_317\": 317,\n",
      "    \"LABEL_318\": 318,\n",
      "    \"LABEL_319\": 319,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_320\": 320,\n",
      "    \"LABEL_321\": 321,\n",
      "    \"LABEL_322\": 322,\n",
      "    \"LABEL_323\": 323,\n",
      "    \"LABEL_324\": 324,\n",
      "    \"LABEL_325\": 325,\n",
      "    \"LABEL_326\": 326,\n",
      "    \"LABEL_327\": 327,\n",
      "    \"LABEL_328\": 328,\n",
      "    \"LABEL_329\": 329,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_330\": 330,\n",
      "    \"LABEL_331\": 331,\n",
      "    \"LABEL_332\": 332,\n",
      "    \"LABEL_333\": 333,\n",
      "    \"LABEL_334\": 334,\n",
      "    \"LABEL_335\": 335,\n",
      "    \"LABEL_336\": 336,\n",
      "    \"LABEL_337\": 337,\n",
      "    \"LABEL_338\": 338,\n",
      "    \"LABEL_339\": 339,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_340\": 340,\n",
      "    \"LABEL_341\": 341,\n",
      "    \"LABEL_342\": 342,\n",
      "    \"LABEL_343\": 343,\n",
      "    \"LABEL_344\": 344,\n",
      "    \"LABEL_345\": 345,\n",
      "    \"LABEL_346\": 346,\n",
      "    \"LABEL_347\": 347,\n",
      "    \"LABEL_348\": 348,\n",
      "    \"LABEL_349\": 349,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_350\": 350,\n",
      "    \"LABEL_351\": 351,\n",
      "    \"LABEL_352\": 352,\n",
      "    \"LABEL_353\": 353,\n",
      "    \"LABEL_354\": 354,\n",
      "    \"LABEL_355\": 355,\n",
      "    \"LABEL_356\": 356,\n",
      "    \"LABEL_357\": 357,\n",
      "    \"LABEL_358\": 358,\n",
      "    \"LABEL_359\": 359,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_360\": 360,\n",
      "    \"LABEL_361\": 361,\n",
      "    \"LABEL_362\": 362,\n",
      "    \"LABEL_363\": 363,\n",
      "    \"LABEL_364\": 364,\n",
      "    \"LABEL_365\": 365,\n",
      "    \"LABEL_366\": 366,\n",
      "    \"LABEL_367\": 367,\n",
      "    \"LABEL_368\": 368,\n",
      "    \"LABEL_369\": 369,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_370\": 370,\n",
      "    \"LABEL_371\": 371,\n",
      "    \"LABEL_372\": 372,\n",
      "    \"LABEL_373\": 373,\n",
      "    \"LABEL_374\": 374,\n",
      "    \"LABEL_375\": 375,\n",
      "    \"LABEL_376\": 376,\n",
      "    \"LABEL_377\": 377,\n",
      "    \"LABEL_378\": 378,\n",
      "    \"LABEL_379\": 379,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_380\": 380,\n",
      "    \"LABEL_381\": 381,\n",
      "    \"LABEL_382\": 382,\n",
      "    \"LABEL_383\": 383,\n",
      "    \"LABEL_384\": 384,\n",
      "    \"LABEL_385\": 385,\n",
      "    \"LABEL_386\": 386,\n",
      "    \"LABEL_387\": 387,\n",
      "    \"LABEL_388\": 388,\n",
      "    \"LABEL_389\": 389,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_390\": 390,\n",
      "    \"LABEL_391\": 391,\n",
      "    \"LABEL_392\": 392,\n",
      "    \"LABEL_393\": 393,\n",
      "    \"LABEL_394\": 394,\n",
      "    \"LABEL_395\": 395,\n",
      "    \"LABEL_396\": 396,\n",
      "    \"LABEL_397\": 397,\n",
      "    \"LABEL_398\": 398,\n",
      "    \"LABEL_399\": 399,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_400\": 400,\n",
      "    \"LABEL_401\": 401,\n",
      "    \"LABEL_402\": 402,\n",
      "    \"LABEL_403\": 403,\n",
      "    \"LABEL_404\": 404,\n",
      "    \"LABEL_405\": 405,\n",
      "    \"LABEL_406\": 406,\n",
      "    \"LABEL_407\": 407,\n",
      "    \"LABEL_408\": 408,\n",
      "    \"LABEL_409\": 409,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_410\": 410,\n",
      "    \"LABEL_411\": 411,\n",
      "    \"LABEL_412\": 412,\n",
      "    \"LABEL_413\": 413,\n",
      "    \"LABEL_414\": 414,\n",
      "    \"LABEL_415\": 415,\n",
      "    \"LABEL_416\": 416,\n",
      "    \"LABEL_417\": 417,\n",
      "    \"LABEL_418\": 418,\n",
      "    \"LABEL_419\": 419,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_420\": 420,\n",
      "    \"LABEL_421\": 421,\n",
      "    \"LABEL_422\": 422,\n",
      "    \"LABEL_423\": 423,\n",
      "    \"LABEL_424\": 424,\n",
      "    \"LABEL_425\": 425,\n",
      "    \"LABEL_426\": 426,\n",
      "    \"LABEL_427\": 427,\n",
      "    \"LABEL_428\": 428,\n",
      "    \"LABEL_429\": 429,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_430\": 430,\n",
      "    \"LABEL_431\": 431,\n",
      "    \"LABEL_432\": 432,\n",
      "    \"LABEL_433\": 433,\n",
      "    \"LABEL_434\": 434,\n",
      "    \"LABEL_435\": 435,\n",
      "    \"LABEL_436\": 436,\n",
      "    \"LABEL_437\": 437,\n",
      "    \"LABEL_438\": 438,\n",
      "    \"LABEL_439\": 439,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_440\": 440,\n",
      "    \"LABEL_441\": 441,\n",
      "    \"LABEL_442\": 442,\n",
      "    \"LABEL_443\": 443,\n",
      "    \"LABEL_444\": 444,\n",
      "    \"LABEL_445\": 445,\n",
      "    \"LABEL_446\": 446,\n",
      "    \"LABEL_447\": 447,\n",
      "    \"LABEL_448\": 448,\n",
      "    \"LABEL_449\": 449,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_450\": 450,\n",
      "    \"LABEL_451\": 451,\n",
      "    \"LABEL_452\": 452,\n",
      "    \"LABEL_453\": 453,\n",
      "    \"LABEL_454\": 454,\n",
      "    \"LABEL_455\": 455,\n",
      "    \"LABEL_456\": 456,\n",
      "    \"LABEL_457\": 457,\n",
      "    \"LABEL_458\": 458,\n",
      "    \"LABEL_459\": 459,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_460\": 460,\n",
      "    \"LABEL_461\": 461,\n",
      "    \"LABEL_462\": 462,\n",
      "    \"LABEL_463\": 463,\n",
      "    \"LABEL_464\": 464,\n",
      "    \"LABEL_465\": 465,\n",
      "    \"LABEL_466\": 466,\n",
      "    \"LABEL_467\": 467,\n",
      "    \"LABEL_468\": 468,\n",
      "    \"LABEL_469\": 469,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_470\": 470,\n",
      "    \"LABEL_471\": 471,\n",
      "    \"LABEL_472\": 472,\n",
      "    \"LABEL_473\": 473,\n",
      "    \"LABEL_474\": 474,\n",
      "    \"LABEL_475\": 475,\n",
      "    \"LABEL_476\": 476,\n",
      "    \"LABEL_477\": 477,\n",
      "    \"LABEL_478\": 478,\n",
      "    \"LABEL_479\": 479,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_480\": 480,\n",
      "    \"LABEL_481\": 481,\n",
      "    \"LABEL_482\": 482,\n",
      "    \"LABEL_483\": 483,\n",
      "    \"LABEL_484\": 484,\n",
      "    \"LABEL_485\": 485,\n",
      "    \"LABEL_486\": 486,\n",
      "    \"LABEL_487\": 487,\n",
      "    \"LABEL_488\": 488,\n",
      "    \"LABEL_489\": 489,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_490\": 490,\n",
      "    \"LABEL_491\": 491,\n",
      "    \"LABEL_492\": 492,\n",
      "    \"LABEL_493\": 493,\n",
      "    \"LABEL_494\": 494,\n",
      "    \"LABEL_495\": 495,\n",
      "    \"LABEL_496\": 496,\n",
      "    \"LABEL_497\": 497,\n",
      "    \"LABEL_498\": 498,\n",
      "    \"LABEL_499\": 499,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_500\": 500,\n",
      "    \"LABEL_501\": 501,\n",
      "    \"LABEL_502\": 502,\n",
      "    \"LABEL_503\": 503,\n",
      "    \"LABEL_504\": 504,\n",
      "    \"LABEL_505\": 505,\n",
      "    \"LABEL_506\": 506,\n",
      "    \"LABEL_507\": 507,\n",
      "    \"LABEL_508\": 508,\n",
      "    \"LABEL_509\": 509,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_510\": 510,\n",
      "    \"LABEL_511\": 511,\n",
      "    \"LABEL_512\": 512,\n",
      "    \"LABEL_513\": 513,\n",
      "    \"LABEL_514\": 514,\n",
      "    \"LABEL_515\": 515,\n",
      "    \"LABEL_516\": 516,\n",
      "    \"LABEL_517\": 517,\n",
      "    \"LABEL_518\": 518,\n",
      "    \"LABEL_519\": 519,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_520\": 520,\n",
      "    \"LABEL_521\": 521,\n",
      "    \"LABEL_522\": 522,\n",
      "    \"LABEL_523\": 523,\n",
      "    \"LABEL_524\": 524,\n",
      "    \"LABEL_525\": 525,\n",
      "    \"LABEL_526\": 526,\n",
      "    \"LABEL_527\": 527,\n",
      "    \"LABEL_528\": 528,\n",
      "    \"LABEL_529\": 529,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_530\": 530,\n",
      "    \"LABEL_531\": 531,\n",
      "    \"LABEL_532\": 532,\n",
      "    \"LABEL_533\": 533,\n",
      "    \"LABEL_534\": 534,\n",
      "    \"LABEL_535\": 535,\n",
      "    \"LABEL_536\": 536,\n",
      "    \"LABEL_537\": 537,\n",
      "    \"LABEL_538\": 538,\n",
      "    \"LABEL_539\": 539,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_540\": 540,\n",
      "    \"LABEL_541\": 541,\n",
      "    \"LABEL_542\": 542,\n",
      "    \"LABEL_543\": 543,\n",
      "    \"LABEL_544\": 544,\n",
      "    \"LABEL_545\": 545,\n",
      "    \"LABEL_546\": 546,\n",
      "    \"LABEL_547\": 547,\n",
      "    \"LABEL_548\": 548,\n",
      "    \"LABEL_549\": 549,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_550\": 550,\n",
      "    \"LABEL_551\": 551,\n",
      "    \"LABEL_552\": 552,\n",
      "    \"LABEL_553\": 553,\n",
      "    \"LABEL_554\": 554,\n",
      "    \"LABEL_555\": 555,\n",
      "    \"LABEL_556\": 556,\n",
      "    \"LABEL_557\": 557,\n",
      "    \"LABEL_558\": 558,\n",
      "    \"LABEL_559\": 559,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_560\": 560,\n",
      "    \"LABEL_561\": 561,\n",
      "    \"LABEL_562\": 562,\n",
      "    \"LABEL_563\": 563,\n",
      "    \"LABEL_564\": 564,\n",
      "    \"LABEL_565\": 565,\n",
      "    \"LABEL_566\": 566,\n",
      "    \"LABEL_567\": 567,\n",
      "    \"LABEL_568\": 568,\n",
      "    \"LABEL_569\": 569,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_570\": 570,\n",
      "    \"LABEL_571\": 571,\n",
      "    \"LABEL_572\": 572,\n",
      "    \"LABEL_573\": 573,\n",
      "    \"LABEL_574\": 574,\n",
      "    \"LABEL_575\": 575,\n",
      "    \"LABEL_576\": 576,\n",
      "    \"LABEL_577\": 577,\n",
      "    \"LABEL_578\": 578,\n",
      "    \"LABEL_579\": 579,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_580\": 580,\n",
      "    \"LABEL_581\": 581,\n",
      "    \"LABEL_582\": 582,\n",
      "    \"LABEL_583\": 583,\n",
      "    \"LABEL_584\": 584,\n",
      "    \"LABEL_585\": 585,\n",
      "    \"LABEL_586\": 586,\n",
      "    \"LABEL_587\": 587,\n",
      "    \"LABEL_588\": 588,\n",
      "    \"LABEL_589\": 589,\n",
      "    \"LABEL_59\": 59,\n",
      "    \"LABEL_590\": 590,\n",
      "    \"LABEL_591\": 591,\n",
      "    \"LABEL_592\": 592,\n",
      "    \"LABEL_593\": 593,\n",
      "    \"LABEL_594\": 594,\n",
      "    \"LABEL_595\": 595,\n",
      "    \"LABEL_596\": 596,\n",
      "    \"LABEL_597\": 597,\n",
      "    \"LABEL_598\": 598,\n",
      "    \"LABEL_599\": 599,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_60\": 60,\n",
      "    \"LABEL_600\": 600,\n",
      "    \"LABEL_601\": 601,\n",
      "    \"LABEL_602\": 602,\n",
      "    \"LABEL_603\": 603,\n",
      "    \"LABEL_604\": 604,\n",
      "    \"LABEL_605\": 605,\n",
      "    \"LABEL_606\": 606,\n",
      "    \"LABEL_607\": 607,\n",
      "    \"LABEL_608\": 608,\n",
      "    \"LABEL_609\": 609,\n",
      "    \"LABEL_61\": 61,\n",
      "    \"LABEL_610\": 610,\n",
      "    \"LABEL_611\": 611,\n",
      "    \"LABEL_612\": 612,\n",
      "    \"LABEL_613\": 613,\n",
      "    \"LABEL_614\": 614,\n",
      "    \"LABEL_615\": 615,\n",
      "    \"LABEL_616\": 616,\n",
      "    \"LABEL_617\": 617,\n",
      "    \"LABEL_618\": 618,\n",
      "    \"LABEL_619\": 619,\n",
      "    \"LABEL_62\": 62,\n",
      "    \"LABEL_620\": 620,\n",
      "    \"LABEL_621\": 621,\n",
      "    \"LABEL_622\": 622,\n",
      "    \"LABEL_623\": 623,\n",
      "    \"LABEL_624\": 624,\n",
      "    \"LABEL_625\": 625,\n",
      "    \"LABEL_626\": 626,\n",
      "    \"LABEL_627\": 627,\n",
      "    \"LABEL_628\": 628,\n",
      "    \"LABEL_629\": 629,\n",
      "    \"LABEL_63\": 63,\n",
      "    \"LABEL_630\": 630,\n",
      "    \"LABEL_631\": 631,\n",
      "    \"LABEL_632\": 632,\n",
      "    \"LABEL_633\": 633,\n",
      "    \"LABEL_634\": 634,\n",
      "    \"LABEL_635\": 635,\n",
      "    \"LABEL_636\": 636,\n",
      "    \"LABEL_637\": 637,\n",
      "    \"LABEL_638\": 638,\n",
      "    \"LABEL_639\": 639,\n",
      "    \"LABEL_64\": 64,\n",
      "    \"LABEL_640\": 640,\n",
      "    \"LABEL_641\": 641,\n",
      "    \"LABEL_642\": 642,\n",
      "    \"LABEL_643\": 643,\n",
      "    \"LABEL_644\": 644,\n",
      "    \"LABEL_645\": 645,\n",
      "    \"LABEL_646\": 646,\n",
      "    \"LABEL_647\": 647,\n",
      "    \"LABEL_648\": 648,\n",
      "    \"LABEL_649\": 649,\n",
      "    \"LABEL_65\": 65,\n",
      "    \"LABEL_650\": 650,\n",
      "    \"LABEL_651\": 651,\n",
      "    \"LABEL_652\": 652,\n",
      "    \"LABEL_653\": 653,\n",
      "    \"LABEL_654\": 654,\n",
      "    \"LABEL_655\": 655,\n",
      "    \"LABEL_656\": 656,\n",
      "    \"LABEL_657\": 657,\n",
      "    \"LABEL_658\": 658,\n",
      "    \"LABEL_659\": 659,\n",
      "    \"LABEL_66\": 66,\n",
      "    \"LABEL_660\": 660,\n",
      "    \"LABEL_661\": 661,\n",
      "    \"LABEL_662\": 662,\n",
      "    \"LABEL_663\": 663,\n",
      "    \"LABEL_664\": 664,\n",
      "    \"LABEL_665\": 665,\n",
      "    \"LABEL_666\": 666,\n",
      "    \"LABEL_667\": 667,\n",
      "    \"LABEL_668\": 668,\n",
      "    \"LABEL_669\": 669,\n",
      "    \"LABEL_67\": 67,\n",
      "    \"LABEL_670\": 670,\n",
      "    \"LABEL_671\": 671,\n",
      "    \"LABEL_672\": 672,\n",
      "    \"LABEL_673\": 673,\n",
      "    \"LABEL_674\": 674,\n",
      "    \"LABEL_675\": 675,\n",
      "    \"LABEL_676\": 676,\n",
      "    \"LABEL_677\": 677,\n",
      "    \"LABEL_678\": 678,\n",
      "    \"LABEL_679\": 679,\n",
      "    \"LABEL_68\": 68,\n",
      "    \"LABEL_680\": 680,\n",
      "    \"LABEL_681\": 681,\n",
      "    \"LABEL_682\": 682,\n",
      "    \"LABEL_683\": 683,\n",
      "    \"LABEL_684\": 684,\n",
      "    \"LABEL_685\": 685,\n",
      "    \"LABEL_686\": 686,\n",
      "    \"LABEL_687\": 687,\n",
      "    \"LABEL_688\": 688,\n",
      "    \"LABEL_689\": 689,\n",
      "    \"LABEL_69\": 69,\n",
      "    \"LABEL_690\": 690,\n",
      "    \"LABEL_691\": 691,\n",
      "    \"LABEL_692\": 692,\n",
      "    \"LABEL_693\": 693,\n",
      "    \"LABEL_694\": 694,\n",
      "    \"LABEL_695\": 695,\n",
      "    \"LABEL_696\": 696,\n",
      "    \"LABEL_697\": 697,\n",
      "    \"LABEL_698\": 698,\n",
      "    \"LABEL_699\": 699,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_70\": 70,\n",
      "    \"LABEL_700\": 700,\n",
      "    \"LABEL_701\": 701,\n",
      "    \"LABEL_702\": 702,\n",
      "    \"LABEL_703\": 703,\n",
      "    \"LABEL_704\": 704,\n",
      "    \"LABEL_705\": 705,\n",
      "    \"LABEL_706\": 706,\n",
      "    \"LABEL_707\": 707,\n",
      "    \"LABEL_708\": 708,\n",
      "    \"LABEL_709\": 709,\n",
      "    \"LABEL_71\": 71,\n",
      "    \"LABEL_710\": 710,\n",
      "    \"LABEL_711\": 711,\n",
      "    \"LABEL_712\": 712,\n",
      "    \"LABEL_713\": 713,\n",
      "    \"LABEL_714\": 714,\n",
      "    \"LABEL_715\": 715,\n",
      "    \"LABEL_716\": 716,\n",
      "    \"LABEL_717\": 717,\n",
      "    \"LABEL_718\": 718,\n",
      "    \"LABEL_719\": 719,\n",
      "    \"LABEL_72\": 72,\n",
      "    \"LABEL_720\": 720,\n",
      "    \"LABEL_721\": 721,\n",
      "    \"LABEL_722\": 722,\n",
      "    \"LABEL_723\": 723,\n",
      "    \"LABEL_724\": 724,\n",
      "    \"LABEL_725\": 725,\n",
      "    \"LABEL_726\": 726,\n",
      "    \"LABEL_727\": 727,\n",
      "    \"LABEL_728\": 728,\n",
      "    \"LABEL_729\": 729,\n",
      "    \"LABEL_73\": 73,\n",
      "    \"LABEL_730\": 730,\n",
      "    \"LABEL_731\": 731,\n",
      "    \"LABEL_732\": 732,\n",
      "    \"LABEL_733\": 733,\n",
      "    \"LABEL_734\": 734,\n",
      "    \"LABEL_735\": 735,\n",
      "    \"LABEL_736\": 736,\n",
      "    \"LABEL_737\": 737,\n",
      "    \"LABEL_738\": 738,\n",
      "    \"LABEL_739\": 739,\n",
      "    \"LABEL_74\": 74,\n",
      "    \"LABEL_740\": 740,\n",
      "    \"LABEL_741\": 741,\n",
      "    \"LABEL_742\": 742,\n",
      "    \"LABEL_743\": 743,\n",
      "    \"LABEL_744\": 744,\n",
      "    \"LABEL_745\": 745,\n",
      "    \"LABEL_746\": 746,\n",
      "    \"LABEL_747\": 747,\n",
      "    \"LABEL_748\": 748,\n",
      "    \"LABEL_749\": 749,\n",
      "    \"LABEL_75\": 75,\n",
      "    \"LABEL_750\": 750,\n",
      "    \"LABEL_751\": 751,\n",
      "    \"LABEL_752\": 752,\n",
      "    \"LABEL_753\": 753,\n",
      "    \"LABEL_754\": 754,\n",
      "    \"LABEL_755\": 755,\n",
      "    \"LABEL_756\": 756,\n",
      "    \"LABEL_757\": 757,\n",
      "    \"LABEL_758\": 758,\n",
      "    \"LABEL_759\": 759,\n",
      "    \"LABEL_76\": 76,\n",
      "    \"LABEL_760\": 760,\n",
      "    \"LABEL_761\": 761,\n",
      "    \"LABEL_762\": 762,\n",
      "    \"LABEL_763\": 763,\n",
      "    \"LABEL_764\": 764,\n",
      "    \"LABEL_765\": 765,\n",
      "    \"LABEL_766\": 766,\n",
      "    \"LABEL_767\": 767,\n",
      "    \"LABEL_768\": 768,\n",
      "    \"LABEL_769\": 769,\n",
      "    \"LABEL_77\": 77,\n",
      "    \"LABEL_770\": 770,\n",
      "    \"LABEL_771\": 771,\n",
      "    \"LABEL_772\": 772,\n",
      "    \"LABEL_773\": 773,\n",
      "    \"LABEL_774\": 774,\n",
      "    \"LABEL_775\": 775,\n",
      "    \"LABEL_776\": 776,\n",
      "    \"LABEL_777\": 777,\n",
      "    \"LABEL_778\": 778,\n",
      "    \"LABEL_779\": 779,\n",
      "    \"LABEL_78\": 78,\n",
      "    \"LABEL_780\": 780,\n",
      "    \"LABEL_781\": 781,\n",
      "    \"LABEL_782\": 782,\n",
      "    \"LABEL_783\": 783,\n",
      "    \"LABEL_784\": 784,\n",
      "    \"LABEL_785\": 785,\n",
      "    \"LABEL_786\": 786,\n",
      "    \"LABEL_787\": 787,\n",
      "    \"LABEL_788\": 788,\n",
      "    \"LABEL_789\": 789,\n",
      "    \"LABEL_79\": 79,\n",
      "    \"LABEL_790\": 790,\n",
      "    \"LABEL_791\": 791,\n",
      "    \"LABEL_792\": 792,\n",
      "    \"LABEL_793\": 793,\n",
      "    \"LABEL_794\": 794,\n",
      "    \"LABEL_795\": 795,\n",
      "    \"LABEL_796\": 796,\n",
      "    \"LABEL_797\": 797,\n",
      "    \"LABEL_798\": 798,\n",
      "    \"LABEL_799\": 799,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_80\": 80,\n",
      "    \"LABEL_800\": 800,\n",
      "    \"LABEL_801\": 801,\n",
      "    \"LABEL_802\": 802,\n",
      "    \"LABEL_803\": 803,\n",
      "    \"LABEL_804\": 804,\n",
      "    \"LABEL_805\": 805,\n",
      "    \"LABEL_806\": 806,\n",
      "    \"LABEL_807\": 807,\n",
      "    \"LABEL_808\": 808,\n",
      "    \"LABEL_809\": 809,\n",
      "    \"LABEL_81\": 81,\n",
      "    \"LABEL_810\": 810,\n",
      "    \"LABEL_811\": 811,\n",
      "    \"LABEL_812\": 812,\n",
      "    \"LABEL_813\": 813,\n",
      "    \"LABEL_814\": 814,\n",
      "    \"LABEL_815\": 815,\n",
      "    \"LABEL_816\": 816,\n",
      "    \"LABEL_817\": 817,\n",
      "    \"LABEL_818\": 818,\n",
      "    \"LABEL_819\": 819,\n",
      "    \"LABEL_82\": 82,\n",
      "    \"LABEL_820\": 820,\n",
      "    \"LABEL_821\": 821,\n",
      "    \"LABEL_822\": 822,\n",
      "    \"LABEL_823\": 823,\n",
      "    \"LABEL_824\": 824,\n",
      "    \"LABEL_825\": 825,\n",
      "    \"LABEL_826\": 826,\n",
      "    \"LABEL_827\": 827,\n",
      "    \"LABEL_828\": 828,\n",
      "    \"LABEL_829\": 829,\n",
      "    \"LABEL_83\": 83,\n",
      "    \"LABEL_830\": 830,\n",
      "    \"LABEL_831\": 831,\n",
      "    \"LABEL_832\": 832,\n",
      "    \"LABEL_833\": 833,\n",
      "    \"LABEL_834\": 834,\n",
      "    \"LABEL_835\": 835,\n",
      "    \"LABEL_836\": 836,\n",
      "    \"LABEL_837\": 837,\n",
      "    \"LABEL_838\": 838,\n",
      "    \"LABEL_839\": 839,\n",
      "    \"LABEL_84\": 84,\n",
      "    \"LABEL_840\": 840,\n",
      "    \"LABEL_841\": 841,\n",
      "    \"LABEL_842\": 842,\n",
      "    \"LABEL_843\": 843,\n",
      "    \"LABEL_844\": 844,\n",
      "    \"LABEL_845\": 845,\n",
      "    \"LABEL_846\": 846,\n",
      "    \"LABEL_847\": 847,\n",
      "    \"LABEL_848\": 848,\n",
      "    \"LABEL_849\": 849,\n",
      "    \"LABEL_85\": 85,\n",
      "    \"LABEL_850\": 850,\n",
      "    \"LABEL_851\": 851,\n",
      "    \"LABEL_852\": 852,\n",
      "    \"LABEL_853\": 853,\n",
      "    \"LABEL_854\": 854,\n",
      "    \"LABEL_855\": 855,\n",
      "    \"LABEL_856\": 856,\n",
      "    \"LABEL_857\": 857,\n",
      "    \"LABEL_858\": 858,\n",
      "    \"LABEL_859\": 859,\n",
      "    \"LABEL_86\": 86,\n",
      "    \"LABEL_860\": 860,\n",
      "    \"LABEL_861\": 861,\n",
      "    \"LABEL_862\": 862,\n",
      "    \"LABEL_863\": 863,\n",
      "    \"LABEL_864\": 864,\n",
      "    \"LABEL_865\": 865,\n",
      "    \"LABEL_866\": 866,\n",
      "    \"LABEL_867\": 867,\n",
      "    \"LABEL_868\": 868,\n",
      "    \"LABEL_869\": 869,\n",
      "    \"LABEL_87\": 87,\n",
      "    \"LABEL_870\": 870,\n",
      "    \"LABEL_871\": 871,\n",
      "    \"LABEL_872\": 872,\n",
      "    \"LABEL_873\": 873,\n",
      "    \"LABEL_874\": 874,\n",
      "    \"LABEL_875\": 875,\n",
      "    \"LABEL_876\": 876,\n",
      "    \"LABEL_877\": 877,\n",
      "    \"LABEL_878\": 878,\n",
      "    \"LABEL_879\": 879,\n",
      "    \"LABEL_88\": 88,\n",
      "    \"LABEL_880\": 880,\n",
      "    \"LABEL_881\": 881,\n",
      "    \"LABEL_882\": 882,\n",
      "    \"LABEL_883\": 883,\n",
      "    \"LABEL_884\": 884,\n",
      "    \"LABEL_885\": 885,\n",
      "    \"LABEL_886\": 886,\n",
      "    \"LABEL_887\": 887,\n",
      "    \"LABEL_888\": 888,\n",
      "    \"LABEL_889\": 889,\n",
      "    \"LABEL_89\": 89,\n",
      "    \"LABEL_890\": 890,\n",
      "    \"LABEL_891\": 891,\n",
      "    \"LABEL_892\": 892,\n",
      "    \"LABEL_893\": 893,\n",
      "    \"LABEL_894\": 894,\n",
      "    \"LABEL_895\": 895,\n",
      "    \"LABEL_896\": 896,\n",
      "    \"LABEL_897\": 897,\n",
      "    \"LABEL_898\": 898,\n",
      "    \"LABEL_899\": 899,\n",
      "    \"LABEL_9\": 9,\n",
      "    \"LABEL_90\": 90,\n",
      "    \"LABEL_900\": 900,\n",
      "    \"LABEL_901\": 901,\n",
      "    \"LABEL_902\": 902,\n",
      "    \"LABEL_903\": 903,\n",
      "    \"LABEL_904\": 904,\n",
      "    \"LABEL_905\": 905,\n",
      "    \"LABEL_906\": 906,\n",
      "    \"LABEL_907\": 907,\n",
      "    \"LABEL_908\": 908,\n",
      "    \"LABEL_909\": 909,\n",
      "    \"LABEL_91\": 91,\n",
      "    \"LABEL_910\": 910,\n",
      "    \"LABEL_911\": 911,\n",
      "    \"LABEL_912\": 912,\n",
      "    \"LABEL_913\": 913,\n",
      "    \"LABEL_914\": 914,\n",
      "    \"LABEL_915\": 915,\n",
      "    \"LABEL_916\": 916,\n",
      "    \"LABEL_917\": 917,\n",
      "    \"LABEL_918\": 918,\n",
      "    \"LABEL_919\": 919,\n",
      "    \"LABEL_92\": 92,\n",
      "    \"LABEL_920\": 920,\n",
      "    \"LABEL_921\": 921,\n",
      "    \"LABEL_922\": 922,\n",
      "    \"LABEL_923\": 923,\n",
      "    \"LABEL_924\": 924,\n",
      "    \"LABEL_925\": 925,\n",
      "    \"LABEL_926\": 926,\n",
      "    \"LABEL_927\": 927,\n",
      "    \"LABEL_928\": 928,\n",
      "    \"LABEL_929\": 929,\n",
      "    \"LABEL_93\": 93,\n",
      "    \"LABEL_930\": 930,\n",
      "    \"LABEL_931\": 931,\n",
      "    \"LABEL_932\": 932,\n",
      "    \"LABEL_933\": 933,\n",
      "    \"LABEL_934\": 934,\n",
      "    \"LABEL_935\": 935,\n",
      "    \"LABEL_936\": 936,\n",
      "    \"LABEL_937\": 937,\n",
      "    \"LABEL_938\": 938,\n",
      "    \"LABEL_939\": 939,\n",
      "    \"LABEL_94\": 94,\n",
      "    \"LABEL_940\": 940,\n",
      "    \"LABEL_941\": 941,\n",
      "    \"LABEL_942\": 942,\n",
      "    \"LABEL_943\": 943,\n",
      "    \"LABEL_944\": 944,\n",
      "    \"LABEL_945\": 945,\n",
      "    \"LABEL_946\": 946,\n",
      "    \"LABEL_947\": 947,\n",
      "    \"LABEL_948\": 948,\n",
      "    \"LABEL_949\": 949,\n",
      "    \"LABEL_95\": 95,\n",
      "    \"LABEL_950\": 950,\n",
      "    \"LABEL_951\": 951,\n",
      "    \"LABEL_952\": 952,\n",
      "    \"LABEL_953\": 953,\n",
      "    \"LABEL_954\": 954,\n",
      "    \"LABEL_955\": 955,\n",
      "    \"LABEL_956\": 956,\n",
      "    \"LABEL_957\": 957,\n",
      "    \"LABEL_958\": 958,\n",
      "    \"LABEL_959\": 959,\n",
      "    \"LABEL_96\": 96,\n",
      "    \"LABEL_960\": 960,\n",
      "    \"LABEL_961\": 961,\n",
      "    \"LABEL_962\": 962,\n",
      "    \"LABEL_963\": 963,\n",
      "    \"LABEL_964\": 964,\n",
      "    \"LABEL_965\": 965,\n",
      "    \"LABEL_966\": 966,\n",
      "    \"LABEL_967\": 967,\n",
      "    \"LABEL_968\": 968,\n",
      "    \"LABEL_969\": 969,\n",
      "    \"LABEL_97\": 97,\n",
      "    \"LABEL_970\": 970,\n",
      "    \"LABEL_971\": 971,\n",
      "    \"LABEL_972\": 972,\n",
      "    \"LABEL_973\": 973,\n",
      "    \"LABEL_974\": 974,\n",
      "    \"LABEL_975\": 975,\n",
      "    \"LABEL_976\": 976,\n",
      "    \"LABEL_977\": 977,\n",
      "    \"LABEL_978\": 978,\n",
      "    \"LABEL_979\": 979,\n",
      "    \"LABEL_98\": 98,\n",
      "    \"LABEL_980\": 980,\n",
      "    \"LABEL_981\": 981,\n",
      "    \"LABEL_982\": 982,\n",
      "    \"LABEL_983\": 983,\n",
      "    \"LABEL_984\": 984,\n",
      "    \"LABEL_985\": 985,\n",
      "    \"LABEL_986\": 986,\n",
      "    \"LABEL_987\": 987,\n",
      "    \"LABEL_988\": 988,\n",
      "    \"LABEL_989\": 989,\n",
      "    \"LABEL_99\": 99,\n",
      "    \"LABEL_990\": 990,\n",
      "    \"LABEL_991\": 991,\n",
      "    \"LABEL_992\": 992,\n",
      "    \"LABEL_993\": 993,\n",
      "    \"LABEL_994\": 994,\n",
      "    \"LABEL_995\": 995,\n",
      "    \"LABEL_996\": 996,\n",
      "    \"LABEL_997\": 997,\n",
      "    \"LABEL_998\": 998,\n",
      "    \"LABEL_999\": 999\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": true,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\chris/.cache\\huggingface\\hub\\models--google--vit-base-patch16-224\\snapshots\\2ddc9d4e473d7ba52128f0df4723e478fa14fb80\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing ViTForImageClassification.\n",
      "\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2341, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2341]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "Setting `WANDB_LOG_MODEL` from true to `end` instead\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8323\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 1950\n",
      "  Number of trainable parameters = 87598885\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d253f26e214cfd9fd55dd78036a610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.8983, 'learning_rate': 2.564102564102564e-06, 'epoch': 0.08}\n",
      "{'loss': 7.8852, 'learning_rate': 5.128205128205128e-06, 'epoch': 0.15}\n",
      "{'loss': 7.8472, 'learning_rate': 7.692307692307694e-06, 'epoch': 0.23}\n",
      "{'loss': 7.8265, 'learning_rate': 1.0256410256410256e-05, 'epoch': 0.31}\n",
      "{'loss': 7.7843, 'learning_rate': 1.282051282051282e-05, 'epoch': 0.38}\n",
      "{'loss': 7.7646, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.46}\n",
      "{'loss': 7.6492, 'learning_rate': 1.794871794871795e-05, 'epoch': 0.54}\n",
      "{'loss': 7.657, 'learning_rate': 2.0512820512820512e-05, 'epoch': 0.61}\n",
      "{'loss': 7.5906, 'learning_rate': 2.307692307692308e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.5704, 'learning_rate': 2.564102564102564e-05, 'epoch': 0.77}\n",
      "{'loss': 7.5164, 'learning_rate': 2.8205128205128207e-05, 'epoch': 0.84}\n",
      "{'loss': 7.4086, 'learning_rate': 3.0769230769230774e-05, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.3281, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793a68d3c9fe40cc9f5947c6284bc847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Designer\\checkpoint-130\n",
      "Configuration saved in models/ViT_Designer\\checkpoint-130\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.261349678039551, 'eval_accuracy': 0.03844305622296973, 'eval_f1': 7.81634328988912e-05, 'eval_precision': 4.058703051586623e-05, 'eval_recall': 0.001053740779768177, 'eval_runtime': 16.3025, 'eval_samples_per_second': 127.649, 'eval_steps_per_second': 8.036, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Designer\\checkpoint-130\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Designer\\checkpoint-130\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.3856, 'learning_rate': 3.58974358974359e-05, 'epoch': 1.08}\n",
      "{'loss': 7.0535, 'learning_rate': 3.846153846153846e-05, 'epoch': 1.15}\n",
      "{'loss': 7.1439, 'learning_rate': 4.1025641025641023e-05, 'epoch': 1.23}\n",
      "{'loss': 7.019, 'learning_rate': 4.358974358974359e-05, 'epoch': 1.31}\n",
      "{'loss': 6.9534, 'learning_rate': 4.615384615384616e-05, 'epoch': 1.38}\n",
      "{'loss': 6.9587, 'learning_rate': 4.871794871794872e-05, 'epoch': 1.46}\n",
      "{'loss': 6.948, 'learning_rate': 4.985754985754986e-05, 'epoch': 1.54}\n",
      "{'loss': 6.9312, 'learning_rate': 4.9572649572649575e-05, 'epoch': 1.61}\n",
      "{'loss': 6.9267, 'learning_rate': 4.928774928774929e-05, 'epoch': 1.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.7684, 'learning_rate': 4.9002849002849004e-05, 'epoch': 1.77}\n",
      "{'loss': 7.0483, 'learning_rate': 4.871794871794872e-05, 'epoch': 1.84}\n",
      "{'loss': 6.8782, 'learning_rate': 4.8433048433048433e-05, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.8186, 'learning_rate': 4.814814814814815e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d937e6ca670146c9b2d48e1c1a298f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Designer\\checkpoint-260\n",
      "Configuration saved in models/ViT_Designer\\checkpoint-260\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.029059886932373, 'eval_accuracy': 0.040365209034118214, 'eval_f1': 0.0002537322642378198, 'eval_precision': 0.00017269507376315745, 'eval_recall': 0.0013171759747102212, 'eval_runtime': 16.2855, 'eval_samples_per_second': 127.783, 'eval_steps_per_second': 8.044, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Designer\\checkpoint-260\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Designer\\checkpoint-260\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.9205, 'learning_rate': 4.786324786324787e-05, 'epoch': 2.08}\n",
      "{'loss': 6.7183, 'learning_rate': 4.7578347578347584e-05, 'epoch': 2.15}\n",
      "{'loss': 6.5752, 'learning_rate': 4.72934472934473e-05, 'epoch': 2.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.7599, 'learning_rate': 4.700854700854701e-05, 'epoch': 2.31}\n",
      "{'loss': 6.7372, 'learning_rate': 4.672364672364672e-05, 'epoch': 2.38}\n",
      "{'loss': 6.5776, 'learning_rate': 4.643874643874644e-05, 'epoch': 2.46}\n",
      "{'loss': 6.7841, 'learning_rate': 4.615384615384616e-05, 'epoch': 2.54}\n",
      "{'loss': 6.6788, 'learning_rate': 4.586894586894587e-05, 'epoch': 2.61}\n",
      "{'loss': 6.6154, 'learning_rate': 4.558404558404559e-05, 'epoch': 2.69}\n",
      "{'loss': 6.578, 'learning_rate': 4.52991452991453e-05, 'epoch': 2.77}\n",
      "{'loss': 6.6511, 'learning_rate': 4.501424501424502e-05, 'epoch': 2.84}\n",
      "{'loss': 6.7345, 'learning_rate': 4.472934472934473e-05, 'epoch': 2.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.5926, 'learning_rate': 4.4444444444444447e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff37e4e897e4629a314a8cc76dd92ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Designer\\checkpoint-390\n",
      "Configuration saved in models/ViT_Designer\\checkpoint-390\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.95673942565918, 'eval_accuracy': 0.04997597308986065, 'eval_f1': 0.0009383677739690817, 'eval_precision': 0.001953929254782652, 'eval_recall': 0.003129406148993331, 'eval_runtime': 16.6614, 'eval_samples_per_second': 124.9, 'eval_steps_per_second': 7.863, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Designer\\checkpoint-390\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Designer\\checkpoint-390\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.546, 'learning_rate': 4.415954415954416e-05, 'epoch': 3.08}\n",
      "{'loss': 6.3578, 'learning_rate': 4.3874643874643876e-05, 'epoch': 3.15}\n",
      "{'loss': 6.4008, 'learning_rate': 4.358974358974359e-05, 'epoch': 3.23}\n",
      "{'loss': 6.457, 'learning_rate': 4.3304843304843306e-05, 'epoch': 3.31}\n",
      "{'loss': 6.3756, 'learning_rate': 4.301994301994302e-05, 'epoch': 3.38}\n",
      "{'loss': 6.3483, 'learning_rate': 4.2735042735042735e-05, 'epoch': 3.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.3662, 'learning_rate': 4.2450142450142457e-05, 'epoch': 3.54}\n",
      "{'loss': 6.4052, 'learning_rate': 4.216524216524217e-05, 'epoch': 3.61}\n",
      "{'loss': 6.3863, 'learning_rate': 4.1880341880341886e-05, 'epoch': 3.69}\n",
      "{'loss': 6.5453, 'learning_rate': 4.15954415954416e-05, 'epoch': 3.77}\n",
      "{'loss': 6.4543, 'learning_rate': 4.131054131054131e-05, 'epoch': 3.84}\n",
      "{'loss': 6.3933, 'learning_rate': 4.1025641025641023e-05, 'epoch': 3.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.3937, 'learning_rate': 4.074074074074074e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a4ac2e6f5d45c9afcfe53a5be313e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Designer\\checkpoint-520\n",
      "Configuration saved in models/ViT_Designer\\checkpoint-520\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.8425140380859375, 'eval_accuracy': 0.050937049495434886, 'eval_f1': 0.0017775095002219843, 'eval_precision': 0.002726756452592505, 'eval_recall': 0.003316596315108681, 'eval_runtime': 16.5691, 'eval_samples_per_second': 125.595, 'eval_steps_per_second': 7.906, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Designer\\checkpoint-520\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Designer\\checkpoint-520\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.3373, 'learning_rate': 4.045584045584046e-05, 'epoch': 4.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.2471, 'learning_rate': 4.0170940170940174e-05, 'epoch': 4.15}\n",
      "{'loss': 6.1965, 'learning_rate': 3.988603988603989e-05, 'epoch': 4.23}\n",
      "{'loss': 6.205, 'learning_rate': 3.9601139601139604e-05, 'epoch': 4.31}\n",
      "{'loss': 6.1024, 'learning_rate': 3.931623931623932e-05, 'epoch': 4.38}\n",
      "{'loss': 6.0579, 'learning_rate': 3.903133903133903e-05, 'epoch': 4.46}\n",
      "{'loss': 6.1527, 'learning_rate': 3.874643874643875e-05, 'epoch': 4.54}\n",
      "{'loss': 6.1716, 'learning_rate': 3.846153846153846e-05, 'epoch': 4.61}\n",
      "{'loss': 6.2096, 'learning_rate': 3.817663817663818e-05, 'epoch': 4.69}\n",
      "{'loss': 6.1559, 'learning_rate': 3.789173789173789e-05, 'epoch': 4.77}\n",
      "{'loss': 6.0256, 'learning_rate': 3.760683760683761e-05, 'epoch': 4.84}\n",
      "{'loss': 6.1238, 'learning_rate': 3.732193732193732e-05, 'epoch': 4.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.137, 'learning_rate': 3.7037037037037037e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e05f38dd4964ef6bacc61ff41f42cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Designer\\checkpoint-650\n",
      "Configuration saved in models/ViT_Designer\\checkpoint-650\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.76987361907959, 'eval_accuracy': 0.06439211917347429, 'eval_f1': 0.003626844642471438, 'eval_precision': 0.004380320566285953, 'eval_recall': 0.006243965308142363, 'eval_runtime': 16.4922, 'eval_samples_per_second': 126.181, 'eval_steps_per_second': 7.943, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Designer\\checkpoint-650\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Designer\\checkpoint-650\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.05, 'learning_rate': 3.675213675213676e-05, 'epoch': 5.08}\n",
      "{'loss': 5.962, 'learning_rate': 3.646723646723647e-05, 'epoch': 5.15}\n",
      "{'loss': 6.0141, 'learning_rate': 3.618233618233619e-05, 'epoch': 5.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.8526, 'learning_rate': 3.58974358974359e-05, 'epoch': 5.31}\n",
      "{'loss': 5.935, 'learning_rate': 3.561253561253561e-05, 'epoch': 5.38}\n",
      "{'loss': 5.9106, 'learning_rate': 3.5327635327635325e-05, 'epoch': 5.46}\n",
      "{'loss': 5.9354, 'learning_rate': 3.504273504273504e-05, 'epoch': 5.54}\n",
      "{'loss': 5.9364, 'learning_rate': 3.475783475783476e-05, 'epoch': 5.61}\n",
      "{'loss': 6.0364, 'learning_rate': 3.4472934472934476e-05, 'epoch': 5.69}\n",
      "{'loss': 5.7886, 'learning_rate': 3.418803418803419e-05, 'epoch': 5.77}\n",
      "{'loss': 5.8779, 'learning_rate': 3.3903133903133905e-05, 'epoch': 5.84}\n",
      "{'loss': 5.8271, 'learning_rate': 3.361823361823362e-05, 'epoch': 5.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.926, 'learning_rate': 3.3333333333333335e-05, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4d8a3b46544cc294e81a6a7c9c5a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Designer\\checkpoint-780\n",
      "Configuration saved in models/ViT_Designer\\checkpoint-780\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.709866523742676, 'eval_accuracy': 0.0691975012013455, 'eval_f1': 0.004617311346584369, 'eval_precision': 0.006136809066421414, 'eval_recall': 0.007276646764187828, 'eval_runtime': 17.0322, 'eval_samples_per_second': 122.181, 'eval_steps_per_second': 7.691, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Designer\\checkpoint-780\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Designer\\checkpoint-780\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.8704, 'learning_rate': 3.304843304843305e-05, 'epoch': 6.08}\n",
      "{'loss': 5.7543, 'learning_rate': 3.2763532763532764e-05, 'epoch': 6.15}\n",
      "{'loss': 5.6789, 'learning_rate': 3.247863247863248e-05, 'epoch': 6.23}\n",
      "{'loss': 5.7973, 'learning_rate': 3.2193732193732194e-05, 'epoch': 6.31}\n",
      "{'loss': 5.6683, 'learning_rate': 3.190883190883191e-05, 'epoch': 6.38}\n",
      "{'loss': 5.6786, 'learning_rate': 3.162393162393162e-05, 'epoch': 6.46}\n",
      "{'loss': 5.6491, 'learning_rate': 3.133903133903134e-05, 'epoch': 6.54}\n",
      "{'loss': 5.6963, 'learning_rate': 3.105413105413106e-05, 'epoch': 6.61}\n",
      "{'loss': 5.6825, 'learning_rate': 3.0769230769230774e-05, 'epoch': 6.69}\n",
      "{'loss': 5.87, 'learning_rate': 3.0484330484330486e-05, 'epoch': 6.77}\n",
      "{'loss': 5.5979, 'learning_rate': 3.01994301994302e-05, 'epoch': 6.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.5953, 'learning_rate': 2.9914529914529915e-05, 'epoch': 6.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.6344, 'learning_rate': 2.962962962962963e-05, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afdbfd5c09942b9b3f733b1922e7543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Designer\\checkpoint-910\n",
      "Configuration saved in models/ViT_Designer\\checkpoint-910\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.65408182144165, 'eval_accuracy': 0.0691975012013455, 'eval_f1': 0.004305009232388145, 'eval_precision': 0.005445529609520523, 'eval_recall': 0.007507463295126372, 'eval_runtime': 16.556, 'eval_samples_per_second': 125.695, 'eval_steps_per_second': 7.913, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Designer\\checkpoint-910\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Designer\\checkpoint-910\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.7366, 'learning_rate': 2.9344729344729345e-05, 'epoch': 7.08}\n",
      "{'loss': 5.5441, 'learning_rate': 2.9059829059829063e-05, 'epoch': 7.15}\n",
      "{'loss': 5.4356, 'learning_rate': 2.8774928774928778e-05, 'epoch': 7.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.4736, 'learning_rate': 2.8490028490028492e-05, 'epoch': 7.31}\n",
      "{'loss': 5.5616, 'learning_rate': 2.8205128205128207e-05, 'epoch': 7.38}\n",
      "{'loss': 5.4509, 'learning_rate': 2.7920227920227922e-05, 'epoch': 7.46}\n",
      "{'loss': 5.5483, 'learning_rate': 2.7635327635327633e-05, 'epoch': 7.54}\n",
      "{'loss': 5.4873, 'learning_rate': 2.7350427350427355e-05, 'epoch': 7.61}\n",
      "{'loss': 5.549, 'learning_rate': 2.706552706552707e-05, 'epoch': 7.69}\n",
      "{'loss': 5.5552, 'learning_rate': 2.6780626780626784e-05, 'epoch': 7.77}\n",
      "{'loss': 5.4486, 'learning_rate': 2.64957264957265e-05, 'epoch': 7.84}\n",
      "{'loss': 5.5252, 'learning_rate': 2.621082621082621e-05, 'epoch': 7.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.529, 'learning_rate': 2.5925925925925925e-05, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135203c81eec46c99e3b7e12de13a6c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Designer\\checkpoint-1040\n",
      "Configuration saved in models/ViT_Designer\\checkpoint-1040\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.624983310699463, 'eval_accuracy': 0.07448342143200384, 'eval_f1': 0.005418290217543795, 'eval_precision': 0.0057238657406802, 'eval_recall': 0.009251598546489371, 'eval_runtime': 16.598, 'eval_samples_per_second': 125.377, 'eval_steps_per_second': 7.893, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Designer\\checkpoint-1040\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Designer\\checkpoint-1040\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.3054, 'learning_rate': 2.564102564102564e-05, 'epoch': 8.08}\n",
      "{'loss': 5.3, 'learning_rate': 2.535612535612536e-05, 'epoch': 8.15}\n",
      "{'loss': 5.482, 'learning_rate': 2.5071225071225073e-05, 'epoch': 8.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.3289, 'learning_rate': 2.4786324786324787e-05, 'epoch': 8.31}\n",
      "{'loss': 5.2802, 'learning_rate': 2.4501424501424502e-05, 'epoch': 8.38}\n",
      "{'loss': 5.2445, 'learning_rate': 2.4216524216524217e-05, 'epoch': 8.46}\n",
      "{'loss': 5.3878, 'learning_rate': 2.3931623931623935e-05, 'epoch': 8.54}\n",
      "{'loss': 5.2229, 'learning_rate': 2.364672364672365e-05, 'epoch': 8.61}\n",
      "{'loss': 5.3554, 'learning_rate': 2.336182336182336e-05, 'epoch': 8.69}\n",
      "{'loss': 5.4404, 'learning_rate': 2.307692307692308e-05, 'epoch': 8.77}\n",
      "{'loss': 5.3235, 'learning_rate': 2.2792022792022794e-05, 'epoch': 8.84}\n",
      "{'loss': 5.3293, 'learning_rate': 2.250712250712251e-05, 'epoch': 8.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.2507, 'learning_rate': 2.2222222222222223e-05, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de37030f71da43ba8d4f26654ebbfed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Designer\\checkpoint-1170\n",
      "Configuration saved in models/ViT_Designer\\checkpoint-1170\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.605820655822754, 'eval_accuracy': 0.07928880345987506, 'eval_f1': 0.00910626698384246, 'eval_precision': 0.012274178411216332, 'eval_recall': 0.012927929751023639, 'eval_runtime': 16.5806, 'eval_samples_per_second': 125.508, 'eval_steps_per_second': 7.901, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Designer\\checkpoint-1170\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Designer\\checkpoint-1170\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.2393, 'learning_rate': 2.1937321937321938e-05, 'epoch': 9.08}\n",
      "{'loss': 5.157, 'learning_rate': 2.1652421652421653e-05, 'epoch': 9.15}\n",
      "{'loss': 5.2391, 'learning_rate': 2.1367521367521368e-05, 'epoch': 9.23}\n",
      "{'loss': 5.1659, 'learning_rate': 2.1082621082621086e-05, 'epoch': 9.31}\n",
      "{'loss': 5.1775, 'learning_rate': 2.07977207977208e-05, 'epoch': 9.38}\n",
      "{'loss': 5.0866, 'learning_rate': 2.0512820512820512e-05, 'epoch': 9.46}\n",
      "{'loss': 5.2044, 'learning_rate': 2.022792022792023e-05, 'epoch': 9.54}\n",
      "{'loss': 5.134, 'learning_rate': 1.9943019943019945e-05, 'epoch': 9.61}\n",
      "{'loss': 5.2218, 'learning_rate': 1.965811965811966e-05, 'epoch': 9.69}\n",
      "{'loss': 5.1977, 'learning_rate': 1.9373219373219374e-05, 'epoch': 9.77}\n",
      "{'loss': 5.1458, 'learning_rate': 1.908831908831909e-05, 'epoch': 9.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.2257, 'learning_rate': 1.8803418803418804e-05, 'epoch': 9.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.1508, 'learning_rate': 1.8518518518518518e-05, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c88dfd209ae41c0b14b4cbb2021c5ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Designer\\checkpoint-1300\n",
      "Configuration saved in models/ViT_Designer\\checkpoint-1300\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.581340312957764, 'eval_accuracy': 0.07880826525708794, 'eval_f1': 0.008227689190315796, 'eval_precision': 0.010239932836158651, 'eval_recall': 0.012153129986613997, 'eval_runtime': 16.5919, 'eval_samples_per_second': 125.423, 'eval_steps_per_second': 7.895, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Designer\\checkpoint-1300\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Designer\\checkpoint-1300\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.0999, 'learning_rate': 1.8233618233618236e-05, 'epoch': 10.08}\n",
      "{'loss': 4.9288, 'learning_rate': 1.794871794871795e-05, 'epoch': 10.15}\n",
      "{'loss': 4.9997, 'learning_rate': 1.7663817663817662e-05, 'epoch': 10.23}\n",
      "{'loss': 5.0291, 'learning_rate': 1.737891737891738e-05, 'epoch': 10.31}\n",
      "{'loss': 5.0502, 'learning_rate': 1.7094017094017095e-05, 'epoch': 10.38}\n",
      "{'loss': 5.1017, 'learning_rate': 1.680911680911681e-05, 'epoch': 10.46}\n",
      "{'loss': 4.994, 'learning_rate': 1.6524216524216525e-05, 'epoch': 10.54}\n",
      "{'loss': 5.1851, 'learning_rate': 1.623931623931624e-05, 'epoch': 10.61}\n",
      "{'loss': 5.1215, 'learning_rate': 1.5954415954415954e-05, 'epoch': 10.69}\n",
      "{'loss': 5.0386, 'learning_rate': 1.566951566951567e-05, 'epoch': 10.77}\n",
      "{'loss': 4.9215, 'learning_rate': 1.5384615384615387e-05, 'epoch': 10.84}\n",
      "{'loss': 5.0941, 'learning_rate': 1.50997150997151e-05, 'epoch': 10.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.1365, 'learning_rate': 1.4814814814814815e-05, 'epoch': 11.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0f574226d04edeb80e914f61b2be83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Designer\\checkpoint-1430\n",
      "Configuration saved in models/ViT_Designer\\checkpoint-1430\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.563826084136963, 'eval_accuracy': 0.07976934166266218, 'eval_f1': 0.007398366333138858, 'eval_precision': 0.007622151561183643, 'eval_recall': 0.011812953913496604, 'eval_runtime': 16.3494, 'eval_samples_per_second': 127.283, 'eval_steps_per_second': 8.013, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Designer\\checkpoint-1430\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Designer\\checkpoint-1430\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.0881, 'learning_rate': 1.4529914529914531e-05, 'epoch': 11.08}\n",
      "{'loss': 4.9497, 'learning_rate': 1.4245014245014246e-05, 'epoch': 11.15}\n",
      "{'loss': 4.8799, 'learning_rate': 1.3960113960113961e-05, 'epoch': 11.23}\n",
      "{'loss': 5.0089, 'learning_rate': 1.3675213675213677e-05, 'epoch': 11.31}\n",
      "{'loss': 4.9284, 'learning_rate': 1.3390313390313392e-05, 'epoch': 11.38}\n",
      "{'loss': 5.0398, 'learning_rate': 1.3105413105413105e-05, 'epoch': 11.46}\n",
      "{'loss': 4.8656, 'learning_rate': 1.282051282051282e-05, 'epoch': 11.54}\n",
      "{'loss': 4.872, 'learning_rate': 1.2535612535612536e-05, 'epoch': 11.61}\n",
      "{'loss': 4.9009, 'learning_rate': 1.2250712250712251e-05, 'epoch': 11.69}\n",
      "{'loss': 4.8807, 'learning_rate': 1.1965811965811967e-05, 'epoch': 11.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.8449, 'learning_rate': 1.168091168091168e-05, 'epoch': 11.84}\n",
      "{'loss': 4.8723, 'learning_rate': 1.1396011396011397e-05, 'epoch': 11.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.0395, 'learning_rate': 1.1111111111111112e-05, 'epoch': 12.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bb237634f54ac1995545f02ad73f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Designer\\checkpoint-1560\n",
      "Configuration saved in models/ViT_Designer\\checkpoint-1560\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.542242527008057, 'eval_accuracy': 0.08601633829889477, 'eval_f1': 0.009646407597132551, 'eval_precision': 0.009582927462185708, 'eval_recall': 0.0152721249115823, 'eval_runtime': 16.6743, 'eval_samples_per_second': 124.802, 'eval_steps_per_second': 7.856, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Designer\\checkpoint-1560\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Designer\\checkpoint-1560\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.0027, 'learning_rate': 1.0826210826210826e-05, 'epoch': 12.08}\n",
      "{'loss': 4.9626, 'learning_rate': 1.0541310541310543e-05, 'epoch': 12.15}\n",
      "{'loss': 4.9096, 'learning_rate': 1.0256410256410256e-05, 'epoch': 12.23}\n",
      "{'loss': 4.7069, 'learning_rate': 9.971509971509972e-06, 'epoch': 12.31}\n",
      "{'loss': 4.8676, 'learning_rate': 9.686609686609687e-06, 'epoch': 12.38}\n",
      "{'loss': 4.8047, 'learning_rate': 9.401709401709402e-06, 'epoch': 12.46}\n",
      "{'loss': 4.9048, 'learning_rate': 9.116809116809118e-06, 'epoch': 12.54}\n",
      "{'loss': 4.8916, 'learning_rate': 8.831908831908831e-06, 'epoch': 12.61}\n",
      "{'loss': 4.8341, 'learning_rate': 8.547008547008548e-06, 'epoch': 12.69}\n",
      "{'loss': 4.8172, 'learning_rate': 8.262108262108262e-06, 'epoch': 12.77}\n",
      "{'loss': 4.8428, 'learning_rate': 7.977207977207977e-06, 'epoch': 12.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.8281, 'learning_rate': 7.692307692307694e-06, 'epoch': 12.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.907, 'learning_rate': 7.4074074074074075e-06, 'epoch': 13.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a87f2d6f9b14af28aa7255c7bbf887c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Designer\\checkpoint-1690\n",
      "Configuration saved in models/ViT_Designer\\checkpoint-1690\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.542965888977051, 'eval_accuracy': 0.08601633829889477, 'eval_f1': 0.00834122904996449, 'eval_precision': 0.009994442754894547, 'eval_recall': 0.013245146098271597, 'eval_runtime': 16.698, 'eval_samples_per_second': 124.626, 'eval_steps_per_second': 7.845, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Designer\\checkpoint-1690\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Designer\\checkpoint-1690\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.9265, 'learning_rate': 7.122507122507123e-06, 'epoch': 13.08}\n",
      "{'loss': 4.7614, 'learning_rate': 6.837606837606839e-06, 'epoch': 13.15}\n",
      "{'loss': 4.8897, 'learning_rate': 6.5527065527065525e-06, 'epoch': 13.23}\n",
      "{'loss': 4.7573, 'learning_rate': 6.267806267806268e-06, 'epoch': 13.31}\n",
      "{'loss': 4.7304, 'learning_rate': 5.982905982905984e-06, 'epoch': 13.38}\n",
      "{'loss': 4.7204, 'learning_rate': 5.6980056980056985e-06, 'epoch': 13.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.829, 'learning_rate': 5.413105413105413e-06, 'epoch': 13.54}\n",
      "{'loss': 4.8529, 'learning_rate': 5.128205128205128e-06, 'epoch': 13.61}\n",
      "{'loss': 4.8227, 'learning_rate': 4.8433048433048435e-06, 'epoch': 13.69}\n",
      "{'loss': 4.7985, 'learning_rate': 4.558404558404559e-06, 'epoch': 13.77}\n",
      "{'loss': 4.7987, 'learning_rate': 4.273504273504274e-06, 'epoch': 13.84}\n",
      "{'loss': 4.8144, 'learning_rate': 3.988603988603989e-06, 'epoch': 13.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.7104, 'learning_rate': 3.7037037037037037e-06, 'epoch': 14.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb68ae5aed444ddbf546008a7b6d897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Designer\\checkpoint-1820\n",
      "Configuration saved in models/ViT_Designer\\checkpoint-1820\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.539475440979004, 'eval_accuracy': 0.07928880345987506, 'eval_f1': 0.00809428640715406, 'eval_precision': 0.00875658071414528, 'eval_recall': 0.01237533880490781, 'eval_runtime': 16.2444, 'eval_samples_per_second': 128.105, 'eval_steps_per_second': 8.064, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Designer\\checkpoint-1820\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Designer\\checkpoint-1820\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.9324, 'learning_rate': 3.4188034188034193e-06, 'epoch': 14.08}\n",
      "{'loss': 4.7791, 'learning_rate': 3.133903133903134e-06, 'epoch': 14.15}\n",
      "{'loss': 4.7969, 'learning_rate': 2.8490028490028492e-06, 'epoch': 14.23}\n",
      "{'loss': 4.7739, 'learning_rate': 2.564102564102564e-06, 'epoch': 14.31}\n",
      "{'loss': 4.7566, 'learning_rate': 2.2792022792022796e-06, 'epoch': 14.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.6845, 'learning_rate': 1.9943019943019943e-06, 'epoch': 14.46}\n",
      "{'loss': 4.6246, 'learning_rate': 1.7094017094017097e-06, 'epoch': 14.54}\n",
      "{'loss': 4.6875, 'learning_rate': 1.4245014245014246e-06, 'epoch': 14.61}\n",
      "{'loss': 4.6558, 'learning_rate': 1.1396011396011398e-06, 'epoch': 14.69}\n",
      "{'loss': 4.688, 'learning_rate': 8.547008547008548e-07, 'epoch': 14.77}\n",
      "{'loss': 4.7405, 'learning_rate': 5.698005698005699e-07, 'epoch': 14.84}\n",
      "{'loss': 4.6541, 'learning_rate': 2.8490028490028494e-07, 'epoch': 14.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2081\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.7767, 'learning_rate': 0.0, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6422f8199e0a4a7c832b40bc3b3b00af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to models/ViT_Designer\\checkpoint-1950\n",
      "Configuration saved in models/ViT_Designer\\checkpoint-1950\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.528878211975098, 'eval_accuracy': 0.08217203267659778, 'eval_f1': 0.010945442556509399, 'eval_precision': 0.012379526177110307, 'eval_recall': 0.014498688952725628, 'eval_runtime': 16.5832, 'eval_samples_per_second': 125.489, 'eval_steps_per_second': 7.9, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/ViT_Designer\\checkpoint-1950\\pytorch_model.bin\n",
      "Image processor saved in models/ViT_Designer\\checkpoint-1950\\preprocessor_config.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from models/ViT_Designer\\checkpoint-1950 (score: 0.010945442556509399).\n",
      "Setting `WANDB_LOG_MODEL` from true to `end` instead\n",
      "Saving model checkpoint to C:\\Users\\chris\\AppData\\Local\\Temp\\tmptb8p1mkl\n",
      "Configuration saved in C:\\Users\\chris\\AppData\\Local\\Temp\\tmptb8p1mkl\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 2245.2166, 'train_samples_per_second': 55.605, 'train_steps_per_second': 0.869, 'train_loss': 5.732390766632863, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in C:\\Users\\chris\\AppData\\Local\\Temp\\tmptb8p1mkl\\pytorch_model.bin\n",
      "Image processor saved in C:\\Users\\chris\\AppData\\Local\\Temp\\tmptb8p1mkl\\preprocessor_config.json\n",
      "Logging model artifacts. ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▃▃▅▆▆▆▇▇▇██▇▇</td></tr><tr><td>eval/f1</td><td>▁▁▂▂▃▄▄▄▇▆▆▇▆▆█</td></tr><tr><td>eval/loss</td><td>█▆▅▄▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▁▂▃▃▄▄▄█▇▅▆▇▆█</td></tr><tr><td>eval/recall</td><td>▁▁▂▂▄▄▄▅▇▆▆█▇▇█</td></tr><tr><td>eval/runtime</td><td>▂▁▅▄▃█▄▄▄▄▂▅▅▁▄</td></tr><tr><td>eval/samples_per_second</td><td>▇█▄▅▆▁▅▅▅▅▇▄▄█▅</td></tr><tr><td>eval/steps_per_second</td><td>▇█▄▅▆▁▅▅▅▅▇▄▄█▅</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>▂▃▅▇███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>██▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.08217</td></tr><tr><td>eval/f1</td><td>0.01095</td></tr><tr><td>eval/loss</td><td>6.52888</td></tr><tr><td>eval/precision</td><td>0.01238</td></tr><tr><td>eval/recall</td><td>0.0145</td></tr><tr><td>eval/runtime</td><td>16.5832</td></tr><tr><td>eval/samples_per_second</td><td>125.489</td></tr><tr><td>eval/steps_per_second</td><td>7.9</td></tr><tr><td>train/epoch</td><td>15.0</td></tr><tr><td>train/global_step</td><td>1950</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>4.7767</td></tr><tr><td>train/total_flos</td><td>9.877063312416707e+18</td></tr><tr><td>train/train_loss</td><td>5.73239</td></tr><tr><td>train/train_runtime</td><td>2245.2166</td></tr><tr><td>train/train_samples_per_second</td><td>55.605</td></tr><tr><td>train/train_steps_per_second</td><td>0.869</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ViT_Designer</strong>: <a href=\"https://wandb.ai/cringgaard/Sailboat%20FGVC/runs/1cpiz4bg\" target=\"_blank\">https://wandb.ai/cringgaard/Sailboat%20FGVC/runs/1cpiz4bg</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230323_153516-1cpiz4bg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for label_type in label_types:\n",
    "    wandb.init(project=\"Sailboat FGVC\", name=model_name+\"_\"+label_type)\n",
    "    torch.cuda.empty_cache()\n",
    "    c_names = dataset[\"full\"].column_names[1:]\n",
    "    c_names.remove(label_type)\n",
    "    dataset_specific = dataset.remove_columns(c_names)\n",
    "\n",
    "    labels = dataset_specific[\"full\"].unique(label_type)\n",
    "    dataset_specific = dataset_specific['full'].train_test_split(test_size=0.2, shuffle=True, seed=43)\n",
    "\n",
    "    labels_train = dataset_specific[\"train\"].unique(label_type)\n",
    "    labels_test = dataset_specific[\"test\"].unique(label_type)\n",
    "\n",
    "    print(sorted(labels_train))\n",
    "    print(sorted(labels_test))\n",
    "    labels_to_remove = [value for value in labels_test if value not in labels_train]\n",
    "    print(labels_to_remove)\n",
    "    # dataset_specific['test'] = dataset_specific[\"test\"].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "    \n",
    "    # labels_test = dataset_specific[\"test\"].unique(label_type)\n",
    "    # print(sorted(labels_test))\n",
    "\n",
    "\n",
    "\n",
    "    labels = dataset['full'].features[label_type].names\n",
    "    print(labels)\n",
    "\n",
    "    def transforms(examples):\n",
    "        examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "        examples[\"labels\"] = examples[label_type]\n",
    "        del examples[label_type]\n",
    "        del examples[\"img_path\"]\n",
    "        return examples\n",
    "\n",
    "    dataset_specific = dataset_specific.with_transform(transforms)\n",
    "    data_collator = DefaultDataCollator()\n",
    "\n",
    "    model = AutoModelForImageClassification.from_pretrained(\n",
    "        checkpoint,\n",
    "        num_labels=len(labels),\n",
    "        # id2label=id2label,\n",
    "        # label2id=label2id,\n",
    "        use_auth_token=access_token,\n",
    "        ignore_mismatched_sizes=True,\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"models/\"+model_name+\"_\"+label_type,\n",
    "        report_to=\"wandb\",\n",
    "        remove_unused_columns=False,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        gradient_accumulation_steps=4,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=15,\n",
    "        warmup_ratio=0.1,\n",
    "        logging_steps=10,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        # no_cuda=True\n",
    "        # push_to_hub=True,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=dataset_specific[\"train\"],\n",
    "        eval_dataset=dataset_specific[\"test\"],\n",
    "        tokenizer=image_processor,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
