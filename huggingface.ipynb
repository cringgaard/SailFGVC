{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset , concatenate_datasets\n",
    "from transformers import AutoImageProcessor\n",
    "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
    "from transformers import DefaultDataCollator\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoModel , AutoModelForImageClassification, TrainingArguments, Trainer , ImageClassificationPipeline , ResNetForImageClassification , ResNetModel , ResNetConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from huggingface_hub import login\n",
    "import wandb\n",
    "from transformers import pipeline\n",
    "from sklearn import metrics\n",
    "import json\n",
    "import PIL\n",
    "from data.clean_classes import *\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image as mpimg\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "data_dir = \"data/\"\n",
    "img_dir = \"E:/data/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_PROJECT'] = \"Sailboat FGVC\"\n",
    "os.environ[\"WANDB_WATCH\"]=\"false\"\n",
    "# os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
    "os.environ[\"WANDB_START_METHOD\"]='thread'\n",
    "wandb_project = \"Sailboat FGVC Clean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset boats_dataset (C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chris\\OneDrive\\Dokumenter\\GitHub\\SailFGVC\\huggingface.ipynb Cell 4\u001b[0m in \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Dokumenter/GitHub/SailFGVC/huggingface.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m write_token \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhf_tvyAXTLDKQPQTKEabdQiRUOMxhqBrtWRey\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Dokumenter/GitHub/SailFGVC/huggingface.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# login(token=access_token)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Dokumenter/GitHub/SailFGVC/huggingface.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m dataset_boat24 \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mcringgaard/boats_dataset\u001b[39;49m\u001b[39m\"\u001b[39;49m , use_auth_token\u001b[39m=\u001b[39;49maccess_token, split\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mboat24\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Dokumenter/GitHub/SailFGVC/huggingface.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m dataset \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39m\u001b[39mcringgaard/boats_dataset\u001b[39m\u001b[39m\"\u001b[39m , use_auth_token\u001b[39m=\u001b[39maccess_token, split\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msailboatdata\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\load.py:1758\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, **config_kwargs)\u001b[0m\n\u001b[0;32m   1754\u001b[0m \u001b[39m# Build dataset for splits\u001b[39;00m\n\u001b[0;32m   1755\u001b[0m keep_in_memory \u001b[39m=\u001b[39m (\n\u001b[0;32m   1756\u001b[0m     keep_in_memory \u001b[39mif\u001b[39;00m keep_in_memory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m is_small_dataset(builder_instance\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size)\n\u001b[0;32m   1757\u001b[0m )\n\u001b[1;32m-> 1758\u001b[0m ds \u001b[39m=\u001b[39m builder_instance\u001b[39m.\u001b[39;49mas_dataset(split\u001b[39m=\u001b[39;49msplit, ignore_verifications\u001b[39m=\u001b[39;49mignore_verifications, in_memory\u001b[39m=\u001b[39;49mkeep_in_memory)\n\u001b[0;32m   1759\u001b[0m \u001b[39m# Rename and cast features to match task schema\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m \u001b[39mif\u001b[39;00m task \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\builder.py:893\u001b[0m, in \u001b[0;36mDatasetBuilder.as_dataset\u001b[1;34m(self, split, run_post_process, ignore_verifications, in_memory)\u001b[0m\n\u001b[0;32m    890\u001b[0m     split \u001b[39m=\u001b[39m {s: s \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39msplits}\n\u001b[0;32m    892\u001b[0m \u001b[39m# Create a dataset for each of the given splits\u001b[39;00m\n\u001b[1;32m--> 893\u001b[0m datasets \u001b[39m=\u001b[39m map_nested(\n\u001b[0;32m    894\u001b[0m     partial(\n\u001b[0;32m    895\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_single_dataset,\n\u001b[0;32m    896\u001b[0m         run_post_process\u001b[39m=\u001b[39;49mrun_post_process,\n\u001b[0;32m    897\u001b[0m         ignore_verifications\u001b[39m=\u001b[39;49mignore_verifications,\n\u001b[0;32m    898\u001b[0m         in_memory\u001b[39m=\u001b[39;49min_memory,\n\u001b[0;32m    899\u001b[0m     ),\n\u001b[0;32m    900\u001b[0m     split,\n\u001b[0;32m    901\u001b[0m     map_tuple\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    902\u001b[0m     disable_tqdm\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m logging\u001b[39m.\u001b[39;49mis_progress_bar_enabled(),\n\u001b[0;32m    903\u001b[0m )\n\u001b[0;32m    904\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(datasets, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    905\u001b[0m     datasets \u001b[39m=\u001b[39m DatasetDict(datasets)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\utils\\py_utils.py:385\u001b[0m, in \u001b[0;36mmap_nested\u001b[1;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, types, disable_tqdm, desc)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[39m# Singleton\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, types):\n\u001b[1;32m--> 385\u001b[0m     \u001b[39mreturn\u001b[39;00m function(data_struct)\n\u001b[0;32m    387\u001b[0m disable_tqdm \u001b[39m=\u001b[39m disable_tqdm \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled()\n\u001b[0;32m    388\u001b[0m iterable \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(data_struct\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m data_struct\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\builder.py:924\u001b[0m, in \u001b[0;36mDatasetBuilder._build_single_dataset\u001b[1;34m(self, split, run_post_process, ignore_verifications, in_memory)\u001b[0m\n\u001b[0;32m    921\u001b[0m     split \u001b[39m=\u001b[39m Split(split)\n\u001b[0;32m    923\u001b[0m \u001b[39m# Build base dataset\u001b[39;00m\n\u001b[1;32m--> 924\u001b[0m ds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_as_dataset(\n\u001b[0;32m    925\u001b[0m     split\u001b[39m=\u001b[39;49msplit,\n\u001b[0;32m    926\u001b[0m     in_memory\u001b[39m=\u001b[39;49min_memory,\n\u001b[0;32m    927\u001b[0m )\n\u001b[0;32m    928\u001b[0m \u001b[39mif\u001b[39;00m run_post_process:\n\u001b[0;32m    929\u001b[0m     \u001b[39mfor\u001b[39;00m resource_file_name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_processing_resources(split)\u001b[39m.\u001b[39mvalues():\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\builder.py:993\u001b[0m, in \u001b[0;36mDatasetBuilder._as_dataset\u001b[1;34m(self, split, in_memory)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_as_dataset\u001b[39m(\u001b[39mself\u001b[39m, split: Union[ReadInstruction, Split] \u001b[39m=\u001b[39m Split\u001b[39m.\u001b[39mTRAIN, in_memory: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dataset:\n\u001b[0;32m    979\u001b[0m     \u001b[39m\"\"\"Constructs a `Dataset`.\u001b[39;00m\n\u001b[0;32m    980\u001b[0m \n\u001b[0;32m    981\u001b[0m \u001b[39m    This is the internal implementation to overwrite called when user calls\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    990\u001b[0m \u001b[39m        `Dataset`\u001b[39;00m\n\u001b[0;32m    991\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 993\u001b[0m     dataset_kwargs \u001b[39m=\u001b[39m ArrowReader(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cache_dir, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfo)\u001b[39m.\u001b[39;49mread(\n\u001b[0;32m    994\u001b[0m         name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    995\u001b[0m         instructions\u001b[39m=\u001b[39;49msplit,\n\u001b[0;32m    996\u001b[0m         split_infos\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfo\u001b[39m.\u001b[39;49msplits\u001b[39m.\u001b[39;49mvalues(),\n\u001b[0;32m    997\u001b[0m         in_memory\u001b[39m=\u001b[39;49min_memory,\n\u001b[0;32m    998\u001b[0m     )\n\u001b[0;32m    999\u001b[0m     fingerprint \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_dataset_fingerprint(split)\n\u001b[0;32m   1000\u001b[0m     \u001b[39mreturn\u001b[39;00m Dataset(fingerprint\u001b[39m=\u001b[39mfingerprint, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_reader.py:215\u001b[0m, in \u001b[0;36mBaseReader.read\u001b[1;34m(self, name, instructions, split_infos, in_memory)\u001b[0m\n\u001b[0;32m    213\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInstruction \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00minstructions\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m corresponds to no data!\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    214\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(msg)\n\u001b[1;32m--> 215\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_files(files\u001b[39m=\u001b[39;49mfiles, original_instructions\u001b[39m=\u001b[39;49minstructions, in_memory\u001b[39m=\u001b[39;49min_memory)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_reader.py:236\u001b[0m, in \u001b[0;36mBaseReader.read_files\u001b[1;34m(self, files, original_instructions, in_memory)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39m\"\"\"Returns single Dataset instance for the set of file instructions.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \n\u001b[0;32m    225\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39m    kwargs to build a Dataset instance.\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[39m# Prepend path to filename\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m pa_table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_files(files, in_memory\u001b[39m=\u001b[39;49min_memory)\n\u001b[0;32m    237\u001b[0m \u001b[39m# If original_instructions is not None, convert it to a human-readable NamedSplit\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m original_instructions \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_reader.py:171\u001b[0m, in \u001b[0;36mBaseReader._read_files\u001b[1;34m(self, files, in_memory)\u001b[0m\n\u001b[0;32m    169\u001b[0m     f[\u001b[39m\"\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path, f[\u001b[39m\"\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    170\u001b[0m \u001b[39mfor\u001b[39;00m f_dict \u001b[39min\u001b[39;00m files:\n\u001b[1;32m--> 171\u001b[0m     pa_table: Table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_table_from_filename(f_dict, in_memory\u001b[39m=\u001b[39;49min_memory)\n\u001b[0;32m    172\u001b[0m     pa_tables\u001b[39m.\u001b[39mappend(pa_table)\n\u001b[0;32m    173\u001b[0m pa_tables \u001b[39m=\u001b[39m [t \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m pa_tables \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(t) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_reader.py:306\u001b[0m, in \u001b[0;36mArrowReader._get_table_from_filename\u001b[1;34m(self, filename_skip_take, in_memory)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[39m\"\"\"Returns a Dataset instance from given (filename, skip, take).\"\"\"\u001b[39;00m\n\u001b[0;32m    301\u001b[0m filename, skip, take \u001b[39m=\u001b[39m (\n\u001b[0;32m    302\u001b[0m     filename_skip_take[\u001b[39m\"\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    303\u001b[0m     filename_skip_take[\u001b[39m\"\u001b[39m\u001b[39mskip\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mskip\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m filename_skip_take \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    304\u001b[0m     filename_skip_take[\u001b[39m\"\u001b[39m\u001b[39mtake\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtake\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m filename_skip_take \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    305\u001b[0m )\n\u001b[1;32m--> 306\u001b[0m table \u001b[39m=\u001b[39m ArrowReader\u001b[39m.\u001b[39;49mread_table(filename, in_memory\u001b[39m=\u001b[39;49min_memory)\n\u001b[0;32m    307\u001b[0m \u001b[39m# here we don't want to slice an empty table, or it may segfault\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[39mif\u001b[39;00m skip \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m take \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m (skip \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m take \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(table)):\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_reader.py:325\u001b[0m, in \u001b[0;36mArrowReader.read_table\u001b[1;34m(filename, in_memory)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \u001b[39mRead table from file.\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[39m    pyarrow.Table\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    324\u001b[0m table_cls \u001b[39m=\u001b[39m InMemoryTable \u001b[39mif\u001b[39;00m in_memory \u001b[39melse\u001b[39;00m MemoryMappedTable\n\u001b[1;32m--> 325\u001b[0m \u001b[39mreturn\u001b[39;00m table_cls\u001b[39m.\u001b[39;49mfrom_file(filename)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\table.py:977\u001b[0m, in \u001b[0;36mMemoryMappedTable.from_file\u001b[1;34m(cls, filename, replays)\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    976\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_file\u001b[39m(\u001b[39mcls\u001b[39m, filename: \u001b[39mstr\u001b[39m, replays\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 977\u001b[0m     table \u001b[39m=\u001b[39m _memory_mapped_arrow_table_from_file(filename)\n\u001b[0;32m    978\u001b[0m     table \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_apply_replays(table, replays)\n\u001b[0;32m    979\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(table, filename, replays)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\table.py:51\u001b[0m, in \u001b[0;36m_memory_mapped_arrow_table_from_file\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     49\u001b[0m memory_mapped_stream \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39mmemory_map(filename)\n\u001b[0;32m     50\u001b[0m opened_stream \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39mipc\u001b[39m.\u001b[39mopen_stream(memory_mapped_stream)\n\u001b[1;32m---> 51\u001b[0m pa_table \u001b[39m=\u001b[39m opened_stream\u001b[39m.\u001b[39;49mread_all()\n\u001b[0;32m     52\u001b[0m \u001b[39mreturn\u001b[39;00m pa_table\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "access_token = \"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\"\n",
    "write_token = \"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\"\n",
    "# login(token=access_token)\n",
    "dataset_boat24 = load_dataset(\"cringgaard/boats_dataset\" , use_auth_token=access_token, split=\"boat24\")\n",
    "dataset = load_dataset(\"cringgaard/boats_dataset\" , use_auth_token=access_token, split=\"sailboatdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "# checkpoint = \"google/vit-base-patch16-224\"\n",
    "# model_name = \"ViT\"\n",
    "model_dir = \"D:/models/\"\n",
    "checkpoint = \"microsoft/resnet-18\"\n",
    "model_name = \"ResNet18\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "size = (\n",
    "    image_processor.size[\"shortest_edge\"]\n",
    "    if \"shortest_edge\" in image_processor.size\n",
    "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    ")\n",
    "_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "label_types = [\"Hull Type\" , \"Rigging Type\" ,  \"Construction\" , \"Ballast Type\" , \"Designer\"]\n",
    "# label_types = [\"Rigging Type\" , \"Construction\" , \"Ballast Type\" , \"Designer\"]\n",
    "# label_types = [\"Hull Type\" , \"Rigging Type\"]\n",
    "label_maps = {\n",
    "    \"Hull Type\" : Hull_Type_Classes,\n",
    "    \"Rigging Type\" : Rigging_Type_Classes,\n",
    "    \"Construction\" : Construction_Classes,\n",
    "    \"Ballast Type\" : Ballast_Type_Classes,\n",
    "    \"Designer\" : Designer_Classes\n",
    "}\n",
    "# label_types = [\"Ballast Type\" , \"Designer\"]\n",
    "# label_types = [\"Designer\"]\n",
    "# losses = [\"CE\" , \"WeightedCE\"]\n",
    "# losses = [\"WeightedCE\"]\n",
    "losses = [\"CE\"]\n",
    "batch_sizes = [16]\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions = eval_pred.predictions\n",
    "    labels = eval_pred.label_ids\n",
    "\n",
    "    # print(\"Predictions\",predictions)\n",
    "    # print(\"Labels\",labels)\n",
    "\n",
    "    predictions = predictions.argmax(axis=1)\n",
    "\n",
    "    if len(np.shape(labels)) > 1:\n",
    "        # print(\"Several Labels\")\n",
    "        labels = np.transpose(labels)[-1]\n",
    "        # print(\"Labels\",labels)\n",
    "\n",
    "    metrics = {}\n",
    "    metrics.update(accuracy.compute(predictions=predictions, references=labels))\n",
    "    metrics.update(f1.compute(predictions=predictions, references=labels , average=\"macro\"))\n",
    "    metrics.update(precision.compute(predictions=predictions, references=labels , average=\"macro\"))\n",
    "    metrics.update(recall.compute(predictions=predictions, references=labels , average=\"macro\"))\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compute_metrics_multitask(eval_pred):\n",
    "        predictions = eval_pred.predictions\n",
    "        labels = np.transpose(eval_pred.label_ids)\n",
    "        metrics = {}\n",
    "\n",
    "        # for i , head in enumerate(labels.keys()):\n",
    "        #     preds[head] = predictions[i]\n",
    "        \n",
    "        # predictions = preds\n",
    "\n",
    "        # for head in labels.keys():\n",
    "        for i , head in enumerate(label_types):\n",
    "            predicted_labels = predictions[i].argmax(axis=1)\n",
    "            # print(\"Predicted Labels :\",predicted_labels)\n",
    "            # print(\"True Labels :\",labels[i])\n",
    "            # print(\"Predicted Labels Shape :\",predicted_labels.shape)\n",
    "            # print(\"True Labels Shape :\",labels[i].shape)\n",
    "            f1 = f1_score(labels[i], predicted_labels, average='macro')\n",
    "            accuracy = accuracy_score(labels[i], predicted_labels)\n",
    "            metrics[f'{label_types[i]}_f1'] = f1\n",
    "            metrics[f'{label_types[i]}_accuracy'] = accuracy\n",
    "\n",
    "        return metrics\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testModel = MultitaskViT()\n",
    "# outputs = testModel(**{'pixel_values' : test_images})\n",
    "# print([x.shape for x in outputs])\n",
    "# # compute_metrics_multitask(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for gradient_accumulation_step in batch_sizes:\n",
    "# wandb.init(project=\"Sailboat FGVC\", name=model_name+\"_multitask\")\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# dataset_specific = dataset['full'].train_test_split(test_size=0.2, shuffle=True, seed=43)\n",
    "\n",
    "# def transforms(examples):\n",
    "#     examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "#     del examples[\"img_path\"]\n",
    "#     del examples[\"name\"]\n",
    "#     return examples\n",
    "\n",
    "\n",
    "# # id2label = {float(i): label for i, label in enumerate(label_types)}\n",
    "# # label2id = {label: float(i) for i, label in enumerate(label_types)}\n",
    "\n",
    "\n",
    "# dataset_specific = dataset_specific.with_transform(transforms)\n",
    "# # dataset_specific.set_format(type=\"torch\")\n",
    "# data_collator = DefaultDataCollator()\n",
    "\n",
    "# model = MultitaskViT()\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"E:/models/\"+model_name+\"_multitask\",\n",
    "#     report_to=\"wandb\",\n",
    "#     remove_unused_columns=False,\n",
    "#     evaluation_strategy=\"steps\",\n",
    "#     save_strategy=\"steps\",\n",
    "#     learning_rate=5e-5,\n",
    "#     per_device_train_batch_size=16,\n",
    "#     gradient_accumulation_steps=2,\n",
    "#     per_device_eval_batch_size=16,\n",
    "#     num_train_epochs=100,\n",
    "#     warmup_ratio=0.1,\n",
    "#     logging_steps=10,\n",
    "#     load_best_model_at_end=True,\n",
    "#     metric_for_best_model=\"f1\",\n",
    "#     # no_cuda=True\n",
    "#     # push_to_hub=True,\n",
    "# )\n",
    "\n",
    "# trainer = MultiTaskTrainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     data_collator=data_collator,\n",
    "#     train_dataset=dataset_specific[\"train\"],\n",
    "#     eval_dataset=dataset_specific[\"test\"],\n",
    "#     tokenizer=image_processor,\n",
    "#     compute_metrics=compute_metrics_multitask,\n",
    "    \n",
    "# )\n",
    "\n",
    "# trainer.train()\n",
    "# wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for label_type in label_types:\n",
    "#     name = \"Baseline_\"+label_type\n",
    "#     # wandb.init(project=\"Sailboat FGVC\", name=name)\n",
    "#     torch.cuda.empty_cache()\n",
    "#     c_names = dataset.column_names[1:]\n",
    "#     c_names.remove(label_type)\n",
    "#     dataset_specific = dataset.remove_columns(c_names)\n",
    "\n",
    "#     labels = dataset.features[label_type].names\n",
    "#     id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "#     label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "\n",
    "#     dataset_specific = dataset_specific.train_test_split(test_size=0.2, shuffle=True, seed=43)\n",
    "\n",
    "#     labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "#     labels_to_remove = np.where(labels_train_counts < 2)[0] # remove labels with less than 2 examples\n",
    "#     dataset_specific['train'] = dataset_specific['train'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "#     dataset_specific['test'] = dataset_specific['test'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "#     labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "#     y_pred = labels_train_counts/labels_train_counts.sum()\n",
    "#     y_pred = (np.array([y_pred]*len(dataset_specific['test'][label_type])))\n",
    "#     baseline_metrics = compute_metrics([y_pred, dataset_specific['test'][label_type]])\n",
    "#     baseline_metrics = {\"eval/\"+ key: val for key, val in baseline_metrics.items()}\n",
    "#     print(baseline_metrics)\n",
    "#     # wandb.log(baseline_metrics)\n",
    "#     wandb.log\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_size in batch_sizes:\n",
    "#     for loss in losses:\n",
    "#         for label_type in label_types: \n",
    "#             tags = [model_name , label_type, loss, str(batch_size)]\n",
    "#             name = \"_\".join(tags)\n",
    "#             wandb.init(project=wandb_project, name=name , group = label_type , tags = tags)\n",
    "#             torch.cuda.empty_cache()\n",
    "#             c_names = dataset.column_names[1:]\n",
    "#             c_names.remove(label_type)\n",
    "#             # Map labels to ids using label map\n",
    "#             dataset_specific = dataset.remove_columns(c_names)\n",
    "#             labels = dataset.features[label_type].names\n",
    "\n",
    "#             dataset_specific = dataset_specific.train_test_split(test_size=0.2, shuffle=True, seed=43)\n",
    "\n",
    "#             labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "#             labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "#             labels_to_remove = np.where(labels_train_counts < 1)[0] # remove labels with less than 2 examples\n",
    "#             labels_to_remove = np.union1d(labels_to_remove, np.where(labels_test_counts < 1)[0])\n",
    "#             # dataset_specific['train'] = dataset_specific['train'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "#             dataset_specific['test'] = dataset_specific['test'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "\n",
    "#             id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "#             label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "\n",
    "#             dataset_specific['train'] = dataset_specific['train'].filter(lambda x: id2label[x[label_type]] not in [\"NaN\"])\n",
    "#             dataset_specific['test'] = dataset_specific['test'].filter(lambda x: id2label[x[label_type]] not in [\"NaN\"])\n",
    "\n",
    "#             id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "#             label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "\n",
    "#             labels = [id2label[label2id[x]] for x in labels]\n",
    "            \n",
    "#             labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "#             labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "\n",
    "#             if loss == \"WeightedCE\":\n",
    "#                 weights = np.array([1 if x == 0 else x for x in labels_train_counts])\n",
    "#                 weights = (1/weights)\n",
    "#                 weights /= weights.sum()\n",
    "#                 weights = torch.tensor(weights, dtype=torch.float , device=torch.device(\"cuda:0\"))\n",
    "\n",
    "#                 class WeightedCETrainer(Trainer):\n",
    "#                     def __init__(self, *args, **kwargs):\n",
    "#                         super().__init__(*args, **kwargs)\n",
    "#                     def compute_loss(self, model, inputs, return_outputs=False):\n",
    "#                         labels = inputs.get(\"labels\")\n",
    "#                         labels.to(torch.device(\"cuda:0\"))\n",
    "#                         outputs = model(**inputs)\n",
    "#                         logits = outputs.get(\"logits\")\n",
    "#                         # loss_fct = nn.CrossEntropyLoss(weight=weights , label_smoothing=0.1)\n",
    "#                         loss_fct = nn.CrossEntropyLoss(weight=weights)\n",
    "#                         loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "#                         return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "#             def transforms(examples):\n",
    "#                 examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "#                 examples[\"labels\"] = examples[label_type]\n",
    "#                 del examples[label_type]\n",
    "#                 del examples[\"img_path\"]\n",
    "#                 return examples\n",
    "\n",
    "#             data_collator = DefaultDataCollator()\n",
    "\n",
    "#             model = ResNetForImageClassification.from_pretrained(\n",
    "#                 checkpoint,\n",
    "#                 num_labels=len(labels),\n",
    "#                 id2label=id2label,\n",
    "#                 label2id=label2id,\n",
    "#                 use_auth_token=access_token,\n",
    "#                 ignore_mismatched_sizes=True,\n",
    "#             )\n",
    "\n",
    "#             training_args = TrainingArguments(\n",
    "#                 output_dir=model_dir+name,\n",
    "#                 report_to=\"wandb\",\n",
    "#                 remove_unused_columns=False,\n",
    "#                 evaluation_strategy=\"epoch\",\n",
    "#                 logging_strategy=\"epoch\",\n",
    "#                 save_strategy=\"epoch\",\n",
    "#                 # eval_steps = 10,\n",
    "#                 # logging_steps = 10,\n",
    "#                 # save_steps = 10,\n",
    "#                 save_total_limit=10,\n",
    "#                 learning_rate=5e-5,\n",
    "#                 per_device_train_batch_size=batch_size,\n",
    "#                 gradient_accumulation_steps=1,\n",
    "#                 per_device_eval_batch_size=batch_size,\n",
    "#                 num_train_epochs=EPOCHS,\n",
    "#                 warmup_ratio=0.1,\n",
    "#                 load_best_model_at_end=True,\n",
    "#                 metric_for_best_model=\"f1\",\n",
    "#                 # label_smoothing_factor=0.1,\n",
    "#                 # no_cuda=True\n",
    "#                 # push_to_hub=True,\n",
    "#                 # hub_strategy=\"end\",\n",
    "#                 # hub_model_id=\"boats_dataset\",\n",
    "#                 # hub_token=write_token,\n",
    "#             )\n",
    "#             if loss == \"CE\":\n",
    "#                 trainer = Trainer(\n",
    "#                 model=model,\n",
    "#                 args=training_args,\n",
    "#                 data_collator=data_collator,\n",
    "#                 train_dataset=dataset_specific[\"train\"].with_transform(transforms),\n",
    "#                 eval_dataset=dataset_specific[\"test\"].with_transform(transforms),\n",
    "#                 tokenizer=image_processor,\n",
    "#                 compute_metrics=compute_metrics,\n",
    "#                 )\n",
    "#             elif loss == \"WeightedCE\":\n",
    "#                 trainer = WeightedCETrainer(\n",
    "#                     model=model,\n",
    "#                     args=training_args,\n",
    "#                     data_collator=data_collator,\n",
    "#                     train_dataset=dataset_specific[\"train\"].with_transform(transforms),\n",
    "#                     eval_dataset=dataset_specific[\"test\"].with_transform(transforms),\n",
    "#                     tokenizer=image_processor,\n",
    "#                     compute_metrics=compute_metrics,\n",
    "#                 )\n",
    "#             # Plot Label Distribution For Training Data\n",
    "#             fig1 = plt.figure()\n",
    "#             ax = fig1.add_axes([0,0,1,1])\n",
    "#             ax.bar([label2id[x] for x in labels], labels_train_counts/labels_train_counts.sum()) # Normalized\n",
    "#             ax.set_ylabel(\"Number of examples normalised\")\n",
    "#             ax.set_title(\"Label Distribution\")\n",
    "#             wandb.log({\"Label Distribution Train\": (fig1)})\n",
    "\n",
    "#             # Plot Label Distribution For Test Data\n",
    "#             fig2 = plt.figure()\n",
    "#             ax = fig2.add_axes([0,0,1,1])\n",
    "#             ax.bar([label2id[x] for x in labels], labels_test_counts/labels_test_counts.sum()) # Normalized\n",
    "#             ax.set_ylabel(\"Number of examples normalised\")\n",
    "#             ax.set_title(\"Label Distribution\")\n",
    "#             wandb.log({\"Label Distribution Test\": (fig2)})\n",
    "\n",
    "#             # Log label2id\n",
    "#             wandb.log({\"Labels\": wandb.Table(data = list(zip(label2id.keys() , label2id.values())) , columns=[\"Label\" , \"ID\"])})\n",
    "\n",
    "#             # Train Model\n",
    "#             trainer.train()\n",
    "\n",
    "#             # Save Model\n",
    "#             trainer.save_model(model_dir+name)\n",
    "\n",
    "#             pipeline = ImageClassificationPipeline(model=trainer.model, feature_extractor = trainer.tokenizer , framework=\"pt\", device=0)\n",
    "#             predict_data = dataset_specific['test'].select(np.random.randint(0, len(dataset_specific['test']), batch_size))\n",
    "#             images = [predict_data['img_path'][i] for i in range(batch_size)]\n",
    "#             predictions = pipeline(images)\n",
    "#             prediction_table = []\n",
    "#             for i in range(len(predictions)):\n",
    "#                 prediction_table.append([wandb.Image(images[i]) , predictions[i] , id2label[predict_data[label_type][i]]])\n",
    "#             columns = [\"Image\" , \"Label Predictions\" , \"True Label\"]\n",
    "#             wandb.log({\"Image Predicitions\" : wandb.Table(data=prediction_table, columns=columns)})\n",
    "\n",
    "#             # Plot confusion matrix\n",
    "#             y_pred = trainer.predict(dataset_specific['test'].with_transform(transforms)).predictions.argmax(-1)\n",
    "#             y_true = dataset_specific[\"test\"][label_type]\n",
    "#             wandb.log({\"Confusion Matrix\": wandb.sklearn.plot_confusion_matrix(y_true, y_pred, labels=labels)})\n",
    "#             wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multitask Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedModel\n",
    "from transformers.models.resnet.modeling_resnet import ImageClassifierOutputWithNoAttention\n",
    "from typing import Optional\n",
    "\n",
    "class ResNetCustomModel(PreTrainedModel):\n",
    "    def __init__(self, config, num_classes_list):\n",
    "        super().__init__(config)\n",
    "        self.num_classes_list = num_classes_list\n",
    "        self.resnet = ResNetModel.from_pretrained(\"microsoft/resnet-18\")\n",
    "        self.heads = nn.ModuleList([nn.Sequential(nn.Flatten() , nn.Linear(512, num_classes)) for num_classes in num_classes_list])\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        pixel_values: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> ImageClassifierOutputWithNoAttention:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the image classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.resnet(pixel_values, output_hidden_states=output_hidden_states, return_dict=return_dict)\n",
    "        pooled_outputs = outputs.pooler_output if return_dict else outputs[1]\n",
    "        class_logits = []\n",
    "        for head in self.heads:\n",
    "            class_logits.append(head(pooled_outputs))\n",
    "\n",
    "        loss = None\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = 0\n",
    "            i = 0\n",
    "            for logits in class_logits:\n",
    "                loss += self.criterion(logits, torch.transpose(labels,0,1)[i])\n",
    "                i += 1\n",
    "            loss = loss / len(class_logits)\n",
    "        \n",
    "        return ImageClassifierOutputWithNoAttention(loss=loss, logits=class_logits, hidden_states=outputs.hidden_states)\n",
    "\n",
    "\n",
    "from transformers import PretrainedConfig\n",
    "class ResNetCustomModelConfig(PretrainedConfig):\n",
    "    def __init__(self, num_classes_list = [Hull_Type_Classes.__len__(),Rigging_Type_Classes.__len__(),Construction_Classes.__len__(),Ballast_Type_Classes.__len__(),Designer_Classes.__len__()], label2id = None , **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_classes_list = num_classes_list\n",
    "        self.hidden_size = 512  # Specify the hidden size of the model\n",
    "        self.num_labels = sum(num_classes_list)  # Total number of labels across all classification heads\n",
    "        self.label2id = label2id if label2id is not None else {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make a list containing all combinations of the list of label types\n",
    "# import itertools\n",
    "# label_combinations = list(itertools.combinations(label_types, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for label_combination in label_combinations:\n",
    "#     label_types = [label_combination[0] , label_combination[1]]\n",
    "#     print(label_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_image_search = load_dataset(\"cringgaard/boats_dataset\" , use_auth_token=access_token, split=\"image_search\")\n",
    "# for batch_size in batch_sizes:\n",
    "#     # for label_combination in label_combinations:\n",
    "#         # label_types = [label_combination[0] , label_combination[1]]\n",
    "#         label_types = [\"Hull Type\" , \"Rigging Type\" ,  \"Construction\" , \"Ballast Type\" , \"Designer\"]\n",
    "#         tags = [model_name , 'multitask' , \"image_search\"]+label_types\n",
    "#         name = name = \"_\".join(tags)\n",
    "#         wandb.init(project=wandb_project, name=name , tags=tags)\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "#         dataset_specific = dataset_image_search.remove_columns('name')\n",
    "\n",
    "#         dataset_specific = dataset_specific.train_test_split(test_size=0.1, shuffle=True, seed=42)\n",
    "\n",
    "\n",
    "#         for label_type in label_types:\n",
    "#             labels = np.unique(dataset_specific['train'][label_type])\n",
    "#             labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "#             labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "#             labels_to_remove = np.where(labels_train_counts < 1)[0] # remove labels with less than 2 examples\n",
    "#             labels_to_remove = np.union1d(labels_to_remove, np.where(labels_test_counts < 1)[0])\n",
    "#             # dataset_specific['train'] = dataset_specific['train'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "#             dataset_specific['test'] = dataset_specific['test'].filter(lambda x: x[label_type] not in labels_to_remove)            \n",
    "#             labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "#             labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "\n",
    "#         def transforms(examples):\n",
    "#             examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "#             # examples[\"labels\"] = {label_type : examples[label_type] for label_type in label_types}\n",
    "#             labs = [examples[label_type] for label_type in label_types]\n",
    "#             examples['labels'] = list(map(list, zip(*labs)))\n",
    "#             # Remove all other keys in dictionary\n",
    "#             for key in list(examples.keys()):\n",
    "#                 if key not in [\"pixel_values\" , \"labels\"]:\n",
    "#                     del examples[key]\n",
    "#             return examples\n",
    "        \n",
    "#         data_collator = DefaultDataCollator()\n",
    "#         device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#         num_classes_list = [\n",
    "#                 Hull_Type_Classes.__len__(),\n",
    "#                 Rigging_Type_Classes.__len__(),\n",
    "#                 Construction_Classes.__len__(),\n",
    "#                 Ballast_Type_Classes.__len__(),\n",
    "#                 Designer_Classes.__len__()\n",
    "#         ]\n",
    "#         label2id = {\n",
    "#             \"Hull Type\" : {v : k for k, v in Hull_Type_Classes.items()},\n",
    "#             \"Rigging Type\" : {v : k for k, v in Rigging_Type_Classes.items()},\n",
    "#             \"Construction\" : {v : k for k, v in Construction_Classes.items()},\n",
    "#             \"Ballast Type\" : {v : k for k, v in Ballast_Type_Classes.items()},\n",
    "#             \"Designer\" : {v : k for k, v in Designer_Classes.items()}\n",
    "#         }\n",
    "#         id2label = {\n",
    "#             \"Hull Type\" : Hull_Type_Classes,\n",
    "#             \"Rigging Type\" : Rigging_Type_Classes,\n",
    "#             \"Construction\" : Construction_Classes,\n",
    "#             \"Ballast Type\" : Ballast_Type_Classes,\n",
    "#             \"Designer\" : Designer_Classes\n",
    "#         }\n",
    "\n",
    "#         config = ResNetCustomModelConfig(num_classes_list, label2id=label2id)\n",
    "#         model = ResNetCustomModel(config , num_classes_list=num_classes_list)\n",
    "\n",
    "#         training_args = TrainingArguments(\n",
    "#             output_dir=model_dir+name,\n",
    "#             report_to=\"wandb\",\n",
    "#             remove_unused_columns=False,\n",
    "#             evaluation_strategy=\"epoch\",\n",
    "#             logging_strategy=\"epoch\",\n",
    "#             save_strategy=\"epoch\",\n",
    "#             eval_steps = 10,\n",
    "#             logging_steps = 10,\n",
    "#             # save_steps = 10,\n",
    "#             save_total_limit=1,\n",
    "#             learning_rate=5e-5,\n",
    "#             per_device_train_batch_size=batch_size,\n",
    "#             gradient_accumulation_steps=1,\n",
    "#             per_device_eval_batch_size=batch_size,\n",
    "#             num_train_epochs=EPOCHS,\n",
    "#             warmup_ratio=0.1,\n",
    "#         )\n",
    "\n",
    "#         trainer = Trainer(\n",
    "#             model=model,\n",
    "#             args=training_args,\n",
    "#             data_collator=data_collator,\n",
    "#             train_dataset=dataset_specific[\"train\"].with_transform(transforms),\n",
    "#             eval_dataset=dataset_specific[\"test\"].with_transform(transforms),\n",
    "#             tokenizer=image_processor,\n",
    "#             compute_metrics = compute_metrics_multitask,\n",
    "#         )\n",
    "#         trainer.train()\n",
    "#         trainer.save_model(model_dir+name)\n",
    "#         wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_image_search = load_dataset(\"cringgaard/boats_dataset\" , use_auth_token=access_token, split=\"image_search\")\n",
    "# label_types = [\"Hull Type\" , \"Rigging Type\" ,  \"Construction\" , \"Ballast Type\" , \"Designer\"]\n",
    "# for batch_size in batch_sizes:\n",
    "#     # for label_combination in label_combinations:\n",
    "#         # label_types = [label_combination[0] , label_combination[1]]\n",
    "#         name = model_name+\"_Multitask\" #_Image_Search\"\n",
    "#         for label_type in label_types:\n",
    "#             name += \"_\"+label_type\n",
    "#         wandb.init(project=wandb_project, name=name , tags = [model_name , 'multitask']+label_types)\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "#         # c_names = dataset.column_names[1:]\n",
    "#         # c_names.remove(label_types[0])\n",
    "#         # c_names.remove(label_types[1])\n",
    "\n",
    "#         dataset_specific = dataset.remove_columns('name')\n",
    "\n",
    "#         dataset_specific = dataset.train_test_split(test_size=0.2, shuffle=True, seed=43)\n",
    "#         dataset_specific['train'] = concatenate_datasets([dataset_specific['train'] , dataset_image_search])\n",
    "\n",
    "\n",
    "#         for label_type in label_types:\n",
    "#             labels = np.unique(dataset_specific['train'][label_type])\n",
    "#             labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "#             labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "#             labels_to_remove = np.where(labels_train_counts < 1)[0] # remove labels with less than 2 examples\n",
    "#             labels_to_remove = np.union1d(labels_to_remove, np.where(labels_test_counts < 1)[0])\n",
    "#             # dataset_specific['train'] = dataset_specific['train'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "#             dataset_specific['test'] = dataset_specific['test'].filter(lambda x: x[label_type] not in labels_to_remove)            \n",
    "#             labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "#             labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "\n",
    "#         def transforms(examples):\n",
    "#             examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "#             # Remove all other keys in dictionary\n",
    "#             for key in list(examples.keys()):\n",
    "#                 if key not in label_types+[\"pixel_values\"]:\n",
    "#                     del examples[key]\n",
    "#             return examples\n",
    "        \n",
    "#         data_collator = DefaultDataCollator()\n",
    "#         device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#         model = MultitaskResnet(device)\n",
    "\n",
    "#         training_args = TrainingArguments(\n",
    "#             output_dir=model_dir+name,\n",
    "#             report_to=\"wandb\",\n",
    "#             remove_unused_columns=False,\n",
    "#             evaluation_strategy=\"epoch\",\n",
    "#             logging_strategy=\"epoch\",\n",
    "#             save_strategy=\"epoch\",\n",
    "#             eval_steps = 10,\n",
    "#             logging_steps = 10,\n",
    "#             # save_steps = 10,\n",
    "#             save_total_limit=1,\n",
    "#             learning_rate=5e-5,\n",
    "#             per_device_train_batch_size=batch_size,\n",
    "#             gradient_accumulation_steps=1,\n",
    "#             per_device_eval_batch_size=batch_size,\n",
    "#             num_train_epochs=EPOCHS,\n",
    "#             warmup_ratio=0.1,\n",
    "#         )\n",
    "\n",
    "#         trainer = MultitaskTrainer(\n",
    "#             model=model,\n",
    "#             args=training_args,\n",
    "#             data_collator=data_collator,\n",
    "#             train_dataset=dataset_specific[\"train\"].with_transform(transforms),\n",
    "#             eval_dataset=dataset_specific[\"test\"].with_transform(transforms),\n",
    "#             tokenizer=image_processor,\n",
    "#             compute_metrics = MultitaskTrainer.compute_metrics,\n",
    "#             label_types=label_types,\n",
    "#         )\n",
    "#         print(trainer.label_types)\n",
    "#         trainer.train()\n",
    "#         trainer.save_model(model_dir+name)\n",
    "\n",
    "#         from collections import namedtuple\n",
    "#         predictions = trainer.predict(dataset_specific['test'].with_transform(transforms)).predictions\n",
    "#         labels = {}\n",
    "#         for label_type in label_types:\n",
    "#             labels[label_type] = (dataset_specific['test'][label_type])\n",
    "#         # Make tuple of labels\n",
    "#         labels = tuple(labels.values())\n",
    "#         eval_pred = namedtuple(\"EvalPrediction\", [\"predictions\", \"label_ids\"])\n",
    "#         metrics = trainer.compute_metrics(trainer , eval_pred(predictions, labels))\n",
    "#         print(metrics)\n",
    "#         wandb.log(metrics)\n",
    "#         wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = MultitaskTrainer.compute_metrics(trainer , eval_pred(predictions, labels))\n",
    "# print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import namedtuple\n",
    "# predictions = trainer.predict(dataset_specific['test'].with_transform(transforms)).predictions\n",
    "# labels = (dataset_specific['test'][label_types[0]] , dataset_specific['test'][label_types[1]], dataset_specific['test'][label_types[2]] , dataset_specific['test'][label_types[3]] , dataset_specific['test'][label_types[4]])\n",
    "# eval_pred = namedtuple(\"EvalPrediction\", [\"predictions\", \"label_ids\"])\n",
    "# metrics = compute_metrics_multitask(eval_pred(predictions, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lab_types = list(dataset_specific['test'].features.items())[1:-1]\n",
    "# for i in range(len(lab_types)):\n",
    "#     lab_types[i] = lab_types[i][0]\n",
    "# # Construct a dictionary of label_type and dataset labels\n",
    "# labels = {}\n",
    "# for label in lab_types:\n",
    "#     labels[label] = {label : dataset_specific['test'][label]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = {key : value for key , value in dataset_specific['test'].features.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Data Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boat24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_size in batch_sizes:\n",
    "#     for label_type in label_types:\n",
    "#         tags = [model_name , label_type , 'boat24']\n",
    "#         name = \"_\".join(tags)\n",
    "#         wandb.init(project=wandb_project, name=name , group = label_type , tags = tags)\n",
    "#         torch.cuda.empty_cache()\n",
    "#         c_names = dataset.column_names[1:]\n",
    "#         c_names.remove(label_type)\n",
    "#         dataset_specific = dataset.remove_columns(c_names)\n",
    "#         labels = dataset.features[label_type].names\n",
    "#         dataset_boat24_specific = dataset_boat24.remove_columns(c_names)\n",
    "\n",
    "#         dataset_specific = dataset_specific.train_test_split(test_size=0.2, shuffle=True, seed=43)  # 80-20 split for train and test\n",
    "#         dataset_specific['train'] = concatenate_datasets([dataset_specific['train'] , dataset_boat24_specific]) # add boat24 dataset to training set\n",
    "        \n",
    "#         labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "#         labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "#         labels_to_remove = np.where(labels_train_counts < 1)[0] # remove labels with less than 2 examples\n",
    "#         labels_to_remove = np.union1d(labels_to_remove, np.where(labels_test_counts < 1)[0])\n",
    "#         # dataset_specific['train'] = dataset_specific['train'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "#         dataset_specific['test'] = dataset_specific['test'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "\n",
    "#         id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "#         label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "\n",
    "#         dataset_specific['train'] = dataset_specific['train'].filter(lambda x: id2label[x[label_type]] not in [\"NaN\"])\n",
    "#         dataset_specific['test'] = dataset_specific['test'].filter(lambda x: id2label[x[label_type]] not in [\"NaN\"])\n",
    "\n",
    "#         id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "#         label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "        \n",
    "#         labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "#         labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "\n",
    "#         labels = [id2label[label2id[x]] for x in labels]\n",
    "        \n",
    "\n",
    "#         def transforms(examples):\n",
    "#             examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "#             examples[\"labels\"] = examples[label_type]\n",
    "#             del examples[label_type]\n",
    "#             del examples[\"img_path\"]\n",
    "#             return examples\n",
    "#         data_collator = DefaultDataCollator()\n",
    "\n",
    "#         model = ResNetForImageClassification.from_pretrained(\n",
    "#             checkpoint,\n",
    "#             num_labels=len(labels),\n",
    "#             id2label=id2label,\n",
    "#             label2id=label2id,\n",
    "#             use_auth_token=access_token,\n",
    "#             ignore_mismatched_sizes=True,\n",
    "#         )\n",
    "\n",
    "#         training_args = TrainingArguments(\n",
    "#             output_dir=model_dir+name,\n",
    "#             report_to=\"wandb\",\n",
    "#             remove_unused_columns=False,\n",
    "#             evaluation_strategy=\"epoch\",\n",
    "#             logging_strategy=\"epoch\",\n",
    "#             save_strategy=\"epoch\",\n",
    "#             # eval_steps = 10,\n",
    "#             # logging_steps = 10,\n",
    "#             # save_steps = 10,\n",
    "#             save_total_limit=30,\n",
    "#             learning_rate=5e-5,\n",
    "#             per_device_train_batch_size=batch_size,\n",
    "#             gradient_accumulation_steps=1,\n",
    "#             per_device_eval_batch_size=batch_size,\n",
    "#             num_train_epochs=EPOCHS,\n",
    "#             warmup_ratio=0.1,\n",
    "#             load_best_model_at_end=True,\n",
    "#             metric_for_best_model=\"f1\",\n",
    "#             # label_smoothing_factor=0.1,\n",
    "#             # no_cuda=True\n",
    "#             # push_to_hub=True,\n",
    "#             # hub_strategy=\"end\",\n",
    "#             # hub_model_id=\"boats_dataset\",\n",
    "#             # hub_token=write_token,\n",
    "#         )\n",
    "\n",
    "#         trainer = Trainer(\n",
    "#             model=model,\n",
    "#             args=training_args,\n",
    "#             data_collator=data_collator,\n",
    "#             train_dataset=dataset_specific[\"train\"].with_transform(transforms),\n",
    "#             eval_dataset=dataset_specific[\"test\"].with_transform(transforms),\n",
    "#             tokenizer=image_processor,\n",
    "#             compute_metrics=compute_metrics,\n",
    "#         )\n",
    "#         # Plot Label Distribution For Training Data\n",
    "#         fig1 = plt.figure()\n",
    "#         ax = fig1.add_axes([0,0,1,1])\n",
    "#         ax.bar([label2id[x] for x in labels], labels_train_counts/labels_train_counts.sum()) # Normalized\n",
    "#         ax.set_ylabel(\"Number of examples normalised\")\n",
    "#         ax.set_title(\"Label Distribution\")\n",
    "#         wandb.log({\"Label Distribution Train\": (fig1)})\n",
    "\n",
    "#         # Plot Label Distribution For Test Data\n",
    "#         fig2 = plt.figure()\n",
    "#         ax = fig2.add_axes([0,0,1,1])\n",
    "#         ax.bar([label2id[x] for x in labels], labels_test_counts/labels_test_counts.sum()) # Normalized\n",
    "#         ax.set_ylabel(\"Number of examples normalised\")\n",
    "#         ax.set_title(\"Label Distribution\")\n",
    "#         wandb.log({\"Label Distribution Test\": (fig2)})\n",
    "\n",
    "#         # Log label2id\n",
    "#         wandb.log({\"Labels\": wandb.Table(data = list(zip(label2id.keys() , label2id.values())) , columns=[\"Label\" , \"ID\"])})\n",
    "\n",
    "#         # Train Model\n",
    "#         trainer.train()\n",
    "\n",
    "#         # Save Model\n",
    "#         trainer.save_model(model_dir+name)\n",
    "\n",
    "#         pipeline = ImageClassificationPipeline(model=trainer.model, feature_extractor = trainer.tokenizer , framework=\"pt\", device=0)\n",
    "#         predict_data = dataset_specific['test'].select(np.random.randint(0, len(dataset_specific['test']), batch_size))\n",
    "#         images = [predict_data['img_path'][i] for i in range(batch_size)]\n",
    "#         predictions = pipeline(images)\n",
    "#         prediction_table = []\n",
    "#         for i in range(len(predictions)):\n",
    "#             prediction_table.append([wandb.Image(images[i]) , predictions[i] , id2label[predict_data[label_type][i]]])\n",
    "#         columns = [\"Image\" , \"Label Predictions\" , \"True Label\"]\n",
    "#         wandb.log({\"Image Predicitions\" : wandb.Table(data=prediction_table, columns=columns)})\n",
    "\n",
    "#         # Plot confusion matrix\n",
    "#         y_pred = trainer.predict(dataset_specific['test'].with_transform(transforms)).predictions.argmax(-1)\n",
    "#         y_true = dataset_specific[\"test\"][label_type]\n",
    "#         wandb.log({\"Confusion Matrix\": wandb.sklearn.plot_confusion_matrix(y_true, y_pred, labels=labels)})\n",
    "#         wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_image_search = load_dataset(\"cringgaard/boats_dataset\" , use_auth_token=access_token, split=\"image_search\")\n",
    "# for batch_size in batch_sizes:\n",
    "#     for label_type in label_types:\n",
    "#         tags = [model_name , label_type , 'image_search' , 'EPOCHS'+str(EPOCHS)]\n",
    "#         name = \"_\".join(tags)\n",
    "#         wandb.init(project=wandb_project, name=name , group = label_type , tags = tags)\n",
    "#         torch.cuda.empty_cache()\n",
    "#         c_names = dataset.column_names[1:]\n",
    "#         c_names.remove(label_type)\n",
    "#         dataset_specific = dataset.remove_columns(c_names)\n",
    "#         labels = dataset.features[label_type].names\n",
    "#         dataset_image_search_specific = dataset_image_search.remove_columns(c_names)\n",
    "\n",
    "#         dataset_specific = dataset_specific.train_test_split(test_size=0.2, shuffle=True, seed=43)  # 80-20 split for train and test\n",
    "#         dataset_specific['train'] = concatenate_datasets([dataset_specific['train'] , dataset_image_search_specific]) # add image_search dataset to training set\n",
    "        \n",
    "#         labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "#         labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "#         labels_to_remove = np.where(labels_train_counts < 1)[0] # remove labels with less than 2 examples\n",
    "#         labels_to_remove = np.union1d(labels_to_remove, np.where(labels_test_counts < 1)[0])\n",
    "#         # dataset_specific['train'] = dataset_specific['train'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "#         dataset_specific['test'] = dataset_specific['test'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "\n",
    "#         id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "#         label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "\n",
    "#         dataset_specific['train'] = dataset_specific['train'].filter(lambda x: id2label[x[label_type]] not in [\"NaN\"])\n",
    "#         dataset_specific['test'] = dataset_specific['test'].filter(lambda x: id2label[x[label_type]] not in [\"NaN\"])\n",
    "\n",
    "#         id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "#         label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "        \n",
    "#         labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "#         labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "\n",
    "#         labels = [id2label[label2id[x]] for x in labels]\n",
    "        \n",
    "\n",
    "#         def transforms(examples):\n",
    "#             examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "#             examples[\"labels\"] = examples[label_type]\n",
    "#             del examples[label_type]\n",
    "#             del examples[\"img_path\"]\n",
    "#             return examples\n",
    "#         data_collator = DefaultDataCollator()\n",
    "\n",
    "#         model = ResNetForImageClassification.from_pretrained(\n",
    "#             checkpoint,\n",
    "#             num_labels=len(labels),\n",
    "#             id2label=id2label,\n",
    "#             label2id=label2id,\n",
    "#             use_auth_token=access_token,\n",
    "#             ignore_mismatched_sizes=True,\n",
    "#         )\n",
    "\n",
    "#         training_args = TrainingArguments(\n",
    "#             output_dir=model_dir+name,\n",
    "#             report_to=\"wandb\",\n",
    "#             remove_unused_columns=False,\n",
    "#             evaluation_strategy=\"epoch\",\n",
    "#             logging_strategy=\"epoch\",\n",
    "#             save_strategy=\"epoch\",\n",
    "#             # eval_steps = 10,\n",
    "#             # logging_steps = 10,\n",
    "#             # save_steps = 10,\n",
    "#             save_total_limit=30,\n",
    "#             learning_rate=5e-5,\n",
    "#             per_device_train_batch_size=batch_size,\n",
    "#             gradient_accumulation_steps=1,\n",
    "#             per_device_eval_batch_size=batch_size,\n",
    "#             num_train_epochs=EPOCHS,\n",
    "#             warmup_ratio=0.1,\n",
    "#             load_best_model_at_end=True,\n",
    "#             metric_for_best_model=\"f1\",\n",
    "#             # label_smoothing_factor=0.1,\n",
    "#             # no_cuda=True\n",
    "#             # push_to_hub=True,\n",
    "#             # hub_strategy=\"end\",\n",
    "#             # hub_model_id=\"boats_dataset\",\n",
    "#             # hub_token=write_token,\n",
    "#         )\n",
    "\n",
    "#         trainer = Trainer(\n",
    "#             model=model,\n",
    "#             args=training_args,\n",
    "#             data_collator=data_collator,\n",
    "#             train_dataset=dataset_specific[\"train\"].with_transform(transforms),\n",
    "#             eval_dataset=dataset_specific[\"test\"].with_transform(transforms),\n",
    "#             tokenizer=image_processor,\n",
    "#             compute_metrics=compute_metrics,\n",
    "#         )\n",
    "#         # Plot Label Distribution For Training Data\n",
    "#         fig1 = plt.figure()\n",
    "#         ax = fig1.add_axes([0,0,1,1])\n",
    "#         ax.bar([label2id[x] for x in labels], labels_train_counts/labels_train_counts.sum()) # Normalized\n",
    "#         ax.set_ylabel(\"Number of examples normalised\")\n",
    "#         ax.set_title(\"Label Distribution\")\n",
    "#         wandb.log({\"Label Distribution Train\": (fig1)})\n",
    "\n",
    "#         # Plot Label Distribution For Test Data\n",
    "#         fig2 = plt.figure()\n",
    "#         ax = fig2.add_axes([0,0,1,1])\n",
    "#         ax.bar([label2id[x] for x in labels], labels_test_counts/labels_test_counts.sum()) # Normalized\n",
    "#         ax.set_ylabel(\"Number of examples normalised\")\n",
    "#         ax.set_title(\"Label Distribution\")\n",
    "#         wandb.log({\"Label Distribution Test\": (fig2)})\n",
    "\n",
    "#         # Log label2id\n",
    "#         wandb.log({\"Labels\": wandb.Table(data = list(zip(label2id.keys() , label2id.values())) , columns=[\"Label\" , \"ID\"])})\n",
    "\n",
    "#         # Train Model\n",
    "#         trainer.train()\n",
    "\n",
    "#         # Save Model\n",
    "#         trainer.save_model(model_dir+name)\n",
    "\n",
    "#         pipeline = ImageClassificationPipeline(model=trainer.model, feature_extractor = trainer.tokenizer , framework=\"pt\", device=0)\n",
    "#         predict_data = dataset_specific['test'].select(np.random.randint(0, len(dataset_specific['test']), 100))\n",
    "#         images = [predict_data['img_path'][i] for i in range(100)]\n",
    "#         predictions = pipeline(images)\n",
    "#         prediction_table = []\n",
    "#         for i in range(len(predictions)):\n",
    "#             prediction_table.append([wandb.Image(images[i]) , predictions[i] , id2label[predict_data[label_type][i]]])\n",
    "#         columns = [\"Image\" , \"Label Predictions\" , \"True Label\"]\n",
    "#         wandb.log({\"Image Predicitions\" : wandb.Table(data=prediction_table, columns=columns)})\n",
    "\n",
    "#         # Plot confusion matrix\n",
    "#         y_pred = trainer.predict(dataset_specific['test'].with_transform(transforms)).predictions.argmax(-1)\n",
    "#         y_true = dataset_specific[\"test\"][label_type]\n",
    "#         wandb.log({\"Confusion Matrix\": wandb.sklearn.plot_confusion_matrix(y_true, y_pred, labels=labels)})\n",
    "#         wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For subnetworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_image_search = load_dataset(\"cringgaard/boats_dataset\" , use_auth_token=access_token, split=\"image_search\")\n",
    "# for batch_size in batch_sizes:\n",
    "#     for label_type in label_types:\n",
    "#         tags = [model_name , label_type , 'image_search' , 'EPOCHS'+str(EPOCHS)]\n",
    "#         name = \"_\".join(tags)\n",
    "#         wandb.init(project=wandb_project, name=name , group = label_type , tags = tags)\n",
    "#         torch.cuda.empty_cache()\n",
    "#         c_names = dataset.column_names[1:]\n",
    "#         c_names.remove(label_type)\n",
    "#         dataset_specific = dataset_image_search.remove_columns(c_names)\n",
    "#         labels = dataset.features[label_type].names\n",
    "\n",
    "#         dataset_specific = dataset_specific.train_test_split(test_size=0.1 , seed=42)\n",
    "        \n",
    "#         labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "#         labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "#         labels_to_remove = np.where(labels_train_counts < 1)[0] # remove labels with less than 2 examples\n",
    "#         labels_to_remove = np.union1d(labels_to_remove, np.where(labels_test_counts < 1)[0])\n",
    "#         # dataset_specific['train'] = dataset_specific['train'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "#         dataset_specific['test'] = dataset_specific['test'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "\n",
    "#         id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "#         label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "\n",
    "#         dataset_specific['train'] = dataset_specific['train'].filter(lambda x: id2label[x[label_type]] not in [\"NaN\"])\n",
    "#         dataset_specific['test'] = dataset_specific['test'].filter(lambda x: id2label[x[label_type]] not in [\"NaN\"])\n",
    "\n",
    "#         id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "#         label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "        \n",
    "#         labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "#         labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "\n",
    "#         labels = [id2label[label2id[x]] for x in labels]\n",
    "        \n",
    "\n",
    "#         def transforms(examples):\n",
    "#             examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "#             examples[\"labels\"] = examples[label_type]\n",
    "#             del examples[label_type]\n",
    "#             del examples[\"img_path\"]\n",
    "#             return examples\n",
    "#         data_collator = DefaultDataCollator()\n",
    "\n",
    "#         model = ResNetForImageClassification.from_pretrained(\n",
    "#             checkpoint,\n",
    "#             num_labels=len(labels),\n",
    "#             id2label=id2label,\n",
    "#             label2id=label2id,\n",
    "#             use_auth_token=access_token,\n",
    "#             ignore_mismatched_sizes=True,\n",
    "#         )\n",
    "\n",
    "#         training_args = TrainingArguments(\n",
    "#             output_dir=model_dir+name,\n",
    "#             report_to=\"wandb\",\n",
    "#             remove_unused_columns=False,\n",
    "#             evaluation_strategy=\"epoch\",\n",
    "#             logging_strategy=\"epoch\",\n",
    "#             save_strategy=\"epoch\",\n",
    "#             # eval_steps = 10,\n",
    "#             # logging_steps = 10,\n",
    "#             # save_steps = 10,\n",
    "#             save_total_limit=30,\n",
    "#             learning_rate=5e-5,\n",
    "#             per_device_train_batch_size=batch_size,\n",
    "#             gradient_accumulation_steps=1,\n",
    "#             per_device_eval_batch_size=batch_size,\n",
    "#             num_train_epochs=EPOCHS,\n",
    "#             warmup_ratio=0.1,\n",
    "#             load_best_model_at_end=True,\n",
    "#             metric_for_best_model=\"f1\",\n",
    "#             # label_smoothing_factor=0.1,\n",
    "#             # no_cuda=True\n",
    "#             # push_to_hub=True,\n",
    "#             # hub_strategy=\"end\",\n",
    "#             # hub_model_id=\"boats_dataset\",\n",
    "#             # hub_token=write_token,\n",
    "#         )\n",
    "\n",
    "#         trainer = Trainer(\n",
    "#             model=model,\n",
    "#             args=training_args,\n",
    "#             data_collator=data_collator,\n",
    "#             train_dataset=dataset_specific[\"train\"].with_transform(transforms),\n",
    "#             eval_dataset=dataset_specific[\"test\"].with_transform(transforms),\n",
    "#             tokenizer=image_processor,\n",
    "#             compute_metrics=compute_metrics,\n",
    "#         )\n",
    "#         # Plot Label Distribution For Training Data\n",
    "#         fig1 = plt.figure()\n",
    "#         ax = fig1.add_axes([0,0,1,1])\n",
    "#         ax.bar([label2id[x] for x in labels], labels_train_counts/labels_train_counts.sum()) # Normalized\n",
    "#         ax.set_ylabel(\"Number of examples normalised\")\n",
    "#         ax.set_title(\"Label Distribution\")\n",
    "#         wandb.log({\"Label Distribution Train\": (fig1)})\n",
    "\n",
    "#         # Plot Label Distribution For Test Data\n",
    "#         fig2 = plt.figure()\n",
    "#         ax = fig2.add_axes([0,0,1,1])\n",
    "#         ax.bar([label2id[x] for x in labels], labels_test_counts/labels_test_counts.sum()) # Normalized\n",
    "#         ax.set_ylabel(\"Number of examples normalised\")\n",
    "#         ax.set_title(\"Label Distribution\")\n",
    "#         wandb.log({\"Label Distribution Test\": (fig2)})\n",
    "\n",
    "#         # Log label2id\n",
    "#         wandb.log({\"Labels\": wandb.Table(data = list(zip(label2id.keys() , label2id.values())) , columns=[\"Label\" , \"ID\"])})\n",
    "\n",
    "#         # Train Model\n",
    "#         trainer.train()\n",
    "\n",
    "#         # Save Model\n",
    "#         trainer.save_model(model_dir+name)\n",
    "\n",
    "#         pipeline = ImageClassificationPipeline(model=trainer.model, feature_extractor = trainer.tokenizer , framework=\"pt\", device=0)\n",
    "#         predict_data = dataset_specific['test'].select(np.random.randint(0, len(dataset_specific['test']), 100))\n",
    "#         images = [predict_data['img_path'][i] for i in range(100)]\n",
    "#         predictions = pipeline(images)\n",
    "#         prediction_table = []\n",
    "#         for i in range(len(predictions)):\n",
    "#             prediction_table.append([wandb.Image(images[i]) , predictions[i] , id2label[predict_data[label_type][i]]])\n",
    "#         columns = [\"Image\" , \"Label Predictions\" , \"True Label\"]\n",
    "#         wandb.log({\"Image Predicitions\" : wandb.Table(data=prediction_table, columns=columns)})\n",
    "\n",
    "#         # Plot confusion matrix\n",
    "#         y_pred = trainer.predict(dataset_specific['test'].with_transform(transforms)).predictions.argmax(-1)\n",
    "#         y_true = dataset_specific[\"test\"][label_type]\n",
    "#         wandb.log({\"Confusion Matrix\": wandb.sklearn.plot_confusion_matrix(y_true, y_pred, labels=labels)})\n",
    "#         wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boat Class Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End to End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #launch tensorboard\n",
    "# %load_ext tensorboard\n",
    "# EPOCHS = 100\n",
    "# dataset_image_search = load_dataset(\"cringgaard/boats_dataset\" , use_auth_token=access_token, split=\"image_search\")\n",
    "# for batch_size in batch_sizes:\n",
    "#         tags = [model_name , \"Boat_Class\"]\n",
    "#         name = \"_\".join(tags)\n",
    "#         wandb.init(project=wandb_project, name=name , tags=[\"Boat_Class\"])\n",
    "#         torch.cuda.empty_cache()\n",
    "#         c_names = dataset.column_names[1:]\n",
    "#         c_names.remove('name')\n",
    "#         # NOTE boat24 has wrong labels\n",
    "#         # dataset_specific_test = dataset.remove_columns(c_names)\n",
    "#         # dataset_boat24_specific_train = dataset_boat24.remove_columns(c_names)\n",
    "#         # dataset_image_search_specific_train = dataset_image_search.remove_columns(c_names)\n",
    "#         dataset_specific = dataset_image_search.remove_columns(c_names)\n",
    "#         # Split into train and eval\n",
    "#         dataset_specific = dataset_specific.train_test_split(test_size=0.1 , seed=42)\n",
    "        \n",
    "#         labels = dataset.features['name'].names\n",
    "#         id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "#         label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "\n",
    "#         labels_train_counts = np.bincount(dataset_specific['train']['name'] , minlength=len(labels))\n",
    "#         labels_test_counts = np.bincount(dataset_specific['test']['name'] , minlength=len(labels))\n",
    "\n",
    "#         # weights = np.array([1 if x == 0 else x for x in labels_train_counts])\n",
    "#         # weights = (1/weights)\n",
    "#         # weights /= weights.sum()\n",
    "#         # weights = torch.tensor(weights, dtype=torch.float , device=torch.device(\"cuda:0\"))\n",
    "\n",
    "#         # class WeightedCETrainer(Trainer):\n",
    "#         #     def __init__(self, *args, **kwargs):\n",
    "#         #         super().__init__(*args, **kwargs)\n",
    "#         #     def compute_loss(self, model, inputs, return_outputs=False):\n",
    "#         #         labels = inputs.get(\"labels\")\n",
    "#         #         labels.to(torch.device(\"cuda:0\"))\n",
    "#         #         outputs = model(**inputs)\n",
    "#         #         logits = outputs.get(\"logits\")\n",
    "#         #         # loss_fct = nn.CrossEntropyLoss(weight=weights , label_smoothing=0.1)\n",
    "#         #         loss_fct = nn.CrossEntropyLoss(weight=weights)\n",
    "#         #         loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "#         #         return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "#         def transforms(examples):\n",
    "#             examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "#             examples[\"labels\"] = examples['name']\n",
    "#             del examples[\"name\"]\n",
    "#             del examples[\"img_path\"]\n",
    "#             return examples\n",
    "#         data_collator = DefaultDataCollator()\n",
    "\n",
    "#         model = AutoModelForImageClassification.from_pretrained(\n",
    "#             checkpoint,\n",
    "#             num_labels=len(labels),\n",
    "#             id2label=id2label,\n",
    "#             label2id=label2id,\n",
    "#             use_auth_token=access_token,\n",
    "#             ignore_mismatched_sizes=True,\n",
    "#         )\n",
    "\n",
    "#         training_args = TrainingArguments(\n",
    "#             output_dir=model_dir+name,\n",
    "#             report_to=\"tensorboard\",\n",
    "#             remove_unused_columns=False,\n",
    "#             evaluation_strategy=\"epoch\",\n",
    "#             logging_strategy=\"epoch\",\n",
    "#             save_strategy=\"epoch\",\n",
    "#             # eval_steps = 10,\n",
    "#             # logging_steps = 10,\n",
    "#             # save_steps = 10,\n",
    "#             save_total_limit=30,\n",
    "#             learning_rate=5e-5,\n",
    "#             per_device_train_batch_size=batch_size,\n",
    "#             gradient_accumulation_steps=1,\n",
    "#             per_device_eval_batch_size=batch_size,\n",
    "#             num_train_epochs=EPOCHS,\n",
    "#             warmup_ratio=0.1,\n",
    "#             load_best_model_at_end=True,\n",
    "#             metric_for_best_model=\"accuracy\",\n",
    "#             # label_smoothing_factor=0.1,\n",
    "#             # no_cuda=True\n",
    "#             # push_to_hub=True,\n",
    "#             # hub_strategy=\"end\",\n",
    "#             # hub_model_id=\"boats_dataset\",\n",
    "#             # hub_token=write_token,\n",
    "#         )\n",
    "\n",
    "#         trainer = Trainer(\n",
    "#             model=model,\n",
    "#             args=training_args,\n",
    "#             data_collator=data_collator,\n",
    "#             train_dataset=dataset_specific['train'].with_transform(transforms),\n",
    "#             eval_dataset=dataset_specific['test'].with_transform(transforms),\n",
    "#             tokenizer=image_processor,\n",
    "#             compute_metrics=compute_metrics,\n",
    "#         )\n",
    "#         # # Plot Label Distribution For Training Data\n",
    "#         # fig1 = plt.figure()\n",
    "#         # ax = fig1.add_axes([0,0,1,1])\n",
    "#         # ax.bar([label2id[x] for x in labels], labels_train_counts/dataset_specific['train'].__len__()) # Normalized\n",
    "#         # ax.set_ylabel(\"Number of examples normalised\")\n",
    "#         # ax.set_title(\"Label Distribution\")\n",
    "#         # wandb.log({\"Label Distribution Train\": (fig1)})\n",
    "\n",
    "#         # # Plot Label Distribution For Test Data\n",
    "#         # fig2 = plt.figure()\n",
    "#         # ax = fig2.add_axes([0,0,1,1])\n",
    "#         # ax.bar([label2id[x] for x in labels], labels_test_counts/dataset_specific['test'].__len__()) # Normalized\n",
    "#         # ax.set_ylabel(\"Number of examples normalised\")\n",
    "#         # ax.set_title(\"Label Distribution\")\n",
    "#         # wandb.log({\"Label Distribution Test\": (fig2)})\n",
    "\n",
    "#         # # Log label2id\n",
    "#         # wandb.log({\"Labels\": wandb.Table(data = list(zip(label2id.keys() , label2id.values())) , columns=[\"Label\" , \"ID\"])})\n",
    "\n",
    "#         # Train Model\n",
    "#         trainer.train()\n",
    "\n",
    "#         # Save Model\n",
    "#         trainer.save_model(model_dir+name+\"/best_model\")\n",
    "\n",
    "#         pipeline = ImageClassificationPipeline(model=trainer.model, feature_extractor = trainer.tokenizer , framework=\"pt\", device=0)\n",
    "#         predict_data = dataset_specific['test'].select(np.random.randint(0, len(dataset_specific['test']), 100))\n",
    "#         images = [predict_data['img_path'][i] for i in range(100)]\n",
    "#         predictions = pipeline(images)\n",
    "#         prediction_table = []\n",
    "#         for i in range(len(predictions)):\n",
    "#             prediction_table.append([wandb.Image(images[i]) , predictions[i] , id2label[predict_data['name'][i]]])\n",
    "#         columns = [\"Image\" , \"Label Predictions\" , \"True Label\"]\n",
    "#         wandb.log({\"Image Predicitions\" : wandb.Table(data=prediction_table, columns=columns)})\n",
    "\n",
    "#         metrics = trainer.evaluate(dataset_specific['test'].with_transform(transforms))\n",
    "#         wandb.log(metrics)\n",
    "#         wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [model_name , label_types[0], losses[0], str(16)]\n",
    "name = \"_\".join(tags)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subnetworks Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BoatClassifier(nn.Module):\n",
    "#     def __init__(self, device):\n",
    "#         super(BoatClassifier, self).__init__()\n",
    "#         self.device = device\n",
    "#         self.subnetworks = {\n",
    "#             \"Hull Type\" : ResNetForImageClassification.from_pretrained(model_dir+\"ResNet18_Hull Type_image_search_EPOCHS20\"),\n",
    "#             \"Rigging Type\": ResNetForImageClassification.from_pretrained(model_dir+\"ResNet18_Rigging Type_image_search_EPOCHS20\"),\n",
    "#             \"Construction\": ResNetForImageClassification.from_pretrained(model_dir+\"ResNet18_Construction_image_search_EPOCHS20\"),\n",
    "#             \"Ballast Type\": ResNetForImageClassification.from_pretrained(model_dir+\"ResNet18_Ballast Type_image_search_EPOCHS20\"),\n",
    "#             \"Designer\": ResNetForImageClassification.from_pretrained(model_dir+\"ResNet18_Designer_image_search_EPOCHS20\"),\n",
    "#         }\n",
    "#         subnetwork_output_size = 0\n",
    "#         for key in self.subnetworks.keys():\n",
    "#             for param in self.subnetworks[key].parameters():\n",
    "#                 param.requires_grad = False\n",
    "#             self.subnetworks[key].to(self.device)\n",
    "#             subnetwork_output_size += self.subnetworks[key].classifier[1].out_features\n",
    "\n",
    "#         self.object_model = ResNetModel.from_pretrained(checkpoint)\n",
    "#         self.object_model.to(self.device)\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             # nn.Flatten() ,\n",
    "#             nn.Linear(subnetwork_output_size+self.object_model.config.hidden_sizes[-1] , Name_Classes.__len__())\n",
    "#         )\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "#         self.flatten = nn.Flatten()\n",
    "\n",
    "#     def forward(self, **inputs):\n",
    "#         # Run through the 5 subnetworks and get the outputs without gradients\n",
    "#         with torch.no_grad():\n",
    "#             subnetwork_outputs = []\n",
    "#             for key in self.subnetworks.keys():\n",
    "#                 subnetwork_outputs.append((self.subnetworks[key].forward(inputs['pixel_values']).logits))\n",
    "#         # Run through the object model and get the output with gradients\n",
    "#         object_model_output = self.object_model(inputs['pixel_values'])\n",
    "#         # Concatenate the outputs\n",
    "#         x = torch.cat(subnetwork_outputs + [self.flatten(object_model_output.pooler_output)] , dim=1)\n",
    "\n",
    "\n",
    "#         # Run through the linear layers\n",
    "#         x = self.classifier(x)\n",
    "#         # Run through softmax\n",
    "#         x = self.softmax(x)\n",
    "#         if inputs['labels'] is not None:\n",
    "#             loss = nn.CrossEntropyLoss()(x, inputs['labels'])\n",
    "#             return {\"loss\": loss, \"logits\": x}\n",
    "#         return {\"logits\": x}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #launch tensorboard\n",
    "# %load_ext tensorboard\n",
    "# EPOCHS = 100\n",
    "# dataset_image_search = load_dataset(\"cringgaard/boats_dataset\" , use_auth_token=access_token, split=\"image_search\")\n",
    "# for batch_size in batch_sizes:\n",
    "#         tags = [model_name , \"Boat_Class\" , \"Subnetworks\"]\n",
    "#         name = \"_\".join(tags)\n",
    "#         wandb.init(project=wandb_project, name=name , tags=[\"Boat_Class\"])\n",
    "#         torch.cuda.empty_cache()\n",
    "#         c_names = dataset.column_names[1:]\n",
    "#         c_names.remove('name')\n",
    "#         # NOTE boat24 has wrong labels\n",
    "#         # dataset_specific_test = dataset.remove_columns(c_names)\n",
    "#         # dataset_boat24_specific_train = dataset_boat24.remove_columns(c_names)\n",
    "#         # dataset_image_search_specific_train = dataset_image_search.remove_columns(c_names)\n",
    "#         dataset_specific = dataset_image_search.remove_columns(c_names)\n",
    "\n",
    "#         # Debugging dataset\n",
    "#         dataset_specific = dataset_specific.select(range(1000))\n",
    "\n",
    "#         # Split into train and eval\n",
    "#         dataset_specific = dataset_specific.train_test_split(test_size=0.1 , seed=42)\n",
    "        \n",
    "#         labels = dataset.features['name'].names\n",
    "#         id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "#         label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "\n",
    "#         labels_train_counts = np.bincount(dataset_specific['train']['name'] , minlength=len(labels))\n",
    "#         labels_test_counts = np.bincount(dataset_specific['test']['name'] , minlength=len(labels))\n",
    "\n",
    "#         # weights = np.array([1 if x == 0 else x for x in labels_train_counts])\n",
    "#         # weights = (1/weights)\n",
    "#         # weights /= weights.sum()\n",
    "#         # weights = torch.tensor(weights, dtype=torch.float , device=torch.device(\"cuda:0\"))\n",
    "\n",
    "#         # class WeightedCETrainer(Trainer):\n",
    "#         #     def __init__(self, *args, **kwargs):\n",
    "#         #         super().__init__(*args, **kwargs)\n",
    "#         #     def compute_loss(self, model, inputs, return_outputs=False):\n",
    "#         #         labels = inputs.get(\"labels\")\n",
    "#         #         labels.to(torch.device(\"cuda:0\"))\n",
    "#         #         outputs = model(**inputs)\n",
    "#         #         logits = outputs.get(\"logits\")\n",
    "#         #         # loss_fct = nn.CrossEntropyLoss(weight=weights , label_smoothing=0.1)\n",
    "#         #         loss_fct = nn.CrossEntropyLoss(weight=weights)\n",
    "#         #         loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "#         #         return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "#         def transforms(examples):\n",
    "#             examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "#             examples[\"labels\"] = examples['name']\n",
    "#             del examples[\"name\"]\n",
    "#             del examples[\"img_path\"]\n",
    "#             return examples\n",
    "        \n",
    "#         data_collator = DefaultDataCollator()\n",
    "#         device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#         model = BoatClassifier(device)\n",
    "\n",
    "#         training_args = TrainingArguments(\n",
    "#             output_dir=model_dir+name,\n",
    "#             report_to=\"tensorboard\",\n",
    "#             remove_unused_columns=False,\n",
    "#             evaluation_strategy=\"epoch\",\n",
    "#             logging_strategy=\"epoch\",\n",
    "#             save_strategy=\"epoch\",\n",
    "#             # eval_steps = 10,\n",
    "#             # logging_steps = 10,\n",
    "#             # save_steps = 10,\n",
    "#             save_total_limit=30,\n",
    "#             learning_rate=5e-5,\n",
    "#             per_device_train_batch_size=batch_size,\n",
    "#             gradient_accumulation_steps=1,\n",
    "#             per_device_eval_batch_size=batch_size,\n",
    "#             num_train_epochs=EPOCHS,\n",
    "#             warmup_ratio=0.1,\n",
    "#             load_best_model_at_end=True,\n",
    "#             metric_for_best_model=\"accuracy\",\n",
    "#             # label_smoothing_factor=0.1,\n",
    "#             # no_cuda=True\n",
    "#             # push_to_hub=True,\n",
    "#             # hub_strategy=\"end\",\n",
    "#             # hub_model_id=\"boats_dataset\",\n",
    "#             # hub_token=write_token,\n",
    "#         )\n",
    "\n",
    "#         trainer = Trainer(\n",
    "#             model=model,\n",
    "#             args=training_args,\n",
    "#             data_collator=data_collator,\n",
    "#             train_dataset=dataset_specific['train'].with_transform(transforms),\n",
    "#             eval_dataset=dataset_specific['test'].with_transform(transforms),\n",
    "#             tokenizer=image_processor,\n",
    "#             compute_metrics=compute_metrics,\n",
    "#         )\n",
    "#         # # Plot Label Distribution For Training Data\n",
    "#         # fig1 = plt.figure()\n",
    "#         # ax = fig1.add_axes([0,0,1,1])\n",
    "#         # ax.bar([label2id[x] for x in labels], labels_train_counts/dataset_specific['train'].__len__()) # Normalized\n",
    "#         # ax.set_ylabel(\"Number of examples normalised\")\n",
    "#         # ax.set_title(\"Label Distribution\")\n",
    "#         # wandb.log({\"Label Distribution Train\": (fig1)})\n",
    "\n",
    "#         # # Plot Label Distribution For Test Data\n",
    "#         # fig2 = plt.figure()\n",
    "#         # ax = fig2.add_axes([0,0,1,1])\n",
    "#         # ax.bar([label2id[x] for x in labels], labels_test_counts/dataset_specific['test'].__len__()) # Normalized\n",
    "#         # ax.set_ylabel(\"Number of examples normalised\")\n",
    "#         # ax.set_title(\"Label Distribution\")\n",
    "#         # wandb.log({\"Label Distribution Test\": (fig2)})\n",
    "\n",
    "#         # # Log label2id\n",
    "#         # wandb.log({\"Labels\": wandb.Table(data = list(zip(label2id.keys() , label2id.values())) , columns=[\"Label\" , \"ID\"])})\n",
    "\n",
    "#         # Train Model\n",
    "#         trainer.train()\n",
    "\n",
    "#         # Save Model\n",
    "#         trainer.save_model(model_dir+name+\"/best_model\")\n",
    "\n",
    "#         pipeline = ImageClassificationPipeline(model=trainer.model, feature_extractor = trainer.tokenizer , framework=\"pt\", device=0)\n",
    "#         predict_data = dataset_specific['test'].select(np.random.randint(0, len(dataset_specific['test']), 100))\n",
    "#         images = [predict_data['img_path'][i] for i in range(100)]\n",
    "#         predictions = pipeline(images)\n",
    "#         prediction_table = []\n",
    "#         for i in range(len(predictions)):\n",
    "#             prediction_table.append([wandb.Image(images[i]) , predictions[i] , id2label[predict_data['name'][i]]])\n",
    "#         columns = [\"Image\" , \"Label Predictions\" , \"True Label\"]\n",
    "#         wandb.log({\"Image Predicitions\" : wandb.Table(data=prediction_table, columns=columns)})\n",
    "\n",
    "#         metrics = trainer.evaluate(dataset_specific['test'].with_transform(transforms))\n",
    "#         wandb.log(metrics)\n",
    "#         wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset boats_dataset (C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e)\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcringgaard\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\chris\\OneDrive\\Dokumenter\\GitHub\\SailFGVC\\wandb\\run-20230602_164712-3cuxghqj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cringgaard/Sailboat%20FGVC%20Clean/runs/3cuxghqj\" target=\"_blank\">ViT_Boat_Class_ViT</a></strong> to <a href=\"https://wandb.ai/cringgaard/Sailboat%20FGVC%20Clean\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-6ba3f8e86ac10bfb.arrow and C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-2d2e014a9e7eea82.arrow\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([7108, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([7108]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 73926\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 462100\n",
      "  Number of trainable parameters = 91264708\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef46d131d4d484691ed4c0381113788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 8.956, 'learning_rate': 5e-06, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef73f667b48484480cbfd2ecbcc83ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-4621\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-4621\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.884149551391602, 'eval_accuracy': 0.0, 'eval_f1': 0.0, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 185.3746, 'eval_samples_per_second': 44.31, 'eval_steps_per_second': 2.773, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-4621\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-4621\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 8.8007, 'learning_rate': 1e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47754655b6e144c69cefd00120945e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-9242\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-9242\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.747682571411133, 'eval_accuracy': 0.0008522035549062576, 'eval_f1': 0.00018491675598685035, 'eval_precision': 0.00022341446980268025, 'eval_recall': 0.0009232264334305151, 'eval_runtime': 124.216, 'eval_samples_per_second': 66.127, 'eval_steps_per_second': 4.138, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-9242\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-9242\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 8.4755, 'learning_rate': 1.5e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5b2ad5ddf940ecafb163ba80497106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-13863\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-13863\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.389898300170898, 'eval_accuracy': 0.003165327489651814, 'eval_f1': 0.0014139176666663207, 'eval_precision': 0.0014220326084224434, 'eval_recall': 0.003283755070504153, 'eval_runtime': 141.5598, 'eval_samples_per_second': 58.025, 'eval_steps_per_second': 3.631, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-13863\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-13863\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 8.0246, 'learning_rate': 2e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464aab10f2fc4338a2ac4f9b6a237833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-18484\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-18484\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.025288581848145, 'eval_accuracy': 0.008400292184075968, 'eval_f1': 0.0038171201122529376, 'eval_precision': 0.0037192121547170516, 'eval_recall': 0.008524904214559387, 'eval_runtime': 233.913, 'eval_samples_per_second': 35.116, 'eval_steps_per_second': 2.197, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-18484\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-18484\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.5835, 'learning_rate': 2.5e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14375931649a4ae9b755eed07860ac0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-23105\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-23105\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.7087016105651855, 'eval_accuracy': 0.01643535427319211, 'eval_f1': 0.008287111246320632, 'eval_precision': 0.008237709949389186, 'eval_recall': 0.01645766039647856, 'eval_runtime': 123.8366, 'eval_samples_per_second': 66.329, 'eval_steps_per_second': 4.151, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-23105\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-23105\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.1042, 'learning_rate': 3e-05, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f602724918424ab17b84258122269d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-27726\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-27726\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.349783420562744, 'eval_accuracy': 0.030679327976625273, 'eval_f1': 0.0165313811861633, 'eval_precision': 0.01605155580011795, 'eval_recall': 0.030596642326655432, 'eval_runtime': 140.2243, 'eval_samples_per_second': 58.578, 'eval_steps_per_second': 3.666, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-27726\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-27726\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.5783, 'learning_rate': 3.5e-05, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe2f7af7f784adf9e95b5205af68c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-32347\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-32347\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.032502174377441, 'eval_accuracy': 0.04723642561480399, 'eval_f1': 0.027745165904315642, 'eval_precision': 0.028170801163112207, 'eval_recall': 0.04366469937292512, 'eval_runtime': 145.1522, 'eval_samples_per_second': 56.589, 'eval_steps_per_second': 3.541, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-32347\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-32347\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.9949, 'learning_rate': 4e-05, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7cbe73d29e495caa85d04c7ea9532c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-36968\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-36968\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.701854705810547, 'eval_accuracy': 0.07219381543705868, 'eval_f1': 0.04427740475095939, 'eval_precision': 0.0444026092069138, 'eval_recall': 0.06635802469135803, 'eval_runtime': 144.2117, 'eval_samples_per_second': 56.958, 'eval_steps_per_second': 3.564, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-36968\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-36968\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.366, 'learning_rate': 4.5e-05, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec51c259dbc74d3dbc1c405082453270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-41589\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-41589\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.386385917663574, 'eval_accuracy': 0.09934258582907232, 'eval_f1': 0.06429219435307354, 'eval_precision': 0.06683799032006779, 'eval_recall': 0.08842293906810035, 'eval_runtime': 146.5167, 'eval_samples_per_second': 56.062, 'eval_steps_per_second': 3.508, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-41589\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-41589\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.6858, 'learning_rate': 5e-05, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c6ea9f4dd44dc58f5ded20be27fbd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-46210\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-46210\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.117397308349609, 'eval_accuracy': 0.1212563915266618, 'eval_f1': 0.08105644139440364, 'eval_precision': 0.0836395402165243, 'eval_recall': 0.10524904214559386, 'eval_runtime': 144.1045, 'eval_samples_per_second': 57.0, 'eval_steps_per_second': 3.567, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-46210\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-46210\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9775, 'learning_rate': 4.9444444444444446e-05, 'epoch': 11.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d91780cb5844e4cb1ae094cb34e1173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-50831\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-50831\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.897875785827637, 'eval_accuracy': 0.1434136839542245, 'eval_f1': 0.09927230615809937, 'eval_precision': 0.10446225452609308, 'eval_recall': 0.12379657249809908, 'eval_runtime': 144.0862, 'eval_samples_per_second': 57.008, 'eval_steps_per_second': 3.567, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-50831\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-50831\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.2707, 'learning_rate': 4.888888888888889e-05, 'epoch': 12.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4145d97e449f4557854c0d2a8153b434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-55452\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-55452\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.755012512207031, 'eval_accuracy': 0.15631848064280496, 'eval_f1': 0.10964192311636815, 'eval_precision': 0.11749260844511232, 'eval_recall': 0.13096139505535478, 'eval_runtime': 146.3388, 'eval_samples_per_second': 56.13, 'eval_steps_per_second': 3.512, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-55452\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-55452\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6499, 'learning_rate': 4.8333333333333334e-05, 'epoch': 13.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb7c8bdf5a4457da917ea3e308fcc00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-60073\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-60073\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.716735363006592, 'eval_accuracy': 0.17348429510591673, 'eval_f1': 0.12397607123135983, 'eval_precision': 0.13303324782951856, 'eval_recall': 0.14661889963167585, 'eval_runtime': 150.321, 'eval_samples_per_second': 54.643, 'eval_steps_per_second': 3.419, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-60073\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-60073\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0933, 'learning_rate': 4.7777777777777784e-05, 'epoch': 14.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f00903777d44d8994139803e594579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-64694\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-64694\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.6765666007995605, 'eval_accuracy': 0.18298027757487217, 'eval_f1': 0.13111575592817065, 'eval_precision': 0.1411243268252136, 'eval_recall': 0.1518332196452933, 'eval_runtime': 153.3478, 'eval_samples_per_second': 53.565, 'eval_steps_per_second': 3.352, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-64694\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-64694\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6502, 'learning_rate': 4.722222222222222e-05, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eddaba76eed14d7c893595fbe7fe7f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-69315\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-69315\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.651655197143555, 'eval_accuracy': 0.18882395909422936, 'eval_f1': 0.13335859750954088, 'eval_precision': 0.1447393485129334, 'eval_recall': 0.15339679301943454, 'eval_runtime': 148.1412, 'eval_samples_per_second': 55.447, 'eval_steps_per_second': 3.47, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-69315\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-69315\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3132, 'learning_rate': 4.666666666666667e-05, 'epoch': 16.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c8b391d3364b3ebf4f089eb290020d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-73936\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-73936\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.719595909118652, 'eval_accuracy': 0.18188458728999268, 'eval_f1': 0.12945872236287356, 'eval_precision': 0.14119544487836758, 'eval_recall': 0.14697941275734053, 'eval_runtime': 147.358, 'eval_samples_per_second': 55.742, 'eval_steps_per_second': 3.488, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-73936\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-73936\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0692, 'learning_rate': 4.6111111111111115e-05, 'epoch': 17.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9eaead34b24e558cd3497f44bb71ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-78557\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-78557\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.7837066650390625, 'eval_accuracy': 0.19588507426345264, 'eval_f1': 0.14200352598790097, 'eval_precision': 0.1556167507763975, 'eval_recall': 0.1591881793478261, 'eval_runtime': 147.4394, 'eval_samples_per_second': 55.711, 'eval_steps_per_second': 3.486, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-78557\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-78557\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8999, 'learning_rate': 4.555555555555556e-05, 'epoch': 18.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95cfb30dcf944d90a4f0e506aa7d85ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-83178\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-83178\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.821348190307617, 'eval_accuracy': 0.19332846359873387, 'eval_f1': 0.13768478326829955, 'eval_precision': 0.1499040334583317, 'eval_recall': 0.1580886433276232, 'eval_runtime': 151.8091, 'eval_samples_per_second': 54.107, 'eval_steps_per_second': 3.386, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-83178\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-83178\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7804, 'learning_rate': 4.5e-05, 'epoch': 19.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8f94f9addd4e94b81a97b8c16e0ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-87799\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-87799\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.872054576873779, 'eval_accuracy': 0.18675432188945704, 'eval_f1': 0.13613220103856175, 'eval_precision': 0.14961696674620584, 'eval_recall': 0.15272481862662393, 'eval_runtime': 147.8969, 'eval_samples_per_second': 55.539, 'eval_steps_per_second': 3.475, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-87799\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-87799\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6916, 'learning_rate': 4.4444444444444447e-05, 'epoch': 20.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ff7f56043644fd9425fb47a16f66c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-92420\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-92420\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.920873641967773, 'eval_accuracy': 0.19284149013878743, 'eval_f1': 0.1375141180438185, 'eval_precision': 0.14831847840394125, 'eval_recall': 0.15710498110227336, 'eval_runtime': 146.3278, 'eval_samples_per_second': 56.134, 'eval_steps_per_second': 3.513, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-92420\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-92420\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.636, 'learning_rate': 4.388888888888889e-05, 'epoch': 21.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef995525f4f4b1ca9a2ec50042d857b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-97041\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-97041\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.961556434631348, 'eval_accuracy': 0.19028487947406866, 'eval_f1': 0.13828346046889092, 'eval_precision': 0.1496341039387397, 'eval_recall': 0.15673572196751004, 'eval_runtime': 145.238, 'eval_samples_per_second': 56.555, 'eval_steps_per_second': 3.539, 'epoch': 21.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-97041\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-97041\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5919, 'learning_rate': 4.3333333333333334e-05, 'epoch': 22.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec44a99317d40c68dc4918f87fe26f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-101662\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-101662\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.0099897384643555, 'eval_accuracy': 0.19612856099342585, 'eval_f1': 0.14167390388143186, 'eval_precision': 0.15546377532644062, 'eval_recall': 0.15875720583248557, 'eval_runtime': 147.7768, 'eval_samples_per_second': 55.584, 'eval_steps_per_second': 3.478, 'epoch': 22.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-101662\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-101662\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.537, 'learning_rate': 4.277777777777778e-05, 'epoch': 23.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940f474e0bff4ced8520a24c0cfc2d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-106283\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-106283\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.0364179611206055, 'eval_accuracy': 0.19418066715364013, 'eval_f1': 0.14261984001868394, 'eval_precision': 0.15676053658457603, 'eval_recall': 0.1596820809248555, 'eval_runtime': 150.1167, 'eval_samples_per_second': 54.717, 'eval_steps_per_second': 3.424, 'epoch': 23.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-106283\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-106283\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5047, 'learning_rate': 4.222222222222222e-05, 'epoch': 24.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b03562b95564fe29a93f5ac457d070d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-110904\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-110904\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.088176250457764, 'eval_accuracy': 0.19625030435841245, 'eval_f1': 0.1405501458248711, 'eval_precision': 0.15220096753063786, 'eval_recall': 0.15908706677937448, 'eval_runtime': 145.2411, 'eval_samples_per_second': 56.554, 'eval_steps_per_second': 3.539, 'epoch': 24.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-110904\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-110904\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4901, 'learning_rate': 4.166666666666667e-05, 'epoch': 25.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830c30dd94b6407690641a8e3cb7391f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-115525\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-115525\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.06094217300415, 'eval_accuracy': 0.1983199415631848, 'eval_f1': 0.1430921134665628, 'eval_precision': 0.1569611861462082, 'eval_recall': 0.16051338529312095, 'eval_runtime': 147.1304, 'eval_samples_per_second': 55.828, 'eval_steps_per_second': 3.493, 'epoch': 25.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-115525\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-115525\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4541, 'learning_rate': 4.111111111111111e-05, 'epoch': 26.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a54b431fb942eaa9f7e9796aed40ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-120146\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-120146\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.156139373779297, 'eval_accuracy': 0.19357195032870708, 'eval_f1': 0.14134733530169497, 'eval_precision': 0.15700574497406922, 'eval_recall': 0.15755846957311534, 'eval_runtime': 149.6441, 'eval_samples_per_second': 54.89, 'eval_steps_per_second': 3.435, 'epoch': 26.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-120146\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-120146\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4398, 'learning_rate': 4.055555555555556e-05, 'epoch': 27.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef60b9649dd348d7aea4860137f4181f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-124767\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-124767\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.156641483306885, 'eval_accuracy': 0.19235451667884101, 'eval_f1': 0.13955286186747243, 'eval_precision': 0.15407775850674205, 'eval_recall': 0.1568697324509305, 'eval_runtime': 146.74, 'eval_samples_per_second': 55.977, 'eval_steps_per_second': 3.503, 'epoch': 27.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-124767\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-124767\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4291, 'learning_rate': 4e-05, 'epoch': 28.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bcb252a68d74dceb4a3ef11813a6b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-129388\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-129388\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.202596664428711, 'eval_accuracy': 0.19369369369369369, 'eval_f1': 0.14226432379654091, 'eval_precision': 0.15626666022404226, 'eval_recall': 0.157976774339027, 'eval_runtime': 144.1344, 'eval_samples_per_second': 56.988, 'eval_steps_per_second': 3.566, 'epoch': 28.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-129388\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-129388\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4019, 'learning_rate': 3.944444444444445e-05, 'epoch': 29.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b988f3db1340d6a7f96ac6f7f33939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-134009\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-134009\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.239863395690918, 'eval_accuracy': 0.19892865838811785, 'eval_f1': 0.142040819574036, 'eval_precision': 0.15488963481636547, 'eval_recall': 0.16117848520577172, 'eval_runtime': 142.6028, 'eval_samples_per_second': 57.601, 'eval_steps_per_second': 3.604, 'epoch': 29.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-134009\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-134009\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-63] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3837, 'learning_rate': 3.888888888888889e-05, 'epoch': 30.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377b23f3996d4c3898df05d6fc9179c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-138630\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-138630\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.25309419631958, 'eval_accuracy': 0.20002434867299732, 'eval_f1': 0.14442094806367115, 'eval_precision': 0.15689159984075526, 'eval_recall': 0.16284194961041915, 'eval_runtime': 121.3031, 'eval_samples_per_second': 67.715, 'eval_steps_per_second': 4.237, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-138630\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-138630\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-57] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3634, 'learning_rate': 3.8333333333333334e-05, 'epoch': 31.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fda9f73e6754a8dba0f15122bf757ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-143251\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-143251\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.287364959716797, 'eval_accuracy': 0.19771122473825176, 'eval_f1': 0.14212520640369597, 'eval_precision': 0.15546592745682428, 'eval_recall': 0.1591677905147224, 'eval_runtime': 124.4921, 'eval_samples_per_second': 65.98, 'eval_steps_per_second': 4.129, 'epoch': 31.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-143251\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-143251\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-4621] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3549, 'learning_rate': 3.777777777777778e-05, 'epoch': 32.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a23f012f3424f7dbc23ce2b2b9d9833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-147872\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-147872\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.266894817352295, 'eval_accuracy': 0.19783296810323836, 'eval_f1': 0.14074434599282468, 'eval_precision': 0.15448374403749657, 'eval_recall': 0.1594010592742844, 'eval_runtime': 126.9897, 'eval_samples_per_second': 64.682, 'eval_steps_per_second': 4.048, 'epoch': 32.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-147872\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-147872\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-9242] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3499, 'learning_rate': 3.722222222222222e-05, 'epoch': 33.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62315e02bbe94c349c515744e71fd9b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-152493\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-152493\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.336761474609375, 'eval_accuracy': 0.19868517165814464, 'eval_f1': 0.14191306273373142, 'eval_precision': 0.1540321802479857, 'eval_recall': 0.16109422492401215, 'eval_runtime': 120.0989, 'eval_samples_per_second': 68.394, 'eval_steps_per_second': 4.28, 'epoch': 33.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-152493\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-152493\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-13863] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3355, 'learning_rate': 3.6666666666666666e-05, 'epoch': 34.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450fa49dfacb4634839ae3907d47505d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-157114\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-157114\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.330626010894775, 'eval_accuracy': 0.19259800340881422, 'eval_f1': 0.13976862268903673, 'eval_precision': 0.15374038070457552, 'eval_recall': 0.15666610102381356, 'eval_runtime': 120.2742, 'eval_samples_per_second': 68.294, 'eval_steps_per_second': 4.274, 'epoch': 34.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-157114\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-157114\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-18484] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3205, 'learning_rate': 3.611111111111111e-05, 'epoch': 35.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268cf6250a9849888a5e38e237aa8200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-161735\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-161735\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.385305404663086, 'eval_accuracy': 0.19357195032870708, 'eval_f1': 0.138795558374737, 'eval_precision': 0.1519705858898017, 'eval_recall': 0.15670103092783505, 'eval_runtime': 130.3287, 'eval_samples_per_second': 63.025, 'eval_steps_per_second': 3.944, 'epoch': 35.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-161735\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-161735\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-23105] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3105, 'learning_rate': 3.555555555555556e-05, 'epoch': 36.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57394af4e52948828a83a3b403efc79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-166356\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-166356\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.347142696380615, 'eval_accuracy': 0.19625030435841245, 'eval_f1': 0.14352276472819767, 'eval_precision': 0.15626243639401532, 'eval_recall': 0.16144878324844367, 'eval_runtime': 118.8764, 'eval_samples_per_second': 69.097, 'eval_steps_per_second': 4.324, 'epoch': 36.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-166356\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-166356\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-27726] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3007, 'learning_rate': 3.5e-05, 'epoch': 37.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2440ecc0194d508910e4cc67509843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-170977\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-170977\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.374868869781494, 'eval_accuracy': 0.20038957876795715, 'eval_f1': 0.1460090472698359, 'eval_precision': 0.1579401526812256, 'eval_recall': 0.16386303379026343, 'eval_runtime': 119.3642, 'eval_samples_per_second': 68.815, 'eval_steps_per_second': 4.306, 'epoch': 37.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-170977\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-170977\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-32347] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2938, 'learning_rate': 3.444444444444445e-05, 'epoch': 38.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7df7b72ef3d4ad2899b5496644756d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-175598\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-175598\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.398069858551025, 'eval_accuracy': 0.20148526905283662, 'eval_f1': 0.14627993546017984, 'eval_precision': 0.1609246315840002, 'eval_recall': 0.16336558044806518, 'eval_runtime': 119.163, 'eval_samples_per_second': 68.931, 'eval_steps_per_second': 4.313, 'epoch': 38.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-175598\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-175598\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-36968] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2817, 'learning_rate': 3.388888888888889e-05, 'epoch': 39.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48b591e0b4c401681bafcce17885c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-180219\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-180219\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.4076128005981445, 'eval_accuracy': 0.1981981981981982, 'eval_f1': 0.14512114546081936, 'eval_precision': 0.15994550390355416, 'eval_recall': 0.16101109601449276, 'eval_runtime': 118.6061, 'eval_samples_per_second': 69.254, 'eval_steps_per_second': 4.334, 'epoch': 39.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-180219\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-180219\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-41589] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2763, 'learning_rate': 3.3333333333333335e-05, 'epoch': 40.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab2083bb37f462dbcaab039fc1657c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-184840\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-184840\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.414286136627197, 'eval_accuracy': 0.1997808619430241, 'eval_f1': 0.14404949776451048, 'eval_precision': 0.1564981818671386, 'eval_recall': 0.16365281311846197, 'eval_runtime': 116.862, 'eval_samples_per_second': 70.288, 'eval_steps_per_second': 4.398, 'epoch': 40.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-184840\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-184840\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-46210] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2774, 'learning_rate': 3.277777777777778e-05, 'epoch': 41.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90baecba2f554550abe75a92e6c4bb83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-189461\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-189461\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.416447162628174, 'eval_accuracy': 0.19929388848307766, 'eval_f1': 0.14617937373402548, 'eval_precision': 0.15956577174167413, 'eval_recall': 0.16443823080833758, 'eval_runtime': 116.2786, 'eval_samples_per_second': 70.641, 'eval_steps_per_second': 4.42, 'epoch': 41.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-189461\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-189461\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-50831] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2595, 'learning_rate': 3.222222222222223e-05, 'epoch': 42.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba2a8d4f72e4730a481ece7f516e506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-194082\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-194082\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.402364253997803, 'eval_accuracy': 0.20270270270270271, 'eval_f1': 0.1470393763095233, 'eval_precision': 0.162106761384511, 'eval_recall': 0.16495748155656925, 'eval_runtime': 121.6673, 'eval_samples_per_second': 67.512, 'eval_steps_per_second': 4.225, 'epoch': 42.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-194082\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-194082\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-55452] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2594, 'learning_rate': 3.1666666666666666e-05, 'epoch': 43.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6980ba441d73433681b1edc92748b5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-198703\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-198703\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.450509071350098, 'eval_accuracy': 0.1953981008035062, 'eval_f1': 0.14018287155558654, 'eval_precision': 0.15133427140451514, 'eval_recall': 0.15939404197698034, 'eval_runtime': 121.3519, 'eval_samples_per_second': 67.687, 'eval_steps_per_second': 4.236, 'epoch': 43.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-198703\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-198703\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-60073] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2508, 'learning_rate': 3.111111111111111e-05, 'epoch': 44.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8efeff28950e441a832e3d5709eb3b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-203324\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-203324\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.4183549880981445, 'eval_accuracy': 0.20343316289262237, 'eval_f1': 0.14634001805890035, 'eval_precision': 0.15755681894547263, 'eval_recall': 0.16749082698278295, 'eval_runtime': 118.9529, 'eval_samples_per_second': 69.053, 'eval_steps_per_second': 4.321, 'epoch': 44.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-203324\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-203324\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-64694] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.246, 'learning_rate': 3.055555555555556e-05, 'epoch': 45.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d18ebe7b249407faaeb99de060d15cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-207945\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-207945\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.404882431030273, 'eval_accuracy': 0.20331141952763573, 'eval_f1': 0.14607077343803757, 'eval_precision': 0.1578782657240554, 'eval_recall': 0.16617348664186676, 'eval_runtime': 116.18, 'eval_samples_per_second': 70.701, 'eval_steps_per_second': 4.424, 'epoch': 45.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-207945\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-207945\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-69315] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2407, 'learning_rate': 3e-05, 'epoch': 46.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8a0348e7074175aa755660c86fe58c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-212566\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-212566\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.434908866882324, 'eval_accuracy': 0.2072072072072072, 'eval_f1': 0.15017162353769195, 'eval_precision': 0.1650198364302665, 'eval_recall': 0.1705779433344621, 'eval_runtime': 115.973, 'eval_samples_per_second': 70.827, 'eval_steps_per_second': 4.432, 'epoch': 46.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-212566\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-212566\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-73936] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2259, 'learning_rate': 2.9444444444444448e-05, 'epoch': 47.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344768071c4a4815ba977fd2739d4cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-217187\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-217187\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.448704242706299, 'eval_accuracy': 0.20538105673240808, 'eval_f1': 0.15060018207916231, 'eval_precision': 0.16649791248389928, 'eval_recall': 0.16746862513365976, 'eval_runtime': 119.4155, 'eval_samples_per_second': 68.785, 'eval_steps_per_second': 4.304, 'epoch': 47.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-217187\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-217187\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-78557] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2326, 'learning_rate': 2.8888888888888888e-05, 'epoch': 48.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5587922db145a8a5d9078e9f842f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-221808\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-221808\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.436191558837891, 'eval_accuracy': 0.19710250791331874, 'eval_f1': 0.14464941596338318, 'eval_precision': 0.15947790082649058, 'eval_recall': 0.16102572763609752, 'eval_runtime': 119.247, 'eval_samples_per_second': 68.882, 'eval_steps_per_second': 4.31, 'epoch': 48.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-221808\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-221808\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-83178] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2229, 'learning_rate': 2.8333333333333335e-05, 'epoch': 49.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6119e521be8a4f52a99effb9308efee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-226429\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-226429\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.45194149017334, 'eval_accuracy': 0.1996591185780375, 'eval_f1': 0.14334294366974104, 'eval_precision': 0.15518706057921744, 'eval_recall': 0.16342941735098598, 'eval_runtime': 118.3415, 'eval_samples_per_second': 69.409, 'eval_steps_per_second': 4.343, 'epoch': 49.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-226429\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-226429\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-87799] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2167, 'learning_rate': 2.777777777777778e-05, 'epoch': 50.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42e5978dcdb47218d0ef8fc0c827a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-231050\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-231050\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.395005702972412, 'eval_accuracy': 0.20465059654248843, 'eval_f1': 0.14789840352720676, 'eval_precision': 0.16100191034268113, 'eval_recall': 0.1674104124408384, 'eval_runtime': 118.8528, 'eval_samples_per_second': 69.111, 'eval_steps_per_second': 4.325, 'epoch': 50.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-231050\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-231050\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-92420] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2098, 'learning_rate': 2.7222222222222223e-05, 'epoch': 51.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f151ddb7c8f04379a959ffe1dea4f9f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-235671\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-235671\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.434077739715576, 'eval_accuracy': 0.20379839298758218, 'eval_f1': 0.1473101953733962, 'eval_precision': 0.15820659877744483, 'eval_recall': 0.16798335032279987, 'eval_runtime': 118.1016, 'eval_samples_per_second': 69.55, 'eval_steps_per_second': 4.352, 'epoch': 51.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-235671\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-235671\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-97041] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2087, 'learning_rate': 2.6666666666666667e-05, 'epoch': 52.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6feaad6699d4bd9b36422d5f6cd889b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-240292\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-240292\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.488887310028076, 'eval_accuracy': 0.20258095933771608, 'eval_f1': 0.14640284533847636, 'eval_precision': 0.16130823476236553, 'eval_recall': 0.16555442923917327, 'eval_runtime': 119.8085, 'eval_samples_per_second': 68.559, 'eval_steps_per_second': 4.29, 'epoch': 52.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-240292\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-240292\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-101662] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.202, 'learning_rate': 2.6111111111111114e-05, 'epoch': 53.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e00a6f99be4654b59514b45736d11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-244913\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-244913\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.4511613845825195, 'eval_accuracy': 0.20659849038227415, 'eval_f1': 0.14754569391993327, 'eval_precision': 0.1633838688732198, 'eval_recall': 0.16606659905341448, 'eval_runtime': 120.9528, 'eval_samples_per_second': 67.911, 'eval_steps_per_second': 4.25, 'epoch': 53.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-244913\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-244913\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-106283] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1979, 'learning_rate': 2.5555555555555554e-05, 'epoch': 54.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7af51dedeed4982bbac69fb7d6edea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-249534\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-249534\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.461017608642578, 'eval_accuracy': 0.20452885317750183, 'eval_f1': 0.14820661126549434, 'eval_precision': 0.16205741280821423, 'eval_recall': 0.16699848152522354, 'eval_runtime': 118.6131, 'eval_samples_per_second': 69.25, 'eval_steps_per_second': 4.333, 'epoch': 54.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-249534\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-249534\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-110904] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1835, 'learning_rate': 2.5e-05, 'epoch': 55.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74d35b672124eec8f493909bcb39a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-254155\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-254155\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.459342956542969, 'eval_accuracy': 0.2012417823228634, 'eval_f1': 0.1451706461488887, 'eval_precision': 0.16035065738219728, 'eval_recall': 0.16164895710350255, 'eval_runtime': 119.567, 'eval_samples_per_second': 68.698, 'eval_steps_per_second': 4.299, 'epoch': 55.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-254155\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-254155\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-115525] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1884, 'learning_rate': 2.4444444444444445e-05, 'epoch': 56.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bcff7311607443bab59acb5b1272b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-258776\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-258776\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.4660844802856445, 'eval_accuracy': 0.20793766739712685, 'eval_f1': 0.15028211287597226, 'eval_precision': 0.1639132302592211, 'eval_recall': 0.16903995027405774, 'eval_runtime': 118.3413, 'eval_samples_per_second': 69.409, 'eval_steps_per_second': 4.343, 'epoch': 56.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-258776\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-258776\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-120146] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1836, 'learning_rate': 2.3888888888888892e-05, 'epoch': 57.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa1e7ae86b8497995bf38ea9d14f403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-263397\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-263397\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.501589298248291, 'eval_accuracy': 0.20075480886291697, 'eval_f1': 0.14494819198616668, 'eval_precision': 0.1600502310628893, 'eval_recall': 0.16262447257383966, 'eval_runtime': 122.3168, 'eval_samples_per_second': 67.153, 'eval_steps_per_second': 4.202, 'epoch': 57.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-263397\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-263397\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-124767] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1794, 'learning_rate': 2.3333333333333336e-05, 'epoch': 58.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f645ff4245f24b6fa601d562e132e2d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-268018\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-268018\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.44420051574707, 'eval_accuracy': 0.2086681275870465, 'eval_f1': 0.1514405227723894, 'eval_precision': 0.16380722707089268, 'eval_recall': 0.1712669938511874, 'eval_runtime': 124.7934, 'eval_samples_per_second': 65.821, 'eval_steps_per_second': 4.119, 'epoch': 58.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-268018\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-268018\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-129388] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.178, 'learning_rate': 2.277777777777778e-05, 'epoch': 59.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af59d3d7611c4a26add9aa801af6df66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-272639\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-272639\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.469483852386475, 'eval_accuracy': 0.20270270270270271, 'eval_f1': 0.14760413350721718, 'eval_precision': 0.16063978850322463, 'eval_recall': 0.16644357844798371, 'eval_runtime': 122.8958, 'eval_samples_per_second': 66.837, 'eval_steps_per_second': 4.182, 'epoch': 59.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-272639\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-272639\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-134009] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1769, 'learning_rate': 2.2222222222222223e-05, 'epoch': 60.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3835702a3df44c6999147885b2baf2aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-277260\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-277260\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.471854209899902, 'eval_accuracy': 0.20452885317750183, 'eval_f1': 0.14816357280660994, 'eval_precision': 0.1625235642159882, 'eval_recall': 0.16690744162607088, 'eval_runtime': 123.2211, 'eval_samples_per_second': 66.661, 'eval_steps_per_second': 4.171, 'epoch': 60.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-277260\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-277260\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-138630] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1707, 'learning_rate': 2.1666666666666667e-05, 'epoch': 61.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5589dd8632ce4facb37edc6e8f427d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-281881\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-281881\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.425459861755371, 'eval_accuracy': 0.20781592403214025, 'eval_f1': 0.15014895103953627, 'eval_precision': 0.16438022537259178, 'eval_recall': 0.16820752049759682, 'eval_runtime': 118.897, 'eval_samples_per_second': 69.085, 'eval_steps_per_second': 4.323, 'epoch': 61.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-281881\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-281881\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-143251] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1657, 'learning_rate': 2.111111111111111e-05, 'epoch': 62.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ddaf6ba77214cfd8c0f3395ad7f4807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-286502\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-286502\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.454789161682129, 'eval_accuracy': 0.20343316289262237, 'eval_f1': 0.14605622660849818, 'eval_precision': 0.1589342346182407, 'eval_recall': 0.16764904576929573, 'eval_runtime': 120.8053, 'eval_samples_per_second': 67.994, 'eval_steps_per_second': 4.255, 'epoch': 62.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-286502\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-286502\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-147872] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1651, 'learning_rate': 2.0555555555555555e-05, 'epoch': 63.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94055a0c43b949309f19863edb99ef1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-291123\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-291123\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.469484806060791, 'eval_accuracy': 0.20525931336742148, 'eval_f1': 0.147883858147639, 'eval_precision': 0.16297573420079337, 'eval_recall': 0.16581839702401083, 'eval_runtime': 121.1537, 'eval_samples_per_second': 67.798, 'eval_steps_per_second': 4.243, 'epoch': 63.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-291123\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-291123\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-152493] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1553, 'learning_rate': 2e-05, 'epoch': 64.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518707258fdd48ad87e2ec187df88851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-295744\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-295744\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.448824882507324, 'eval_accuracy': 0.20525931336742148, 'eval_f1': 0.14837742720929756, 'eval_precision': 0.16158028144861367, 'eval_recall': 0.16743472878685572, 'eval_runtime': 120.147, 'eval_samples_per_second': 68.366, 'eval_steps_per_second': 4.278, 'epoch': 64.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-295744\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-295744\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-157114] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1571, 'learning_rate': 1.9444444444444445e-05, 'epoch': 65.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebcac8177c694cec86df09701ac6760c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-300365\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-300365\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.473654747009277, 'eval_accuracy': 0.20623326028731434, 'eval_f1': 0.14774058019079955, 'eval_precision': 0.16114961509409703, 'eval_recall': 0.16696760040499495, 'eval_runtime': 119.6008, 'eval_samples_per_second': 68.678, 'eval_steps_per_second': 4.298, 'epoch': 65.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-300365\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-300365\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-161735] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1531, 'learning_rate': 1.888888888888889e-05, 'epoch': 66.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f6605547c044a08f5e6ad457749f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-304986\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-304986\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.4325079917907715, 'eval_accuracy': 0.2073289505721938, 'eval_f1': 0.1493467961441597, 'eval_precision': 0.16290202295779446, 'eval_recall': 0.16802433665708974, 'eval_runtime': 121.4603, 'eval_samples_per_second': 67.627, 'eval_steps_per_second': 4.232, 'epoch': 66.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-304986\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-304986\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-166356] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1513, 'learning_rate': 1.8333333333333333e-05, 'epoch': 67.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56881706dc1c488cb4558e12efd58ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-309607\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-309607\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.4794440269470215, 'eval_accuracy': 0.20586803019235453, 'eval_f1': 0.14852307433608247, 'eval_precision': 0.16145106946607427, 'eval_recall': 0.16741192411924122, 'eval_runtime': 121.1339, 'eval_samples_per_second': 67.809, 'eval_steps_per_second': 4.243, 'epoch': 67.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-309607\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-309607\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-170977] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1494, 'learning_rate': 1.777777777777778e-05, 'epoch': 68.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613f572981cf46e39cb3716df8f19129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-314228\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-314228\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.476215362548828, 'eval_accuracy': 0.20757243730216704, 'eval_f1': 0.1492116133224054, 'eval_precision': 0.1614089479737174, 'eval_recall': 0.16894105725384226, 'eval_runtime': 122.5702, 'eval_samples_per_second': 67.015, 'eval_steps_per_second': 4.194, 'epoch': 68.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-314228\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-314228\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-175598] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1454, 'learning_rate': 1.7222222222222224e-05, 'epoch': 69.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5000daa75d3f48d09ea01563c5b4fcc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-318849\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-318849\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.4447479248046875, 'eval_accuracy': 0.2083028974920867, 'eval_f1': 0.15221937635029037, 'eval_precision': 0.16659897015162403, 'eval_recall': 0.16992255949352777, 'eval_runtime': 122.4626, 'eval_samples_per_second': 67.074, 'eval_steps_per_second': 4.197, 'epoch': 69.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-318849\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-318849\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-180219] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1452, 'learning_rate': 1.6666666666666667e-05, 'epoch': 70.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e614e5595656471e86e9fd93cc0348b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-323470\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-323470\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.444791793823242, 'eval_accuracy': 0.20805941076211346, 'eval_f1': 0.14928959835241495, 'eval_precision': 0.16287154250680086, 'eval_recall': 0.16865642237982664, 'eval_runtime': 120.2072, 'eval_samples_per_second': 68.332, 'eval_steps_per_second': 4.276, 'epoch': 70.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-323470\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-323470\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-184840] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1383, 'learning_rate': 1.6111111111111115e-05, 'epoch': 71.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab30ceaf92db447a87d89dfe3b5402dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-328091\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-328091\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.45462703704834, 'eval_accuracy': 0.20623326028731434, 'eval_f1': 0.14941279143101618, 'eval_precision': 0.16416343902844072, 'eval_recall': 0.1668185397682529, 'eval_runtime': 121.6205, 'eval_samples_per_second': 67.538, 'eval_steps_per_second': 4.226, 'epoch': 71.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-328091\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-328091\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-189461] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1402, 'learning_rate': 1.5555555555555555e-05, 'epoch': 72.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf68dd920724b7f8007134f73d97c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-332712\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-332712\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.424317359924316, 'eval_accuracy': 0.2068419771122474, 'eval_f1': 0.14904876788751026, 'eval_precision': 0.1628968253968254, 'eval_recall': 0.16787807076853728, 'eval_runtime': 119.0904, 'eval_samples_per_second': 68.973, 'eval_steps_per_second': 4.316, 'epoch': 72.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-332712\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-332712\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-194082] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.139, 'learning_rate': 1.5e-05, 'epoch': 73.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861063980c11462791453d5b8cbda789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-337333\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-337333\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.444360733032227, 'eval_accuracy': 0.20903335768200634, 'eval_f1': 0.15083344434277676, 'eval_precision': 0.16361911167695595, 'eval_recall': 0.1697494535059694, 'eval_runtime': 121.9228, 'eval_samples_per_second': 67.371, 'eval_steps_per_second': 4.216, 'epoch': 73.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-337333\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-337333\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-198703] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1351, 'learning_rate': 1.4444444444444444e-05, 'epoch': 74.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc717d92d78948ddb837022289cd7bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-341954\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-341954\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.420421123504639, 'eval_accuracy': 0.2086681275870465, 'eval_f1': 0.14994285791997, 'eval_precision': 0.1633126172044045, 'eval_recall': 0.16864972512061033, 'eval_runtime': 121.3751, 'eval_samples_per_second': 67.674, 'eval_steps_per_second': 4.235, 'epoch': 74.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-341954\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-341954\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-203324] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1347, 'learning_rate': 1.388888888888889e-05, 'epoch': 75.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5d776ded514b8e9d29382db62326b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-346575\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-346575\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.419335842132568, 'eval_accuracy': 0.2098855612369126, 'eval_f1': 0.15159282721370912, 'eval_precision': 0.16424890787536503, 'eval_recall': 0.17010756321450693, 'eval_runtime': 121.8914, 'eval_samples_per_second': 67.388, 'eval_steps_per_second': 4.217, 'epoch': 75.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-346575\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-346575\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-207945] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1304, 'learning_rate': 1.3333333333333333e-05, 'epoch': 76.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7f9e1c47b740e09e1dfe0b6ad02ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-351196\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-351196\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.398141384124756, 'eval_accuracy': 0.21414657901144388, 'eval_f1': 0.15355923222826054, 'eval_precision': 0.16542718976929502, 'eval_recall': 0.17460076473234368, 'eval_runtime': 122.5736, 'eval_samples_per_second': 67.013, 'eval_steps_per_second': 4.193, 'epoch': 76.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-351196\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-351196\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-212566] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1293, 'learning_rate': 1.2777777777777777e-05, 'epoch': 77.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c888692be1ec44119a59830f00b92f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-355817\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-355817\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.416439533233643, 'eval_accuracy': 0.20952033114195276, 'eval_f1': 0.1513082454076243, 'eval_precision': 0.1658294617921947, 'eval_recall': 0.16887135582787757, 'eval_runtime': 143.393, 'eval_samples_per_second': 57.283, 'eval_steps_per_second': 3.585, 'epoch': 77.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-355817\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-355817\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-217187] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1252, 'learning_rate': 1.2222222222222222e-05, 'epoch': 78.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0fd9044e4344c788fa2284fec47af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-360438\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-360438\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.376171112060547, 'eval_accuracy': 0.2174336498660823, 'eval_f1': 0.15589200478051943, 'eval_precision': 0.16959768740671402, 'eval_recall': 0.17599079375771864, 'eval_runtime': 144.015, 'eval_samples_per_second': 57.036, 'eval_steps_per_second': 3.569, 'epoch': 78.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-360438\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-360438\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-221808] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1243, 'learning_rate': 1.1666666666666668e-05, 'epoch': 79.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6014d79d270e4272b26f03e20b1cb015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-365059\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-365059\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.384848594665527, 'eval_accuracy': 0.20964207450693936, 'eval_f1': 0.15293288886062817, 'eval_precision': 0.16738869727642308, 'eval_recall': 0.17077213123979965, 'eval_runtime': 143.3654, 'eval_samples_per_second': 57.294, 'eval_steps_per_second': 3.585, 'epoch': 79.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-365059\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-365059\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-226429] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.12, 'learning_rate': 1.1111111111111112e-05, 'epoch': 80.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab1e0d6df7994d9d8c5b1a39089f1f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-369680\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-369680\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.395618438720703, 'eval_accuracy': 0.2175553932310689, 'eval_f1': 0.15712278229583648, 'eval_precision': 0.17108206105335935, 'eval_recall': 0.17705836006528225, 'eval_runtime': 146.5492, 'eval_samples_per_second': 56.049, 'eval_steps_per_second': 3.507, 'epoch': 80.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-369680\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-369680\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-231050] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1142, 'learning_rate': 1.0555555555555555e-05, 'epoch': 81.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61099747fc7245dc9aef8757cf21ae06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-374301\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-374301\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.353093147277832, 'eval_accuracy': 0.2175553932310689, 'eval_f1': 0.1563086052040521, 'eval_precision': 0.1695704515645494, 'eval_recall': 0.17618043844856662, 'eval_runtime': 119.4987, 'eval_samples_per_second': 68.737, 'eval_steps_per_second': 4.301, 'epoch': 81.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-374301\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-374301\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-235671] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1181, 'learning_rate': 1e-05, 'epoch': 82.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb09184f08846d6a94e8e66c0ad9d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-378922\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-378922\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.400214672088623, 'eval_accuracy': 0.21828585342098855, 'eval_f1': 0.1555219219613159, 'eval_precision': 0.1685648148148148, 'eval_recall': 0.17575196408529742, 'eval_runtime': 118.6762, 'eval_samples_per_second': 69.214, 'eval_steps_per_second': 4.331, 'epoch': 82.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-378922\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-378922\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-240292] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1154, 'learning_rate': 9.444444444444445e-06, 'epoch': 83.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5915ec3a5339497a9d0d0382af4dc10b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-383543\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-383543\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.362945556640625, 'eval_accuracy': 0.22072072072072071, 'eval_f1': 0.15852482349195646, 'eval_precision': 0.17183529572287365, 'eval_recall': 0.1776729029720771, 'eval_runtime': 158.1105, 'eval_samples_per_second': 51.951, 'eval_steps_per_second': 3.251, 'epoch': 83.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-383543\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-383543\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-244913] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1139, 'learning_rate': 8.88888888888889e-06, 'epoch': 84.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a227d277b0854876b4ffea2d7544290f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-388164\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-388164\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.36318302154541, 'eval_accuracy': 0.21682493304114925, 'eval_f1': 0.15724718555900621, 'eval_precision': 0.1712172187715666, 'eval_recall': 0.17719655797101444, 'eval_runtime': 146.452, 'eval_samples_per_second': 56.087, 'eval_steps_per_second': 3.51, 'epoch': 84.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-388164\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-388164\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-249534] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1136, 'learning_rate': 8.333333333333334e-06, 'epoch': 85.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3e2d1a96ef4dc7a709f0a580288f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-392785\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-392785\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.348397254943848, 'eval_accuracy': 0.21560749939128318, 'eval_f1': 0.15501802900690664, 'eval_precision': 0.16747088342133842, 'eval_recall': 0.17572463768115942, 'eval_runtime': 119.9018, 'eval_samples_per_second': 68.506, 'eval_steps_per_second': 4.287, 'epoch': 85.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-392785\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-392785\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-254155] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1131, 'learning_rate': 7.777777777777777e-06, 'epoch': 86.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e379cd8a6fe47fe980dcb5f316c2dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-397406\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-397406\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.379720211029053, 'eval_accuracy': 0.21682493304114925, 'eval_f1': 0.1559797723254388, 'eval_precision': 0.17017931103080622, 'eval_recall': 0.17642901391000732, 'eval_runtime': 121.6825, 'eval_samples_per_second': 67.504, 'eval_steps_per_second': 4.224, 'epoch': 86.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-397406\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-397406\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-258776] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1165, 'learning_rate': 7.222222222222222e-06, 'epoch': 87.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd91defe9db47cfbe25f1e3efd4342c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-402027\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-402027\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.399720668792725, 'eval_accuracy': 0.21341611882152423, 'eval_f1': 0.15455434444340144, 'eval_precision': 0.16852691303019088, 'eval_recall': 0.17386395472628452, 'eval_runtime': 118.9393, 'eval_samples_per_second': 69.06, 'eval_steps_per_second': 4.322, 'epoch': 87.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-402027\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-402027\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-263397] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1098, 'learning_rate': 6.666666666666667e-06, 'epoch': 88.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605ce484d7e5498981b1a36a128a4587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-406648\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-406648\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.373951435089111, 'eval_accuracy': 0.21439006574141709, 'eval_f1': 0.15426675983262253, 'eval_precision': 0.16725738701619963, 'eval_recall': 0.17400629673356943, 'eval_runtime': 120.3662, 'eval_samples_per_second': 68.242, 'eval_steps_per_second': 4.27, 'epoch': 88.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-406648\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-406648\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-268018] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.106, 'learning_rate': 6.111111111111111e-06, 'epoch': 89.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dca714866b94a0c851bbaa140e61160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-411269\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-411269\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.378893852233887, 'eval_accuracy': 0.2160944728512296, 'eval_f1': 0.15693327952649985, 'eval_precision': 0.1704968449629467, 'eval_recall': 0.17703389830508476, 'eval_runtime': 119.1833, 'eval_samples_per_second': 68.919, 'eval_steps_per_second': 4.313, 'epoch': 89.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-411269\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-411269\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-272639] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1042, 'learning_rate': 5.555555555555556e-06, 'epoch': 90.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da7ae7ea7c02463894b49f4095268e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-415890\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-415890\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.379732608795166, 'eval_accuracy': 0.21658144631117604, 'eval_f1': 0.15479130058263124, 'eval_precision': 0.1677145337301587, 'eval_recall': 0.17452396953405014, 'eval_runtime': 119.3736, 'eval_samples_per_second': 68.809, 'eval_steps_per_second': 4.306, 'epoch': 90.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-415890\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-415890\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-277260] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1021, 'learning_rate': 5e-06, 'epoch': 91.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec9b09f4c4a4d6fa1d84b179b8bc077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-420511\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-420511\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.3395771980285645, 'eval_accuracy': 0.22011200389578767, 'eval_f1': 0.1601954294651208, 'eval_precision': 0.17519115084050146, 'eval_recall': 0.18003879237645468, 'eval_runtime': 118.7927, 'eval_samples_per_second': 69.146, 'eval_steps_per_second': 4.327, 'epoch': 91.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-420511\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-420511\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-281881] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0987, 'learning_rate': 4.444444444444445e-06, 'epoch': 92.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672cba49f4504032a8df9848c48878ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-425132\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-425132\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.35274076461792, 'eval_accuracy': 0.22011200389578767, 'eval_f1': 0.15976677199029746, 'eval_precision': 0.1750574492531597, 'eval_recall': 0.1783065236818588, 'eval_runtime': 119.6733, 'eval_samples_per_second': 68.637, 'eval_steps_per_second': 4.295, 'epoch': 92.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-425132\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-425132\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-286502] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1006, 'learning_rate': 3.888888888888889e-06, 'epoch': 93.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ceebda3bbfe44da8028d71f805a9d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-429753\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-429753\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.357621192932129, 'eval_accuracy': 0.2160944728512296, 'eval_f1': 0.15773028659104607, 'eval_precision': 0.17303516174402248, 'eval_recall': 0.17585372714486636, 'eval_runtime': 118.755, 'eval_samples_per_second': 69.168, 'eval_steps_per_second': 4.328, 'epoch': 93.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-429753\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-429753\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-291123] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.103, 'learning_rate': 3.3333333333333333e-06, 'epoch': 94.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa459181e964ebdad8e166d9e07d3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-434374\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-434374\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.3733344078063965, 'eval_accuracy': 0.21524226929632334, 'eval_f1': 0.15479613443505116, 'eval_precision': 0.16743093035720918, 'eval_recall': 0.17388554552546528, 'eval_runtime': 118.5823, 'eval_samples_per_second': 69.268, 'eval_steps_per_second': 4.335, 'epoch': 94.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-434374\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-434374\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-295744] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0973, 'learning_rate': 2.777777777777778e-06, 'epoch': 95.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823fcbef2fd3443f9d2caf829c664ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-438995\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-438995\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.3125128746032715, 'eval_accuracy': 0.22145118091064037, 'eval_f1': 0.1600902493915594, 'eval_precision': 0.17523353647807796, 'eval_recall': 0.17869219572276343, 'eval_runtime': 118.398, 'eval_samples_per_second': 69.376, 'eval_steps_per_second': 4.341, 'epoch': 95.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-438995\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-438995\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-300365] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0952, 'learning_rate': 2.2222222222222225e-06, 'epoch': 96.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27adbd93433b473598e6bfb0b5a5cf9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-443616\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-443616\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.33460807800293, 'eval_accuracy': 0.22145118091064037, 'eval_f1': 0.15839061480344044, 'eval_precision': 0.17172440118331905, 'eval_recall': 0.17732409262970383, 'eval_runtime': 118.6027, 'eval_samples_per_second': 69.256, 'eval_steps_per_second': 4.334, 'epoch': 96.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-443616\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-443616\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-304986] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0935, 'learning_rate': 1.6666666666666667e-06, 'epoch': 97.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061e7d17e901492e904becde0cd8a7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-448237\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-448237\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.301833152770996, 'eval_accuracy': 0.2220598977355734, 'eval_f1': 0.15845848418263372, 'eval_precision': 0.17164957203269765, 'eval_recall': 0.17970416526327607, 'eval_runtime': 119.5174, 'eval_samples_per_second': 68.726, 'eval_steps_per_second': 4.301, 'epoch': 97.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-448237\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-448237\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-309607] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.096, 'learning_rate': 1.1111111111111112e-06, 'epoch': 98.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d6b8cc991a4704a7128a405dad206c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-452858\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-452858\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.2989912033081055, 'eval_accuracy': 0.22522522522522523, 'eval_f1': 0.16335142726600604, 'eval_precision': 0.17761536428931754, 'eval_recall': 0.18338377893615831, 'eval_runtime': 119.6691, 'eval_samples_per_second': 68.639, 'eval_steps_per_second': 4.295, 'epoch': 98.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-452858\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-452858\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-314228] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0958, 'learning_rate': 5.555555555555556e-07, 'epoch': 99.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fee589228a644b89e1401ff7193d101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-457479\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-457479\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.32241153717041, 'eval_accuracy': 0.2191380569758948, 'eval_f1': 0.15508402652809997, 'eval_precision': 0.16727601558152477, 'eval_recall': 0.17455203116304951, 'eval_runtime': 120.8004, 'eval_samples_per_second': 67.996, 'eval_steps_per_second': 4.255, 'epoch': 99.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-457479\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-457479\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-318849] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0972, 'learning_rate': 0.0, 'epoch': 100.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77599e6574df4a809df91efb2b274649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT\\checkpoint-462100\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-462100\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.33422327041626, 'eval_accuracy': 0.2192598003408814, 'eval_f1': 0.15853998127565594, 'eval_precision': 0.1721199318241832, 'eval_recall': 0.17862544110233575, 'eval_runtime': 120.675, 'eval_samples_per_second': 68.067, 'eval_steps_per_second': 4.259, 'epoch': 100.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-462100\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT\\checkpoint-462100\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ViT_Boat_Class_ViT\\checkpoint-323470] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from D:/models/ViT_Boat_Class_ViT\\checkpoint-452858 (score: 0.22522522522522523).\n",
      "Saving model checkpoint to D:/models/ViT_Boat_Class_ViT/best_model\n",
      "Configuration saved in D:/models/ViT_Boat_Class_ViT/best_model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 207854.9764, 'train_samples_per_second': 35.566, 'train_steps_per_second': 2.223, 'train_loss': 1.0734034057696438, 'epoch': 100.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Boat_Class_ViT/best_model\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Boat_Class_ViT/best_model\\preprocessor_config.json\n",
      "Disabling tokenizer parallelism, we're using DataLoader multithreading already\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8214\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ad72666b33464aa2bf649bb79d4139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d12500f73de4fb0ac446da57f1a9282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='113.296 MB of 113.296 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>eval_accuracy</td><td></td></tr><tr><td>eval_f1</td><td></td></tr><tr><td>eval_loss</td><td></td></tr><tr><td>eval_precision</td><td></td></tr><tr><td>eval_recall</td><td></td></tr><tr><td>eval_runtime</td><td></td></tr><tr><td>eval_samples_per_second</td><td></td></tr><tr><td>eval_steps_per_second</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>100.0</td></tr><tr><td>eval_accuracy</td><td>0.21305</td></tr><tr><td>eval_f1</td><td>0.15496</td></tr><tr><td>eval_loss</td><td>6.36408</td></tr><tr><td>eval_precision</td><td>0.17038</td></tr><tr><td>eval_recall</td><td>0.17288</td></tr><tr><td>eval_runtime</td><td>123.3107</td></tr><tr><td>eval_samples_per_second</td><td>66.612</td></tr><tr><td>eval_steps_per_second</td><td>4.168</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ViT_Boat_Class_ViT</strong>: <a href=\"https://wandb.ai/cringgaard/Sailboat%20FGVC%20Clean/runs/3cuxghqj\" target=\"_blank\">https://wandb.ai/cringgaard/Sailboat%20FGVC%20Clean/runs/3cuxghqj</a><br/>Synced 5 W&B file(s), 1 media file(s), 101 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230602_164712-3cuxghqj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#launch tensorboard\n",
    "%load_ext tensorboard\n",
    "EPOCHS = 100\n",
    "model_name = \"ViT\"\n",
    "checkpoint = \"google/vit-base-patch16-224\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint)\n",
    "\n",
    "dataset_image_search = load_dataset(\"cringgaard/boats_dataset\" , use_auth_token=access_token, split=\"image_search\")\n",
    "for batch_size in batch_sizes:\n",
    "        tags = [model_name , \"Boat_Class\" , \"ViT\"]\n",
    "        name = \"_\".join(tags)\n",
    "        wandb.init(project=wandb_project, name=name , tags=tags)\n",
    "        torch.cuda.empty_cache()\n",
    "        c_names = dataset.column_names[1:]\n",
    "        c_names.remove('name')\n",
    "        # NOTE boat24 has wrong labels\n",
    "        # dataset_specific_test = dataset.remove_columns(c_names)\n",
    "        # dataset_boat24_specific_train = dataset_boat24.remove_columns(c_names)\n",
    "        # dataset_image_search_specific_train = dataset_image_search.remove_columns(c_names)\n",
    "        dataset_specific = dataset_image_search.remove_columns(c_names)\n",
    "\n",
    "\n",
    "        # # Debugging dataset\n",
    "        # dataset_specific = dataset_specific.select(range(1000))\n",
    "\n",
    "        # Split into train and eval\n",
    "        dataset_specific = dataset_specific.train_test_split(test_size=0.1 , seed=42)\n",
    "        \n",
    "        labels = dataset.features['name'].names\n",
    "        id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "        label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "\n",
    "        labels_train_counts = np.bincount(dataset_specific['train']['name'] , minlength=len(labels))\n",
    "        labels_test_counts = np.bincount(dataset_specific['test']['name'] , minlength=len(labels))\n",
    "\n",
    "        # weights = np.array([1 if x == 0 else x for x in labels_train_counts])\n",
    "        # weights = (1/weights)\n",
    "        # weights /= weights.sum()\n",
    "        # weights = torch.tensor(weights, dtype=torch.float , device=torch.device(\"cuda:0\"))\n",
    "\n",
    "        # class WeightedCETrainer(Trainer):\n",
    "        #     def __init__(self, *args, **kwargs):\n",
    "        #         super().__init__(*args, **kwargs)\n",
    "        #     def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        #         labels = inputs.get(\"labels\")\n",
    "        #         labels.to(torch.device(\"cuda:0\"))\n",
    "        #         outputs = model(**inputs)\n",
    "        #         logits = outputs.get(\"logits\")\n",
    "        #         # loss_fct = nn.CrossEntropyLoss(weight=weights , label_smoothing=0.1)\n",
    "        #         loss_fct = nn.CrossEntropyLoss(weight=weights)\n",
    "        #         loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        #         return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        def transforms(examples):\n",
    "            examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "            examples[\"labels\"] = examples['name']\n",
    "            del examples[\"name\"]\n",
    "            del examples[\"img_path\"]\n",
    "            return examples\n",
    "        \n",
    "        data_collator = DefaultDataCollator()\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # model = BoatClassifier(device)\n",
    "        model = AutoModelForImageClassification.from_pretrained(\n",
    "             checkpoint,\n",
    "             num_labels=len(labels),\n",
    "             id2label=id2label,\n",
    "             label2id=label2id,\n",
    "             ignore_mismatched_sizes=True,\n",
    "             )\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=model_dir+name,\n",
    "            report_to=\"tensorboard\",\n",
    "            remove_unused_columns=False,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            logging_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            # eval_steps = 10,\n",
    "            # logging_steps = 10,\n",
    "            # save_steps = 10,\n",
    "            save_total_limit=30,\n",
    "            learning_rate=5e-5,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            gradient_accumulation_steps=1,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=EPOCHS,\n",
    "            warmup_ratio=0.1,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"accuracy\",\n",
    "            # label_smoothing_factor=0.1,\n",
    "            # no_cuda=True\n",
    "            # push_to_hub=True,\n",
    "            # hub_strategy=\"end\",\n",
    "            # hub_model_id=\"boats_dataset\",\n",
    "            # hub_token=write_token,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            data_collator=data_collator,\n",
    "            train_dataset=dataset_specific['train'].with_transform(transforms),\n",
    "            eval_dataset=dataset_specific['test'].with_transform(transforms),\n",
    "            tokenizer=image_processor,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "        # # Plot Label Distribution For Training Data\n",
    "        # fig1 = plt.figure()\n",
    "        # ax = fig1.add_axes([0,0,1,1])\n",
    "        # ax.bar([label2id[x] for x in labels], labels_train_counts/dataset_specific['train'].__len__()) # Normalized\n",
    "        # ax.set_ylabel(\"Number of examples normalised\")\n",
    "        # ax.set_title(\"Label Distribution\")\n",
    "        # wandb.log({\"Label Distribution Train\": (fig1)})\n",
    "\n",
    "        # # Plot Label Distribution For Test Data\n",
    "        # fig2 = plt.figure()\n",
    "        # ax = fig2.add_axes([0,0,1,1])\n",
    "        # ax.bar([label2id[x] for x in labels], labels_test_counts/dataset_specific['test'].__len__()) # Normalized\n",
    "        # ax.set_ylabel(\"Number of examples normalised\")\n",
    "        # ax.set_title(\"Label Distribution\")\n",
    "        # wandb.log({\"Label Distribution Test\": (fig2)})\n",
    "\n",
    "        # # Log label2id\n",
    "        # wandb.log({\"Labels\": wandb.Table(data = list(zip(label2id.keys() , label2id.values())) , columns=[\"Label\" , \"ID\"])})\n",
    "\n",
    "        # Train Model\n",
    "        trainer.train()\n",
    "\n",
    "        # Save Model\n",
    "        trainer.save_model(model_dir+name+\"/best_model\")\n",
    "\n",
    "        pipeline = ImageClassificationPipeline(model=trainer.model, feature_extractor = trainer.tokenizer , framework=\"pt\", device=0)\n",
    "        predict_data = dataset_specific['test'].select(np.random.randint(0, len(dataset_specific['test']), 100))\n",
    "        images = [predict_data['img_path'][i] for i in range(100)]\n",
    "        predictions = pipeline(images)\n",
    "        prediction_table = []\n",
    "        for i in range(len(predictions)):\n",
    "            prediction_table.append([wandb.Image(images[i]) , predictions[i] , id2label[predict_data['name'][i]]])\n",
    "        columns = [\"Image\" , \"Label Predictions\" , \"True Label\"]\n",
    "        wandb.log({\"Image Predicitions\" : wandb.Table(data=prediction_table, columns=columns)})\n",
    "\n",
    "        metrics = trainer.evaluate(dataset_specific['test'].with_transform(transforms))\n",
    "        wandb.log(metrics)\n",
    "        wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multitask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import PreTrainedModel\n",
    "# from transformers.models.resnet.modeling_resnet import ImageClassifierOutputWithNoAttention\n",
    "# from typing import Optional\n",
    "\n",
    "# class MultitaskBoatClassifier(PreTrainedModel):\n",
    "#     def __init__(self, config, num_classes_list , label2id , id2label):\n",
    "#         super().__init__(config)\n",
    "#         self.num_classes_list = num_classes_list\n",
    "#         self.label2id = label2id\n",
    "#         self.id2label = id2label\n",
    "#         self.resnet = ResNetModel.from_pretrained(\"microsoft/resnet-18\" , num_labels =Name_Classes.__len__() , label2id=self.label2id , id2label=self.id2label)\n",
    "#         self.heads = nn.ModuleList([nn.Sequential(nn.Flatten() , nn.Linear(512, num_classes)) for num_classes in num_classes_list])\n",
    "#         self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#     def forward(\n",
    "#         self,\n",
    "#         pixel_values: Optional[torch.FloatTensor] = None,\n",
    "#         labels: Optional[torch.LongTensor] = None,\n",
    "#         output_hidden_states: Optional[bool] = None,\n",
    "#         return_dict: Optional[bool] = None,\n",
    "#     ) -> ImageClassifierOutputWithNoAttention:\n",
    "#         r\"\"\"\n",
    "#         labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "#             Labels for computing the image classification/regression loss. Indices should be in `[0, ...,\n",
    "#             config.num_labels - 1]`. If `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "#         \"\"\"\n",
    "#         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "#         outputs = self.resnet(pixel_values, output_hidden_states=output_hidden_states, return_dict=return_dict)\n",
    "#         pooled_outputs = outputs.pooler_output if return_dict else outputs[1]\n",
    "#         class_logits = []\n",
    "#         for head in self.heads:\n",
    "#             class_logits.append(head(pooled_outputs))\n",
    "\n",
    "#         loss = None\n",
    "\n",
    "#         if labels is not None:\n",
    "#             loss = 0\n",
    "#             i = 0\n",
    "#             for logits in class_logits:\n",
    "#                 loss += self.criterion(logits, torch.transpose(labels,0,1)[i])\n",
    "#                 i += 1\n",
    "#             loss = loss / len(class_logits)\n",
    "        \n",
    "#         # print(class_logits[-1])\n",
    "#         # print(class_logits[-1].shape)\n",
    "#         return ImageClassifierOutputWithNoAttention(loss=loss, logits=class_logits[-1], hidden_states=outputs.hidden_states)\n",
    "\n",
    "\n",
    "# from transformers import PretrainedConfig\n",
    "# class MultitaskBoatClassifierConfig(PretrainedConfig):\n",
    "#     def __init__(self, num_classes_list = [Hull_Type_Classes.__len__(),Rigging_Type_Classes.__len__(),Construction_Classes.__len__(),Ballast_Type_Classes.__len__(),Designer_Classes.__len__() , Name_Classes.__len__()], label2id = None , **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "#         self.num_classes_list = num_classes_list\n",
    "#         self.hidden_size = 512  # Specify the hidden size of the model\n",
    "#         self.num_labels = sum(num_classes_list)  # Total number of labels across all classification heads\n",
    "#         self.label2id = label2id if label2id is not None else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #launch tensorboard\n",
    "# %load_ext tensorboard\n",
    "\n",
    "# dataset_image_search = load_dataset(\"cringgaard/boats_dataset\" , use_auth_token=access_token, split=\"image_search\")\n",
    "# for batch_size in batch_sizes:\n",
    "#     # for label_combination in label_combinations:\n",
    "#         # label_types = [label_combination[0] , label_combination[1]]\n",
    "#         label_types = [\"Hull Type\" , \"Rigging Type\" ,  \"Construction\" , \"Ballast Type\" , \"Designer\"]\n",
    "#         tags = [model_name , \"Boat_Class\" , \"multitask\"]\n",
    "#         name = \"_\".join(tags)\n",
    "#         wandb.init(project=wandb_project, name=name , tags=tags)\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "#         # FOR DEBUGGING\n",
    "#         # dataset_specific = dataset_image_search.select(np.random.randint(0, len(dataset_image_search), 1000))\n",
    "#         # dataset_specific = dataset_specific.train_test_split(test_size=0.1, shuffle=True, seed=42)\n",
    "\n",
    "\n",
    "#         dataset_specific = dataset_image_search.train_test_split(test_size=0.1, shuffle=True, seed=42)\n",
    "\n",
    "#         for label_type in label_types:\n",
    "#             labels = np.unique(dataset_specific['train'][label_type])\n",
    "#             labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "#             labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "#             labels_to_remove = np.where(labels_train_counts < 1)[0] # remove labels with less than 2 examples\n",
    "#             labels_to_remove = np.union1d(labels_to_remove, np.where(labels_test_counts < 1)[0])\n",
    "#             # dataset_specific['train'] = dataset_specific['train'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "#             dataset_specific['test'] = dataset_specific['test'].filter(lambda x: x[label_type] not in labels_to_remove)            \n",
    "#             labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "#             labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "\n",
    "#         def transforms(examples):\n",
    "#             examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "#             # examples[\"labels\"] = {label_type : examples[label_type] for label_type in label_types}\n",
    "#             labs = [examples[label_type] for label_type in label_types+[\"name\"]]\n",
    "#             examples['labels'] = list(map(list, zip(*labs)))\n",
    "#             # Remove all other keys in dictionary\n",
    "#             for key in list(examples.keys()):\n",
    "#                 if key not in [\"pixel_values\" , \"labels\"]:\n",
    "#                     del examples[key]\n",
    "#             return examples\n",
    "        \n",
    "#         data_collator = DefaultDataCollator()\n",
    "#         device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#         num_classes_list = [\n",
    "#                 Hull_Type_Classes.__len__(),\n",
    "#                 Rigging_Type_Classes.__len__(),\n",
    "#                 Construction_Classes.__len__(),\n",
    "#                 Ballast_Type_Classes.__len__(),\n",
    "#                 Designer_Classes.__len__(),\n",
    "#                 Name_Classes.__len__()\n",
    "#         ]\n",
    "\n",
    "#         labels = dataset.features['name'].names\n",
    "#         id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "#         label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "        \n",
    "\n",
    "#         config = MultitaskBoatClassifierConfig(num_classes_list, label2id=label2id , id2label=id2label)\n",
    "#         model = MultitaskBoatClassifier(config , num_classes_list=num_classes_list , label2id=label2id , id2label=id2label)\n",
    "\n",
    "#         training_args = TrainingArguments(\n",
    "#             output_dir=model_dir+name,\n",
    "#             report_to=\"tensorboard\",\n",
    "#             remove_unused_columns=False,\n",
    "#             evaluation_strategy=\"epoch\",\n",
    "#             logging_strategy=\"epoch\",\n",
    "#             save_strategy=\"epoch\",\n",
    "#             eval_steps = 10,\n",
    "#             logging_steps = 10,\n",
    "#             # save_steps = 10,\n",
    "#             save_total_limit=1,\n",
    "#             learning_rate=5e-5,\n",
    "#             per_device_train_batch_size=batch_size,\n",
    "#             gradient_accumulation_steps=1,\n",
    "#             per_device_eval_batch_size=batch_size,\n",
    "#             num_train_epochs=EPOCHS,\n",
    "#             warmup_ratio=0.1,\n",
    "#         )\n",
    "\n",
    "#         trainer = Trainer(\n",
    "#             model=model,\n",
    "#             args=training_args,\n",
    "#             data_collator=data_collator,\n",
    "#             train_dataset=dataset_specific[\"train\"].with_transform(transforms),\n",
    "#             eval_dataset=dataset_specific[\"test\"].with_transform(transforms),\n",
    "#             tokenizer=image_processor,\n",
    "#             compute_metrics = compute_metrics,\n",
    "#         )\n",
    "\n",
    "#         trainer.train()\n",
    "\n",
    "#         # Save Model\n",
    "#         trainer.save_model(model_dir+name+\"/best_model\")\n",
    "\n",
    "#         pipeline = ImageClassificationPipeline(model=trainer.model, feature_extractor = trainer.tokenizer , framework=\"pt\", device=0)\n",
    "#         predict_data = dataset_specific['test'].select(np.random.randint(0, len(dataset_specific['test']), 100))\n",
    "#         images = [predict_data['img_path'][i] for i in range(100)]\n",
    "#         predictions = pipeline(images)\n",
    "#         prediction_table = []\n",
    "#         for i in range(len(predictions)):\n",
    "#             prediction_table.append([wandb.Image(images[i]) , predictions[i] , id2label[predict_data['name'][i]]])\n",
    "#         columns = [\"Image\" , \"Label Predictions\" , \"True Label\"]\n",
    "#         wandb.log({\"Image Predicitions\" : wandb.Table(data=prediction_table, columns=columns)})\n",
    "\n",
    "#         metrics = trainer.evaluate(dataset_specific['test'].with_transform(transforms))\n",
    "#         wandb.log(metrics)\n",
    "#         wandb.finish()\n",
    "#         wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
