{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoImageProcessor\n",
    "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
    "from transformers import DefaultDataCollator\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoModel , AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from huggingface_hub import login\n",
    "import wandb\n",
    "from transformers import pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "from data.classes import *\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image as mpimg\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_PROJECT'] = \"Sailboat FGVC\"\n",
    "os.environ[\"WANDB_WATCH\"]=\"false\"\n",
    "os.environ[\"WANDB_LOG_MODEL\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset boats_dataset (C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b)\n"
     ]
    }
   ],
   "source": [
    "access_token = \"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\"\n",
    "write_token = \"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\"\n",
    "# login(token=access_token)\n",
    "dataset = load_dataset(\"cringgaard/boats_dataset\" , use_auth_token=access_token, split=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"google/vit-base-patch16-224\"\n",
    "model_name = \"ViT\"\n",
    "# checkpoint = \"microsoft/resnet-18\"\n",
    "# model_name = \"ResNet18\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "size = (\n",
    "    image_processor.size[\"shortest_edge\"]\n",
    "    if \"shortest_edge\" in image_processor.size\n",
    "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    ")\n",
    "_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_types = [\"Hull Type\" , \"Rigging Type\" ,  \"Construction\" , \"Ballast Type\" , \"Designer\"]\n",
    "# label_types = [\"Construction\" , \"Ballast Type\" , \"Designer\"]\n",
    "batch_sizes = [2]\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    metrics = {}\n",
    "    metrics.update(accuracy.compute(predictions=predictions, references=labels))\n",
    "    metrics.update(f1.compute(predictions=predictions, references=labels , average=\"macro\"))\n",
    "    metrics.update(precision.compute(predictions=predictions, references=labels , average=\"macro\"))\n",
    "    metrics.update(recall.compute(predictions=predictions, references=labels , average=\"macro\"))\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics_multitask(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    f1_score = 0\n",
    "    precision_score = 0\n",
    "    recall_score = 0\n",
    "    accuracy_score = 0\n",
    "    for i , label in enumerate(label_types):\n",
    "        predictions, labels = eval_pred[1]\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        accuracy_score += accuracy.compute(predictions=predictions, references=labels).values()\n",
    "        f1_score += f1.compute(predictions=predictions, references=labels , average=\"macro\").values()\n",
    "        precision_score += precision.compute(predictions=predictions, references=labels , average=\"macro\").values()\n",
    "        recall_score += recall.compute(predictions=predictions, references=labels , average=\"macro\").values()\n",
    "        \n",
    "    accuracy_score /= len(label_types)\n",
    "    f1_score /= len(label_types)\n",
    "    precision_score /= len(label_types)\n",
    "    recall_score /= len(label_types)\n",
    "    metrics = {'accuracy' : accuracy_score , 'f1' : f1_score , 'precision' : precision_score , 'recall' : recall_score}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_images = [_transforms(img.convert(\"RGB\")) for img in dataset['full'][0:16][\"img_path\"]]\n",
    "# test_images = torch.stack(test_images)\n",
    "# print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModel.from_pretrained(checkpoint)\n",
    "# model(torch.stack(test_images))['last_hidden_state']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskViT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultitaskViT, self).__init__()\n",
    "        self.base_model = AutoModel.from_pretrained(checkpoint , id2label = None , label2id = None)\n",
    "        self.linear1 = nn.Linear(768, 1024)\n",
    "        self.SoftMax = nn.Softmax(dim=1)\n",
    "        self.Hull_Type = nn.Linear(1024, (Hull_Type_Classes.__len__()))\n",
    "        self.Rigging_Type = nn.Linear(1024, (Rigging_Type_Classes.__len__()))\n",
    "        self.Construction = nn.Linear(1024, (Construction_Classes.__len__()))\n",
    "        self.Ballast_Type = nn.Linear(1024, (Ballast_Type_Classes.__len__()))\n",
    "        self.Designer = nn.Linear(1024, (Designer_Classes.__len__()))\n",
    "\n",
    "        \n",
    "    def forward(self, **inputs):\n",
    "        outputs = self.base_model(inputs['pixel_values'])['pooler_output']\n",
    "        outputs = nn.GELU()(outputs)\n",
    "        outputs = self.linear1(outputs)\n",
    "        hull_type = self.SoftMax(self.Hull_Type(outputs))\n",
    "        rigging_type = self.SoftMax(self.Rigging_Type(outputs))\n",
    "        construction = self.SoftMax(self.Construction(outputs))\n",
    "        ballast_type = self.SoftMax(self.Ballast_Type(outputs))\n",
    "        designer = self.SoftMax(self.Designer(outputs))\n",
    "        return hull_type, rigging_type, construction, ballast_type, designer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    def compute_loss(self, model, inputs):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        model_output = model(**inputs)\n",
    "        total_loss = 0\n",
    "        for i in range (len(model_output)):    \n",
    "            total_loss += criterion(model_output[i], inputs[label_types[i]])\n",
    "        return total_loss\n",
    "    \n",
    "    def compute_metrics(self, eval_pred):\n",
    "        return compute_metrics_multitask(eval_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testModel = MultitaskViT()\n",
    "# outputs = testModel(**{'pixel_values' : test_images})\n",
    "# print([x.shape for x in outputs])\n",
    "# # compute_metrics_multitask(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for gradient_accumulation_step in batch_sizes:\n",
    "# wandb.init(project=\"Sailboat FGVC\", name=model_name+\"_multitask\")\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# dataset_specific = dataset['full'].train_test_split(test_size=0.2, shuffle=True, seed=43)\n",
    "\n",
    "# def transforms(examples):\n",
    "#     examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "#     del examples[\"img_path\"]\n",
    "#     del examples[\"name\"]\n",
    "#     return examples\n",
    "\n",
    "\n",
    "# # id2label = {float(i): label for i, label in enumerate(label_types)}\n",
    "# # label2id = {label: float(i) for i, label in enumerate(label_types)}\n",
    "\n",
    "\n",
    "# dataset_specific = dataset_specific.with_transform(transforms)\n",
    "# # dataset_specific.set_format(type=\"torch\")\n",
    "# data_collator = DefaultDataCollator()\n",
    "\n",
    "# model = MultitaskViT()\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"E:/models/\"+model_name+\"_multitask\",\n",
    "#     report_to=\"wandb\",\n",
    "#     remove_unused_columns=False,\n",
    "#     evaluation_strategy=\"steps\",\n",
    "#     save_strategy=\"steps\",\n",
    "#     learning_rate=5e-5,\n",
    "#     per_device_train_batch_size=16,\n",
    "#     gradient_accumulation_steps=2,\n",
    "#     per_device_eval_batch_size=16,\n",
    "#     num_train_epochs=100,\n",
    "#     warmup_ratio=0.1,\n",
    "#     logging_steps=10,\n",
    "#     load_best_model_at_end=True,\n",
    "#     metric_for_best_model=\"f1\",\n",
    "#     # no_cuda=True\n",
    "#     # push_to_hub=True,\n",
    "# )\n",
    "\n",
    "# trainer = MultiTaskTrainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     data_collator=data_collator,\n",
    "#     train_dataset=dataset_specific[\"train\"],\n",
    "#     eval_dataset=dataset_specific[\"test\"],\n",
    "#     tokenizer=image_processor,\n",
    "#     compute_metrics=compute_metrics_multitask,\n",
    "    \n",
    "# )\n",
    "\n",
    "# trainer.train()\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Go from index to label\n",
    "# label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "# print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcringgaard\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\chris\\OneDrive\\Dokumenter\\GitHub\\SailFGVC\\wandb\\run-20230425_153653-2q2fcjio</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cringgaard/Sailboat%20FGVC/runs/2q2fcjio\" target=\"_blank\">ViT_Hull Type_Label Smoothing_WeightedCE</a></strong> to <a href=\"https://wandb.ai/cringgaard/Sailboat%20FGVC\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\\cache-7e02f6d0f03e0fc9.arrow and C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\\cache-18fdfce3e1669319.arrow\n",
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\\cache-594dc0edc4ea28fb.arrow\n",
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\\cache-59a8c7aab501b52b.arrow\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([67, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([67]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `WANDB_LOG_MODEL` from true to `end` instead\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8318\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 13000\n",
      "  Number of trainable parameters = 85850179\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc2b9da1571448b9249de92744f4848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for size in batch_sizes:\n",
    "    for label_type in label_types:\n",
    "        name = model_name+\"_\"+label_type+\"_Label Smoothing_WeightedCE\"\n",
    "        wandb.init(project=\"Sailboat FGVC\", name=name)\n",
    "        torch.cuda.empty_cache()\n",
    "        c_names = dataset.column_names[1:]\n",
    "        c_names.remove(label_type)\n",
    "        dataset_specific = dataset.remove_columns(c_names)\n",
    "\n",
    "        labels = dataset.features[label_type].names\n",
    "        id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "        label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "\n",
    "        dataset_specific = dataset_specific.train_test_split(test_size=0.2, shuffle=True, seed=43)\n",
    "\n",
    "        # labels_train = dataset_specific['train'].unique(label_type)\n",
    "        # labels_test = dataset_specific['test'].unique(label_type)\n",
    "\n",
    "        labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "        labels_to_remove = np.where(labels_train_counts < 2)[0] # remove labels with less than 2 examples\n",
    "        dataset_specific['train'] = dataset_specific['train'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "        dataset_specific['test'] = dataset_specific['test'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "        labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "\n",
    "\n",
    "        # for key in list(id2label.keys()):\n",
    "        #     if key in labels_to_remove:\n",
    "        #         label2id.pop(id2label[key])\n",
    "        #         id2label.pop(key)\n",
    "\n",
    "        weights = np.array([1 if x == 0 else x for x in labels_train_counts])\n",
    "        weights = (1/weights)\n",
    "        weights /= weights.sum()\n",
    "        weights = torch.tensor(weights, dtype=torch.float , device=torch.device(\"cuda:0\"))\n",
    "\n",
    "        class WeightedCETrainer(Trainer):\n",
    "            def __init__(self, *args, **kwargs):\n",
    "                super().__init__(*args, **kwargs)\n",
    "            def compute_loss(self, model, inputs, return_outputs=False):\n",
    "                labels = inputs.get(\"labels\")\n",
    "                labels.to(torch.device(\"cuda:0\"))\n",
    "                outputs = model(**inputs)\n",
    "                logits = outputs.get(\"logits\")\n",
    "                loss_fct = nn.CrossEntropyLoss(weight=weights , label_smoothing=0.1)\n",
    "                # loss_fct = nn.CrossEntropyLoss(weight=weights)\n",
    "                loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "                return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        def transforms(examples):\n",
    "            examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "            examples[\"labels\"] = examples[label_type]\n",
    "            del examples[label_type]\n",
    "            del examples[\"img_path\"]\n",
    "            return examples\n",
    "        data_collator = DefaultDataCollator()\n",
    "\n",
    "        model = AutoModelForImageClassification.from_pretrained(\n",
    "            checkpoint,\n",
    "            num_labels=len(labels),\n",
    "            id2label=id2label,\n",
    "            label2id=label2id,\n",
    "            use_auth_token=access_token,\n",
    "            ignore_mismatched_sizes=True,\n",
    "        )\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=\"E:/models/\"+name,\n",
    "            report_to=\"wandb\",\n",
    "            remove_unused_columns=False,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            logging_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            # eval_steps = 10,\n",
    "            # logging_steps = 10,\n",
    "            # save_steps = 10,\n",
    "            save_total_limit=1,\n",
    "            learning_rate=5e-5,\n",
    "            per_device_train_batch_size=16,\n",
    "            gradient_accumulation_steps=size,\n",
    "            per_device_eval_batch_size=16,\n",
    "            num_train_epochs=EPOCHS,\n",
    "            warmup_ratio=0.1,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"f1\",\n",
    "            # label_smoothing_factor=0.1,\n",
    "            # no_cuda=True\n",
    "            # push_to_hub=True,\n",
    "            # hub_strategy=\"end\",\n",
    "            # hub_model_id=\"boats_dataset\",\n",
    "            # hub_token=write_token,\n",
    "        )\n",
    "\n",
    "        trainer = WeightedCETrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            data_collator=data_collator,\n",
    "            train_dataset=dataset_specific[\"train\"].with_transform(transforms),\n",
    "            eval_dataset=dataset_specific[\"test\"].with_transform(transforms),\n",
    "            tokenizer=image_processor,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "\n",
    "        fig1 = plt.figure()\n",
    "        ax = fig1.add_axes([0,0,1,1])\n",
    "        ax.bar(range(0,len(np.where(labels_train_counts > 0)[0])), labels_train_counts[np.where(labels_train_counts > 0)[0]])\n",
    "        wandb.log({\"Label Distribution\": wandb.Image(fig1)})\n",
    "        trainer.train()\n",
    "        # Plot confusion matrix\n",
    "        y_pred = trainer.predict(dataset_specific['test'].with_transform(transforms)).predictions.argmax(-1)\n",
    "        y_true = dataset_specific[\"test\"][label_type]\n",
    "        fig2 = sns.heatmap(metrics.confusion_matrix(y_true, y_pred)).get_figure()\n",
    "        wandb.log({\"Confusion Matrix\": wandb.Image(fig2)})\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = dataset_specific[\"test\"][label_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
