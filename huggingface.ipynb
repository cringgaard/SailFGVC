{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset , concatenate_datasets\n",
    "from transformers import AutoImageProcessor\n",
    "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
    "from transformers import DefaultDataCollator\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoModel , AutoModelForImageClassification, TrainingArguments, Trainer , ImageClassificationPipeline , ResNetForImageClassification , ResNetBackbone\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from huggingface_hub import login\n",
    "import wandb\n",
    "from transformers import pipeline\n",
    "from sklearn import metrics\n",
    "import json\n",
    "import PIL\n",
    "from data.clean_classes import *\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image as mpimg\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "data_dir = \"data/\"\n",
    "img_dir = \"E:/data/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_PROJECT'] = \"Sailboat FGVC\"\n",
    "os.environ[\"WANDB_WATCH\"]=\"false\"\n",
    "# os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
    "os.environ[\"WANDB_START_METHOD\"]='thread'\n",
    "wandb_project = \"Sailboat FGVC Clean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = \"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\"\n",
    "write_token = \"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\"\n",
    "# login(token=access_token)\n",
    "dataset_boat24 = load_dataset(\"cringgaard/boats_dataset\" , use_auth_token=access_token, split=\"boat24\")\n",
    "dataset = load_dataset(\"cringgaard/boats_dataset\" , use_auth_token=access_token, split=\"sailboatdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = \"google/vit-base-patch16-224\"\n",
    "# model_name = \"ViT\"\n",
    "model_dir = \"D:/models/\"\n",
    "checkpoint = \"microsoft/resnet-18\"\n",
    "model_name = \"ResNet18\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "size = (\n",
    "    image_processor.size[\"shortest_edge\"]\n",
    "    if \"shortest_edge\" in image_processor.size\n",
    "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    ")\n",
    "_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "label_types = [\"Hull Type\" , \"Rigging Type\" ,  \"Construction\" , \"Ballast Type\" , \"Designer\"]\n",
    "# label_types = [\"Construction\" , \"Ballast Type\" , \"Designer\"]\n",
    "# label_types = [\"Hull Type\" , \"Rigging Type\"]\n",
    "label_maps = {\n",
    "    \"Hull Type\" : Hull_Type_Classes,\n",
    "    \"Rigging Type\" : Rigging_Type_Classes,\n",
    "    \"Construction\" : Construction_Classes,\n",
    "    \"Ballast Type\" : Ballast_Type_Classes,\n",
    "    \"Designer\" : Designer_Classes\n",
    "}\n",
    "# label_types = [\"Ballast Type\" , \"Designer\"]\n",
    "# label_types = [\"Designer\"]\n",
    "# losses = [\"CE\" , \"WeightedCE\"]\n",
    "# losses = [\"WeightedCE\"]\n",
    "losses = [\"CE\"]\n",
    "batch_sizes = [16]\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    metrics = {}\n",
    "    metrics.update(accuracy.compute(predictions=predictions, references=labels))\n",
    "    metrics.update(f1.compute(predictions=predictions, references=labels , average=\"macro\"))\n",
    "    metrics.update(precision.compute(predictions=predictions, references=labels , average=\"macro\"))\n",
    "    metrics.update(recall.compute(predictions=predictions, references=labels , average=\"macro\"))\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskResnet(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(MultitaskResnet, self).__init__()\n",
    "        self.base_model = ResNetBackbone.from_pretrained(\"microsoft/resnet-18\")\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(512*7**2 , 1024)\n",
    "        self.linear2 = nn.Linear(1024 , 1024)\n",
    "        self.linear3 = nn.Linear(1024 , 1024)\n",
    "        self.SoftMax = nn.Softmax(dim=1)\n",
    "        self.GELU = nn.GELU()\n",
    "        \n",
    "        # Define the classification heads\n",
    "        self.heads = nn.ModuleDict({\n",
    "            \"Hull Type\": nn.Linear(1024, Hull_Type_Classes.__len__()),\n",
    "            \"Rigging Type\": nn.Linear(1024, Rigging_Type_Classes.__len__()),\n",
    "            \"Construction\": nn.Linear(1024, Construction_Classes.__len__()),\n",
    "            \"Ballast Type\": nn.Linear(1024, Ballast_Type_Classes.__len__()),\n",
    "            \"Designer\": nn.Linear(1024, Designer_Classes.__len__())\n",
    "        })\n",
    "        \n",
    "        # Move the classification heads to the specified device\n",
    "        self.to(device)\n",
    "        for head in self.heads.values():\n",
    "            head.to(device)\n",
    "        \n",
    "    def forward(self, **inputs):\n",
    "        outputs = self.base_model.forward(pixel_values=inputs['pixel_values'])\n",
    "        outputs = self.flatten(outputs.feature_maps[-1])\n",
    "        outputs = self.linear1(outputs)\n",
    "        outputs = self.GELU(outputs)\n",
    "        outputs = self.linear2(outputs)\n",
    "        outputs = self.GELU(outputs)\n",
    "        outputs = self.linear3(outputs)\n",
    "        outputs = self.GELU(outputs)\n",
    "        # Forward pass through each classification head\n",
    "        output_dict = {}\n",
    "        for head, linear_layer in self.heads.items():\n",
    "            output_dict[head] = self.SoftMax(linear_layer(outputs))\n",
    "        \n",
    "        return output_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskTrainer(Trainer): # Inherit from trainer\n",
    "    def __init__(self, label_types, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.label_types = label_types\n",
    "        self.label_types_2_index = {\n",
    "            \"Hull Type\" : 0,\n",
    "            \"Rigging Type\" : 1,\n",
    "            \"Construction\" : 2,\n",
    "            \"Ballast Type\" : 3,\n",
    "            \"Designer\" : 4\n",
    "        }\n",
    "\n",
    "    def compute_loss(self , model , inputs):\n",
    "        labels = {}\n",
    "        for head in self.label_types:\n",
    "            labels[head] = inputs.pop(head)\n",
    "        outputs = model.forward(**inputs)\n",
    "        losses = {}\n",
    "\n",
    "        for head, logits in outputs.items():\n",
    "            if head in self.label_types:\n",
    "                loss = self.compute_cross_entropy_loss(logits, labels[head])\n",
    "                losses[head] = loss\n",
    "\n",
    "        total_loss = sum(losses.values())\n",
    "        return total_loss\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_cross_entropy_loss(predictions, targets):\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        return loss(predictions, targets)\n",
    "\n",
    "    def compute_metrics(self , eval_pred):\n",
    "        predictions, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "        metrics = {}\n",
    "        preds = {}\n",
    "\n",
    "        # for i , head in enumerate(labels.keys()):\n",
    "        #     preds[head] = predictions[i]\n",
    "        \n",
    "        # predictions = preds\n",
    "\n",
    "        # for head in labels.keys():\n",
    "        for i , head in enumerate(self.label_types):\n",
    "            predicted_labels = predictions[self.label_types_2_index[head]].argmax(axis=1)\n",
    "            f1 = f1_score(labels[i], predicted_labels, average='macro')\n",
    "            accuracy = accuracy_score(labels[i], predicted_labels)\n",
    "            metrics[f'{self.label_types[i]}_f1'] = f1\n",
    "            metrics[f'{self.label_types[i]}_accuracy'] = accuracy\n",
    "\n",
    "        return metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiTaskTrainer(Trainer): # Define multitask trainer where label types are defined in the init\n",
    "#     def __init__(self, label_types, *args, **kwargs):\n",
    "#         super().__init__(*args, **kwargs)\n",
    "#         self.criterion = nn.CrossEntropyLoss()\n",
    "#         self.label_types = label_types\n",
    "#     def compute_loss(self, model, inputs):\n",
    "#         labels = inputs.get('labels')\n",
    "#         outputs = model(**inputs)\n",
    "\n",
    "#         total_loss = 0\n",
    "#         for i in range (len(self.label_types)):\n",
    "#             total_loss += self.criterion(outputs[label_types[i]], inputs[label_types[i]])\n",
    "#         return total_loss\n",
    "\n",
    "#         # model_output = model(**inputs)\n",
    "#         # total_loss = 0\n",
    "#         # for i in range (len(model_output)):    \n",
    "#         #     total_loss += self.criterion(model_output[label_types[i]], inputs[label_types[i]])\n",
    "#         # return total_loss\n",
    "        \n",
    "#     # def compute_metrics(self , model , inputs):\n",
    "#     #     # Construct a dictionary of label_type and dataset labels\n",
    "#     #     labels = {}\n",
    "#     #     for label in self.label_types:\n",
    "#     #         labels[label] = inputs[label]\n",
    "#     #     outputs = self.predict(inputs).predictions\n",
    "#     #     predictions = {}\n",
    "#     #     for i in range (len(self.label_types)):\n",
    "#     #         predictions[label_types[i]] = outputs[i].argmax(-1)\n",
    "#     #     return compute_metrics_multitask(predictions, labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testModel = MultitaskViT()\n",
    "# outputs = testModel(**{'pixel_values' : test_images})\n",
    "# print([x.shape for x in outputs])\n",
    "# # compute_metrics_multitask(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for gradient_accumulation_step in batch_sizes:\n",
    "# wandb.init(project=\"Sailboat FGVC\", name=model_name+\"_multitask\")\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# dataset_specific = dataset['full'].train_test_split(test_size=0.2, shuffle=True, seed=43)\n",
    "\n",
    "# def transforms(examples):\n",
    "#     examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "#     del examples[\"img_path\"]\n",
    "#     del examples[\"name\"]\n",
    "#     return examples\n",
    "\n",
    "\n",
    "# # id2label = {float(i): label for i, label in enumerate(label_types)}\n",
    "# # label2id = {label: float(i) for i, label in enumerate(label_types)}\n",
    "\n",
    "\n",
    "# dataset_specific = dataset_specific.with_transform(transforms)\n",
    "# # dataset_specific.set_format(type=\"torch\")\n",
    "# data_collator = DefaultDataCollator()\n",
    "\n",
    "# model = MultitaskViT()\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"E:/models/\"+model_name+\"_multitask\",\n",
    "#     report_to=\"wandb\",\n",
    "#     remove_unused_columns=False,\n",
    "#     evaluation_strategy=\"steps\",\n",
    "#     save_strategy=\"steps\",\n",
    "#     learning_rate=5e-5,\n",
    "#     per_device_train_batch_size=16,\n",
    "#     gradient_accumulation_steps=2,\n",
    "#     per_device_eval_batch_size=16,\n",
    "#     num_train_epochs=100,\n",
    "#     warmup_ratio=0.1,\n",
    "#     logging_steps=10,\n",
    "#     load_best_model_at_end=True,\n",
    "#     metric_for_best_model=\"f1\",\n",
    "#     # no_cuda=True\n",
    "#     # push_to_hub=True,\n",
    "# )\n",
    "\n",
    "# trainer = MultiTaskTrainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     data_collator=data_collator,\n",
    "#     train_dataset=dataset_specific[\"train\"],\n",
    "#     eval_dataset=dataset_specific[\"test\"],\n",
    "#     tokenizer=image_processor,\n",
    "#     compute_metrics=compute_metrics_multitask,\n",
    "    \n",
    "# )\n",
    "\n",
    "# trainer.train()\n",
    "# wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for label_type in label_types:\n",
    "#     name = \"Baseline_\"+label_type\n",
    "#     # wandb.init(project=\"Sailboat FGVC\", name=name)\n",
    "#     torch.cuda.empty_cache()\n",
    "#     c_names = dataset.column_names[1:]\n",
    "#     c_names.remove(label_type)\n",
    "#     dataset_specific = dataset.remove_columns(c_names)\n",
    "\n",
    "#     labels = dataset.features[label_type].names\n",
    "#     id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "#     label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "\n",
    "#     dataset_specific = dataset_specific.train_test_split(test_size=0.2, shuffle=True, seed=43)\n",
    "\n",
    "#     labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "#     labels_to_remove = np.where(labels_train_counts < 2)[0] # remove labels with less than 2 examples\n",
    "#     dataset_specific['train'] = dataset_specific['train'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "#     dataset_specific['test'] = dataset_specific['test'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "#     labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "#     y_pred = labels_train_counts/labels_train_counts.sum()\n",
    "#     y_pred = (np.array([y_pred]*len(dataset_specific['test'][label_type])))\n",
    "#     baseline_metrics = compute_metrics([y_pred, dataset_specific['test'][label_type]])\n",
    "#     baseline_metrics = {\"eval/\"+ key: val for key, val in baseline_metrics.items()}\n",
    "#     print(baseline_metrics)\n",
    "#     # wandb.log(baseline_metrics)\n",
    "#     wandb.log\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_size in batch_sizes:\n",
    "#     for loss in losses:\n",
    "#         for label_type in label_types: \n",
    "#             tags = [model_name , label_type, loss, str(batch_size)]\n",
    "#             name = \"_\".join(tags)\n",
    "#             wandb.init(project=wandb_project, name=name , group = label_type , tags = tags)\n",
    "#             torch.cuda.empty_cache()\n",
    "#             c_names = dataset.column_names[1:]\n",
    "#             c_names.remove(label_type)\n",
    "#             # Map labels to ids using label map\n",
    "#             dataset_specific = dataset.remove_columns(c_names)\n",
    "#             labels = dataset.features[label_type].names\n",
    "\n",
    "#             dataset_specific = dataset_specific.train_test_split(test_size=0.2, shuffle=True, seed=43)\n",
    "\n",
    "#             labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "#             labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "#             labels_to_remove = np.where(labels_train_counts < 1)[0] # remove labels with less than 2 examples\n",
    "#             labels_to_remove = np.union1d(labels_to_remove, np.where(labels_test_counts < 1)[0])\n",
    "#             # dataset_specific['train'] = dataset_specific['train'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "#             dataset_specific['test'] = dataset_specific['test'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "\n",
    "#             id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "#             label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "\n",
    "#             dataset_specific['train'] = dataset_specific['train'].filter(lambda x: id2label[x[label_type]] not in [\"NaN\"])\n",
    "#             dataset_specific['test'] = dataset_specific['test'].filter(lambda x: id2label[x[label_type]] not in [\"NaN\"])\n",
    "\n",
    "#             id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "#             label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "\n",
    "#             labels = [id2label[label2id[x]] for x in labels]\n",
    "            \n",
    "#             labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "#             labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "\n",
    "#             if loss == \"WeightedCE\":\n",
    "#                 weights = np.array([1 if x == 0 else x for x in labels_train_counts])\n",
    "#                 weights = (1/weights)\n",
    "#                 weights /= weights.sum()\n",
    "#                 weights = torch.tensor(weights, dtype=torch.float , device=torch.device(\"cuda:0\"))\n",
    "\n",
    "#                 class WeightedCETrainer(Trainer):\n",
    "#                     def __init__(self, *args, **kwargs):\n",
    "#                         super().__init__(*args, **kwargs)\n",
    "#                     def compute_loss(self, model, inputs, return_outputs=False):\n",
    "#                         labels = inputs.get(\"labels\")\n",
    "#                         labels.to(torch.device(\"cuda:0\"))\n",
    "#                         outputs = model(**inputs)\n",
    "#                         logits = outputs.get(\"logits\")\n",
    "#                         # loss_fct = nn.CrossEntropyLoss(weight=weights , label_smoothing=0.1)\n",
    "#                         loss_fct = nn.CrossEntropyLoss(weight=weights)\n",
    "#                         loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "#                         return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "#             def transforms(examples):\n",
    "#                 examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "#                 examples[\"labels\"] = examples[label_type]\n",
    "#                 del examples[label_type]\n",
    "#                 del examples[\"img_path\"]\n",
    "#                 return examples\n",
    "\n",
    "#             data_collator = DefaultDataCollator()\n",
    "\n",
    "#             model = ResNetForImageClassification.from_pretrained(\n",
    "#                 checkpoint,\n",
    "#                 num_labels=len(labels),\n",
    "#                 id2label=id2label,\n",
    "#                 label2id=label2id,\n",
    "#                 use_auth_token=access_token,\n",
    "#                 ignore_mismatched_sizes=True,\n",
    "#             )\n",
    "\n",
    "#             training_args = TrainingArguments(\n",
    "#                 output_dir=model_dir+name,\n",
    "#                 report_to=\"wandb\",\n",
    "#                 remove_unused_columns=False,\n",
    "#                 evaluation_strategy=\"epoch\",\n",
    "#                 logging_strategy=\"epoch\",\n",
    "#                 save_strategy=\"epoch\",\n",
    "#                 # eval_steps = 10,\n",
    "#                 # logging_steps = 10,\n",
    "#                 # save_steps = 10,\n",
    "#                 save_total_limit=1,\n",
    "#                 learning_rate=5e-5,\n",
    "#                 per_device_train_batch_size=batch_size,\n",
    "#                 gradient_accumulation_steps=1,\n",
    "#                 per_device_eval_batch_size=batch_size,\n",
    "#                 num_train_epochs=EPOCHS,\n",
    "#                 warmup_ratio=0.1,\n",
    "#                 load_best_model_at_end=True,\n",
    "#                 metric_for_best_model=\"f1\",\n",
    "#                 # label_smoothing_factor=0.1,\n",
    "#                 # no_cuda=True\n",
    "#                 # push_to_hub=True,\n",
    "#                 # hub_strategy=\"end\",\n",
    "#                 # hub_model_id=\"boats_dataset\",\n",
    "#                 # hub_token=write_token,\n",
    "#             )\n",
    "#             if loss == \"CE\":\n",
    "#                 trainer = Trainer(\n",
    "#                 model=model,\n",
    "#                 args=training_args,\n",
    "#                 data_collator=data_collator,\n",
    "#                 train_dataset=dataset_specific[\"train\"].with_transform(transforms),\n",
    "#                 eval_dataset=dataset_specific[\"test\"].with_transform(transforms),\n",
    "#                 tokenizer=image_processor,\n",
    "#                 compute_metrics=compute_metrics,\n",
    "#                 )\n",
    "#             elif loss == \"WeightedCE\":\n",
    "#                 trainer = WeightedCETrainer(\n",
    "#                     model=model,\n",
    "#                     args=training_args,\n",
    "#                     data_collator=data_collator,\n",
    "#                     train_dataset=dataset_specific[\"train\"].with_transform(transforms),\n",
    "#                     eval_dataset=dataset_specific[\"test\"].with_transform(transforms),\n",
    "#                     tokenizer=image_processor,\n",
    "#                     compute_metrics=compute_metrics,\n",
    "#                 )\n",
    "#             # Plot Label Distribution For Training Data\n",
    "#             fig1 = plt.figure()\n",
    "#             ax = fig1.add_axes([0,0,1,1])\n",
    "#             ax.bar([label2id[x] for x in labels], labels_train_counts/labels_train_counts.sum()) # Normalized\n",
    "#             ax.set_ylabel(\"Number of examples normalised\")\n",
    "#             ax.set_title(\"Label Distribution\")\n",
    "#             wandb.log({\"Label Distribution Train\": (fig1)})\n",
    "\n",
    "#             # Plot Label Distribution For Test Data\n",
    "#             fig2 = plt.figure()\n",
    "#             ax = fig2.add_axes([0,0,1,1])\n",
    "#             ax.bar([label2id[x] for x in labels], labels_test_counts/labels_test_counts.sum()) # Normalized\n",
    "#             ax.set_ylabel(\"Number of examples normalised\")\n",
    "#             ax.set_title(\"Label Distribution\")\n",
    "#             wandb.log({\"Label Distribution Test\": (fig2)})\n",
    "\n",
    "#             # Log label2id\n",
    "#             wandb.log({\"Labels\": wandb.Table(data = list(zip(label2id.keys() , label2id.values())) , columns=[\"Label\" , \"ID\"])})\n",
    "\n",
    "#             # Train Model\n",
    "#             trainer.train()\n",
    "\n",
    "#             # Save Model\n",
    "#             trainer.save_model(model_dir+name)\n",
    "\n",
    "#             pipeline = ImageClassificationPipeline(model=trainer.model, feature_extractor = trainer.tokenizer , framework=\"pt\", device=0)\n",
    "#             predict_data = dataset_specific['test'].select(np.random.randint(0, len(dataset_specific['test']), batch_size))\n",
    "#             images = [predict_data['img_path'][i] for i in range(batch_size)]\n",
    "#             predictions = pipeline(images)\n",
    "#             prediction_table = []\n",
    "#             for i in range(len(predictions)):\n",
    "#                 prediction_table.append([wandb.Image(images[i]) , predictions[i] , id2label[predict_data[label_type][i]]])\n",
    "#             columns = [\"Image\" , \"Label Predictions\" , \"True Label\"]\n",
    "#             wandb.log({\"Image Predicitions\" : wandb.Table(data=prediction_table, columns=columns)})\n",
    "\n",
    "#             # Plot confusion matrix\n",
    "#             y_pred = trainer.predict(dataset_specific['test'].with_transform(transforms)).predictions.argmax(-1)\n",
    "#             y_true = dataset_specific[\"test\"][label_type]\n",
    "#             wandb.log({\"Confusion Matrix\": wandb.sklearn.plot_confusion_matrix(y_true, y_pred, labels=labels)})\n",
    "#             wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multitask Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list containing all combinations of the list of label types\n",
    "import itertools\n",
    "label_combinations = list(itertools.combinations(label_types, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for label_combination in label_combinations:\n",
    "#     label_types = [label_combination[0] , label_combination[1]]\n",
    "#     print(label_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_image_search = load_dataset(\"cringgaard/boats_dataset\" , use_auth_token=access_token, split=\"image_search\")\n",
    "for batch_size in batch_sizes:\n",
    "    for label_combination in label_combinations:\n",
    "        label_types = [label_combination[0] , label_combination[1]]\n",
    "        name = model_name+\"_Multitask\"\n",
    "        for label_type in label_types:\n",
    "            name += \"_\"+label_type\n",
    "        wandb.init(project=wandb_project, name=name , tags = [model_name , 'multitask']+label_types)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # c_names = dataset.column_names[1:]\n",
    "        # c_names.remove(label_types[0])\n",
    "        # c_names.remove(label_types[1])\n",
    "\n",
    "        dataset_specific = dataset.remove_columns('name')\n",
    "\n",
    "        dataset_specific = dataset.train_test_split(test_size=0.2, shuffle=True, seed=43)\n",
    "        # dataset_specific['train'] = concatenate_datasets([dataset_specific['train'] , dataset_image_search])\n",
    "\n",
    "\n",
    "        for label_type in label_types:\n",
    "            labels = np.unique(dataset_specific['train'][label_type])\n",
    "            labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "            labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "            labels_to_remove = np.where(labels_train_counts < 1)[0] # remove labels with less than 2 examples\n",
    "            labels_to_remove = np.union1d(labels_to_remove, np.where(labels_test_counts < 1)[0])\n",
    "            # dataset_specific['train'] = dataset_specific['train'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "            dataset_specific['test'] = dataset_specific['test'].filter(lambda x: x[label_type] not in labels_to_remove)            \n",
    "            labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "            labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "\n",
    "        def transforms(examples):\n",
    "            examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "            # Remove all other keys in dictionary\n",
    "            for key in list(examples.keys()):\n",
    "                if key not in label_types+[\"pixel_values\"]:\n",
    "                    del examples[key]\n",
    "            return examples\n",
    "        \n",
    "        data_collator = DefaultDataCollator()\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = MultitaskResnet(device)\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=model_dir+name,\n",
    "            report_to=\"wandb\",\n",
    "            remove_unused_columns=False,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            logging_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            eval_steps = 10,\n",
    "            logging_steps = 10,\n",
    "            # save_steps = 10,\n",
    "            save_total_limit=1,\n",
    "            learning_rate=5e-5,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            gradient_accumulation_steps=1,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=EPOCHS,\n",
    "            warmup_ratio=0.1,\n",
    "        )\n",
    "\n",
    "        trainer = MultitaskTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            data_collator=data_collator,\n",
    "            train_dataset=dataset_specific[\"train\"].with_transform(transforms),\n",
    "            eval_dataset=dataset_specific[\"test\"].with_transform(transforms),\n",
    "            tokenizer=image_processor,\n",
    "            compute_metrics = MultitaskTrainer.compute_metrics,\n",
    "            label_types=label_types,\n",
    "        )\n",
    "        print(trainer.label_types)\n",
    "        trainer.train()\n",
    "        trainer.save_model(model_dir+name)\n",
    "\n",
    "        from collections import namedtuple\n",
    "        predictions = trainer.predict(dataset_specific['test'].with_transform(transforms)).predictions\n",
    "        labels = {}\n",
    "        for label_type in label_types:\n",
    "            labels[label_type] = (dataset_specific['test'][label_type])\n",
    "        # Make tuple of labels\n",
    "        labels = tuple(labels.values())\n",
    "        eval_pred = namedtuple(\"EvalPrediction\", [\"predictions\", \"label_ids\"])\n",
    "        metrics = trainer.compute_metrics(trainer , eval_pred(predictions, labels))\n",
    "        print(metrics)\n",
    "        wandb.log(metrics)\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_image_search = load_dataset(\"cringgaard/boats_dataset\" , use_auth_token=access_token, split=\"image_search\")\n",
    "label_types = [\"Hull Type\" , \"Rigging Type\" ,  \"Construction\" , \"Ballast Type\" , \"Designer\"]\n",
    "for batch_size in batch_sizes:\n",
    "    # for label_combination in label_combinations:\n",
    "        # label_types = [label_combination[0] , label_combination[1]]\n",
    "        name = model_name+\"_Multitask_Image_Search\"\n",
    "        for label_type in label_types:\n",
    "            name += \"_\"+label_type\n",
    "        wandb.init(project=wandb_project, name=name , tags = [model_name , 'multitask' , 'image_search' ]+label_types)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # c_names = dataset.column_names[1:]\n",
    "        # c_names.remove(label_types[0])\n",
    "        # c_names.remove(label_types[1])\n",
    "\n",
    "        dataset_specific = dataset.remove_columns('name')\n",
    "\n",
    "        dataset_specific = dataset.train_test_split(test_size=0.2, shuffle=True, seed=43)\n",
    "        dataset_specific['train'] = concatenate_datasets([dataset_specific['train'] , dataset_image_search])\n",
    "\n",
    "\n",
    "        for label_type in label_types:\n",
    "            labels = np.unique(dataset_specific['train'][label_type])\n",
    "            labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "            labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "            labels_to_remove = np.where(labels_train_counts < 1)[0] # remove labels with less than 2 examples\n",
    "            labels_to_remove = np.union1d(labels_to_remove, np.where(labels_test_counts < 1)[0])\n",
    "            # dataset_specific['train'] = dataset_specific['train'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "            dataset_specific['test'] = dataset_specific['test'].filter(lambda x: x[label_type] not in labels_to_remove)            \n",
    "            labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "            labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "\n",
    "        def transforms(examples):\n",
    "            examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "            # Remove all other keys in dictionary\n",
    "            for key in list(examples.keys()):\n",
    "                if key not in label_types+[\"pixel_values\"]:\n",
    "                    del examples[key]\n",
    "            return examples\n",
    "        \n",
    "        data_collator = DefaultDataCollator()\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = MultitaskResnet(device)\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=model_dir+name,\n",
    "            report_to=\"wandb\",\n",
    "            remove_unused_columns=False,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            logging_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            eval_steps = 10,\n",
    "            logging_steps = 10,\n",
    "            # save_steps = 10,\n",
    "            save_total_limit=1,\n",
    "            learning_rate=5e-5,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            gradient_accumulation_steps=1,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=EPOCHS,\n",
    "            warmup_ratio=0.1,\n",
    "        )\n",
    "\n",
    "        trainer = MultitaskTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            data_collator=data_collator,\n",
    "            train_dataset=dataset_specific[\"train\"].with_transform(transforms),\n",
    "            eval_dataset=dataset_specific[\"test\"].with_transform(transforms),\n",
    "            tokenizer=image_processor,\n",
    "            compute_metrics = MultitaskTrainer.compute_metrics,\n",
    "            label_types=label_types,\n",
    "        )\n",
    "        print(trainer.label_types)\n",
    "        trainer.train()\n",
    "        trainer.save_model(model_dir+name)\n",
    "\n",
    "        from collections import namedtuple\n",
    "        predictions = trainer.predict(dataset_specific['test'].with_transform(transforms)).predictions\n",
    "        labels = {}\n",
    "        for label_type in label_types:\n",
    "            labels[label_type] = (dataset_specific['test'][label_type])\n",
    "        # Make tuple of labels\n",
    "        labels = tuple(labels.values())\n",
    "        eval_pred = namedtuple(\"EvalPrediction\", [\"predictions\", \"label_ids\"])\n",
    "        metrics = trainer.compute_metrics(trainer , eval_pred(predictions, labels))\n",
    "        print(metrics)\n",
    "        wandb.log(metrics)\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MultitaskTrainer.compute_metrics(trainer , eval_pred(predictions, labels))\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "predictions = trainer.predict(dataset_specific['test'].with_transform(transforms)).predictions\n",
    "labels = (dataset_specific['test'][label_types[0]] , dataset_specific['test'][label_types[1]], dataset_specific['test'][label_types[2]] , dataset_specific['test'][label_types[3]] , dataset_specific['test'][label_types[4]])\n",
    "eval_pred = namedtuple(\"EvalPrediction\", [\"predictions\", \"label_ids\"])\n",
    "metrics = compute_metrics_multitask(eval_pred(predictions, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_types = list(dataset_specific['test'].features.items())[1:-1]\n",
    "for i in range(len(lab_types)):\n",
    "    lab_types[i] = lab_types[i][0]\n",
    "# Construct a dictionary of label_type and dataset labels\n",
    "labels = {}\n",
    "for label in lab_types:\n",
    "    labels[label] = {label : dataset_specific['test'][label]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {key : value for key , value in dataset_specific['test'].features.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Data Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boat24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    for label_type in label_types:\n",
    "        tags = [model_name , label_type , 'boat24']\n",
    "        name = \"_\".join(tags)\n",
    "        wandb.init(project=wandb_project, name=name , group = label_type , tags = tags)\n",
    "        torch.cuda.empty_cache()\n",
    "        c_names = dataset.column_names[1:]\n",
    "        c_names.remove(label_type)\n",
    "        dataset_specific = dataset.remove_columns(c_names)\n",
    "        labels = dataset.features[label_type].names\n",
    "        dataset_boat24_specific = dataset_boat24.remove_columns(c_names)\n",
    "\n",
    "        dataset_specific = dataset_specific.train_test_split(test_size=0.2, shuffle=True, seed=43)  # 80-20 split for train and test\n",
    "        dataset_specific['train'] = concatenate_datasets([dataset_specific['train'] , dataset_boat24_specific]) # add boat24 dataset to training set\n",
    "        \n",
    "        labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "        labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "        labels_to_remove = np.where(labels_train_counts < 1)[0] # remove labels with less than 2 examples\n",
    "        labels_to_remove = np.union1d(labels_to_remove, np.where(labels_test_counts < 1)[0])\n",
    "        # dataset_specific['train'] = dataset_specific['train'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "        dataset_specific['test'] = dataset_specific['test'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "\n",
    "        id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "        label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "\n",
    "        dataset_specific['train'] = dataset_specific['train'].filter(lambda x: id2label[x[label_type]] not in [\"NaN\"])\n",
    "        dataset_specific['test'] = dataset_specific['test'].filter(lambda x: id2label[x[label_type]] not in [\"NaN\"])\n",
    "\n",
    "        id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "        label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "        \n",
    "        labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "        labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "\n",
    "        labels = [id2label[label2id[x]] for x in labels]\n",
    "        \n",
    "\n",
    "        def transforms(examples):\n",
    "            examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "            examples[\"labels\"] = examples[label_type]\n",
    "            del examples[label_type]\n",
    "            del examples[\"img_path\"]\n",
    "            return examples\n",
    "        data_collator = DefaultDataCollator()\n",
    "\n",
    "        model = ResNetForImageClassification.from_pretrained(\n",
    "            checkpoint,\n",
    "            num_labels=len(labels),\n",
    "            id2label=id2label,\n",
    "            label2id=label2id,\n",
    "            use_auth_token=access_token,\n",
    "            ignore_mismatched_sizes=True,\n",
    "        )\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=model_dir+name,\n",
    "            report_to=\"wandb\",\n",
    "            remove_unused_columns=False,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            logging_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            # eval_steps = 10,\n",
    "            # logging_steps = 10,\n",
    "            # save_steps = 10,\n",
    "            save_total_limit=30,\n",
    "            learning_rate=5e-5,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            gradient_accumulation_steps=1,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=EPOCHS,\n",
    "            warmup_ratio=0.1,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"f1\",\n",
    "            # label_smoothing_factor=0.1,\n",
    "            # no_cuda=True\n",
    "            # push_to_hub=True,\n",
    "            # hub_strategy=\"end\",\n",
    "            # hub_model_id=\"boats_dataset\",\n",
    "            # hub_token=write_token,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            data_collator=data_collator,\n",
    "            train_dataset=dataset_specific[\"train\"].with_transform(transforms),\n",
    "            eval_dataset=dataset_specific[\"test\"].with_transform(transforms),\n",
    "            tokenizer=image_processor,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "        # Plot Label Distribution For Training Data\n",
    "        fig1 = plt.figure()\n",
    "        ax = fig1.add_axes([0,0,1,1])\n",
    "        ax.bar([label2id[x] for x in labels], labels_train_counts/labels_train_counts.sum()) # Normalized\n",
    "        ax.set_ylabel(\"Number of examples normalised\")\n",
    "        ax.set_title(\"Label Distribution\")\n",
    "        wandb.log({\"Label Distribution Train\": (fig1)})\n",
    "\n",
    "        # Plot Label Distribution For Test Data\n",
    "        fig2 = plt.figure()\n",
    "        ax = fig2.add_axes([0,0,1,1])\n",
    "        ax.bar([label2id[x] for x in labels], labels_test_counts/labels_test_counts.sum()) # Normalized\n",
    "        ax.set_ylabel(\"Number of examples normalised\")\n",
    "        ax.set_title(\"Label Distribution\")\n",
    "        wandb.log({\"Label Distribution Test\": (fig2)})\n",
    "\n",
    "        # Log label2id\n",
    "        wandb.log({\"Labels\": wandb.Table(data = list(zip(label2id.keys() , label2id.values())) , columns=[\"Label\" , \"ID\"])})\n",
    "\n",
    "        # Train Model\n",
    "        trainer.train()\n",
    "\n",
    "        # Save Model\n",
    "        trainer.save_model(model_dir+name)\n",
    "\n",
    "        pipeline = ImageClassificationPipeline(model=trainer.model, feature_extractor = trainer.tokenizer , framework=\"pt\", device=0)\n",
    "        predict_data = dataset_specific['test'].select(np.random.randint(0, len(dataset_specific['test']), batch_size))\n",
    "        images = [predict_data['img_path'][i] for i in range(batch_size)]\n",
    "        predictions = pipeline(images)\n",
    "        prediction_table = []\n",
    "        for i in range(len(predictions)):\n",
    "            prediction_table.append([wandb.Image(images[i]) , predictions[i] , id2label[predict_data[label_type][i]]])\n",
    "        columns = [\"Image\" , \"Label Predictions\" , \"True Label\"]\n",
    "        wandb.log({\"Image Predicitions\" : wandb.Table(data=prediction_table, columns=columns)})\n",
    "\n",
    "        # Plot confusion matrix\n",
    "        y_pred = trainer.predict(dataset_specific['test'].with_transform(transforms)).predictions.argmax(-1)\n",
    "        y_true = dataset_specific[\"test\"][label_type]\n",
    "        wandb.log({\"Confusion Matrix\": wandb.sklearn.plot_confusion_matrix(y_true, y_pred, labels=labels)})\n",
    "        wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_image_search = load_dataset(\"cringgaard/boats_dataset\" , use_auth_token=access_token, split=\"image_search\")\n",
    "for batch_size in batch_sizes:\n",
    "    for label_type in label_types:\n",
    "        tags = [model_name , label_type , 'image_search']\n",
    "        name = \"_\".join(tags)\n",
    "        wandb.init(project=wandb_project, name=name , group = label_type , tags = tags)\n",
    "        torch.cuda.empty_cache()\n",
    "        c_names = dataset.column_names[1:]\n",
    "        c_names.remove(label_type)\n",
    "        dataset_specific = dataset.remove_columns(c_names)\n",
    "        labels = dataset.features[label_type].names\n",
    "        dataset_image_search_specific = dataset_image_search.remove_columns(c_names)\n",
    "\n",
    "        dataset_specific = dataset_specific.train_test_split(test_size=0.2, shuffle=True, seed=43)  # 80-20 split for train and test\n",
    "        dataset_specific['train'] = concatenate_datasets([dataset_specific['train'] , dataset_image_search_specific]) # add image_search dataset to training set\n",
    "        \n",
    "        labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "        labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "        labels_to_remove = np.where(labels_train_counts < 1)[0] # remove labels with less than 2 examples\n",
    "        labels_to_remove = np.union1d(labels_to_remove, np.where(labels_test_counts < 1)[0])\n",
    "        # dataset_specific['train'] = dataset_specific['train'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "        dataset_specific['test'] = dataset_specific['test'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "\n",
    "        id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "        label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "\n",
    "        dataset_specific['train'] = dataset_specific['train'].filter(lambda x: id2label[x[label_type]] not in [\"NaN\"])\n",
    "        dataset_specific['test'] = dataset_specific['test'].filter(lambda x: id2label[x[label_type]] not in [\"NaN\"])\n",
    "\n",
    "        id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "        label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "        \n",
    "        labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "        labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "\n",
    "        labels = [id2label[label2id[x]] for x in labels]\n",
    "        \n",
    "\n",
    "        def transforms(examples):\n",
    "            examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "            examples[\"labels\"] = examples[label_type]\n",
    "            del examples[label_type]\n",
    "            del examples[\"img_path\"]\n",
    "            return examples\n",
    "        data_collator = DefaultDataCollator()\n",
    "\n",
    "        model = ResNetForImageClassification.from_pretrained(\n",
    "            checkpoint,\n",
    "            num_labels=len(labels),\n",
    "            id2label=id2label,\n",
    "            label2id=label2id,\n",
    "            use_auth_token=access_token,\n",
    "            ignore_mismatched_sizes=True,\n",
    "        )\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=model_dir+name,\n",
    "            report_to=\"wandb\",\n",
    "            remove_unused_columns=False,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            logging_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            # eval_steps = 10,\n",
    "            # logging_steps = 10,\n",
    "            # save_steps = 10,\n",
    "            save_total_limit=30,\n",
    "            learning_rate=5e-5,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            gradient_accumulation_steps=1,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=EPOCHS,\n",
    "            warmup_ratio=0.1,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"f1\",\n",
    "            # label_smoothing_factor=0.1,\n",
    "            # no_cuda=True\n",
    "            # push_to_hub=True,\n",
    "            # hub_strategy=\"end\",\n",
    "            # hub_model_id=\"boats_dataset\",\n",
    "            # hub_token=write_token,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            data_collator=data_collator,\n",
    "            train_dataset=dataset_specific[\"train\"].with_transform(transforms),\n",
    "            eval_dataset=dataset_specific[\"test\"].with_transform(transforms),\n",
    "            tokenizer=image_processor,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "        # Plot Label Distribution For Training Data\n",
    "        fig1 = plt.figure()\n",
    "        ax = fig1.add_axes([0,0,1,1])\n",
    "        ax.bar([label2id[x] for x in labels], labels_train_counts/labels_train_counts.sum()) # Normalized\n",
    "        ax.set_ylabel(\"Number of examples normalised\")\n",
    "        ax.set_title(\"Label Distribution\")\n",
    "        wandb.log({\"Label Distribution Train\": (fig1)})\n",
    "\n",
    "        # Plot Label Distribution For Test Data\n",
    "        fig2 = plt.figure()\n",
    "        ax = fig2.add_axes([0,0,1,1])\n",
    "        ax.bar([label2id[x] for x in labels], labels_test_counts/labels_test_counts.sum()) # Normalized\n",
    "        ax.set_ylabel(\"Number of examples normalised\")\n",
    "        ax.set_title(\"Label Distribution\")\n",
    "        wandb.log({\"Label Distribution Test\": (fig2)})\n",
    "\n",
    "        # Log label2id\n",
    "        wandb.log({\"Labels\": wandb.Table(data = list(zip(label2id.keys() , label2id.values())) , columns=[\"Label\" , \"ID\"])})\n",
    "\n",
    "        # Train Model\n",
    "        trainer.train()\n",
    "\n",
    "        # Save Model\n",
    "        trainer.save_model(model_dir+name)\n",
    "\n",
    "        pipeline = ImageClassificationPipeline(model=trainer.model, feature_extractor = trainer.tokenizer , framework=\"pt\", device=0)\n",
    "        predict_data = dataset_specific['test'].select(np.random.randint(0, len(dataset_specific['test']), batch_size))\n",
    "        images = [predict_data['img_path'][i] for i in range(batch_size)]\n",
    "        predictions = pipeline(images)\n",
    "        prediction_table = []\n",
    "        for i in range(len(predictions)):\n",
    "            prediction_table.append([wandb.Image(images[i]) , predictions[i] , id2label[predict_data[label_type][i]]])\n",
    "        columns = [\"Image\" , \"Label Predictions\" , \"True Label\"]\n",
    "        wandb.log({\"Image Predicitions\" : wandb.Table(data=prediction_table, columns=columns)})\n",
    "\n",
    "        # Plot confusion matrix\n",
    "        y_pred = trainer.predict(dataset_specific['test'].with_transform(transforms)).predictions.argmax(-1)\n",
    "        y_true = dataset_specific[\"test\"][label_type]\n",
    "        wandb.log({\"Confusion Matrix\": wandb.sklearn.plot_confusion_matrix(y_true, y_pred, labels=labels)})\n",
    "        wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boat Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-347050\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-347050\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-347050\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-347050\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.974880218505859, 'eval_accuracy': 0.148743957524368, 'eval_f1': 0.09636845509041275, 'eval_precision': 0.11118664824443439, 'eval_recall': 0.10755699683657521, 'eval_runtime': 281.8026, 'eval_samples_per_second': 89.559, 'eval_steps_per_second': 5.6, 'epoch': 55.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-157750] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7383, 'learning_rate': 2.4444444444444445e-05, 'epoch': 56.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf2d150e9ab44439bfa3f79900d7c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-353360\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-353360\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-353360\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-353360\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.034610748291016, 'eval_accuracy': 0.15302321895554322, 'eval_f1': 0.10004820835465171, 'eval_precision': 0.1126876055980425, 'eval_recall': 0.11463937064899657, 'eval_runtime': 290.4494, 'eval_samples_per_second': 86.893, 'eval_steps_per_second': 5.433, 'epoch': 56.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-164060] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7025, 'learning_rate': 2.3888888888888892e-05, 'epoch': 57.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad96e520b9b45428f22c6a4d14f876f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-359670\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-359670\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-359670\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-359670\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.061897277832031, 'eval_accuracy': 0.15100245661304382, 'eval_f1': 0.09891831181211995, 'eval_precision': 0.11337893507427027, 'eval_recall': 0.11214657482828685, 'eval_runtime': 290.0121, 'eval_samples_per_second': 87.024, 'eval_steps_per_second': 5.441, 'epoch': 57.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-170370] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6686, 'learning_rate': 2.3333333333333336e-05, 'epoch': 58.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c7406bf2524ea3b3954bfc9a5fded6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-365980\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-365980\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-365980\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-365980\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.070904731750488, 'eval_accuracy': 0.15124019335922023, 'eval_f1': 0.09587638803058252, 'eval_precision': 0.10949992478976335, 'eval_recall': 0.11034223921751993, 'eval_runtime': 288.214, 'eval_samples_per_second': 87.567, 'eval_steps_per_second': 5.475, 'epoch': 58.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-176680] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6463, 'learning_rate': 2.277777777777778e-05, 'epoch': 59.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d8986f8a184a2f9767a66cbe0462bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-372290\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-372290\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-372290\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-372290\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.183341979980469, 'eval_accuracy': 0.15274585941833743, 'eval_f1': 0.0963871634848272, 'eval_precision': 0.11047151712998429, 'eval_recall': 0.11000581526018033, 'eval_runtime': 298.1005, 'eval_samples_per_second': 84.663, 'eval_steps_per_second': 5.294, 'epoch': 59.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-182990] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.627, 'learning_rate': 2.2222222222222223e-05, 'epoch': 60.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e983cacc714c6998cb28b4daa2067e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-378600\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-378600\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-378600\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-378600\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.13469123840332, 'eval_accuracy': 0.15175528964260243, 'eval_f1': 0.09820976751230778, 'eval_precision': 0.11279032024015861, 'eval_recall': 0.1099697437581596, 'eval_runtime': 291.2306, 'eval_samples_per_second': 86.66, 'eval_steps_per_second': 5.418, 'epoch': 60.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-189300] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6014, 'learning_rate': 2.1666666666666667e-05, 'epoch': 61.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1283fe7bae34947955a2572951ce9ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-384910\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-384910\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-384910\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-384910\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.222197532653809, 'eval_accuracy': 0.15203264917980822, 'eval_f1': 0.09703126791448924, 'eval_precision': 0.11136610578032682, 'eval_recall': 0.11082415661380057, 'eval_runtime': 290.8786, 'eval_samples_per_second': 86.765, 'eval_steps_per_second': 5.425, 'epoch': 61.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-195610] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5815, 'learning_rate': 2.111111111111111e-05, 'epoch': 62.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73dd560e36404f8ca9b8ea66ae4b0101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-391220\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-391220\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.181488990783691, 'eval_accuracy': 0.15246849988113162, 'eval_f1': 0.09748572602226291, 'eval_precision': 0.11074782337977707, 'eval_recall': 0.1132099897348067, 'eval_runtime': 289.4327, 'eval_samples_per_second': 87.198, 'eval_steps_per_second': 5.452, 'epoch': 62.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-391220\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-391220\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-201920] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5635, 'learning_rate': 2.0555555555555555e-05, 'epoch': 63.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331c9e7f58a9419c9610b6c6a5d933e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-397530\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-397530\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-397530\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-397530\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.117063522338867, 'eval_accuracy': 0.15337982407480782, 'eval_f1': 0.09823615517420287, 'eval_precision': 0.11209534025946782, 'eval_recall': 0.11141432909437694, 'eval_runtime': 279.9114, 'eval_samples_per_second': 90.164, 'eval_steps_per_second': 5.637, 'epoch': 63.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-208230] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5328, 'learning_rate': 2e-05, 'epoch': 64.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4fa356dc144ab280d3502428279557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-403840\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-403840\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-403840\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-403840\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.250040054321289, 'eval_accuracy': 0.15139868452333782, 'eval_f1': 0.09723971264898884, 'eval_precision': 0.11201686363609173, 'eval_recall': 0.10842309324266082, 'eval_runtime': 283.9927, 'eval_samples_per_second': 88.868, 'eval_steps_per_second': 5.556, 'epoch': 64.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-214540] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5055, 'learning_rate': 1.9444444444444445e-05, 'epoch': 65.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3781e980ab6d4f95981c966561c73cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-410150\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-410150\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-410150\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-410150\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.202343940734863, 'eval_accuracy': 0.15444963943260162, 'eval_f1': 0.0996126670682711, 'eval_precision': 0.11205375508639404, 'eval_recall': 0.11347915058782956, 'eval_runtime': 281.9151, 'eval_samples_per_second': 89.523, 'eval_steps_per_second': 5.597, 'epoch': 65.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-220850] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4826, 'learning_rate': 1.888888888888889e-05, 'epoch': 66.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34eaa994150c461d955a29b31e5cf7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-416460\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-416460\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-416460\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-416460\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.318313598632812, 'eval_accuracy': 0.15516284967113084, 'eval_f1': 0.09946252910188615, 'eval_precision': 0.11349615965817073, 'eval_recall': 0.11250471064021739, 'eval_runtime': 280.1854, 'eval_samples_per_second': 90.076, 'eval_steps_per_second': 5.632, 'epoch': 66.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-227160] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.476, 'learning_rate': 1.8333333333333333e-05, 'epoch': 67.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1829ff3756c479a9d0b426def87802f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-422770\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-422770\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-422770\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-422770\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.203668594360352, 'eval_accuracy': 0.15623266502892463, 'eval_f1': 0.0997308806685611, 'eval_precision': 0.11381643986861566, 'eval_recall': 0.11286380045058018, 'eval_runtime': 264.3803, 'eval_samples_per_second': 95.461, 'eval_steps_per_second': 5.969, 'epoch': 67.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-233470] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.443, 'learning_rate': 1.777777777777778e-05, 'epoch': 68.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e792cb8e9f94ac8bc4985bc7b4f74e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-429080\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-429080\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-429080\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-429080\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.300580024719238, 'eval_accuracy': 0.15678738410333623, 'eval_f1': 0.09817643760416385, 'eval_precision': 0.11058209931335825, 'eval_recall': 0.1132352837634352, 'eval_runtime': 266.5552, 'eval_samples_per_second': 94.682, 'eval_steps_per_second': 5.92, 'epoch': 68.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-239780] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4372, 'learning_rate': 1.7222222222222224e-05, 'epoch': 69.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe0bb33bf5c4ac39b3df0d4d4cd03da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-435390\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-435390\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-435390\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-435390\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.306597709655762, 'eval_accuracy': 0.15738172596877725, 'eval_f1': 0.09949929010413348, 'eval_precision': 0.11257993262621943, 'eval_recall': 0.11372258257835627, 'eval_runtime': 278.6343, 'eval_samples_per_second': 90.578, 'eval_steps_per_second': 5.663, 'epoch': 69.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-246090] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4165, 'learning_rate': 1.6666666666666667e-05, 'epoch': 70.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7301f7273b2f404fadb265720583dc96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-441700\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-441700\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-441700\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-441700\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.25644302368164, 'eval_accuracy': 0.15579681432760123, 'eval_f1': 0.09919071847857754, 'eval_precision': 0.11319085825788294, 'eval_recall': 0.11369165363949627, 'eval_runtime': 287.9732, 'eval_samples_per_second': 87.64, 'eval_steps_per_second': 5.48, 'epoch': 70.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-252400] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3971, 'learning_rate': 1.6111111111111115e-05, 'epoch': 71.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7975f44a3449cfa17d7390cc663f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-448010\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-448010\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-448010\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-448010\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.246031761169434, 'eval_accuracy': 0.15829305016245343, 'eval_f1': 0.10028104647308289, 'eval_precision': 0.11362359880980835, 'eval_recall': 0.11505146732997215, 'eval_runtime': 272.0012, 'eval_samples_per_second': 92.786, 'eval_steps_per_second': 5.801, 'epoch': 71.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-258710] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3953, 'learning_rate': 1.5555555555555555e-05, 'epoch': 72.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291989484bd24560b0230ae514736640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-454320\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-454320\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.30361557006836, 'eval_accuracy': 0.15987796180362945, 'eval_f1': 0.10123368940464586, 'eval_precision': 0.11455963593695243, 'eval_recall': 0.1140935936150427, 'eval_runtime': 270.5631, 'eval_samples_per_second': 93.28, 'eval_steps_per_second': 5.832, 'epoch': 72.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-454320\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-454320\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-265020] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3691, 'learning_rate': 1.5e-05, 'epoch': 73.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d17972364ff4e4cad139203281cc98a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-460630\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-460630\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.314002990722656, 'eval_accuracy': 0.15603455107377764, 'eval_f1': 0.0976619959742616, 'eval_precision': 0.11065845273273556, 'eval_recall': 0.11113460208558115, 'eval_runtime': 272.1471, 'eval_samples_per_second': 92.737, 'eval_steps_per_second': 5.798, 'epoch': 73.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-460630\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-460630\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-271330] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3502, 'learning_rate': 1.4444444444444444e-05, 'epoch': 74.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79d6bef16b842ffb0a1181d04652985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-466940\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-466940\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-466940\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-466940\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.285233497619629, 'eval_accuracy': 0.16158174181789364, 'eval_f1': 0.10419506161716427, 'eval_precision': 0.12006682557026256, 'eval_recall': 0.11752460224452242, 'eval_runtime': 272.543, 'eval_samples_per_second': 92.602, 'eval_steps_per_second': 5.79, 'epoch': 74.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-277640] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3269, 'learning_rate': 1.388888888888889e-05, 'epoch': 75.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec184c8225634e64a68caba7fd610053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-473250\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-473250\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-473250\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-473250\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.426592826843262, 'eval_accuracy': 0.15960060226642364, 'eval_f1': 0.10025981087075034, 'eval_precision': 0.11431757605763099, 'eval_recall': 0.11406984428525556, 'eval_runtime': 271.1398, 'eval_samples_per_second': 93.081, 'eval_steps_per_second': 5.82, 'epoch': 75.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-283950] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.322, 'learning_rate': 1.3333333333333333e-05, 'epoch': 76.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4622d042e4fc4edda736a70c645f1723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-479560\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-479560\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-479560\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-479560\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.364123344421387, 'eval_accuracy': 0.16063079483318804, 'eval_f1': 0.10081729677245214, 'eval_precision': 0.1140723366693339, 'eval_recall': 0.11399241807826273, 'eval_runtime': 274.1939, 'eval_samples_per_second': 92.044, 'eval_steps_per_second': 5.755, 'epoch': 76.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-290260] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3, 'learning_rate': 1.2777777777777777e-05, 'epoch': 77.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd136275bb0461f8129e727f4c6e3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-485870\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-485870\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-485870\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-485870\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.324753761291504, 'eval_accuracy': 0.15861003249068864, 'eval_f1': 0.09996646868443271, 'eval_precision': 0.11217420405641049, 'eval_recall': 0.1157993059700556, 'eval_runtime': 273.4656, 'eval_samples_per_second': 92.289, 'eval_steps_per_second': 5.77, 'epoch': 77.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-296570] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2859, 'learning_rate': 1.2222222222222222e-05, 'epoch': 78.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2666ee392fd342ad8d7b9dea7b5791af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-492180\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-492180\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.41101360321045, 'eval_accuracy': 0.15999683017671765, 'eval_f1': 0.10028160735484719, 'eval_precision': 0.11470070079653448, 'eval_recall': 0.11311054200626733, 'eval_runtime': 275.3456, 'eval_samples_per_second': 91.659, 'eval_steps_per_second': 5.731, 'epoch': 78.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-492180\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-492180\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-302880] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.281, 'learning_rate': 1.1666666666666668e-05, 'epoch': 79.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62c92107155496f9d7be43e253b25b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-498490\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-498490\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-498490\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-498490\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.389043807983398, 'eval_accuracy': 0.16011569854980584, 'eval_f1': 0.10107050203487479, 'eval_precision': 0.11620115001619534, 'eval_recall': 0.11410441297844832, 'eval_runtime': 277.0386, 'eval_samples_per_second': 91.099, 'eval_steps_per_second': 5.696, 'epoch': 79.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-309190] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2592, 'learning_rate': 1.1111111111111112e-05, 'epoch': 80.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33896eb5ff084570aba4d691821ec9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-504800\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-504800\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-504800\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-504800\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.348461151123047, 'eval_accuracy': 0.16078928599730566, 'eval_f1': 0.10136528856055631, 'eval_precision': 0.11575747959417457, 'eval_recall': 0.11452097196070597, 'eval_runtime': 284.6893, 'eval_samples_per_second': 88.651, 'eval_steps_per_second': 5.543, 'epoch': 80.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-315500] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2521, 'learning_rate': 1.0555555555555555e-05, 'epoch': 81.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f690a2e1fd4ca8b21c358d05fd265e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-511110\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-511110\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-511110\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-511110\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.462214469909668, 'eval_accuracy': 0.16213646089230527, 'eval_f1': 0.10257827735283627, 'eval_precision': 0.11650527194788403, 'eval_recall': 0.11499289419586178, 'eval_runtime': 286.8831, 'eval_samples_per_second': 87.973, 'eval_steps_per_second': 5.5, 'epoch': 81.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-321810] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2416, 'learning_rate': 1e-05, 'epoch': 82.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b6078613634c8982f5364c8866df7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-517420\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-517420\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-517420\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-517420\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.411730766296387, 'eval_accuracy': 0.16193834693715825, 'eval_f1': 0.1023890059338264, 'eval_precision': 0.11564399233045958, 'eval_recall': 0.1154777395386975, 'eval_runtime': 276.3894, 'eval_samples_per_second': 91.313, 'eval_steps_per_second': 5.709, 'epoch': 82.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-328120] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.224, 'learning_rate': 9.444444444444445e-06, 'epoch': 83.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a7a62348054d90a006d390653ebecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-523730\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-523730\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-523730\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-523730\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.379608154296875, 'eval_accuracy': 0.16185910135509946, 'eval_f1': 0.10157169338912644, 'eval_precision': 0.11318682417105048, 'eval_recall': 0.1157944528629594, 'eval_runtime': 285.5894, 'eval_samples_per_second': 88.372, 'eval_steps_per_second': 5.525, 'epoch': 83.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-334430] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2252, 'learning_rate': 8.88888888888889e-06, 'epoch': 84.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001bbdcc508a48108ac6bad628b4f916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-530040\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-530040\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-530040\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-530040\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.354217529296875, 'eval_accuracy': 0.16324589904112846, 'eval_f1': 0.10375753052576071, 'eval_precision': 0.11763712912649867, 'eval_recall': 0.11745247622204415, 'eval_runtime': 287.2995, 'eval_samples_per_second': 87.846, 'eval_steps_per_second': 5.493, 'epoch': 84.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-340740] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2061, 'learning_rate': 8.333333333333334e-06, 'epoch': 85.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486247cd86854b5987ad81ca72a77a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-536350\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-536350\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-536350\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-536350\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.44255542755127, 'eval_accuracy': 0.16261193438465807, 'eval_f1': 0.10131100991978442, 'eval_precision': 0.1138971979835564, 'eval_recall': 0.11535062783938892, 'eval_runtime': 286.7982, 'eval_samples_per_second': 87.999, 'eval_steps_per_second': 5.502, 'epoch': 85.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-347050] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1927, 'learning_rate': 7.777777777777777e-06, 'epoch': 86.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6708fd496454b9a82476f52a2a7e279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-542660\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-542660\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-542660\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-542660\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.371198654174805, 'eval_accuracy': 0.16494967905539265, 'eval_f1': 0.1037682688867977, 'eval_precision': 0.11671867961004036, 'eval_recall': 0.11787405564025509, 'eval_runtime': 288.0732, 'eval_samples_per_second': 87.61, 'eval_steps_per_second': 5.478, 'epoch': 86.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-353360] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1874, 'learning_rate': 7.222222222222222e-06, 'epoch': 87.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c5f28b307c469c93dc2c2f25517646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-548970\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-548970\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-548970\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-548970\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.328777313232422, 'eval_accuracy': 0.16399873207068705, 'eval_f1': 0.10343448993776526, 'eval_precision': 0.11630608207086043, 'eval_recall': 0.1177025854825928, 'eval_runtime': 285.6234, 'eval_samples_per_second': 88.361, 'eval_steps_per_second': 5.525, 'epoch': 87.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-359670] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1696, 'learning_rate': 6.666666666666667e-06, 'epoch': 88.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19a40921db04f40ae1149574544f880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-555280\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-555280\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-555280\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-555280\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.498411178588867, 'eval_accuracy': 0.16233457484745226, 'eval_f1': 0.10013105706112603, 'eval_precision': 0.11388493601939441, 'eval_recall': 0.11325923056596857, 'eval_runtime': 288.5736, 'eval_samples_per_second': 87.458, 'eval_steps_per_second': 5.468, 'epoch': 88.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-365980] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1586, 'learning_rate': 6.111111111111111e-06, 'epoch': 89.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "494101f7fccc4fa6b4be9e053789112e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-561590\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-561590\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-561590\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-561590\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.370438575744629, 'eval_accuracy': 0.16348363578730485, 'eval_f1': 0.10360725354537957, 'eval_precision': 0.11591955682452923, 'eval_recall': 0.11779483459115028, 'eval_runtime': 287.5935, 'eval_samples_per_second': 87.756, 'eval_steps_per_second': 5.487, 'epoch': 89.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-372290] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1413, 'learning_rate': 5.555555555555556e-06, 'epoch': 90.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e469b22f70545abaa429a3bcf16e2b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-567900\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-567900\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-567900\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-567900\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.420188903808594, 'eval_accuracy': 0.16570251208495126, 'eval_f1': 0.10439023908269494, 'eval_precision': 0.1171379345054487, 'eval_recall': 0.12003757719892691, 'eval_runtime': 279.4712, 'eval_samples_per_second': 90.306, 'eval_steps_per_second': 5.646, 'epoch': 90.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-378600] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1458, 'learning_rate': 5e-06, 'epoch': 91.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2c7f55eedf47c4b6394145f5f2935b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-574210\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-574210\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-574210\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-574210\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.354120254516602, 'eval_accuracy': 0.16411760044377527, 'eval_f1': 0.10486274428627426, 'eval_precision': 0.11910447437353484, 'eval_recall': 0.1184878790428624, 'eval_runtime': 278.622, 'eval_samples_per_second': 90.582, 'eval_steps_per_second': 5.664, 'epoch': 91.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-384910] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1299, 'learning_rate': 4.444444444444445e-06, 'epoch': 92.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e30fde242054530bdd83dfb9e202ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-580520\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-580520\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-580520\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-580520\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.291173934936523, 'eval_accuracy': 0.16399873207068705, 'eval_f1': 0.10233256594484932, 'eval_precision': 0.1159213171169072, 'eval_recall': 0.11569679598416288, 'eval_runtime': 264.963, 'eval_samples_per_second': 95.251, 'eval_steps_per_second': 5.956, 'epoch': 92.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-391220] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1254, 'learning_rate': 3.888888888888889e-06, 'epoch': 93.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d206e1415041268bb1e35c086fced2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-586830\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-586830\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-586830\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-586830\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.421126365661621, 'eval_accuracy': 0.16693081860686268, 'eval_f1': 0.10484755325386255, 'eval_precision': 0.1186768258005251, 'eval_recall': 0.11798062539826185, 'eval_runtime': 282.5042, 'eval_samples_per_second': 89.337, 'eval_steps_per_second': 5.586, 'epoch': 93.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-397530] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1319, 'learning_rate': 3.3333333333333333e-06, 'epoch': 94.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26dda237105c4e51ada38e97aec83bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-593140\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-593140\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-593140\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-593140\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.42834758758545, 'eval_accuracy': 0.16340439020524605, 'eval_f1': 0.10202624073095161, 'eval_precision': 0.11564561283407239, 'eval_recall': 0.11535373672873182, 'eval_runtime': 288.7627, 'eval_samples_per_second': 87.4, 'eval_steps_per_second': 5.465, 'epoch': 94.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-403840] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1027, 'learning_rate': 2.777777777777778e-06, 'epoch': 95.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28544a068c004ed28584b76bfc9faaf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-599450\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-599450\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-599450\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-599450\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.502588272094727, 'eval_accuracy': 0.16558364371186307, 'eval_f1': 0.1043519484755305, 'eval_precision': 0.11946132885953642, 'eval_recall': 0.11699275805097713, 'eval_runtime': 288.7927, 'eval_samples_per_second': 87.391, 'eval_steps_per_second': 5.464, 'epoch': 95.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-410150] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1046, 'learning_rate': 2.2222222222222225e-06, 'epoch': 96.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e20fd045a1f47d6981c7acdf3c789ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-605760\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-605760\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.336350440979004, 'eval_accuracy': 0.16241382042951105, 'eval_f1': 0.1031732168501665, 'eval_precision': 0.11519123066141995, 'eval_recall': 0.11797704932771556, 'eval_runtime': 285.7052, 'eval_samples_per_second': 88.336, 'eval_steps_per_second': 5.523, 'epoch': 96.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-605760\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-605760\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-416460] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0969, 'learning_rate': 1.6666666666666667e-06, 'epoch': 97.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da05dab6436849fc83059e2dd0c29447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-612070\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-612070\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-612070\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-612070\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.441780090332031, 'eval_accuracy': 0.16669308186068627, 'eval_f1': 0.10605573355854682, 'eval_precision': 0.11799586595202909, 'eval_recall': 0.12147725434307888, 'eval_runtime': 272.5217, 'eval_samples_per_second': 92.609, 'eval_steps_per_second': 5.79, 'epoch': 97.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-422770] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0956, 'learning_rate': 1.1111111111111112e-06, 'epoch': 98.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b921ccb4404c78b5225619eb805b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-618380\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-618380\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-618380\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-618380\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.343453407287598, 'eval_accuracy': 0.16752516047230367, 'eval_f1': 0.10589514707151002, 'eval_precision': 0.11883301361262721, 'eval_recall': 0.12087748633121924, 'eval_runtime': 284.4619, 'eval_samples_per_second': 88.722, 'eval_steps_per_second': 5.547, 'epoch': 98.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-429080] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0855, 'learning_rate': 5.555555555555556e-07, 'epoch': 99.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c5c6d158a5456092ea741651d961c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-624690\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-624690\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.369701385498047, 'eval_accuracy': 0.16665345906965687, 'eval_f1': 0.1038524243702249, 'eval_precision': 0.11814350783199572, 'eval_recall': 0.11799277534668229, 'eval_runtime': 276.5353, 'eval_samples_per_second': 91.265, 'eval_steps_per_second': 5.706, 'epoch': 99.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-624690\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-624690\\preprocessor_config.json\n",
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-435390] due to args.save_total_limit\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25238\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0785, 'learning_rate': 0.0, 'epoch': 100.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2fa3bcfe61342478708266d15971b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class\\checkpoint-631000\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class\\checkpoint-631000\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class\\checkpoint-631000\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class\\checkpoint-631000\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.48879623413086, 'eval_accuracy': 0.16479118789127506, 'eval_f1': 0.1056426757554171, 'eval_precision': 0.11999177649490574, 'eval_recall': 0.11828458901608721, 'eval_runtime': 283.4552, 'eval_samples_per_second': 89.037, 'eval_steps_per_second': 5.567, 'epoch': 100.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [D:\\models\\ResNet18_Boat_Class\\checkpoint-441700] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from D:/models/ResNet18_Boat_Class\\checkpoint-618380 (score: 0.16752516047230367).\n",
      "Saving model checkpoint to D:/models/ResNet18_Boat_Class/best_model\n",
      "Configuration saved in D:/models/ResNet18_Boat_Class/best_model\\config.json\n",
      "Model weights saved in D:/models/ResNet18_Boat_Class/best_model\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ResNet18_Boat_Class/best_model\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 149433.2861, 'train_samples_per_second': 67.555, 'train_steps_per_second': 4.223, 'train_loss': 2.7933498802124603, 'epoch': 100.0}\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chris\\OneDrive\\Dokumenter\\GitHub\\SailFGVC\\huggingface.ipynb Cell 35\u001b[0m in \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Dokumenter/GitHub/SailFGVC/huggingface.ipynb#X46sZmlsZQ%3D%3D?line=124'>125</a>\u001b[0m pipeline \u001b[39m=\u001b[39m ImageClassificationPipeline(model\u001b[39m=\u001b[39mtrainer\u001b[39m.\u001b[39mmodel, feature_extractor \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mtokenizer , framework\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, device\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Dokumenter/GitHub/SailFGVC/huggingface.ipynb#X46sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m predict_data \u001b[39m=\u001b[39m dataset_specific[\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mselect(np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(dataset_specific[\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m]), batch_size))\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Dokumenter/GitHub/SailFGVC/huggingface.ipynb#X46sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m images \u001b[39m=\u001b[39m [predict_data[\u001b[39m'\u001b[39m\u001b[39mimg_path\u001b[39m\u001b[39m'\u001b[39m][i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m)]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Dokumenter/GitHub/SailFGVC/huggingface.ipynb#X46sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m predictions \u001b[39m=\u001b[39m pipeline(images)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Dokumenter/GitHub/SailFGVC/huggingface.ipynb#X46sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m prediction_table \u001b[39m=\u001b[39m []\n",
      "\u001b[1;32mc:\\Users\\chris\\OneDrive\\Dokumenter\\GitHub\\SailFGVC\\huggingface.ipynb Cell 35\u001b[0m in \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Dokumenter/GitHub/SailFGVC/huggingface.ipynb#X46sZmlsZQ%3D%3D?line=124'>125</a>\u001b[0m pipeline \u001b[39m=\u001b[39m ImageClassificationPipeline(model\u001b[39m=\u001b[39mtrainer\u001b[39m.\u001b[39mmodel, feature_extractor \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mtokenizer , framework\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, device\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Dokumenter/GitHub/SailFGVC/huggingface.ipynb#X46sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m predict_data \u001b[39m=\u001b[39m dataset_specific[\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mselect(np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(dataset_specific[\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m]), batch_size))\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Dokumenter/GitHub/SailFGVC/huggingface.ipynb#X46sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m images \u001b[39m=\u001b[39m [predict_data[\u001b[39m'\u001b[39;49m\u001b[39mimg_path\u001b[39;49m\u001b[39m'\u001b[39;49m][i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m)]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Dokumenter/GitHub/SailFGVC/huggingface.ipynb#X46sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m predictions \u001b[39m=\u001b[39m pipeline(images)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Dokumenter/GitHub/SailFGVC/huggingface.ipynb#X46sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m prediction_table \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#launch tensorboard\n",
    "%load_ext tensorboard\n",
    "EPOCHS = 100\n",
    "dataset_image_search = load_dataset(\"cringgaard/boats_dataset\" , use_auth_token=access_token, split=\"image_search\")\n",
    "for batch_size in batch_sizes:\n",
    "        tags = [model_name , \"Boat_Class\"]\n",
    "        name = \"_\".join(tags)\n",
    "        wandb.init(project=wandb_project, name=name , tags=[\"Boat_Class\"])\n",
    "        torch.cuda.empty_cache()\n",
    "        c_names = dataset.column_names[1:]\n",
    "        c_names.remove('name')\n",
    "        # dataset_specific_test = dataset.remove_columns(c_names)\n",
    "        dataset_boat24_specific_train = dataset_boat24.remove_columns(c_names)\n",
    "        dataset_image_search_specific_train = dataset_image_search.remove_columns(c_names)\n",
    "        dataset_specific = concatenate_datasets([dataset_boat24_specific_train , dataset_image_search_specific_train])\n",
    "        # Split into train and eval\n",
    "        dataset_specific = dataset_specific.train_test_split(test_size=0.2)\n",
    "        \n",
    "        labels = dataset.features['name'].names\n",
    "        id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "        label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "\n",
    "        labels_train_counts = np.bincount(dataset_specific['train']['name'] , minlength=len(labels))\n",
    "        labels_test_counts = np.bincount(dataset_specific['test']['name'] , minlength=len(labels))\n",
    "\n",
    "        # weights = np.array([1 if x == 0 else x for x in labels_train_counts])\n",
    "        # weights = (1/weights)\n",
    "        # weights /= weights.sum()\n",
    "        # weights = torch.tensor(weights, dtype=torch.float , device=torch.device(\"cuda:0\"))\n",
    "\n",
    "        # class WeightedCETrainer(Trainer):\n",
    "        #     def __init__(self, *args, **kwargs):\n",
    "        #         super().__init__(*args, **kwargs)\n",
    "        #     def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        #         labels = inputs.get(\"labels\")\n",
    "        #         labels.to(torch.device(\"cuda:0\"))\n",
    "        #         outputs = model(**inputs)\n",
    "        #         logits = outputs.get(\"logits\")\n",
    "        #         # loss_fct = nn.CrossEntropyLoss(weight=weights , label_smoothing=0.1)\n",
    "        #         loss_fct = nn.CrossEntropyLoss(weight=weights)\n",
    "        #         loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        #         return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        def transforms(examples):\n",
    "            examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "            examples[\"labels\"] = examples['name']\n",
    "            del examples[\"name\"]\n",
    "            del examples[\"img_path\"]\n",
    "            return examples\n",
    "        data_collator = DefaultDataCollator()\n",
    "\n",
    "        model = AutoModelForImageClassification.from_pretrained(\n",
    "            checkpoint,\n",
    "            num_labels=len(labels),\n",
    "            id2label=id2label,\n",
    "            label2id=label2id,\n",
    "            use_auth_token=access_token,\n",
    "            ignore_mismatched_sizes=True,\n",
    "        )\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=model_dir+name,\n",
    "            report_to=\"tensorboard\",\n",
    "            remove_unused_columns=False,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            logging_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            # eval_steps = 10,\n",
    "            # logging_steps = 10,\n",
    "            # save_steps = 10,\n",
    "            save_total_limit=30,\n",
    "            learning_rate=5e-5,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            gradient_accumulation_steps=1,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=EPOCHS,\n",
    "            warmup_ratio=0.1,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"accuracy\",\n",
    "            # label_smoothing_factor=0.1,\n",
    "            # no_cuda=True\n",
    "            # push_to_hub=True,\n",
    "            # hub_strategy=\"end\",\n",
    "            # hub_model_id=\"boats_dataset\",\n",
    "            # hub_token=write_token,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            data_collator=data_collator,\n",
    "            train_dataset=dataset_specific['train'].with_transform(transforms),\n",
    "            eval_dataset=dataset_specific['test'].with_transform(transforms),\n",
    "            tokenizer=image_processor,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "        # # Plot Label Distribution For Training Data\n",
    "        # fig1 = plt.figure()\n",
    "        # ax = fig1.add_axes([0,0,1,1])\n",
    "        # ax.bar([label2id[x] for x in labels], labels_train_counts/dataset_specific['train'].__len__()) # Normalized\n",
    "        # ax.set_ylabel(\"Number of examples normalised\")\n",
    "        # ax.set_title(\"Label Distribution\")\n",
    "        # wandb.log({\"Label Distribution Train\": (fig1)})\n",
    "\n",
    "        # # Plot Label Distribution For Test Data\n",
    "        # fig2 = plt.figure()\n",
    "        # ax = fig2.add_axes([0,0,1,1])\n",
    "        # ax.bar([label2id[x] for x in labels], labels_test_counts/dataset_specific['test'].__len__()) # Normalized\n",
    "        # ax.set_ylabel(\"Number of examples normalised\")\n",
    "        # ax.set_title(\"Label Distribution\")\n",
    "        # wandb.log({\"Label Distribution Test\": (fig2)})\n",
    "\n",
    "        # # Log label2id\n",
    "        # wandb.log({\"Labels\": wandb.Table(data = list(zip(label2id.keys() , label2id.values())) , columns=[\"Label\" , \"ID\"])})\n",
    "\n",
    "        # Train Model\n",
    "        trainer.train()\n",
    "\n",
    "        # Save Model\n",
    "        trainer.save_model(model_dir+name+\"/best_model\")\n",
    "\n",
    "        pipeline = ImageClassificationPipeline(model=trainer.model, feature_extractor = trainer.tokenizer , framework=\"pt\", device=0)\n",
    "        predict_data = dataset_specific['test'].select(np.random.randint(0, len(dataset_specific['test']), batch_size))\n",
    "        images = [predict_data['img_path'][i] for i in range(100)]\n",
    "        predictions = pipeline(images)\n",
    "        prediction_table = []\n",
    "        for i in range(len(predictions)):\n",
    "            prediction_table.append([wandb.Image(images[i]) , predictions[i] , id2label[predict_data['name'][i]]])\n",
    "        columns = [\"Image\" , \"Label Predictions\" , \"True Label\"]\n",
    "        wandb.log({\"Image Predicitions\" : wandb.Table(data=prediction_table, columns=columns)})\n",
    "\n",
    "        metrics = trainer.evaluate(dataset_specific['test'].with_transform(transforms))\n",
    "        wandb.log(metrics)\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [model_name , label_types[0], losses[0], str(16)]\n",
    "name = \"_\".join(tags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
