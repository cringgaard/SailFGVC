{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset , concatenate_datasets\n",
    "from transformers import AutoImageProcessor\n",
    "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
    "from transformers import DefaultDataCollator\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoModel , AutoModelForImageClassification, TrainingArguments, Trainer , ImageClassificationPipeline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from huggingface_hub import login\n",
    "import wandb\n",
    "from transformers import pipeline\n",
    "from sklearn import metrics\n",
    "import json\n",
    "import PIL\n",
    "from data.classes import *\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image as mpimg\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "data_dir = \"data/\"\n",
    "img_dir = \"E:/data/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_PROJECT'] = \"Sailboat FGVC\"\n",
    "os.environ[\"WANDB_WATCH\"]=\"false\"\n",
    "# os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
    "os.environ[\"WANDB_START_METHOD\"]='thread'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2fb3fbc870e4c1d9b9e9392608b5861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset boats_dataset/default to C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\ac77c96413075b65bde5f4ce5b46b31b58e32b84572b90c3ff4ef16b31cee590...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea9c96350e743d5a7a571a999d1e96d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2aefc672804fd29075c6bcd331c465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ffb01d5bbcd49b7ad9f24bd92c36b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating sailboatdata split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6c6054252c4f83bc4e3a44e9752237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating boat24 split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52aeb3871a1545079312b4d2fb69c0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating image_search split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\download\\streaming_download_manager.py:695: DtypeWarning: Columns (39,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset boats_dataset downloaded and prepared to C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\ac77c96413075b65bde5f4ce5b46b31b58e32b84572b90c3ff4ef16b31cee590. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset boats_dataset (C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\ac77c96413075b65bde5f4ce5b46b31b58e32b84572b90c3ff4ef16b31cee590)\n"
     ]
    }
   ],
   "source": [
    "access_token = \"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\"\n",
    "write_token = \"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\"\n",
    "# login(token=access_token)\n",
    "dataset_boat24 = load_dataset(\"cringgaard/boats_dataset\" , use_auth_token=access_token, split=\"boat24\")\n",
    "dataset = load_dataset(\"cringgaard/boats_dataset\" , use_auth_token=access_token, split=\"sailboatdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"google/vit-base-patch16-224\"\n",
    "model_name = \"ViT\"\n",
    "model_dir = \"D:/models/\"\n",
    "# checkpoint = \"microsoft/resnet-18\"\n",
    "# model_name = \"ResNet18\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "size = (\n",
    "    image_processor.size[\"shortest_edge\"]\n",
    "    if \"shortest_edge\" in image_processor.size\n",
    "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    ")\n",
    "_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "label_types = [\"Hull Type\" , \"Rigging Type\" ,  \"Construction\" , \"Ballast Type\" , \"Designer\"]\n",
    "# label_types = [\"Hull Type\"]\n",
    "label_maps = {\n",
    "    \"Hull Type\" : Hull_Type_Classes,\n",
    "    \"Rigging Type\" : Rigging_Type_Classes,\n",
    "    \"Construction\" : Construction_Classes,\n",
    "    \"Ballast Type\" : Ballast_Type_Classes,\n",
    "    \"Designer\" : Designer_Classes\n",
    "}\n",
    "# label_types = [\"Ballast Type\" , \"Designer\"]\n",
    "# label_types = [\"Designer\"]\n",
    "losses = [\"CE\" , \"WeightedCE\"]\n",
    "# losses = [\"WeightedCE\"]\n",
    "# losses = [\"CE\"]\n",
    "batch_sizes = [16]\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    metrics = {}\n",
    "    metrics.update(accuracy.compute(predictions=predictions, references=labels))\n",
    "    metrics.update(f1.compute(predictions=predictions, references=labels , average=\"macro\"))\n",
    "    metrics.update(precision.compute(predictions=predictions, references=labels , average=\"macro\"))\n",
    "    metrics.update(recall.compute(predictions=predictions, references=labels , average=\"macro\"))\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics_multitask(eval_pred):\n",
    "    print(eval_pred)\n",
    "    metrics = {}\n",
    "    for i , label in enumerate(label_types):\n",
    "        print(eval_pred[i])\n",
    "        predictions, labels = eval_pred[i]\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        accuracy_score = accuracy.compute(predictions=predictions, references=labels).values()\n",
    "        f1_score = f1.compute(predictions=predictions, references=labels , average=\"macro\").values()\n",
    "        precision_score = precision.compute(predictions=predictions, references=labels , average=\"macro\").values()\n",
    "        recall_score = recall.compute(predictions=predictions, references=labels , average=\"macro\").values()\n",
    "        metrics[\"accuracy_\"+label] = accuracy_score\n",
    "        metrics[\"f1_\"+label] = f1_score\n",
    "        metrics[\"precision_\"+label] = precision_score\n",
    "        metrics[\"recall_\"+label] = recall_score\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskViT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultitaskViT, self).__init__()\n",
    "        self.base_model = AutoModel.from_pretrained(checkpoint , id2label = None , label2id = None)\n",
    "        self.linear1 = nn.Linear(768, 1024)\n",
    "        self.SoftMax = nn.Softmax(dim=1)\n",
    "        self.Hull_Type = nn.Linear(1024, (Hull_Type_Classes.__len__()))\n",
    "        self.Rigging_Type = nn.Linear(1024, (Rigging_Type_Classes.__len__()))\n",
    "        self.Construction = nn.Linear(1024, (Construction_Classes.__len__()))\n",
    "        self.Ballast_Type = nn.Linear(1024, (Ballast_Type_Classes.__len__()))\n",
    "        self.Designer = nn.Linear(1024, (Designer_Classes.__len__()))\n",
    "\n",
    "        \n",
    "    def forward(self, **inputs):\n",
    "        outputs = self.base_model(inputs['pixel_values'])['pooler_output']\n",
    "        outputs = self.linear1(outputs)\n",
    "        hull_type = self.SoftMax(self.Hull_Type(outputs))\n",
    "        rigging_type = self.SoftMax(self.Rigging_Type(outputs))\n",
    "        construction = self.SoftMax(self.Construction(outputs))\n",
    "        ballast_type = self.SoftMax(self.Ballast_Type(outputs))\n",
    "        designer = self.SoftMax(self.Designer(outputs))\n",
    "        return {\"Hull Type\" : hull_type,\n",
    "                \"Rigging Type\" : rigging_type,\n",
    "                \"Construction\" : construction,\n",
    "                \"Ballast Type\" : ballast_type,\n",
    "                \"Designer\" : designer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    def compute_loss(self, model, inputs):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        model_output = model(**inputs)\n",
    "        total_loss = 0\n",
    "        for i in range (len(model_output)):    \n",
    "            total_loss += criterion(model_output[label_types[i]], inputs[label_types[i]])\n",
    "        return total_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testModel = MultitaskViT()\n",
    "# outputs = testModel(**{'pixel_values' : test_images})\n",
    "# print([x.shape for x in outputs])\n",
    "# # compute_metrics_multitask(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for gradient_accumulation_step in batch_sizes:\n",
    "# wandb.init(project=\"Sailboat FGVC\", name=model_name+\"_multitask\")\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# dataset_specific = dataset['full'].train_test_split(test_size=0.2, shuffle=True, seed=43)\n",
    "\n",
    "# def transforms(examples):\n",
    "#     examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "#     del examples[\"img_path\"]\n",
    "#     del examples[\"name\"]\n",
    "#     return examples\n",
    "\n",
    "\n",
    "# # id2label = {float(i): label for i, label in enumerate(label_types)}\n",
    "# # label2id = {label: float(i) for i, label in enumerate(label_types)}\n",
    "\n",
    "\n",
    "# dataset_specific = dataset_specific.with_transform(transforms)\n",
    "# # dataset_specific.set_format(type=\"torch\")\n",
    "# data_collator = DefaultDataCollator()\n",
    "\n",
    "# model = MultitaskViT()\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"E:/models/\"+model_name+\"_multitask\",\n",
    "#     report_to=\"wandb\",\n",
    "#     remove_unused_columns=False,\n",
    "#     evaluation_strategy=\"steps\",\n",
    "#     save_strategy=\"steps\",\n",
    "#     learning_rate=5e-5,\n",
    "#     per_device_train_batch_size=16,\n",
    "#     gradient_accumulation_steps=2,\n",
    "#     per_device_eval_batch_size=16,\n",
    "#     num_train_epochs=100,\n",
    "#     warmup_ratio=0.1,\n",
    "#     logging_steps=10,\n",
    "#     load_best_model_at_end=True,\n",
    "#     metric_for_best_model=\"f1\",\n",
    "#     # no_cuda=True\n",
    "#     # push_to_hub=True,\n",
    "# )\n",
    "\n",
    "# trainer = MultiTaskTrainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     data_collator=data_collator,\n",
    "#     train_dataset=dataset_specific[\"train\"],\n",
    "#     eval_dataset=dataset_specific[\"test\"],\n",
    "#     tokenizer=image_processor,\n",
    "#     compute_metrics=compute_metrics_multitask,\n",
    "    \n",
    "# )\n",
    "\n",
    "# trainer.train()\n",
    "# wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for label_type in label_types:\n",
    "#     name = \"Baseline_\"+label_type\n",
    "#     # wandb.init(project=\"Sailboat FGVC\", name=name)\n",
    "#     torch.cuda.empty_cache()\n",
    "#     c_names = dataset.column_names[1:]\n",
    "#     c_names.remove(label_type)\n",
    "#     dataset_specific = dataset.remove_columns(c_names)\n",
    "\n",
    "#     labels = dataset.features[label_type].names\n",
    "#     id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "#     label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "\n",
    "#     dataset_specific = dataset_specific.train_test_split(test_size=0.2, shuffle=True, seed=43)\n",
    "\n",
    "#     labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "#     labels_to_remove = np.where(labels_train_counts < 2)[0] # remove labels with less than 2 examples\n",
    "#     dataset_specific['train'] = dataset_specific['train'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "#     dataset_specific['test'] = dataset_specific['test'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "#     labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "#     y_pred = labels_train_counts/labels_train_counts.sum()\n",
    "#     y_pred = (np.array([y_pred]*len(dataset_specific['test'][label_type])))\n",
    "#     baseline_metrics = compute_metrics([y_pred, dataset_specific['test'][label_type]])\n",
    "#     baseline_metrics = {\"eval/\"+ key: val for key, val in baseline_metrics.items()}\n",
    "#     print(baseline_metrics)\n",
    "#     # wandb.log(baseline_metrics)\n",
    "#     wandb.log\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_size in batch_sizes:\n",
    "#     for loss in losses:\n",
    "#         for label_type in label_types: \n",
    "#             tags = [model_name , label_type, loss, str(batch_size)]\n",
    "#             name = \"_\".join(tags)\n",
    "#             wandb.init(project=\"Sailboat FGVC Models\", name=name , group = label_type , tags = tags)\n",
    "#             torch.cuda.empty_cache()\n",
    "#             c_names = dataset.column_names[1:]\n",
    "#             c_names.remove(label_type)\n",
    "#             # Map labels to ids using label map\n",
    "#             dataset_specific = dataset.remove_columns(c_names)\n",
    "#             labels = dataset.features[label_type].names\n",
    "\n",
    "#             dataset_specific = dataset_specific.train_test_split(test_size=0.2, shuffle=True, seed=43)\n",
    "\n",
    "#             labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "#             labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "#             labels_to_remove = np.where(labels_train_counts < 1)[0] # remove labels with less than 2 examples\n",
    "#             labels_to_remove = np.union1d(labels_to_remove, np.where(labels_test_counts < 1)[0])\n",
    "#             # dataset_specific['train'] = dataset_specific['train'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "#             dataset_specific['test'] = dataset_specific['test'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "\n",
    "#             id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "#             label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "\n",
    "#             dataset_specific['train'] = dataset_specific['train'].filter(lambda x: id2label[x[label_type]] not in [\"NaN\"])\n",
    "#             dataset_specific['test'] = dataset_specific['test'].filter(lambda x: id2label[x[label_type]] not in [\"NaN\"])\n",
    "\n",
    "            \n",
    "#             labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "#             labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "\n",
    "#             if loss == \"WeightedCE\":\n",
    "#                 weights = np.array([1 if x == 0 else x for x in labels_train_counts])\n",
    "#                 weights = (1/weights)\n",
    "#                 weights /= weights.sum()\n",
    "#                 weights = torch.tensor(weights, dtype=torch.float , device=torch.device(\"cuda:0\"))\n",
    "\n",
    "#                 class WeightedCETrainer(Trainer):\n",
    "#                     def __init__(self, *args, **kwargs):\n",
    "#                         super().__init__(*args, **kwargs)\n",
    "#                     def compute_loss(self, model, inputs, return_outputs=False):\n",
    "#                         labels = inputs.get(\"labels\")\n",
    "#                         labels.to(torch.device(\"cuda:0\"))\n",
    "#                         outputs = model(**inputs)\n",
    "#                         logits = outputs.get(\"logits\")\n",
    "#                         # loss_fct = nn.CrossEntropyLoss(weight=weights , label_smoothing=0.1)\n",
    "#                         loss_fct = nn.CrossEntropyLoss(weight=weights)\n",
    "#                         loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "#                         return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "#             def transforms(examples):\n",
    "#                 examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "#                 examples[\"labels\"] = examples[label_type]\n",
    "#                 del examples[label_type]\n",
    "#                 del examples[\"img_path\"]\n",
    "#                 return examples\n",
    "\n",
    "#             data_collator = DefaultDataCollator()\n",
    "\n",
    "#             model = AutoModelForImageClassification.from_pretrained(\n",
    "#                 checkpoint,\n",
    "#                 num_labels=len(labels),\n",
    "#                 id2label=id2label,\n",
    "#                 label2id=label2id,\n",
    "#                 use_auth_token=access_token,\n",
    "#                 ignore_mismatched_sizes=True,\n",
    "#             )\n",
    "\n",
    "#             training_args = TrainingArguments(\n",
    "#                 output_dir=model_dir+name,\n",
    "#                 report_to=\"wandb\",\n",
    "#                 remove_unused_columns=False,\n",
    "#                 evaluation_strategy=\"epoch\",\n",
    "#                 logging_strategy=\"epoch\",\n",
    "#                 save_strategy=\"epoch\",\n",
    "#                 # eval_steps = 10,\n",
    "#                 # logging_steps = 10,\n",
    "#                 # save_steps = 10,\n",
    "#                 save_total_limit=1,\n",
    "#                 learning_rate=5e-5,\n",
    "#                 per_device_train_batch_size=batch_size,\n",
    "#                 gradient_accumulation_steps=1,\n",
    "#                 per_device_eval_batch_size=batch_size,\n",
    "#                 num_train_epochs=EPOCHS,\n",
    "#                 warmup_ratio=0.1,\n",
    "#                 load_best_model_at_end=True,\n",
    "#                 metric_for_best_model=\"f1\",\n",
    "#                 # label_smoothing_factor=0.1,\n",
    "#                 # no_cuda=True\n",
    "#                 # push_to_hub=True,\n",
    "#                 # hub_strategy=\"end\",\n",
    "#                 # hub_model_id=\"boats_dataset\",\n",
    "#                 # hub_token=write_token,\n",
    "#             )\n",
    "#             if loss == \"CE\":\n",
    "#                 trainer = Trainer(\n",
    "#                 model=model,\n",
    "#                 args=training_args,\n",
    "#                 data_collator=data_collator,\n",
    "#                 train_dataset=dataset_specific[\"train\"].with_transform(transforms),\n",
    "#                 eval_dataset=dataset_specific[\"test\"].with_transform(transforms),\n",
    "#                 tokenizer=image_processor,\n",
    "#                 compute_metrics=compute_metrics,\n",
    "#                 )\n",
    "#             elif loss == \"WeightedCE\":\n",
    "#                 trainer = WeightedCETrainer(\n",
    "#                     model=model,\n",
    "#                     args=training_args,\n",
    "#                     data_collator=data_collator,\n",
    "#                     train_dataset=dataset_specific[\"train\"].with_transform(transforms),\n",
    "#                     eval_dataset=dataset_specific[\"test\"].with_transform(transforms),\n",
    "#                     tokenizer=image_processor,\n",
    "#                     compute_metrics=compute_metrics,\n",
    "#                 )\n",
    "#             # Plot Label Distribution For Training Data\n",
    "#             fig1 = plt.figure()\n",
    "#             ax = fig1.add_axes([0,0,1,1])\n",
    "#             ax.bar([label2id[x] for x in labels], labels_train_counts/labels_train_counts.sum()) # Normalized\n",
    "#             ax.set_ylabel(\"Number of examples normalised\")\n",
    "#             ax.set_title(\"Label Distribution\")\n",
    "#             wandb.log({\"Label Distribution Train\": (fig1)})\n",
    "\n",
    "#             # Plot Label Distribution For Test Data\n",
    "#             fig2 = plt.figure()\n",
    "#             ax = fig2.add_axes([0,0,1,1])\n",
    "#             ax.bar([label2id[x] for x in labels], labels_test_counts/labels_test_counts.sum()) # Normalized\n",
    "#             ax.set_ylabel(\"Number of examples normalised\")\n",
    "#             ax.set_title(\"Label Distribution\")\n",
    "#             wandb.log({\"Label Distribution Test\": (fig2)})\n",
    "\n",
    "#             # Log label2id\n",
    "#             wandb.log({\"Labels\": wandb.Table(data = list(zip(label2id.keys() , label2id.values())) , columns=[\"Label\" , \"ID\"])})\n",
    "\n",
    "#             # Train Model\n",
    "#             trainer.train()\n",
    "\n",
    "#             # Save Model\n",
    "#             trainer.save_model(model_dir+name)\n",
    "\n",
    "#             pipeline = ImageClassificationPipeline(model=trainer.model, feature_extractor = trainer.tokenizer , framework=\"pt\", device=0)\n",
    "#             predict_data = dataset_specific['test'].select(np.random.randint(0, len(dataset_specific['test']), 4))\n",
    "#             images = [predict_data['img_path'][i] for i in range(4)]\n",
    "#             predictions = pipeline(images)\n",
    "#             prediction_table = []\n",
    "#             for i in range(len(predictions)):\n",
    "#                 prediction_table.append([wandb.Image(images[i]) , predictions[i] , id2label[predict_data[label_type][i]]])\n",
    "#             columns = [\"Image\" , \"Label Predictions\" , \"True Label\"]\n",
    "#             wandb.log({\"Image Predicitions\" : wandb.Table(data=prediction_table, columns=columns)})\n",
    "\n",
    "#             # Plot confusion matrix\n",
    "#             y_pred = trainer.predict(dataset_specific['test'].with_transform(transforms)).predictions.argmax(-1)\n",
    "#             y_true = dataset_specific[\"test\"][label_type]\n",
    "#             wandb.log({\"Confusion Matrix\": wandb.sklearn.plot_confusion_matrix(y_true, y_pred, labels=labels)})\n",
    "#             wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multitask Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_size in batch_sizes:\n",
    "#     name = model_name+\"_Multitask\"\n",
    "#     wandb.init(project=\"Sailboat FGVC\", name=name , tags = [model_name , 'multitask'])\n",
    "#     torch.cuda.empty_cache()\n",
    "#     dataset_specific = dataset.train_test_split(test_size=0.2, shuffle=True, seed=43)\n",
    "    \n",
    "#     for col in dataset_specific.column_names:\n",
    "#         print(col)\n",
    "\n",
    "#     def transforms(examples):\n",
    "#         examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "#         del examples[\"img_path\"]\n",
    "#         del examples[\"name\"]\n",
    "#         return examples\n",
    "    \n",
    "#     data_collator = DefaultDataCollator()\n",
    "\n",
    "#     model = MultitaskViT()\n",
    "\n",
    "#     training_args = TrainingArguments(\n",
    "#         output_dir=model_dir+name,\n",
    "#         report_to=\"wandb\",\n",
    "#         remove_unused_columns=False,\n",
    "#         evaluation_strategy=\"epoch\",\n",
    "#         logging_strategy=\"epoch\",\n",
    "#         save_strategy=\"epoch\",\n",
    "#         eval_steps = 10,\n",
    "#         logging_steps = 10,\n",
    "#         # save_steps = 10,\n",
    "#         save_total_limit=1,\n",
    "#         learning_rate=5e-5,\n",
    "#         per_device_train_batch_size=batch_size,\n",
    "#         gradient_accumulation_steps=1,\n",
    "#         per_device_eval_batch_size=batch_size,\n",
    "#         num_train_epochs=EPOCHS,\n",
    "#         warmup_ratio=0.1,\n",
    "#         # metric_for_best_model=\"f1\",\n",
    "#         # load_best_model_at_end=True,\n",
    "#         # label_smoothing_factor=0.1,\n",
    "#         # no_cuda=True\n",
    "#         # push_to_hub=True,\n",
    "#         # hub_strategy=\"end\",\n",
    "#         # hub_model_id=\"boats_dataset\",\n",
    "#         # hub_token=write_token,\n",
    "#     )\n",
    "\n",
    "#     trainer = MultiTaskTrainer(\n",
    "#         model=model,\n",
    "#         args=training_args,\n",
    "#         data_collator=data_collator,\n",
    "#         train_dataset=dataset_specific[\"train\"].with_transform(transforms),\n",
    "#         eval_dataset=dataset_specific[\"test\"].with_transform(transforms),\n",
    "#         tokenizer=image_processor,\n",
    "#         compute_metrics=compute_metrics_multitask,\n",
    "#     )\n",
    "#     trainer.train()\n",
    "#     trainer.save_model(model_dir+name)\n",
    "#     wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Data Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boat24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcringgaard\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\chris\\OneDrive\\Dokumenter\\GitHub\\SailFGVC\\wandb\\run-20230516_220753-297f6jf3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cringgaard/Sailboat%20FGVC%20Models/runs/297f6jf3\" target=\"_blank\">ViT_Hull Type_boat24</a></strong> to <a href=\"https://wandb.ai/cringgaard/Sailboat%20FGVC%20Models\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fbc0fc0c3ad451ba914192331a0ba9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dcc1145e475454d9992ee2b7ef5172c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18749e3a523e46bd87a61ec9fae1a892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([67, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([67]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\plotly\\matplotlylib\\renderer.py:647: UserWarning:\n",
      "\n",
      "Looks like the annotation(s) you are trying \n",
      "to draw lies/lay outside the given figure size.\n",
      "\n",
      "Therefore, the resulting Plotly figure may not be \n",
      "large enough to view the full text. To adjust \n",
      "the size of the figure, use the 'width' and \n",
      "'height' keys in the Layout object. Alternatively,\n",
      "use the Margin object to adjust the figure's margins.\n",
      "\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning:\n",
      "\n",
      "This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\n",
      "***** Running training *****\n",
      "  Num examples = 52150\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32600\n",
      "  Number of trainable parameters = 85850179\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3e76ff98a84740989e9510d8b98f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning:\n",
      "\n",
      "Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2024\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4839, 'learning_rate': 5e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e40d4791ce24b42874a254e1126cfb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "Saving model checkpoint to D:/models/ViT_Hull Type_boat24\\checkpoint-3260\n",
      "Configuration saved in D:/models/ViT_Hull Type_boat24\\checkpoint-3260\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.603243589401245, 'eval_accuracy': 0.2574110671936759, 'eval_f1': 0.02930727423311737, 'eval_precision': 0.036072636821736496, 'eval_recall': 0.045294454966451736, 'eval_runtime': 18.4442, 'eval_samples_per_second': 109.737, 'eval_steps_per_second': 6.886, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Hull Type_boat24\\checkpoint-3260\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Hull Type_boat24\\checkpoint-3260\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning:\n",
      "\n",
      "Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2024\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2453, 'learning_rate': 4.4444444444444447e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5dbeb3cb6241e7b24edf4bbf21e894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "Saving model checkpoint to D:/models/ViT_Hull Type_boat24\\checkpoint-6520\n",
      "Configuration saved in D:/models/ViT_Hull Type_boat24\\checkpoint-6520\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.420381784439087, 'eval_accuracy': 0.2949604743083004, 'eval_f1': 0.04833807706483661, 'eval_precision': 0.06917134268299333, 'eval_recall': 0.05694504626053667, 'eval_runtime': 18.0759, 'eval_samples_per_second': 111.972, 'eval_steps_per_second': 7.026, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Hull Type_boat24\\checkpoint-6520\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Hull Type_boat24\\checkpoint-6520\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning:\n",
      "\n",
      "Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2024\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0821, 'learning_rate': 3.888888888888889e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79cdc4a43a9492094e19cab52bd8400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "Saving model checkpoint to D:/models/ViT_Hull Type_boat24\\checkpoint-9780\n",
      "Configuration saved in D:/models/ViT_Hull Type_boat24\\checkpoint-9780\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2636795043945312, 'eval_accuracy': 0.3542490118577075, 'eval_f1': 0.07756784322931251, 'eval_precision': 0.11352889540954411, 'eval_recall': 0.0798306261495456, 'eval_runtime': 17.6792, 'eval_samples_per_second': 114.485, 'eval_steps_per_second': 7.184, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Hull Type_boat24\\checkpoint-9780\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Hull Type_boat24\\checkpoint-9780\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning:\n",
      "\n",
      "Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2024\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8537, 'learning_rate': 3.3333333333333335e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0133ef9c38104aad890b211f6bf519c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "Saving model checkpoint to D:/models/ViT_Hull Type_boat24\\checkpoint-13040\n",
      "Configuration saved in D:/models/ViT_Hull Type_boat24\\checkpoint-13040\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.24774169921875, 'eval_accuracy': 0.366600790513834, 'eval_f1': 0.09537135771583562, 'eval_precision': 0.1243202639114011, 'eval_recall': 0.09237933454025048, 'eval_runtime': 16.4654, 'eval_samples_per_second': 122.925, 'eval_steps_per_second': 7.713, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in D:/models/ViT_Hull Type_boat24\\checkpoint-13040\\pytorch_model.bin\n",
      "Image processor saved in D:/models/ViT_Hull Type_boat24\\checkpoint-13040\\preprocessor_config.json\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning:\n",
      "\n",
      "Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    for label_type in label_types:\n",
    "        tags = [model_name , label_type , 'boat24']\n",
    "        name = \"_\".join(tags)\n",
    "        wandb.init(project=\"Sailboat FGVC Models\", name=name , group = label_type , tags = tags)\n",
    "        torch.cuda.empty_cache()\n",
    "        c_names = dataset.column_names[1:]\n",
    "        c_names.remove(label_type)\n",
    "        dataset_specific = dataset.remove_columns(c_names)\n",
    "        dataset_boat24_specific = dataset_boat24.remove_columns(c_names)\n",
    "\n",
    "        dataset_specific = dataset_specific.train_test_split(test_size=0.2, shuffle=True, seed=43)  # 80-20 split for train and test\n",
    "        dataset_specific['train'] = concatenate_datasets([dataset_specific['train'] , dataset_boat24_specific]) # add boat24 dataset to training set\n",
    "        \n",
    "        labels = dataset.features[label_type].names\n",
    "        labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "        labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "        labels_to_remove = np.where(labels_train_counts < 1)[0] # remove labels with less than 2 examples\n",
    "        labels_to_remove = np.union1d(labels_to_remove, np.where(labels_test_counts < 1)[0])\n",
    "        # dataset_specific['train'] = dataset_specific['train'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "        dataset_specific['test'] = dataset_specific['test'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "\n",
    "        dataset_specific['train'] = dataset_specific['train'].filter(lambda x: label_maps[label_type][x[label_type]] not in [\"NaN\"])\n",
    "        dataset_specific['test'] = dataset_specific['test'].filter(lambda x: label_maps[label_type][x[label_type]] not in [\"NaN\"])\n",
    "\n",
    "        id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "        label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "\n",
    "        labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "        labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "        \n",
    "\n",
    "        def transforms(examples):\n",
    "            examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "            examples[\"labels\"] = examples[label_type]\n",
    "            del examples[label_type]\n",
    "            del examples[\"img_path\"]\n",
    "            return examples\n",
    "        data_collator = DefaultDataCollator()\n",
    "\n",
    "        model = AutoModelForImageClassification.from_pretrained(\n",
    "            checkpoint,\n",
    "            num_labels=len(labels),\n",
    "            id2label=id2label,\n",
    "            label2id=label2id,\n",
    "            use_auth_token=access_token,\n",
    "            ignore_mismatched_sizes=True,\n",
    "        )\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=model_dir+name,\n",
    "            report_to=\"wandb\",\n",
    "            remove_unused_columns=False,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            logging_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            # eval_steps = 10,\n",
    "            # logging_steps = 10,\n",
    "            # save_steps = 10,\n",
    "            save_total_limit=30,\n",
    "            learning_rate=5e-5,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            gradient_accumulation_steps=1,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=EPOCHS,\n",
    "            warmup_ratio=0.1,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"f1\",\n",
    "            # label_smoothing_factor=0.1,\n",
    "            # no_cuda=True\n",
    "            # push_to_hub=True,\n",
    "            # hub_strategy=\"end\",\n",
    "            # hub_model_id=\"boats_dataset\",\n",
    "            # hub_token=write_token,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            data_collator=data_collator,\n",
    "            train_dataset=dataset_specific[\"train\"].with_transform(transforms),\n",
    "            eval_dataset=dataset_specific[\"test\"].with_transform(transforms),\n",
    "            tokenizer=image_processor,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "        # Plot Label Distribution For Training Data\n",
    "        fig1 = plt.figure()\n",
    "        ax = fig1.add_axes([0,0,1,1])\n",
    "        ax.bar([label2id[x] for x in labels], labels_train_counts/labels_train_counts.sum()) # Normalized\n",
    "        ax.set_ylabel(\"Number of examples normalised\")\n",
    "        ax.set_title(\"Label Distribution\")\n",
    "        wandb.log({\"Label Distribution Train\": (fig1)})\n",
    "\n",
    "        # Plot Label Distribution For Test Data\n",
    "        fig2 = plt.figure()\n",
    "        ax = fig2.add_axes([0,0,1,1])\n",
    "        ax.bar([label2id[x] for x in labels], labels_test_counts/labels_test_counts.sum()) # Normalized\n",
    "        ax.set_ylabel(\"Number of examples normalised\")\n",
    "        ax.set_title(\"Label Distribution\")\n",
    "        wandb.log({\"Label Distribution Test\": (fig2)})\n",
    "\n",
    "        # Log label2id\n",
    "        wandb.log({\"Labels\": wandb.Table(data = list(zip(label2id.keys() , label2id.values())) , columns=[\"Label\" , \"ID\"])})\n",
    "\n",
    "        # Train Model\n",
    "        trainer.train()\n",
    "\n",
    "        # Save Model\n",
    "        trainer.save_model(model_dir+name)\n",
    "\n",
    "        pipeline = ImageClassificationPipeline(model=trainer.model, feature_extractor = trainer.tokenizer , framework=\"pt\", device=0)\n",
    "        predict_data = dataset_specific['test'].select(np.random.randint(0, len(dataset_specific['test']), 4))\n",
    "        images = [predict_data['img_path'][i] for i in range(4)]\n",
    "        predictions = pipeline(images)\n",
    "        prediction_table = []\n",
    "        for i in range(len(predictions)):\n",
    "            prediction_table.append([wandb.Image(images[i]) , predictions[i] , id2label[predict_data[label_type][i]]])\n",
    "        columns = [\"Image\" , \"Label Predictions\" , \"True Label\"]\n",
    "        wandb.log({\"Image Predicitions\" : wandb.Table(data=prediction_table, columns=columns)})\n",
    "\n",
    "        # Plot confusion matrix\n",
    "        y_pred = trainer.predict(dataset_specific['test'].with_transform(transforms)).predictions.argmax(-1)\n",
    "        y_true = dataset_specific[\"test\"][label_type]\n",
    "        wandb.log({\"Confusion Matrix\": wandb.sklearn.plot_confusion_matrix(y_true, y_pred, labels=labels)})\n",
    "        wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boat Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "        tags = [model_name , \"Boat_Class\"]\n",
    "        name = \"_\".join(tags)\n",
    "        wandb.init(project=\"Sailboat FGVC\", name=name , tags=[\"Boat_Class\"])\n",
    "        torch.cuda.empty_cache()\n",
    "        c_names = dataset.column_names[1:]\n",
    "        c_names.remove('name')\n",
    "        dataset_specific_test = dataset.remove_columns(c_names)\n",
    "        dataset_boat24_specific_train = dataset_boat24.remove_columns(c_names)\n",
    "        \n",
    "        labels = dataset.features['name'].names\n",
    "        # id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "        # label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "\n",
    "        labels_train_counts = np.bincount(dataset_boat24_specific_train['name'] , minlength=len(labels))\n",
    "        labels_test_counts = np.bincount(dataset_specific_test['name'] , minlength=len(labels))\n",
    "\n",
    "        # weights = np.array([1 if x == 0 else x for x in labels_train_counts])\n",
    "        # weights = (1/weights)\n",
    "        # weights /= weights.sum()\n",
    "        # weights = torch.tensor(weights, dtype=torch.float , device=torch.device(\"cuda:0\"))\n",
    "\n",
    "        # class WeightedCETrainer(Trainer):\n",
    "        #     def __init__(self, *args, **kwargs):\n",
    "        #         super().__init__(*args, **kwargs)\n",
    "        #     def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        #         labels = inputs.get(\"labels\")\n",
    "        #         labels.to(torch.device(\"cuda:0\"))\n",
    "        #         outputs = model(**inputs)\n",
    "        #         logits = outputs.get(\"logits\")\n",
    "        #         # loss_fct = nn.CrossEntropyLoss(weight=weights , label_smoothing=0.1)\n",
    "        #         loss_fct = nn.CrossEntropyLoss(weight=weights)\n",
    "        #         loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        #         return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        def transforms(examples):\n",
    "            examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "            examples[\"labels\"] = examples['name']\n",
    "            del examples[\"name\"]\n",
    "            del examples[\"img_path\"]\n",
    "            return examples\n",
    "        data_collator = DefaultDataCollator()\n",
    "\n",
    "        model = AutoModelForImageClassification.from_pretrained(\n",
    "            checkpoint,\n",
    "            num_labels=len(labels),\n",
    "            # id2label=id2label,\n",
    "            # label2id=label2id,\n",
    "            use_auth_token=access_token,\n",
    "            ignore_mismatched_sizes=True,\n",
    "        )\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=model_dir+name,\n",
    "            report_to=\"wandb\",\n",
    "            remove_unused_columns=False,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            logging_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            # eval_steps = 10,\n",
    "            # logging_steps = 10,\n",
    "            # save_steps = 10,\n",
    "            save_total_limit=30,\n",
    "            learning_rate=5e-5,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            gradient_accumulation_steps=1,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=EPOCHS,\n",
    "            warmup_ratio=0.1,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"f1\",\n",
    "            # label_smoothing_factor=0.1,\n",
    "            # no_cuda=True\n",
    "            # push_to_hub=True,\n",
    "            # hub_strategy=\"end\",\n",
    "            # hub_model_id=\"boats_dataset\",\n",
    "            # hub_token=write_token,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            data_collator=data_collator,\n",
    "            train_dataset=dataset_boat24_specific_train.with_transform(transforms),\n",
    "            eval_dataset=dataset_specific_test.with_transform(transforms),\n",
    "            tokenizer=image_processor,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "        # # Plot Label Distribution For Training Data\n",
    "        # fig1 = plt.figure()\n",
    "        # ax = fig1.add_axes([0,0,1,1])\n",
    "        # ax.bar([label2id[x] for x in labels], labels_train_counts/dataset_specific['train'].__len__()) # Normalized\n",
    "        # ax.set_ylabel(\"Number of examples normalised\")\n",
    "        # ax.set_title(\"Label Distribution\")\n",
    "        # wandb.log({\"Label Distribution Train\": (fig1)})\n",
    "\n",
    "        # # Plot Label Distribution For Test Data\n",
    "        # fig2 = plt.figure()\n",
    "        # ax = fig2.add_axes([0,0,1,1])\n",
    "        # ax.bar([label2id[x] for x in labels], labels_test_counts/dataset_specific['test'].__len__()) # Normalized\n",
    "        # ax.set_ylabel(\"Number of examples normalised\")\n",
    "        # ax.set_title(\"Label Distribution\")\n",
    "        # wandb.log({\"Label Distribution Test\": (fig2)})\n",
    "\n",
    "        # # Log label2id\n",
    "        # wandb.log({\"Labels\": wandb.Table(data = list(zip(label2id.keys() , label2id.values())) , columns=[\"Label\" , \"ID\"])})\n",
    "\n",
    "        # Train Model\n",
    "        trainer.train()\n",
    "\n",
    "        # Save Model\n",
    "        trainer.save_model(model_dir+name)\n",
    "\n",
    "        pipeline = ImageClassificationPipeline(model=trainer.model, feature_extractor = trainer.tokenizer , framework=\"pt\", device=0)\n",
    "        predict_data = dataset_specific['test'].select(np.random.randint(0, len(dataset_specific['test']), 4))\n",
    "        images = [predict_data['img_path'][i] for i in range(4)]\n",
    "        predictions = pipeline(images)\n",
    "        prediction_table = []\n",
    "        for i in range(len(predictions)):\n",
    "            prediction_table.append([wandb.Image(images[i]) , predictions[i] , id2label[predict_data[label_type][i]]])\n",
    "        columns = [\"Image\" , \"Label Predictions\" , \"True Label\"]\n",
    "        wandb.log({\"Image Predicitions\" : wandb.Table(data=prediction_table, columns=columns)})\n",
    "\n",
    "        # Plot confusion matrix\n",
    "        y_pred = trainer.predict(dataset_specific['test'].with_transform(transforms)).predictions.argmax(-1)\n",
    "        y_true = dataset_specific[\"test\"][label_type]\n",
    "        wandb.log({\"Confusion Matrix\": wandb.sklearn.plot_confusion_matrix(y_true, y_pred, labels=labels)})\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [model_name , label_types[0], losses[0], str(16)]\n",
    "name = \"_\".join(tags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
