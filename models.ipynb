{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms , models\n",
    "from torchvision.models import resnet50, ResNet50_Weights , resnet18, ResNet18_Weights\n",
    "\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if gpu else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoatImages(Dataset):\n",
    "    def __init__(self, _label_type = \"Hull Type\" , root = './', train=True):\n",
    "        self.img_height  = 500  \n",
    "        self.img_width   = 400\n",
    "        self.img_height_crop = 256  \n",
    "        self.img_width_crop  = 256\n",
    "        self.tabular_data = pd.read_csv(\"boat_data_cleaned.csv\")\n",
    "        # self.name_from_path = re.compile(r'\\./data/\\w*\\\\(.+?)\\\\')\n",
    "        self.name_from_path = re.compile(r'\\./data/[^/]+/(.+?)/')\n",
    "\n",
    "        self.train = train\n",
    "        self.label_type = _label_type\n",
    "        self.labels , self.categories = pd.factorize(self.tabular_data[self.label_type])\n",
    "\n",
    "        if self.train:\n",
    "            self.data_folder = os.path.join(root, 'data/train') # FIXME make a better train test split\n",
    "        else:\n",
    "            self.data_folder = os.path.join(root, 'data/test')\n",
    "\n",
    "        self.dataset_train = datasets.ImageFolder(self.data_folder)\n",
    "\n",
    "    # a getter function\n",
    "    @property\n",
    "    def label_type(self):\n",
    "        return self._label_type\n",
    "        \n",
    "    # a setter function\n",
    "    @label_type.setter\n",
    "    def label_type(self, l):\n",
    "        try:\n",
    "            self._label_type = l\n",
    "            self.labels , self.categories = pd.factorize(self.tabular_data[l])\n",
    "        except:\n",
    "            self._label_type = \"Hull Type\"\n",
    "            self.labels , self.categories = pd.factorize(self.tabular_data[self._label_type])\n",
    "            warnings.warn(\"Invalid label_type! Setting label_type to 'Hull Type'\")\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, _ = self.dataset_train.samples[index]\n",
    "        image = self.dataset_train.loader(path)\n",
    "        \n",
    "        boat_name = re.match(self.name_from_path , path).group(1).replace(\"_\",\" \")\n",
    "        try:\n",
    "            label_idx = self.tabular_data.index[(self.tabular_data['name'].eq(boat_name))].tolist()[0]\n",
    "        except:\n",
    "            label_idx = self.tabular_data.index[(self.tabular_data['name'].eq(boat_name+'.'))].tolist()[0]\n",
    "\n",
    "        label = self.labels[label_idx]\n",
    "\n",
    "        image = transforms.Resize(size = self.img_width)(image)\n",
    "\n",
    "\n",
    "        if self.train:\n",
    "            # image = transforms.RandomAffine((-5,5))(image)\n",
    "            image = transforms.RandomCrop((self.img_width_crop, self.img_height_crop))(image)\n",
    "            # image = transforms.ColorJitter(0.8, contrast = 0.4)(image)\n",
    "            # image = transforms.RandomHorizontalFlip(p=0.5)(image)\n",
    "        else:\n",
    "            image = transforms.CenterCrop((self.img_width_crop, self.img_height_crop))(image)\n",
    "\n",
    "        image = transforms.ToTensor()(image)\n",
    "\n",
    "        # if self.transform is not None:\n",
    "        #     image = self.transform(image)\n",
    "        # if self.target_transform is not None:\n",
    "        #     label = self.target_transform(label)\n",
    "\n",
    "        # print(image,label)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_train.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = BoatImages(_label_type = \"Hull Type\")\n",
    "dataset_test = BoatImages(_label_type = \"Hull Type\",train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2**8\n",
    "trainloader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "testloader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def imshow(img):\n",
    "#     img = img / 2 + 0.5     # unnormalize\n",
    "#     npimg = img.numpy()\n",
    "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "#     plt.show()\n",
    "\n",
    "# # get some random training images\n",
    "# dataiter = iter(trainloader)\n",
    "# images, labels = dataiter._next_data()\n",
    "\n",
    "# # show images\n",
    "# imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# # print labels\n",
    "# print(' '.join('%5s' % dataset_train.labels[labels[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(batch_size):\n",
    "#   imshow(images[i])\n",
    "#   #print(classes[labels[i].item()], \"\\n\\n\")\n",
    "#   print(dataset_train.categories[int(labels[i])], \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resNet50(nn.Module):\n",
    "    def __init__(self , num_classes):\n",
    "        super(resNet50 , self).__init__()\n",
    "        self.model_resnet = resnet50(weights=ResNet50_Weights.DEFAULT) # A pretrained resnet 50\n",
    "        num_ftrs = self.model_resnet.fc.in_features\n",
    "        self.model_resnet.fc = nn.Identity()\n",
    "        self.fc1 = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model_resnet(x)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resNet18(nn.Module):\n",
    "    def __init__(self , num_classes):\n",
    "        super(resNet18 , self).__init__()\n",
    "        self.model_resnet = resnet18(weights=ResNet18_Weights.DEFAULT) # A pretrained resnet 18\n",
    "        num_ftrs = self.model_resnet.fc.in_features\n",
    "        self.model_resnet.fc = nn.Identity()\n",
    "        self.fc1 = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model_resnet(x)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class baselineNet(nn.Module):\n",
    "    def __init__(self , num_classes):\n",
    "        super(baselineNet , self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(59536, 2**8)\n",
    "        self.fc2 = nn.Linear(2**8, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resNet18 Hull Type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/.local/lib/python3.10/site-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/chris/.local/lib/python3.10/site-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/chris/.local/lib/python3.10/site-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/chris/.local/lib/python3.10/site-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/chris/.local/lib/python3.10/site-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/chris/.local/lib/python3.10/site-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "no_epochs = 100\n",
    "\n",
    "# types = dataset_train.tabular_data.columns\n",
    "# FIXME Make it work for other label types\n",
    "types = [\n",
    "    \"Hull Type\",\n",
    "    # \"Rigging Type\"\n",
    "]\n",
    "\n",
    "for type in types:\n",
    "    # dataset_train = BoatImages(_label_type = type)\n",
    "    # dataset_test = BoatImages(_label_type = type, train=False)\n",
    "    # trainloader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "    # testloader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "\n",
    "    net_list =[\n",
    "    # baselineNet,\n",
    "    resNet18,\n",
    "    resNet50\n",
    "    ]\n",
    "\n",
    "    for netType in net_list:\n",
    "        torch.cuda.empty_cache()\n",
    "        net = netType(len(dataset_train.categories))\n",
    "        name = str(net.__class__.__name__)\n",
    "        print(name,type)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.95)\n",
    "        net.to(device)\n",
    "\n",
    "        writer = SummaryWriter(comment=name+\"_\"+type)\n",
    "\n",
    "        # Load the TensorBoard notebook extension\n",
    "        %load_ext tensorboard\n",
    "        net.train()\n",
    "        reporting_interval = 50\n",
    "        for epoch in range(no_epochs):  # Loop over the dataset multiple times\n",
    "            epoch_loss = test_loss =  running_loss = 0.0\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                # Get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward + backward + optimize\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Print statistics\n",
    "                epoch_loss += loss.item()\n",
    "                running_loss += loss.item()\n",
    "                if i % reporting_interval == reporting_interval-1:  # Print every reporting_interval mini-batches\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                        (epoch, i + 1, running_loss / reporting_interval))\n",
    "                    running_loss = 0.0\n",
    "            \n",
    "            # Calculate test loss and log to tensorboard\n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                for i, data in enumerate(testloader, 0):\n",
    "                    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                    outputs = net(inputs)\n",
    "                    loss_test = criterion(outputs, labels)\n",
    "                    test_loss += loss_test.item()\n",
    "\n",
    "\n",
    "            writer.add_scalar(\"Loss_train\", epoch_loss/(len(trainloader)), epoch)\n",
    "            writer.add_scalar(\"Loss_test\", test_loss/(len(testloader)), epoch)\n",
    "            net.train()\n",
    "\n",
    "\n",
    "\n",
    "        print('Finished Training' , str(net.__class__.__name__)+\"_\"+type)\n",
    "        torch.save(net , name+'_'+type+'.pth')\n",
    "        writer.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
