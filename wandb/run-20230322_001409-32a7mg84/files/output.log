[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 204, 206, 207, 208, 209, 211, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 257, 258, 259, 261, 263, 264, 265, 266, 267, 268, 269, 270, 272, 273, 274, 275, 276, 277, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 344, 346, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 394, 395, 396, 397, 398, 399, 400, 401, 403, 404, 405, 406, 407, 408, 409, 410, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 444, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 458, 459, 460, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 476, 477, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 494, 495, 496, 497, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 513, 514, 515, 516, 517, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 531, 532, 533, 534, 535, 536, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 567, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 592, 593, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 606, 608, 609, 610, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 633, 634, 635, 636]
[2, 3, 4, 6, 7, 8, 9, 10, 15, 16, 18, 19, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 34, 35, 42, 44, 49, 50, 52, 54, 55, 57, 58, 59, 63, 64, 68, 70, 71, 72, 75, 76, 82, 84, 91, 94, 95, 98, 100, 101, 102, 103, 104, 108, 109, 110, 114, 116, 118, 129, 130, 131, 132, 133, 138, 140, 143, 149, 151, 155, 156, 157, 160, 166, 170, 174, 179, 181, 184, 185, 186, 192, 196, 200, 204, 205, 206, 209, 210, 214, 216, 218, 228, 244, 245, 247, 250, 253, 258, 259, 260, 262, 265, 267, 268, 270, 271, 272, 273, 274, 278, 283, 285, 289, 290, 291, 292, 296, 300, 304, 305, 306, 309, 310, 314, 315, 321, 322, 323, 328, 329, 337, 339, 342, 343, 344, 345, 347, 354, 363, 367, 368, 371, 374, 377, 380, 382, 384, 388, 392, 394, 396, 397, 399, 402, 404, 410, 411, 413, 414, 418, 423, 426, 429, 443, 444, 445, 446, 447, 453, 457, 458, 461, 462, 465, 475, 478, 479, 480, 483, 485, 492, 493, 494, 498, 502, 505, 506, 512, 514, 518, 528, 530, 537, 538, 539, 542, 548, 550, 553, 555, 557, 564, 566, 567, 568, 572, 574, 580, 585, 588, 591, 594, 598, 599, 601, 605, 606, 607, 611, 615, 617, 618, 623, 626, 627, 630, 631]
[245, 475, 566, 131, 518, 19, 260, 27, 512, 605, 216, 530, 478, 553, 323, 185, 630, 480, 143, 82, 485, 479, 539, 611, 462, 537, 310, 205, 345, 363, 607, 591, 278, 538, 262, 443, 493, 498, 402, 445, 102, 210, 347, 594, 447, 44, 457, 200, 157, 461, 568, 380, 411, 392, 343, 271]
['FG w/core,Composite', 'Plywood or GRP', 'Wood', 'Plywood/FG', 'FG', 'Carbon inside/Kevlar ext./SCRIMP', 'Ply with single chine or FG', 'FG or Wood', 'Wood/FG', 'NaN', 'GRP', 'Carbon fiber', 'FG (foam sandwich)', 'GRP Sandwich resin infusion', 'Wood/FG/Composite', 'Wood or FG', 'FG w/balsa core hull & deck', 'FG Foam Core', 'Composite', 'FG/balsa core deck', 'Carbon-epoxy sandwich', 'Carbon/Composite', 'Wood/FG/single chine', 'FG solid hull, balsa cored deck', 'FG w/balsa core deck', 'FG w/cored deck', 'Epoxy w/ Divinycell', 'Cold Molded Mahogany', 'FG (solid)', 'ALU', 'Aluminum', 'FG w/balsa cored deck', 'FG w/foam cored deck', 'Aluminum multi-chine', 'Steel', 'Resin infused GRP', 'wood strip/FG', 'wood strip', 'Ferro Cement', 'FG foam core/infusion', 'FG/ E glass w/balsa core', 'FG /ferro cement', 'FG Composite', 'Wood / FG', 'Wood/FG/multi chine', 'FG Divinycell  & Vinyl', 'FG w/devinacell', 'FG reinforced vinylester with Divinycell core', 'FG Divinycell  & Vinyl w carbon', "Plywood 'stitch & glue'", 'TRILAM Polyethylene', 'FG & Plywood', 'Plywood', 'Wood or foam core', 'Plywood/single chine', "Wood ('hot molded' laminate)", 'FG solid laminate - fabmat', 'FG/balsa cored deck', 'Molded Plywood', 'Wood (Clinker)', 'FG/infusion', 'FG (Infusion)', 'FG vinylester/infusion', 'FG or plywood', 'Glass/carbon fiber over foam core', 'FG/pre-preg foam core w/carbon', 'E-glass/cabon', 'FG solid laminate hull/ply cored deck', 'Foam-cored, vacuum-infused FG', 'FG infusion/balsa above waterline', 'PVC Foam-cored, vacuum-infused GRP', 'GRP-infused PVC Foam Sandwich', 'GRP infused PVC Foam Sandwich', 'GRP w/ PVC foam sandwich, polyester resin', 'FG Balsa Core', 'FG/Carbon Epoxy Sandwich', 'FG composite', 'GRP w/carbon fiber and foam core', 'FG with wood ', 'Wood (clinker)', 'FG & Wood', 'FG w/carbon & kev.', 'FG with foam core above the waterline', 'FG w/Divinycell hull & deck', 'FG ', 'Wood - carvel (mahogany on oak)', 'Cedar planked over white oak frames', 'Plywood / FG', 'Foam sandwich/Carbon/Kevlar', 'FG Sandwich', 'GRP vinylester sandwich', 'Aluminium', 'Polyester composite', 'FG w/airex cored deck', 'Airex foam core', 'FG solid', 'Wood planked w/double chine', 'Wood plank', 'Wood Planked', 'FG w/airex core', 'Plywood or FG', 'Plywood /single chine', 'FG hull/wood deck and cabin', 'FG w/balsa cored deck and coach', 'Wood planked', 'Wood / Steel', 'Wood - clinker', 'Aluminum/FG', 'ALU/FG', 'FG solid laminate', 'FG (solid laminate)', 'FG vinylester w/balsa deck', 'Solid lam. below waterline w kevlar', 'FG w/Vinylester resin', 'FG or Plywood', 'FG w/vinylester resin', 'FG w/ vacuum infusion', 'plywood, multi-chine', 'Fg', 'Fiberglass', 'FG w/balsa deck', 'Wood (strip planked mahogany)', 'Wood (strip. planked mahogany)', 'FG airex hull, divinicell deck', 'plywood or FG', 'GRP with Vinylester', 'Wood /FG', 'FG solid lamine hull/ cored deck.', 'vinylester, E-glass with Kevlar, foam deck', 'FG hull/wood deck', 'FG/Composite', 'FG (solid) ', 'Polyethyline', 'Wood (strip planked)', 'FG w/divinycell core deck', 'FG w/klegecell core', 'Epoxy-FRP', 'FG/wood superstructure', 'FG  (solid)', 'Carbon w/foam core', 'GRP-infused Foam Sandwich w/Vinylester and Polyester resin', 'FG w/carbon infusion', 'FG w/vacuum infusion and CARBON and aramid fibre', 'Wood planked (teak)', 'Wood planked/Molded Plywood/FG', 'FG w/balsa core above waterline', 'FG/balsa cored foredeck', 'FG w/balsa core', 'FG (solid hull/balsa deck)', 'FG hull', 'GF/Alloy', 'FG w/balsa cored hull & deck', 'Wood/GRP', 'Aluminum or steel', 'Aluminum and steel', 'Any', 'FG/plywood deck', 'FG w/ply deck', 'FG w/Klege-Cell', 'FG solid hull/plywood deck', 'Plywood Epoxy', 'Wood (Stitch and glue plywood)', 'Carbon Epoxy Foam', 'FG w/Airex cored hull', 'Carbon-Airex foam-Araldite Epoxy sandwich', 'FG (balsa core cabin trunk)', 'FRP', 'Wood planked, (Mahogany, Oak frames)', 'Wood ', 'FG w/airex cored hull & deck', 'FG w/airex cored hull', 'Kevlar foam epoxy pre-preg.', 'FG/Klegecell', 'Wood Clinker/FG', 'wood/FG', 'EGlass/Vacuum formed sandwich', 'FG with PVC core', 'FG/Kevlar w/balsa', 'Steel or Alu', 'Tecrothene 121', 'FG poly foam sand.', 'Wood (Mahog. on Oak)', 'FG w/Airex core for deck.', 'GRP w/ vinylester resin and balsa core', 'FG/vinylester (composite infusion)', 'Steel (single chine)', 'FG sandwich UD carbon reinforcement, PVC foam', 'Polyeser-PVC sandwich w/ carbon', 'Wood planked single chine', 'Wood single chine', 'FG/airex core', 'FG w/ Divinycell sandwich core', 'FG (Composite)', 'FG Comp.', 'Ply/single chine', 'FG/foam sandwich', 'FG/Sandwich', 'Sandwich E-Glass', 'FG w/foam core deck', 'FG twaron reiforced w/balsa deck', 'FG, PVC foam above WL', 'FG w/ foam sandwich', 'FG w/poly cored deck', 'FG/solid lam. hull/sandwich deck', 'Cold molded or ply with chine', 'FG/PLY/ALU', 'Wood (Mahogany)', 'GRP with foam core', 'Foam core epoxy', 'Foam core epoxy laminate', 'Wood/FG w/balsa deck', 'Wood/Steel/FG', 'Steel (triple chine)', 'Resin infus./PVC foam hull side/balsa deck', 'GRP w/vacuum infused polyester and vinylester', 'Advanced comp.', 'FG w/foam (polypro.) core', 'various', 'Steel/FG/Ferro', 'Swing Keel', 'Wood (Cold molded)', 'FG w/polyurethane foam sand.', 'FG (poly. core)', 'FG (comp)', 'FG foam/vinyl w/infusion/carbon stringers', 'FG w/ airex core', 'FG sandwich hull & deck', 'Wood - Clinker', 'Vacuum infused polyester with balsa core', 'FG - Composite', 'FG w/foam core', 'FG /Fm. core', 'FG or strip plank', 'Wood/hot molded veneer', 'Wood/hot molded veneer (agba/cedar)', 'Molded fiberglass', 'FG multi chine', 'Wood Mahogany on Oak', 'vinyl-ester w/carbon', 'FG epoxy w/PVC core', 'Carbon/Epoxy Sandwich', 'Divinicell sandwich', 'FG w/Airex core', 'Niels Peter Faurby', 'Polyester sandwich - Infused PVC foam', 'Plywood/multi-chine', 'FG w/carbon & airex', 'FG/balsa sandwich', 'Wood or FG, single chine', 'Wood (hot molded)/FG', 'Vacuum-infused vinylester resin', 'FG/ balsa sand. deck', 'FG/poly. core', 'Balsa sandwich infused FG hull', 'Plywood;single chine/FG', 'ALU multi-chine', 'Pre-preg carbon w/nomex sand.', 'FG with carbon-reinforced vinylester.', 'Wood/Steel', 'FGw/balsa cored hull & deck', 'FG/Steel/Wood', 'FG-foam cored hull-balsa deck', 'Plywood Hot Molded', 'Ply wood', 'Wood/FG/double chine', 'FG with balsa and foam core', 'class rules', 'Plywood/GRP/FRP/Composite', 'Wood/GRP/Composite', 'GRP w/E-glass and vinylester resin', 'FG w/foam PVC sandwich', 'FG sandwich w/carbon ', 'E-glass w/ epoxy vinyester + PVC foam core', 'FG hull; wood coachroof', 'Wood Composite/FG', 'FG w/ vinylester resin and PVC foam core', 'FG balsa cored deck', 'FG w/balsa cored deck & topsides', 'FG/ solid hull & balsa cored deck', 'FG/Carbon infusion', 'FG/epoxy/nomex', 'FRP with Vinylester resin', 'Carbon reinforced GRP', 'FG w/ balsa cored deck', 'Roto-moulded polyethylene', 'Plywoo/FG', 'Wood (carvel)', 'Balsa core sandwich set in polyester resin, exterior layer of vinylester', 'FG w/balsa sandwich', 'GRP w/balsa sandwich', 'GRP w/1st layer Vinylester resin', 'GRP w/1st layer Vinylester resin and balsa sandwich', 'EDPM tire/natural rubber', '1100 dtex EDPM tire/natural rubber', 'Natural rubber', 'Wood or GRP', 'FG infusion w/balsa & klegecell', 'Wood/cold molded', 'Carbon-epoxy sandwich pre-preg', 'Carbon fiber composite', 'Carbon fiber w/corecell foam core', 'Carbon fiber composite foam sandwich', 'Roto-Molded Polyethylene', 'Roto Molded Polyethylene', 'ABS', 'Rotomolded Polyethylene', 'Plywood single chine', 'Wood Clinker', 'Wood - carvel', 'ACP', 'ACP (foam & plastic sandwich)', 'ABS/FG', 'Thermo Plastic', 'HG', 'FG (solid hull and balsa deck)', 'FRP / Balsa sandwich above waterline', 'ACP -Thermo formed Plastic', 'Alum. or Steel', 'FG w/no core', 'Solid FRP', 'Wood and GRP', 'FG w/Divinycell core', 'Wood lapstrake/FG', 'Wood/FG (1971)', 'FG/Carbon', 'Wood/Clinker', 'All materials allowed', 'Molded Plywood/FG', 'GRP w/balsa core', 'FG w/plywood cored deck', 'FG w/divinycell deck', 'Composite infusion', 'E glass w/vinyl/PVC core', 'FG with vinylester resin', 'FG and PVC sandwich', 'FG w/closed cell foam core', 'E glass/PVC core/vinyl.', 'FG foam sand. coach roof and deck', 'Wood/Composite', 'Vacuum infused hull', 'Vacuum infused hull, sandwich balsa/ polyester.', 'GRP with vinylester infusion', 'FG/ABS', 'ALUM', 'Carbon', 'FRP with Airex foam core', 'FG balsa cored deck.', 'E glass, corecell', 'E-glass/epoxy/foam sandwich', 'Mahogany planked on Oak', 'FG/wood deck', 'Single chine Ply/FG', 'Wood; Carvel planked', 'FG/vinylVacuum/foam sandwich', 'GRP w/ PVC foam sandwich', 'Vacuum infused polyester with balsa core.', 'Polyester with balsa core hull', 'Foam Sand. /resin infusion', 'Wood/Epoxy Composite', 'Epoxy foam sand.w/Carbon', 'Cold Molded', 'FG/Termanto PVC foam Hull & deck', 'Techcrothene 109 (roto molded)', 'FG/ balsa cored deck', 'Carbon infused FG', 'FG w/Divinycell sandwich core', 'FG w/ vacuum infused Divinycall', 'Teak/FG', 'FG w/balsa or airex cored deck', 'Cold- molded wood', 'Wood (clinker)/Wood(carvel)', 'molded plywood or FG', 'FG hull, Wood Deck', 'FG with foam core + steel frame', 'Infused composite FG with Vinylester resin and balsa core.', 'Infused FG composite with Vinylester resin and balsa core', 'Infused composite hull with Vinylester resin.', 'Vacuum infused composite FG with Vinylester and balsa core.', 'ABS/Corelite', 'FG w/airex hull/balsa core deck', 'Wood planked/cold molded/FG', 'Vinylester Resin infused thermoformed Core-Cell', 'FG foam sand. hull & deck', 'FG single chine', 'FG/Foam Sandwich', 'FG foam sandwich deck', 'FG w/foam cored hull, balsa deck.', 'Wood strip planked/FG w/balsa deck', 'FG with wood deck and cabin', 'FG Hull, FG over ply Deck & Cabin', 'FG/Balsa hull, airex deck', 'Carbon w/sandwich', 'FG/wood/steel/alum.', 'FG w/PVC core', 'GRP w/PVC core', 'FG PVC sandwich w/carbon', 'WOOD', 'FG w/ airex cored deck', 'epoxy infused carbon & foam core', 'Heytex 5509 (inflatable)', 'FG or PLY', 'Plwood/multi-chine', 'FG hull and wood deck opt.', 'GRP w/vinylester and balsa sandwich', 'FG solid hull/plywood cored deck', 'Various', 'Ply Wood', 'Wood (mahogany)', 'FG w/bals cored deck', 'Mahogany strip planked', 'Plywood (hard chine)', 'Aluminium or FRP', 'Vinylester/Fiberglass', 'GRP carbon epoxy', 'FG foam sandwich', 'FRP epoxy resin with full carbon foam sandwich', 'FRP Epoxy with carbon foam sandwich', 'ALU/Wood', 'Vacuum Infused E-Glass Vinylester/Polyester', 'E-Glass Vinylester', 'Wood/ALU/FG', 'plyood/FG', 'Wood or Fiberglass', 'biax. E glass w/Dyvinicel foam core', 'FG infusion w/klegecell core', 'FG with foam core', 'FG w/poly foam sand.', 'FG with vacuum bonded PVC/foam', 'FG/Closed-cell foam and honeycomb PVC sandwich', 'GRP with Airex PVC foam core', 'Kevlar w/epoxy & balsa', 'Wood double planked', 'Wood planked on steel', 'FG/Aluminum', 'FG w/airex hull/klegecell deck', 'Steel (multi chine)', 'FG single laminate', 'Ply, Aluminium or FG', 'FG solid laminate with balsa cored deck', 'FG w/PVC foam/vinylsester', 'Wood (carvel or ply)/FG', 'Polyester', 'Monolithic polyester contact', 'FG w/pvc core w/infusion', 'Alum., Wood or GRP', 'FG infused w/PVC foam topsides and deck/vinylester', 'Alum.', 'Wood/Ply/FG', 'FG/vinylester-balsa-vacuum', 'Epoxy w/foam sand.', 'Solid FG hull and deck', 'FG/w closed cell foam deck', 'Mahogany on Oak', 'wood', 'FG w/vacuum bagged corecell core', 'FG w/corecell foam core', 'FRP w/balsa core bottom/solid topsides', 'FG/sandwich', 'Wood/FG/composite', 'Wood planked/FG', 'GRP/timber', 'FG (Epoxy)', 'HPDE (Roto molded)', 'FG, PVC foam', 'FG w/polyester foam core', 'Glass, polyester resin, foam sandwich, vacuum infusion', 'Glass, Polyester, PVC foam', 'Wood/FG/other', 'Wood (plywood) w/ glass skin overlay', 'Wood (teak over elm) ', 'FG solid laminate below waterline', 'GRP w/ PVC foam core and 1st layer Vinylester resin', 'GRP w/PVC foam core', 'Infused carbon foam sandwich', 'Carbon fiber, vinylester, epoxy divinycell foam sandwich', 'Hull & Deck vacuum bagged  foam sand.', 'Cold Molded or FG', 'E glass/foam sand.,infusion', 'Wood planked hull w/plywood deck.', 'Wood - planked mahogany', 'FG (vacuum-resin-infused)', 'Steel, Wood or GRP', 'Multi-chine ply w/FG', 'Plywood/epoxy', 'Multi-chine PLYw/Epoxy', 'Plywood-multi-chine/FG', 'multi-chine plywood&epoxy', 'multi chine - ply/epoxy/comp.', 'Ply/multi-chine/FG', 'FG/Wood', 'FG w/divin. deck & hull', 'Wood, carvel planked', 'Comptec PE3 Polyethylene', 'Roto Molded poly.', 'Roto molded poly.', 'Polyethylene', 'VGRP foam sandwich', 'GRP monolithic construction', 'Wood carvel mahog.', 'FG (solid) hull/Balsa cored deck', 'FG/Wood Coachroof', 'FG balsa core hull & deck', 'FG w/vacuum infused Vinylester resin', 'GRP w/polyester resin and balsa core', 'FG w/klegecell', 'Vinly w/PVC', 'Marine ply w/carbon fiber and epoxy resin', 'FG foam w/carbon', 'FG bottom/wood topsides', 'Wood (cedar on oak)', 'FG Airex hull/ balsa deck', 'Mahogany', 'Wood, hard chined', 'Wood clinker', 'FG/solid laminate', 'FG (balsa core  cored deck and coach)', 'FG (solid hull/balsa cored deck)', 'FG (balsa cored deck)', 'FG w/ balsa cord deck', 'FG or Ply', 'plywood, hard chine', 'Steel Alum. or Wood', 'glass w/carbon/vinylester/PVC sand.', 'FG solid hull&deck', 'foam sad/vinylester', 'Infused vinylester and polyester w/ foam core', 'Vacuum infusion vinylester resin with carbon fiber', 'Vacuum infusion vinylester resin with carbon fiber and Kevlar', 'FG w/balsa deck & coach', 'FG sandwich w/kevlar', 'Wood-Clinker', 'Carbon w/honeycomb', 'Tubular steel', 'Carbon (pre-preg)', 'Cored composite', 'Wood (pine on oak)', 'E-Glass/Epoxy/PVC foam', 'FG w/poly sandwich deck', 'GRP w/poly sandwich deck', 'FG/ hull w/ Airex/ Deck w/balsa', 'FG w/klegecell deck', 'Wood (carvel planked)', 'Wood/single chine', 'Plywood or GRP w/foam sandwich', 'Wood/clinker', 'Wood - (clinker)', 'FG/ w/epoxy & Nomex (nylon) core', 'FG prepreg/Nomex core', 'glass/kev/nomex', 'Wood-clinker', 'FG - solid', 'Infusion molded FG', 'Vacuum-bagged resin infusion', 'FG w/kevlar (Aramat K)', 'FG w/ kevlar ', 'GRP using ISO/NPG resin', 'FG balsa cored hull & deck', 'High-Impact Luran', 'Epoxy w/foam core', 'wood/FG/ALU', 'Advanced Comp.', 'Carbon Composite', 's-glass/cedar core/carbon/kevlar', 'Hot molded plywood', 'FG w/ sandwich', 'FG/cored deck', 'foam sand.epoxy infusion', 'Modified epoxy E-glass laminate', 'Epoxy/ATC Core-Cell', 'FRP w/PVC foam core', 'FG Vinylester/PVC hull/Balsa deck ', 'FG w/PVC hull and balsa deck', 'Plywood/FG - single chine', 'Wood with alternate steel frames', 'Molded Ply/FG', 'carbon/kevlar with foam core', 'Wood/Clinker/FG', 'Plywood-epoxy', 'FG/Steel', 'Wood (hot molded veneers)', 'PVC', 'GRP sandwich w/PVC foam and Vinylester resin', 'Wood (cold molded)/FG', 'FGw/Carbon', 'FG w/ DC core', 'FG w/ infused vinylester; PVC foam core', 'FG w/ vinylester resin; PVC foam core', 'Epoxy foam sandwich', 'Roto molded poly/Tri-Skin foam sand.', 'FG w/poly foam, carbon and kev.', 'Plywood & Oak', 'Steel/Alu', 'FG sandwich with PVC foam core', 'Wood(clinker)/FG', 'Wood (cold molded)', 'FG w/ deck of Vetrolex core', 'FG cored deck', 'Wood Mahogany', 'Epoxy/foam sandwich', 'E-glass, foam sandwich', 'Wood composite', 'wood / epoxy', 'Wood/ FG', 'Wood - Teak', 'FG (Airex core)', 'Infused epoxy', 'FG (vacuum infusion resin) w/ balsa sandwich', 'FG /balsa w/infusion', 'FG (vacuum infusion) w/balsa core', 'Ply (multi-chine)/FG', 'Wood multi chine', 'Plywood (double chine)', 'FG solid hull/ply sandwich deck', 'FG w/foam core & carbon beams', 'FG-PVC core', 'Steel (multichine)', 'FG w/Klege-cell core', 'Roto molded Poly.', 'FG w/airex in hull and balsa deck', 'FG with kevlar reinforcement', 'Wood & FG', 'Chantier Wrighton (FRA)', 'FG w/foam cored hull & deck', 'Wood (Carvel)', 'EEP Particle foam', 'Foam w/carbon', 'FG with vacuum infused epoxy', 'Epoxy/foam sand. w/E-glass', 'Epoxy infusion', 'Roto Molded Poly.', 'Epoxy/foam sand. w/carbon', 'E Glass, Divinicel Composite foam infused with Vinylester resins', 'Plywd. Alum. FG double chine', 'Plywood, double chine', 'plywood', 'FG foam core/resin infusion', 'Wood /FG single chine']
loading configuration file config.json from cache at C:\Users\chris/.cache\huggingface\hub\models--microsoft--resnet-18\snapshots\2f536bd335677c6b111b3d103af458ef57a6145e\config.json
Model config ResNetConfig {
  "_name_or_path": "microsoft/resnet-18",
  "architectures": [
    "ResNetForImageClassification"
  ],
  "depths": [
    2,
    2,
    2,
    2
  ],
  "downsample_in_first_stage": false,
  "embedding_size": 64,
  "hidden_act": "relu",
  "hidden_sizes": [
    64,
    128,
    256,
    512
  ],
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10",
    "11": "LABEL_11",
    "12": "LABEL_12",
    "13": "LABEL_13",
    "14": "LABEL_14",
    "15": "LABEL_15",
    "16": "LABEL_16",
    "17": "LABEL_17",
    "18": "LABEL_18",
    "19": "LABEL_19",
    "20": "LABEL_20",
    "21": "LABEL_21",
    "22": "LABEL_22",
    "23": "LABEL_23",
    "24": "LABEL_24",
    "25": "LABEL_25",
    "26": "LABEL_26",
    "27": "LABEL_27",
    "28": "LABEL_28",
    "29": "LABEL_29",
    "30": "LABEL_30",
    "31": "LABEL_31",
    "32": "LABEL_32",
    "33": "LABEL_33",
    "34": "LABEL_34",
    "35": "LABEL_35",
    "36": "LABEL_36",
    "37": "LABEL_37",
    "38": "LABEL_38",
    "39": "LABEL_39",
    "40": "LABEL_40",
    "41": "LABEL_41",
    "42": "LABEL_42",
    "43": "LABEL_43",
    "44": "LABEL_44",
    "45": "LABEL_45",
    "46": "LABEL_46",
    "47": "LABEL_47",
    "48": "LABEL_48",
    "49": "LABEL_49",
    "50": "LABEL_50",
    "51": "LABEL_51",
    "52": "LABEL_52",
    "53": "LABEL_53",
    "54": "LABEL_54",
    "55": "LABEL_55",
    "56": "LABEL_56",
    "57": "LABEL_57",
    "58": "LABEL_58",
    "59": "LABEL_59",
    "60": "LABEL_60",
    "61": "LABEL_61",
    "62": "LABEL_62",
    "63": "LABEL_63",
    "64": "LABEL_64",
    "65": "LABEL_65",
    "66": "LABEL_66",
    "67": "LABEL_67",
    "68": "LABEL_68",
    "69": "LABEL_69",
    "70": "LABEL_70",
    "71": "LABEL_71",
    "72": "LABEL_72",
    "73": "LABEL_73",
    "74": "LABEL_74",
    "75": "LABEL_75",
    "76": "LABEL_76",
    "77": "LABEL_77",
    "78": "LABEL_78",
    "79": "LABEL_79",
    "80": "LABEL_80",
    "81": "LABEL_81",
    "82": "LABEL_82",
    "83": "LABEL_83",
    "84": "LABEL_84",
    "85": "LABEL_85",
    "86": "LABEL_86",
    "87": "LABEL_87",
    "88": "LABEL_88",
    "89": "LABEL_89",
    "90": "LABEL_90",
    "91": "LABEL_91",
    "92": "LABEL_92",
    "93": "LABEL_93",
    "94": "LABEL_94",
    "95": "LABEL_95",
    "96": "LABEL_96",
    "97": "LABEL_97",
    "98": "LABEL_98",
    "99": "LABEL_99",
    "100": "LABEL_100",
    "101": "LABEL_101",
    "102": "LABEL_102",
    "103": "LABEL_103",
    "104": "LABEL_104",
    "105": "LABEL_105",
    "106": "LABEL_106",
    "107": "LABEL_107",
    "108": "LABEL_108",
    "109": "LABEL_109",
    "110": "LABEL_110",
    "111": "LABEL_111",
    "112": "LABEL_112",
    "113": "LABEL_113",
    "114": "LABEL_114",
    "115": "LABEL_115",
    "116": "LABEL_116",
    "117": "LABEL_117",
    "118": "LABEL_118",
    "119": "LABEL_119",
    "120": "LABEL_120",
    "121": "LABEL_121",
    "122": "LABEL_122",
    "123": "LABEL_123",
    "124": "LABEL_124",
    "125": "LABEL_125",
    "126": "LABEL_126",
    "127": "LABEL_127",
    "128": "LABEL_128",
    "129": "LABEL_129",
    "130": "LABEL_130",
    "131": "LABEL_131",
    "132": "LABEL_132",
    "133": "LABEL_133",
    "134": "LABEL_134",
    "135": "LABEL_135",
    "136": "LABEL_136",
    "137": "LABEL_137",
    "138": "LABEL_138",
    "139": "LABEL_139",
    "140": "LABEL_140",
    "141": "LABEL_141",
    "142": "LABEL_142",
    "143": "LABEL_143",
    "144": "LABEL_144",
    "145": "LABEL_145",
    "146": "LABEL_146",
    "147": "LABEL_147",
    "148": "LABEL_148",
    "149": "LABEL_149",
    "150": "LABEL_150",
    "151": "LABEL_151",
    "152": "LABEL_152",
    "153": "LABEL_153",
    "154": "LABEL_154",
    "155": "LABEL_155",
    "156": "LABEL_156",
    "157": "LABEL_157",
    "158": "LABEL_158",
    "159": "LABEL_159",
    "160": "LABEL_160",
    "161": "LABEL_161",
    "162": "LABEL_162",
    "163": "LABEL_163",
    "164": "LABEL_164",
    "165": "LABEL_165",
    "166": "LABEL_166",
    "167": "LABEL_167",
    "168": "LABEL_168",
    "169": "LABEL_169",
    "170": "LABEL_170",
    "171": "LABEL_171",
    "172": "LABEL_172",
    "173": "LABEL_173",
    "174": "LABEL_174",
    "175": "LABEL_175",
    "176": "LABEL_176",
    "177": "LABEL_177",
    "178": "LABEL_178",
    "179": "LABEL_179",
    "180": "LABEL_180",
    "181": "LABEL_181",
    "182": "LABEL_182",
    "183": "LABEL_183",
    "184": "LABEL_184",
    "185": "LABEL_185",
    "186": "LABEL_186",
    "187": "LABEL_187",
    "188": "LABEL_188",
    "189": "LABEL_189",
    "190": "LABEL_190",
    "191": "LABEL_191",
    "192": "LABEL_192",
    "193": "LABEL_193",
    "194": "LABEL_194",
    "195": "LABEL_195",
    "196": "LABEL_196",
    "197": "LABEL_197",
    "198": "LABEL_198",
    "199": "LABEL_199",
    "200": "LABEL_200",
    "201": "LABEL_201",
    "202": "LABEL_202",
    "203": "LABEL_203",
    "204": "LABEL_204",
    "205": "LABEL_205",
    "206": "LABEL_206",
    "207": "LABEL_207",
    "208": "LABEL_208",
    "209": "LABEL_209",
    "210": "LABEL_210",
    "211": "LABEL_211",
    "212": "LABEL_212",
    "213": "LABEL_213",
    "214": "LABEL_214",
    "215": "LABEL_215",
    "216": "LABEL_216",
    "217": "LABEL_217",
    "218": "LABEL_218",
    "219": "LABEL_219",
    "220": "LABEL_220",
    "221": "LABEL_221",
    "222": "LABEL_222",
    "223": "LABEL_223",
    "224": "LABEL_224",
    "225": "LABEL_225",
    "226": "LABEL_226",
    "227": "LABEL_227",
    "228": "LABEL_228",
    "229": "LABEL_229",
    "230": "LABEL_230",
    "231": "LABEL_231",
    "232": "LABEL_232",
    "233": "LABEL_233",
    "234": "LABEL_234",
    "235": "LABEL_235",
    "236": "LABEL_236",
    "237": "LABEL_237",
    "238": "LABEL_238",
    "239": "LABEL_239",
    "240": "LABEL_240",
    "241": "LABEL_241",
    "242": "LABEL_242",
    "243": "LABEL_243",
    "244": "LABEL_244",
    "245": "LABEL_245",
    "246": "LABEL_246",
    "247": "LABEL_247",
    "248": "LABEL_248",
    "249": "LABEL_249",
    "250": "LABEL_250",
    "251": "LABEL_251",
    "252": "LABEL_252",
    "253": "LABEL_253",
    "254": "LABEL_254",
    "255": "LABEL_255",
    "256": "LABEL_256",
    "257": "LABEL_257",
    "258": "LABEL_258",
    "259": "LABEL_259",
    "260": "LABEL_260",
    "261": "LABEL_261",
    "262": "LABEL_262",
    "263": "LABEL_263",
    "264": "LABEL_264",
    "265": "LABEL_265",
    "266": "LABEL_266",
    "267": "LABEL_267",
    "268": "LABEL_268",
    "269": "LABEL_269",
    "270": "LABEL_270",
    "271": "LABEL_271",
    "272": "LABEL_272",
    "273": "LABEL_273",
    "274": "LABEL_274",
    "275": "LABEL_275",
    "276": "LABEL_276",
    "277": "LABEL_277",
    "278": "LABEL_278",
    "279": "LABEL_279",
    "280": "LABEL_280",
    "281": "LABEL_281",
    "282": "LABEL_282",
    "283": "LABEL_283",
    "284": "LABEL_284",
    "285": "LABEL_285",
    "286": "LABEL_286",
    "287": "LABEL_287",
    "288": "LABEL_288",
    "289": "LABEL_289",
    "290": "LABEL_290",
    "291": "LABEL_291",
    "292": "LABEL_292",
    "293": "LABEL_293",
    "294": "LABEL_294",
    "295": "LABEL_295",
    "296": "LABEL_296",
    "297": "LABEL_297",
    "298": "LABEL_298",
    "299": "LABEL_299",
    "300": "LABEL_300",
    "301": "LABEL_301",
    "302": "LABEL_302",
    "303": "LABEL_303",
    "304": "LABEL_304",
    "305": "LABEL_305",
    "306": "LABEL_306",
    "307": "LABEL_307",
    "308": "LABEL_308",
    "309": "LABEL_309",
    "310": "LABEL_310",
    "311": "LABEL_311",
    "312": "LABEL_312",
    "313": "LABEL_313",
    "314": "LABEL_314",
    "315": "LABEL_315",
    "316": "LABEL_316",
    "317": "LABEL_317",
    "318": "LABEL_318",
    "319": "LABEL_319",
    "320": "LABEL_320",
    "321": "LABEL_321",
    "322": "LABEL_322",
    "323": "LABEL_323",
    "324": "LABEL_324",
    "325": "LABEL_325",
    "326": "LABEL_326",
    "327": "LABEL_327",
    "328": "LABEL_328",
    "329": "LABEL_329",
    "330": "LABEL_330",
    "331": "LABEL_331",
    "332": "LABEL_332",
    "333": "LABEL_333",
    "334": "LABEL_334",
    "335": "LABEL_335",
    "336": "LABEL_336",
    "337": "LABEL_337",
    "338": "LABEL_338",
    "339": "LABEL_339",
    "340": "LABEL_340",
    "341": "LABEL_341",
    "342": "LABEL_342",
    "343": "LABEL_343",
    "344": "LABEL_344",
    "345": "LABEL_345",
    "346": "LABEL_346",
    "347": "LABEL_347",
    "348": "LABEL_348",
    "349": "LABEL_349",
    "350": "LABEL_350",
    "351": "LABEL_351",
    "352": "LABEL_352",
    "353": "LABEL_353",
    "354": "LABEL_354",
    "355": "LABEL_355",
    "356": "LABEL_356",
    "357": "LABEL_357",
    "358": "LABEL_358",
    "359": "LABEL_359",
    "360": "LABEL_360",
    "361": "LABEL_361",
    "362": "LABEL_362",
    "363": "LABEL_363",
    "364": "LABEL_364",
    "365": "LABEL_365",
    "366": "LABEL_366",
    "367": "LABEL_367",
    "368": "LABEL_368",
    "369": "LABEL_369",
    "370": "LABEL_370",
    "371": "LABEL_371",
    "372": "LABEL_372",
    "373": "LABEL_373",
    "374": "LABEL_374",
    "375": "LABEL_375",
    "376": "LABEL_376",
    "377": "LABEL_377",
    "378": "LABEL_378",
    "379": "LABEL_379",
    "380": "LABEL_380",
    "381": "LABEL_381",
    "382": "LABEL_382",
    "383": "LABEL_383",
    "384": "LABEL_384",
    "385": "LABEL_385",
    "386": "LABEL_386",
    "387": "LABEL_387",
    "388": "LABEL_388",
    "389": "LABEL_389",
    "390": "LABEL_390",
    "391": "LABEL_391",
    "392": "LABEL_392",
    "393": "LABEL_393",
    "394": "LABEL_394",
    "395": "LABEL_395",
    "396": "LABEL_396",
    "397": "LABEL_397",
    "398": "LABEL_398",
    "399": "LABEL_399",
    "400": "LABEL_400",
    "401": "LABEL_401",
    "402": "LABEL_402",
    "403": "LABEL_403",
    "404": "LABEL_404",
    "405": "LABEL_405",
    "406": "LABEL_406",
    "407": "LABEL_407",
    "408": "LABEL_408",
    "409": "LABEL_409",
    "410": "LABEL_410",
    "411": "LABEL_411",
    "412": "LABEL_412",
    "413": "LABEL_413",
    "414": "LABEL_414",
    "415": "LABEL_415",
    "416": "LABEL_416",
    "417": "LABEL_417",
    "418": "LABEL_418",
    "419": "LABEL_419",
    "420": "LABEL_420",
    "421": "LABEL_421",
    "422": "LABEL_422",
    "423": "LABEL_423",
    "424": "LABEL_424",
    "425": "LABEL_425",
    "426": "LABEL_426",
    "427": "LABEL_427",
    "428": "LABEL_428",
    "429": "LABEL_429",
    "430": "LABEL_430",
    "431": "LABEL_431",
    "432": "LABEL_432",
    "433": "LABEL_433",
    "434": "LABEL_434",
    "435": "LABEL_435",
    "436": "LABEL_436",
    "437": "LABEL_437",
    "438": "LABEL_438",
    "439": "LABEL_439",
    "440": "LABEL_440",
    "441": "LABEL_441",
    "442": "LABEL_442",
    "443": "LABEL_443",
    "444": "LABEL_444",
    "445": "LABEL_445",
    "446": "LABEL_446",
    "447": "LABEL_447",
    "448": "LABEL_448",
    "449": "LABEL_449",
    "450": "LABEL_450",
    "451": "LABEL_451",
    "452": "LABEL_452",
    "453": "LABEL_453",
    "454": "LABEL_454",
    "455": "LABEL_455",
    "456": "LABEL_456",
    "457": "LABEL_457",
    "458": "LABEL_458",
    "459": "LABEL_459",
    "460": "LABEL_460",
    "461": "LABEL_461",
    "462": "LABEL_462",
    "463": "LABEL_463",
    "464": "LABEL_464",
    "465": "LABEL_465",
    "466": "LABEL_466",
    "467": "LABEL_467",
    "468": "LABEL_468",
    "469": "LABEL_469",
    "470": "LABEL_470",
    "471": "LABEL_471",
    "472": "LABEL_472",
    "473": "LABEL_473",
    "474": "LABEL_474",
    "475": "LABEL_475",
    "476": "LABEL_476",
    "477": "LABEL_477",
    "478": "LABEL_478",
    "479": "LABEL_479",
    "480": "LABEL_480",
    "481": "LABEL_481",
    "482": "LABEL_482",
    "483": "LABEL_483",
    "484": "LABEL_484",
    "485": "LABEL_485",
    "486": "LABEL_486",
    "487": "LABEL_487",
    "488": "LABEL_488",
    "489": "LABEL_489",
    "490": "LABEL_490",
    "491": "LABEL_491",
    "492": "LABEL_492",
    "493": "LABEL_493",
    "494": "LABEL_494",
    "495": "LABEL_495",
    "496": "LABEL_496",
    "497": "LABEL_497",
    "498": "LABEL_498",
    "499": "LABEL_499",
    "500": "LABEL_500",
    "501": "LABEL_501",
    "502": "LABEL_502",
    "503": "LABEL_503",
    "504": "LABEL_504",
    "505": "LABEL_505",
    "506": "LABEL_506",
    "507": "LABEL_507",
    "508": "LABEL_508",
    "509": "LABEL_509",
    "510": "LABEL_510",
    "511": "LABEL_511",
    "512": "LABEL_512",
    "513": "LABEL_513",
    "514": "LABEL_514",
    "515": "LABEL_515",
    "516": "LABEL_516",
    "517": "LABEL_517",
    "518": "LABEL_518",
    "519": "LABEL_519",
    "520": "LABEL_520",
    "521": "LABEL_521",
    "522": "LABEL_522",
    "523": "LABEL_523",
    "524": "LABEL_524",
    "525": "LABEL_525",
    "526": "LABEL_526",
    "527": "LABEL_527",
    "528": "LABEL_528",
    "529": "LABEL_529",
    "530": "LABEL_530",
    "531": "LABEL_531",
    "532": "LABEL_532",
    "533": "LABEL_533",
    "534": "LABEL_534",
    "535": "LABEL_535",
    "536": "LABEL_536",
    "537": "LABEL_537",
    "538": "LABEL_538",
    "539": "LABEL_539",
    "540": "LABEL_540",
    "541": "LABEL_541",
    "542": "LABEL_542",
    "543": "LABEL_543",
    "544": "LABEL_544",
    "545": "LABEL_545",
    "546": "LABEL_546",
    "547": "LABEL_547",
    "548": "LABEL_548",
    "549": "LABEL_549",
    "550": "LABEL_550",
    "551": "LABEL_551",
    "552": "LABEL_552",
    "553": "LABEL_553",
    "554": "LABEL_554",
    "555": "LABEL_555",
    "556": "LABEL_556",
    "557": "LABEL_557",
    "558": "LABEL_558",
    "559": "LABEL_559",
    "560": "LABEL_560",
    "561": "LABEL_561",
    "562": "LABEL_562",
    "563": "LABEL_563",
    "564": "LABEL_564",
    "565": "LABEL_565",
    "566": "LABEL_566",
    "567": "LABEL_567",
    "568": "LABEL_568",
    "569": "LABEL_569",
    "570": "LABEL_570",
    "571": "LABEL_571",
    "572": "LABEL_572",
    "573": "LABEL_573",
    "574": "LABEL_574",
    "575": "LABEL_575",
    "576": "LABEL_576",
    "577": "LABEL_577",
    "578": "LABEL_578",
    "579": "LABEL_579",
    "580": "LABEL_580",
    "581": "LABEL_581",
    "582": "LABEL_582",
    "583": "LABEL_583",
    "584": "LABEL_584",
    "585": "LABEL_585",
    "586": "LABEL_586",
    "587": "LABEL_587",
    "588": "LABEL_588",
    "589": "LABEL_589",
    "590": "LABEL_590",
    "591": "LABEL_591",
    "592": "LABEL_592",
    "593": "LABEL_593",
    "594": "LABEL_594",
    "595": "LABEL_595",
    "596": "LABEL_596",
    "597": "LABEL_597",
    "598": "LABEL_598",
    "599": "LABEL_599",
    "600": "LABEL_600",
    "601": "LABEL_601",
    "602": "LABEL_602",
    "603": "LABEL_603",
    "604": "LABEL_604",
    "605": "LABEL_605",
    "606": "LABEL_606",
    "607": "LABEL_607",
    "608": "LABEL_608",
    "609": "LABEL_609",
    "610": "LABEL_610",
    "611": "LABEL_611",
    "612": "LABEL_612",
    "613": "LABEL_613",
    "614": "LABEL_614",
    "615": "LABEL_615",
    "616": "LABEL_616",
    "617": "LABEL_617",
    "618": "LABEL_618",
    "619": "LABEL_619",
    "620": "LABEL_620",
    "621": "LABEL_621",
    "622": "LABEL_622",
    "623": "LABEL_623",
    "624": "LABEL_624",
    "625": "LABEL_625",
    "626": "LABEL_626",
    "627": "LABEL_627",
    "628": "LABEL_628",
    "629": "LABEL_629",
    "630": "LABEL_630",
    "631": "LABEL_631",
    "632": "LABEL_632",
    "633": "LABEL_633",
    "634": "LABEL_634",
    "635": "LABEL_635",
    "636": "LABEL_636"
  },
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_100": 100,
    "LABEL_101": 101,
    "LABEL_102": 102,
    "LABEL_103": 103,
    "LABEL_104": 104,
    "LABEL_105": 105,
    "LABEL_106": 106,
    "LABEL_107": 107,
    "LABEL_108": 108,
    "LABEL_109": 109,
    "LABEL_11": 11,
    "LABEL_110": 110,
    "LABEL_111": 111,
    "LABEL_112": 112,
    "LABEL_113": 113,
    "LABEL_114": 114,
    "LABEL_115": 115,
    "LABEL_116": 116,
    "LABEL_117": 117,
    "LABEL_118": 118,
    "LABEL_119": 119,
    "LABEL_12": 12,
    "LABEL_120": 120,
    "LABEL_121": 121,
    "LABEL_122": 122,
    "LABEL_123": 123,
    "LABEL_124": 124,
    "LABEL_125": 125,
    "LABEL_126": 126,
    "LABEL_127": 127,
    "LABEL_128": 128,
    "LABEL_129": 129,
    "LABEL_13": 13,
    "LABEL_130": 130,
    "LABEL_131": 131,
    "LABEL_132": 132,
    "LABEL_133": 133,
    "LABEL_134": 134,
    "LABEL_135": 135,
    "LABEL_136": 136,
    "LABEL_137": 137,
    "LABEL_138": 138,
    "LABEL_139": 139,
    "LABEL_14": 14,
    "LABEL_140": 140,
    "LABEL_141": 141,
    "LABEL_142": 142,
    "LABEL_143": 143,
    "LABEL_144": 144,
    "LABEL_145": 145,
    "LABEL_146": 146,
    "LABEL_147": 147,
    "LABEL_148": 148,
    "LABEL_149": 149,
    "LABEL_15": 15,
    "LABEL_150": 150,
    "LABEL_151": 151,
    "LABEL_152": 152,
    "LABEL_153": 153,
    "LABEL_154": 154,
    "LABEL_155": 155,
    "LABEL_156": 156,
    "LABEL_157": 157,
    "LABEL_158": 158,
    "LABEL_159": 159,
    "LABEL_16": 16,
    "LABEL_160": 160,
    "LABEL_161": 161,
    "LABEL_162": 162,
    "LABEL_163": 163,
    "LABEL_164": 164,
    "LABEL_165": 165,
    "LABEL_166": 166,
    "LABEL_167": 167,
    "LABEL_168": 168,
    "LABEL_169": 169,
    "LABEL_17": 17,
    "LABEL_170": 170,
    "LABEL_171": 171,
    "LABEL_172": 172,
    "LABEL_173": 173,
    "LABEL_174": 174,
    "LABEL_175": 175,
    "LABEL_176": 176,
    "LABEL_177": 177,
    "LABEL_178": 178,
    "LABEL_179": 179,
    "LABEL_18": 18,
    "LABEL_180": 180,
    "LABEL_181": 181,
    "LABEL_182": 182,
    "LABEL_183": 183,
    "LABEL_184": 184,
    "LABEL_185": 185,
    "LABEL_186": 186,
    "LABEL_187": 187,
    "LABEL_188": 188,
    "LABEL_189": 189,
    "LABEL_19": 19,
    "LABEL_190": 190,
    "LABEL_191": 191,
    "LABEL_192": 192,
    "LABEL_193": 193,
    "LABEL_194": 194,
    "LABEL_195": 195,
    "LABEL_196": 196,
    "LABEL_197": 197,
    "LABEL_198": 198,
    "LABEL_199": 199,
    "LABEL_2": 2,
    "LABEL_20": 20,
    "LABEL_200": 200,
    "LABEL_201": 201,
    "LABEL_202": 202,
    "LABEL_203": 203,
    "LABEL_204": 204,
    "LABEL_205": 205,
    "LABEL_206": 206,
    "LABEL_207": 207,
    "LABEL_208": 208,
    "LABEL_209": 209,
    "LABEL_21": 21,
    "LABEL_210": 210,
    "LABEL_211": 211,
    "LABEL_212": 212,
    "LABEL_213": 213,
    "LABEL_214": 214,
    "LABEL_215": 215,
    "LABEL_216": 216,
    "LABEL_217": 217,
    "LABEL_218": 218,
    "LABEL_219": 219,
    "LABEL_22": 22,
    "LABEL_220": 220,
    "LABEL_221": 221,
    "LABEL_222": 222,
    "LABEL_223": 223,
    "LABEL_224": 224,
    "LABEL_225": 225,
    "LABEL_226": 226,
    "LABEL_227": 227,
    "LABEL_228": 228,
    "LABEL_229": 229,
    "LABEL_23": 23,
    "LABEL_230": 230,
    "LABEL_231": 231,
    "LABEL_232": 232,
    "LABEL_233": 233,
    "LABEL_234": 234,
    "LABEL_235": 235,
    "LABEL_236": 236,
    "LABEL_237": 237,
    "LABEL_238": 238,
    "LABEL_239": 239,
    "LABEL_24": 24,
    "LABEL_240": 240,
    "LABEL_241": 241,
    "LABEL_242": 242,
    "LABEL_243": 243,
    "LABEL_244": 244,
    "LABEL_245": 245,
    "LABEL_246": 246,
    "LABEL_247": 247,
    "LABEL_248": 248,
    "LABEL_249": 249,
    "LABEL_25": 25,
    "LABEL_250": 250,
    "LABEL_251": 251,
    "LABEL_252": 252,
    "LABEL_253": 253,
    "LABEL_254": 254,
    "LABEL_255": 255,
    "LABEL_256": 256,
    "LABEL_257": 257,
    "LABEL_258": 258,
    "LABEL_259": 259,
    "LABEL_26": 26,
    "LABEL_260": 260,
    "LABEL_261": 261,
    "LABEL_262": 262,
    "LABEL_263": 263,
    "LABEL_264": 264,
    "LABEL_265": 265,
    "LABEL_266": 266,
    "LABEL_267": 267,
    "LABEL_268": 268,
    "LABEL_269": 269,
    "LABEL_27": 27,
    "LABEL_270": 270,
    "LABEL_271": 271,
    "LABEL_272": 272,
    "LABEL_273": 273,
    "LABEL_274": 274,
    "LABEL_275": 275,
    "LABEL_276": 276,
    "LABEL_277": 277,
    "LABEL_278": 278,
    "LABEL_279": 279,
    "LABEL_28": 28,
    "LABEL_280": 280,
    "LABEL_281": 281,
    "LABEL_282": 282,
    "LABEL_283": 283,
    "LABEL_284": 284,
    "LABEL_285": 285,
    "LABEL_286": 286,
    "LABEL_287": 287,
    "LABEL_288": 288,
    "LABEL_289": 289,
    "LABEL_29": 29,
    "LABEL_290": 290,
    "LABEL_291": 291,
    "LABEL_292": 292,
    "LABEL_293": 293,
    "LABEL_294": 294,
    "LABEL_295": 295,
    "LABEL_296": 296,
    "LABEL_297": 297,
    "LABEL_298": 298,
    "LABEL_299": 299,
    "LABEL_3": 3,
    "LABEL_30": 30,
    "LABEL_300": 300,
    "LABEL_301": 301,
    "LABEL_302": 302,
    "LABEL_303": 303,
    "LABEL_304": 304,
    "LABEL_305": 305,
    "LABEL_306": 306,
    "LABEL_307": 307,
    "LABEL_308": 308,
    "LABEL_309": 309,
    "LABEL_31": 31,
    "LABEL_310": 310,
    "LABEL_311": 311,
    "LABEL_312": 312,
    "LABEL_313": 313,
    "LABEL_314": 314,
    "LABEL_315": 315,
    "LABEL_316": 316,
    "LABEL_317": 317,
    "LABEL_318": 318,
    "LABEL_319": 319,
    "LABEL_32": 32,
    "LABEL_320": 320,
    "LABEL_321": 321,
    "LABEL_322": 322,
    "LABEL_323": 323,
    "LABEL_324": 324,
    "LABEL_325": 325,
    "LABEL_326": 326,
    "LABEL_327": 327,
    "LABEL_328": 328,
    "LABEL_329": 329,
    "LABEL_33": 33,
    "LABEL_330": 330,
    "LABEL_331": 331,
    "LABEL_332": 332,
    "LABEL_333": 333,
    "LABEL_334": 334,
    "LABEL_335": 335,
    "LABEL_336": 336,
    "LABEL_337": 337,
    "LABEL_338": 338,
    "LABEL_339": 339,
    "LABEL_34": 34,
    "LABEL_340": 340,
    "LABEL_341": 341,
    "LABEL_342": 342,
    "LABEL_343": 343,
    "LABEL_344": 344,
    "LABEL_345": 345,
    "LABEL_346": 346,
    "LABEL_347": 347,
    "LABEL_348": 348,
    "LABEL_349": 349,
    "LABEL_35": 35,
    "LABEL_350": 350,
    "LABEL_351": 351,
    "LABEL_352": 352,
    "LABEL_353": 353,
    "LABEL_354": 354,
    "LABEL_355": 355,
    "LABEL_356": 356,
    "LABEL_357": 357,
    "LABEL_358": 358,
    "LABEL_359": 359,
    "LABEL_36": 36,
    "LABEL_360": 360,
    "LABEL_361": 361,
    "LABEL_362": 362,
    "LABEL_363": 363,
    "LABEL_364": 364,
    "LABEL_365": 365,
    "LABEL_366": 366,
    "LABEL_367": 367,
    "LABEL_368": 368,
    "LABEL_369": 369,
    "LABEL_37": 37,
    "LABEL_370": 370,
    "LABEL_371": 371,
    "LABEL_372": 372,
    "LABEL_373": 373,
    "LABEL_374": 374,
    "LABEL_375": 375,
    "LABEL_376": 376,
    "LABEL_377": 377,
    "LABEL_378": 378,
    "LABEL_379": 379,
    "LABEL_38": 38,
    "LABEL_380": 380,
    "LABEL_381": 381,
    "LABEL_382": 382,
    "LABEL_383": 383,
    "LABEL_384": 384,
    "LABEL_385": 385,
    "LABEL_386": 386,
    "LABEL_387": 387,
    "LABEL_388": 388,
    "LABEL_389": 389,
    "LABEL_39": 39,
    "LABEL_390": 390,
    "LABEL_391": 391,
    "LABEL_392": 392,
    "LABEL_393": 393,
    "LABEL_394": 394,
    "LABEL_395": 395,
    "LABEL_396": 396,
    "LABEL_397": 397,
    "LABEL_398": 398,
    "LABEL_399": 399,
    "LABEL_4": 4,
    "LABEL_40": 40,
    "LABEL_400": 400,
    "LABEL_401": 401,
    "LABEL_402": 402,
    "LABEL_403": 403,
    "LABEL_404": 404,
    "LABEL_405": 405,
    "LABEL_406": 406,
    "LABEL_407": 407,
    "LABEL_408": 408,
    "LABEL_409": 409,
    "LABEL_41": 41,
    "LABEL_410": 410,
    "LABEL_411": 411,
    "LABEL_412": 412,
    "LABEL_413": 413,
    "LABEL_414": 414,
    "LABEL_415": 415,
    "LABEL_416": 416,
    "LABEL_417": 417,
    "LABEL_418": 418,
    "LABEL_419": 419,
    "LABEL_42": 42,
    "LABEL_420": 420,
    "LABEL_421": 421,
    "LABEL_422": 422,
    "LABEL_423": 423,
    "LABEL_424": 424,
    "LABEL_425": 425,
    "LABEL_426": 426,
    "LABEL_427": 427,
    "LABEL_428": 428,
    "LABEL_429": 429,
    "LABEL_43": 43,
    "LABEL_430": 430,
    "LABEL_431": 431,
    "LABEL_432": 432,
    "LABEL_433": 433,
    "LABEL_434": 434,
    "LABEL_435": 435,
    "LABEL_436": 436,
    "LABEL_437": 437,
    "LABEL_438": 438,
    "LABEL_439": 439,
    "LABEL_44": 44,
    "LABEL_440": 440,
    "LABEL_441": 441,
    "LABEL_442": 442,
    "LABEL_443": 443,
    "LABEL_444": 444,
    "LABEL_445": 445,
    "LABEL_446": 446,
    "LABEL_447": 447,
    "LABEL_448": 448,
    "LABEL_449": 449,
    "LABEL_45": 45,
    "LABEL_450": 450,
    "LABEL_451": 451,
    "LABEL_452": 452,
    "LABEL_453": 453,
    "LABEL_454": 454,
    "LABEL_455": 455,
    "LABEL_456": 456,
    "LABEL_457": 457,
    "LABEL_458": 458,
    "LABEL_459": 459,
    "LABEL_46": 46,
    "LABEL_460": 460,
    "LABEL_461": 461,
    "LABEL_462": 462,
    "LABEL_463": 463,
    "LABEL_464": 464,
    "LABEL_465": 465,
    "LABEL_466": 466,
    "LABEL_467": 467,
    "LABEL_468": 468,
    "LABEL_469": 469,
    "LABEL_47": 47,
    "LABEL_470": 470,
    "LABEL_471": 471,
    "LABEL_472": 472,
    "LABEL_473": 473,
    "LABEL_474": 474,
    "LABEL_475": 475,
    "LABEL_476": 476,
    "LABEL_477": 477,
    "LABEL_478": 478,
    "LABEL_479": 479,
    "LABEL_48": 48,
    "LABEL_480": 480,
    "LABEL_481": 481,
    "LABEL_482": 482,
    "LABEL_483": 483,
    "LABEL_484": 484,
    "LABEL_485": 485,
    "LABEL_486": 486,
    "LABEL_487": 487,
    "LABEL_488": 488,
    "LABEL_489": 489,
    "LABEL_49": 49,
    "LABEL_490": 490,
    "LABEL_491": 491,
    "LABEL_492": 492,
    "LABEL_493": 493,
    "LABEL_494": 494,
    "LABEL_495": 495,
    "LABEL_496": 496,
    "LABEL_497": 497,
    "LABEL_498": 498,
    "LABEL_499": 499,
    "LABEL_5": 5,
    "LABEL_50": 50,
    "LABEL_500": 500,
    "LABEL_501": 501,
    "LABEL_502": 502,
    "LABEL_503": 503,
    "LABEL_504": 504,
    "LABEL_505": 505,
    "LABEL_506": 506,
    "LABEL_507": 507,
    "LABEL_508": 508,
    "LABEL_509": 509,
    "LABEL_51": 51,
    "LABEL_510": 510,
    "LABEL_511": 511,
    "LABEL_512": 512,
    "LABEL_513": 513,
    "LABEL_514": 514,
    "LABEL_515": 515,
    "LABEL_516": 516,
    "LABEL_517": 517,
    "LABEL_518": 518,
    "LABEL_519": 519,
    "LABEL_52": 52,
    "LABEL_520": 520,
    "LABEL_521": 521,
    "LABEL_522": 522,
    "LABEL_523": 523,
    "LABEL_524": 524,
    "LABEL_525": 525,
    "LABEL_526": 526,
    "LABEL_527": 527,
    "LABEL_528": 528,
    "LABEL_529": 529,
    "LABEL_53": 53,
    "LABEL_530": 530,
    "LABEL_531": 531,
    "LABEL_532": 532,
    "LABEL_533": 533,
    "LABEL_534": 534,
    "LABEL_535": 535,
    "LABEL_536": 536,
    "LABEL_537": 537,
    "LABEL_538": 538,
    "LABEL_539": 539,
    "LABEL_54": 54,
    "LABEL_540": 540,
    "LABEL_541": 541,
    "LABEL_542": 542,
    "LABEL_543": 543,
    "LABEL_544": 544,
    "LABEL_545": 545,
    "LABEL_546": 546,
    "LABEL_547": 547,
    "LABEL_548": 548,
    "LABEL_549": 549,
    "LABEL_55": 55,
    "LABEL_550": 550,
    "LABEL_551": 551,
    "LABEL_552": 552,
    "LABEL_553": 553,
    "LABEL_554": 554,
    "LABEL_555": 555,
    "LABEL_556": 556,
    "LABEL_557": 557,
    "LABEL_558": 558,
    "LABEL_559": 559,
    "LABEL_56": 56,
    "LABEL_560": 560,
    "LABEL_561": 561,
    "LABEL_562": 562,
    "LABEL_563": 563,
    "LABEL_564": 564,
    "LABEL_565": 565,
    "LABEL_566": 566,
    "LABEL_567": 567,
    "LABEL_568": 568,
    "LABEL_569": 569,
    "LABEL_57": 57,
    "LABEL_570": 570,
    "LABEL_571": 571,
    "LABEL_572": 572,
    "LABEL_573": 573,
    "LABEL_574": 574,
    "LABEL_575": 575,
    "LABEL_576": 576,
    "LABEL_577": 577,
    "LABEL_578": 578,
    "LABEL_579": 579,
    "LABEL_58": 58,
    "LABEL_580": 580,
    "LABEL_581": 581,
    "LABEL_582": 582,
    "LABEL_583": 583,
    "LABEL_584": 584,
    "LABEL_585": 585,
    "LABEL_586": 586,
    "LABEL_587": 587,
    "LABEL_588": 588,
    "LABEL_589": 589,
    "LABEL_59": 59,
    "LABEL_590": 590,
    "LABEL_591": 591,
    "LABEL_592": 592,
    "LABEL_593": 593,
    "LABEL_594": 594,
    "LABEL_595": 595,
    "LABEL_596": 596,
    "LABEL_597": 597,
    "LABEL_598": 598,
    "LABEL_599": 599,
    "LABEL_6": 6,
    "LABEL_60": 60,
    "LABEL_600": 600,
    "LABEL_601": 601,
    "LABEL_602": 602,
    "LABEL_603": 603,
    "LABEL_604": 604,
    "LABEL_605": 605,
    "LABEL_606": 606,
    "LABEL_607": 607,
    "LABEL_608": 608,
    "LABEL_609": 609,
    "LABEL_61": 61,
    "LABEL_610": 610,
    "LABEL_611": 611,
    "LABEL_612": 612,
    "LABEL_613": 613,
    "LABEL_614": 614,
    "LABEL_615": 615,
    "LABEL_616": 616,
    "LABEL_617": 617,
    "LABEL_618": 618,
    "LABEL_619": 619,
    "LABEL_62": 62,
    "LABEL_620": 620,
    "LABEL_621": 621,
    "LABEL_622": 622,
    "LABEL_623": 623,
    "LABEL_624": 624,
    "LABEL_625": 625,
    "LABEL_626": 626,
    "LABEL_627": 627,
    "LABEL_628": 628,
    "LABEL_629": 629,
    "LABEL_63": 63,
    "LABEL_630": 630,
    "LABEL_631": 631,
    "LABEL_632": 632,
    "LABEL_633": 633,
    "LABEL_634": 634,
    "LABEL_635": 635,
    "LABEL_636": 636,
    "LABEL_64": 64,
    "LABEL_65": 65,
    "LABEL_66": 66,
    "LABEL_67": 67,
    "LABEL_68": 68,
    "LABEL_69": 69,
    "LABEL_7": 7,
    "LABEL_70": 70,
    "LABEL_71": 71,
    "LABEL_72": 72,
    "LABEL_73": 73,
    "LABEL_74": 74,
    "LABEL_75": 75,
    "LABEL_76": 76,
    "LABEL_77": 77,
    "LABEL_78": 78,
    "LABEL_79": 79,
    "LABEL_8": 8,
    "LABEL_80": 80,
    "LABEL_81": 81,
    "LABEL_82": 82,
    "LABEL_83": 83,
    "LABEL_84": 84,
    "LABEL_85": 85,
    "LABEL_86": 86,
    "LABEL_87": 87,
    "LABEL_88": 88,
    "LABEL_89": 89,
    "LABEL_9": 9,
    "LABEL_90": 90,
    "LABEL_91": 91,
    "LABEL_92": 92,
    "LABEL_93": 93,
    "LABEL_94": 94,
    "LABEL_95": 95,
    "LABEL_96": 96,
    "LABEL_97": 97,
    "LABEL_98": 98,
    "LABEL_99": 99
  },
  "layer_type": "basic",
  "model_type": "resnet",
  "num_channels": 3,
  "out_features": null,
  "stage_names": [
    "stem",
    "stage1",
    "stage2",
    "stage3",
    "stage4"
  ],
  "torch_dtype": "float32",
  "transformers_version": "4.26.1"
}
loading weights file pytorch_model.bin from cache at C:\Users\chris/.cache\huggingface\hub\models--microsoft--resnet-18\snapshots\2f536bd335677c6b111b3d103af458ef57a6145e\pytorch_model.bin
All model checkpoint weights were used when initializing ResNetForImageClassification.
Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-18 and are newly initialized because the shapes did not match:
- classifier.1.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([637, 512]) in the model instantiated
- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([637]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
PyTorch: setting up devices
Setting `WANDB_LOG_MODEL` from true to `end` instead
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 8323
  Num Epochs = 15
  Instantaneous batch size per device = 16
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 4
  Total optimization steps = 1950
  Number of trainable parameters = 11503293
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
{'loss': 7.3119, 'learning_rate': 2.564102564102564e-06, 'epoch': 0.08}
{'loss': 7.2928, 'learning_rate': 5.128205128205128e-06, 'epoch': 0.15}
{'loss': 7.22, 'learning_rate': 7.692307692307694e-06, 'epoch': 0.23}
{'loss': 7.1678, 'learning_rate': 1.0256410256410256e-05, 'epoch': 0.31}
{'loss': 7.1017, 'learning_rate': 1.282051282051282e-05, 'epoch': 0.38}
{'loss': 6.9938, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.46}
{'loss': 6.8635, 'learning_rate': 1.794871794871795e-05, 'epoch': 0.54}
{'loss': 6.6987, 'learning_rate': 2.0512820512820512e-05, 'epoch': 0.61}
{'loss': 6.49, 'learning_rate': 2.307692307692308e-05, 'epoch': 0.69}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 6.3238, 'learning_rate': 2.564102564102564e-05, 'epoch': 0.77}
{'loss': 6.0947, 'learning_rate': 2.8205128205128207e-05, 'epoch': 0.84}
{'loss': 5.825, 'learning_rate': 3.0769230769230774e-05, 'epoch': 0.92}
{'loss': 5.4507, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
Saving model checkpoint to models/model_Construction\checkpoint-130
Configuration saved in models/model_Construction\checkpoint-130\config.json
{'eval_loss': 5.504655838012695, 'eval_accuracy': 0.4454589139836617, 'eval_f1': 0.4454589139836617, 'eval_precision': 0.4454589139836617, 'eval_recall': 0.4454589139836617, 'eval_runtime': 11.6561, 'eval_samples_per_second': 178.533, 'eval_steps_per_second': 11.239, 'epoch': 1.0}
Model weights saved in models/model_Construction\checkpoint-130\pytorch_model.bin
Image processor saved in models/model_Construction\checkpoint-130\preprocessor_config.json
{'loss': 5.116, 'learning_rate': 3.58974358974359e-05, 'epoch': 1.08}
{'loss': 4.6919, 'learning_rate': 3.846153846153846e-05, 'epoch': 1.15}
{'loss': 4.1844, 'learning_rate': 4.1025641025641023e-05, 'epoch': 1.23}
{'loss': 3.7798, 'learning_rate': 4.358974358974359e-05, 'epoch': 1.31}
{'loss': 3.2234, 'learning_rate': 4.615384615384616e-05, 'epoch': 1.38}
{'loss': 3.0111, 'learning_rate': 4.871794871794872e-05, 'epoch': 1.46}
{'loss': 2.7378, 'learning_rate': 4.985754985754986e-05, 'epoch': 1.54}
{'loss': 2.5645, 'learning_rate': 4.9572649572649575e-05, 'epoch': 1.61}
{'loss': 2.2364, 'learning_rate': 4.928774928774929e-05, 'epoch': 1.69}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 1.9868, 'learning_rate': 4.9002849002849004e-05, 'epoch': 1.77}
{'loss': 1.9482, 'learning_rate': 4.871794871794872e-05, 'epoch': 1.84}
{'loss': 1.9857, 'learning_rate': 4.8433048433048433e-05, 'epoch': 1.92}
{'loss': 2.0032, 'learning_rate': 4.814814814814815e-05, 'epoch': 2.0}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'eval_loss': 1.9297281503677368, 'eval_accuracy': 0.7477174435367612, 'eval_f1': 0.7477174435367612, 'eval_precision': 0.7477174435367612, 'eval_recall': 0.7477174435367612, 'eval_runtime': 11.8376, 'eval_samples_per_second': 175.795, 'eval_steps_per_second': 11.066, 'epoch': 2.0}
Saving model checkpoint to models/model_Construction\checkpoint-260
Configuration saved in models/model_Construction\checkpoint-260\config.json
Model weights saved in models/model_Construction\checkpoint-260\pytorch_model.bin
Image processor saved in models/model_Construction\checkpoint-260\preprocessor_config.json
{'loss': 1.8156, 'learning_rate': 4.786324786324787e-05, 'epoch': 2.08}
{'loss': 1.6393, 'learning_rate': 4.7578347578347584e-05, 'epoch': 2.15}
{'loss': 1.6733, 'learning_rate': 4.72934472934473e-05, 'epoch': 2.23}
{'loss': 1.8219, 'learning_rate': 4.700854700854701e-05, 'epoch': 2.31}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 1.8463, 'learning_rate': 4.672364672364672e-05, 'epoch': 2.38}
{'loss': 1.8972, 'learning_rate': 4.643874643874644e-05, 'epoch': 2.46}
{'loss': 1.7588, 'learning_rate': 4.615384615384616e-05, 'epoch': 2.54}
{'loss': 1.8305, 'learning_rate': 4.586894586894587e-05, 'epoch': 2.61}
{'loss': 1.7742, 'learning_rate': 4.558404558404559e-05, 'epoch': 2.69}
{'loss': 1.7114, 'learning_rate': 4.52991452991453e-05, 'epoch': 2.77}
{'loss': 1.4661, 'learning_rate': 4.501424501424502e-05, 'epoch': 2.84}
{'loss': 1.7535, 'learning_rate': 4.472934472934473e-05, 'epoch': 2.92}
{'loss': 1.6377, 'learning_rate': 4.4444444444444447e-05, 'epoch': 3.0}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'eval_loss': 1.8738394975662231, 'eval_accuracy': 0.7438731379144642, 'eval_f1': 0.7438731379144642, 'eval_precision': 0.7438731379144642, 'eval_recall': 0.7438731379144642, 'eval_runtime': 11.6476, 'eval_samples_per_second': 178.664, 'eval_steps_per_second': 11.247, 'epoch': 3.0}
Saving model checkpoint to models/model_Construction\checkpoint-390
Configuration saved in models/model_Construction\checkpoint-390\config.json
Model weights saved in models/model_Construction\checkpoint-390\pytorch_model.bin
Image processor saved in models/model_Construction\checkpoint-390\preprocessor_config.json
{'loss': 1.5571, 'learning_rate': 4.415954415954416e-05, 'epoch': 3.08}
{'loss': 1.5889, 'learning_rate': 4.3874643874643876e-05, 'epoch': 3.15}
{'loss': 1.6234, 'learning_rate': 4.358974358974359e-05, 'epoch': 3.23}
{'loss': 1.471, 'learning_rate': 4.3304843304843306e-05, 'epoch': 3.31}
{'loss': 1.8043, 'learning_rate': 4.301994301994302e-05, 'epoch': 3.38}
{'loss': 1.7666, 'learning_rate': 4.2735042735042735e-05, 'epoch': 3.46}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 1.581, 'learning_rate': 4.2450142450142457e-05, 'epoch': 3.54}
{'loss': 1.7465, 'learning_rate': 4.216524216524217e-05, 'epoch': 3.61}
{'loss': 1.6384, 'learning_rate': 4.1880341880341886e-05, 'epoch': 3.69}
{'loss': 1.6661, 'learning_rate': 4.15954415954416e-05, 'epoch': 3.77}
{'loss': 1.7915, 'learning_rate': 4.131054131054131e-05, 'epoch': 3.84}
{'loss': 1.6618, 'learning_rate': 4.1025641025641023e-05, 'epoch': 3.92}
{'loss': 1.7703, 'learning_rate': 4.074074074074074e-05, 'epoch': 4.0}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'eval_loss': 1.870479941368103, 'eval_accuracy': 0.7477174435367612, 'eval_f1': 0.7477174435367612, 'eval_precision': 0.7477174435367612, 'eval_recall': 0.7477174435367612, 'eval_runtime': 11.483, 'eval_samples_per_second': 181.224, 'eval_steps_per_second': 11.408, 'epoch': 4.0}
Saving model checkpoint to models/model_Construction\checkpoint-520
Configuration saved in models/model_Construction\checkpoint-520\config.json
Model weights saved in models/model_Construction\checkpoint-520\pytorch_model.bin
Image processor saved in models/model_Construction\checkpoint-520\preprocessor_config.json
{'loss': 1.8426, 'learning_rate': 4.045584045584046e-05, 'epoch': 4.08}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 1.5107, 'learning_rate': 4.0170940170940174e-05, 'epoch': 4.15}
{'loss': 1.6979, 'learning_rate': 3.988603988603989e-05, 'epoch': 4.23}
{'loss': 1.6576, 'learning_rate': 3.9601139601139604e-05, 'epoch': 4.31}
{'loss': 1.5589, 'learning_rate': 3.931623931623932e-05, 'epoch': 4.38}
{'loss': 1.5901, 'learning_rate': 3.903133903133903e-05, 'epoch': 4.46}
{'loss': 1.415, 'learning_rate': 3.874643874643875e-05, 'epoch': 4.54}
{'loss': 1.7387, 'learning_rate': 3.846153846153846e-05, 'epoch': 4.61}
{'loss': 1.7326, 'learning_rate': 3.817663817663818e-05, 'epoch': 4.69}
{'loss': 1.6063, 'learning_rate': 3.789173789173789e-05, 'epoch': 4.77}
{'loss': 1.7157, 'learning_rate': 3.760683760683761e-05, 'epoch': 4.84}
{'loss': 1.5124, 'learning_rate': 3.732193732193732e-05, 'epoch': 4.92}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'loss': 1.6354, 'learning_rate': 3.7037037037037037e-05, 'epoch': 5.0}
{'eval_loss': 1.8663653135299683, 'eval_accuracy': 0.7462758289283998, 'eval_f1': 0.7462758289283998, 'eval_precision': 0.7462758289283998, 'eval_recall': 0.7462758289283998, 'eval_runtime': 11.693, 'eval_samples_per_second': 177.97, 'eval_steps_per_second': 11.203, 'epoch': 5.0}
Saving model checkpoint to models/model_Construction\checkpoint-650
Configuration saved in models/model_Construction\checkpoint-650\config.json
Model weights saved in models/model_Construction\checkpoint-650\pytorch_model.bin
Image processor saved in models/model_Construction\checkpoint-650\preprocessor_config.json
{'loss': 1.769, 'learning_rate': 3.675213675213676e-05, 'epoch': 5.08}
{'loss': 1.6645, 'learning_rate': 3.646723646723647e-05, 'epoch': 5.15}
{'loss': 1.4152, 'learning_rate': 3.618233618233619e-05, 'epoch': 5.23}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 1.9204, 'learning_rate': 3.58974358974359e-05, 'epoch': 5.31}
{'loss': 1.4778, 'learning_rate': 3.561253561253561e-05, 'epoch': 5.38}
{'loss': 1.3022, 'learning_rate': 3.5327635327635325e-05, 'epoch': 5.46}
{'loss': 1.7069, 'learning_rate': 3.504273504273504e-05, 'epoch': 5.54}
{'loss': 1.6412, 'learning_rate': 3.475783475783476e-05, 'epoch': 5.61}
{'loss': 1.6366, 'learning_rate': 3.4472934472934476e-05, 'epoch': 5.69}
{'loss': 1.6812, 'learning_rate': 3.418803418803419e-05, 'epoch': 5.77}
{'loss': 1.4757, 'learning_rate': 3.3903133903133905e-05, 'epoch': 5.84}
{'loss': 1.506, 'learning_rate': 3.361823361823362e-05, 'epoch': 5.92}
{'loss': 1.4461, 'learning_rate': 3.3333333333333335e-05, 'epoch': 6.0}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'eval_loss': 1.870680332183838, 'eval_accuracy': 0.7457952907256127, 'eval_f1': 0.7457952907256127, 'eval_precision': 0.7457952907256127, 'eval_recall': 0.7457952907256127, 'eval_runtime': 11.768, 'eval_samples_per_second': 176.835, 'eval_steps_per_second': 11.132, 'epoch': 6.0}
Saving model checkpoint to models/model_Construction\checkpoint-780
Configuration saved in models/model_Construction\checkpoint-780\config.json
Model weights saved in models/model_Construction\checkpoint-780\pytorch_model.bin
Image processor saved in models/model_Construction\checkpoint-780\preprocessor_config.json
{'loss': 1.6169, 'learning_rate': 3.304843304843305e-05, 'epoch': 6.08}
{'loss': 1.4764, 'learning_rate': 3.2763532763532764e-05, 'epoch': 6.15}
{'loss': 1.3941, 'learning_rate': 3.247863247863248e-05, 'epoch': 6.23}
{'loss': 1.6672, 'learning_rate': 3.2193732193732194e-05, 'epoch': 6.31}
{'loss': 1.4231, 'learning_rate': 3.190883190883191e-05, 'epoch': 6.38}
{'loss': 1.3422, 'learning_rate': 3.162393162393162e-05, 'epoch': 6.46}
{'loss': 1.5082, 'learning_rate': 3.133903133903134e-05, 'epoch': 6.54}
{'loss': 1.5289, 'learning_rate': 3.105413105413106e-05, 'epoch': 6.61}
{'loss': 1.6068, 'learning_rate': 3.0769230769230774e-05, 'epoch': 6.69}
{'loss': 1.6706, 'learning_rate': 3.0484330484330486e-05, 'epoch': 6.77}
{'loss': 1.6503, 'learning_rate': 3.01994301994302e-05, 'epoch': 6.84}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 1.6228, 'learning_rate': 2.9914529914529915e-05, 'epoch': 6.92}
{'loss': 1.6258, 'learning_rate': 2.962962962962963e-05, 'epoch': 7.0}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'eval_loss': 1.874191164970398, 'eval_accuracy': 0.746756367131187, 'eval_f1': 0.746756367131187, 'eval_precision': 0.746756367131187, 'eval_recall': 0.746756367131187, 'eval_runtime': 11.703, 'eval_samples_per_second': 177.818, 'eval_steps_per_second': 11.194, 'epoch': 7.0}
Saving model checkpoint to models/model_Construction\checkpoint-910
Configuration saved in models/model_Construction\checkpoint-910\config.json
Model weights saved in models/model_Construction\checkpoint-910\pytorch_model.bin
Image processor saved in models/model_Construction\checkpoint-910\preprocessor_config.json
{'loss': 1.5258, 'learning_rate': 2.9344729344729345e-05, 'epoch': 7.08}
{'loss': 1.6199, 'learning_rate': 2.9059829059829063e-05, 'epoch': 7.15}
{'loss': 1.6214, 'learning_rate': 2.8774928774928778e-05, 'epoch': 7.23}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 1.6523, 'learning_rate': 2.8490028490028492e-05, 'epoch': 7.31}
{'loss': 1.3114, 'learning_rate': 2.8205128205128207e-05, 'epoch': 7.38}
{'loss': 1.5239, 'learning_rate': 2.7920227920227922e-05, 'epoch': 7.46}
{'loss': 1.404, 'learning_rate': 2.7635327635327633e-05, 'epoch': 7.54}
{'loss': 1.6472, 'learning_rate': 2.7350427350427355e-05, 'epoch': 7.61}
{'loss': 1.5206, 'learning_rate': 2.706552706552707e-05, 'epoch': 7.69}
{'loss': 1.3285, 'learning_rate': 2.6780626780626784e-05, 'epoch': 7.77}
{'loss': 1.51, 'learning_rate': 2.64957264957265e-05, 'epoch': 7.84}
{'loss': 1.6042, 'learning_rate': 2.621082621082621e-05, 'epoch': 7.92}
{'loss': 1.5197, 'learning_rate': 2.5925925925925925e-05, 'epoch': 8.0}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'eval_loss': 1.8615740537643433, 'eval_accuracy': 0.747236905333974, 'eval_f1': 0.747236905333974, 'eval_precision': 0.747236905333974, 'eval_recall': 0.747236905333974, 'eval_runtime': 11.668, 'eval_samples_per_second': 178.35, 'eval_steps_per_second': 11.227, 'epoch': 8.0}
Saving model checkpoint to models/model_Construction\checkpoint-1040
Configuration saved in models/model_Construction\checkpoint-1040\config.json
Model weights saved in models/model_Construction\checkpoint-1040\pytorch_model.bin
Image processor saved in models/model_Construction\checkpoint-1040\preprocessor_config.json
{'loss': 1.5474, 'learning_rate': 2.564102564102564e-05, 'epoch': 8.08}
{'loss': 1.4806, 'learning_rate': 2.535612535612536e-05, 'epoch': 8.15}
{'loss': 1.62, 'learning_rate': 2.5071225071225073e-05, 'epoch': 8.23}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 1.4811, 'learning_rate': 2.4786324786324787e-05, 'epoch': 8.31}
{'loss': 1.5481, 'learning_rate': 2.4501424501424502e-05, 'epoch': 8.38}
{'loss': 1.4919, 'learning_rate': 2.4216524216524217e-05, 'epoch': 8.46}
{'loss': 1.4552, 'learning_rate': 2.3931623931623935e-05, 'epoch': 8.54}
{'loss': 1.4118, 'learning_rate': 2.364672364672365e-05, 'epoch': 8.61}
{'loss': 1.5012, 'learning_rate': 2.336182336182336e-05, 'epoch': 8.69}
{'loss': 1.6113, 'learning_rate': 2.307692307692308e-05, 'epoch': 8.77}
{'loss': 1.4407, 'learning_rate': 2.2792022792022794e-05, 'epoch': 8.84}
{'loss': 1.408, 'learning_rate': 2.250712250712251e-05, 'epoch': 8.92}
{'loss': 1.4165, 'learning_rate': 2.2222222222222223e-05, 'epoch': 9.0}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'eval_loss': 1.849804162979126, 'eval_accuracy': 0.746756367131187, 'eval_f1': 0.746756367131187, 'eval_precision': 0.746756367131187, 'eval_recall': 0.746756367131187, 'eval_runtime': 11.449, 'eval_samples_per_second': 181.763, 'eval_steps_per_second': 11.442, 'epoch': 9.0}
Saving model checkpoint to models/model_Construction\checkpoint-1170
Configuration saved in models/model_Construction\checkpoint-1170\config.json
Model weights saved in models/model_Construction\checkpoint-1170\pytorch_model.bin
Image processor saved in models/model_Construction\checkpoint-1170\preprocessor_config.json
{'loss': 1.4374, 'learning_rate': 2.1937321937321938e-05, 'epoch': 9.08}
{'loss': 1.3252, 'learning_rate': 2.1652421652421653e-05, 'epoch': 9.15}
{'loss': 1.4549, 'learning_rate': 2.1367521367521368e-05, 'epoch': 9.23}
{'loss': 1.331, 'learning_rate': 2.1082621082621086e-05, 'epoch': 9.31}
{'loss': 1.5291, 'learning_rate': 2.07977207977208e-05, 'epoch': 9.38}
{'loss': 1.3768, 'learning_rate': 2.0512820512820512e-05, 'epoch': 9.46}
{'loss': 1.647, 'learning_rate': 2.022792022792023e-05, 'epoch': 9.54}
{'loss': 1.4389, 'learning_rate': 1.9943019943019945e-05, 'epoch': 9.61}
{'loss': 1.3966, 'learning_rate': 1.965811965811966e-05, 'epoch': 9.69}
{'loss': 1.624, 'learning_rate': 1.9373219373219374e-05, 'epoch': 9.77}
{'loss': 1.3072, 'learning_rate': 1.908831908831909e-05, 'epoch': 9.84}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 1.574, 'learning_rate': 1.8803418803418804e-05, 'epoch': 9.92}
{'loss': 1.3944, 'learning_rate': 1.8518518518518518e-05, 'epoch': 10.0}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
Saving model checkpoint to models/model_Construction\checkpoint-1300
Configuration saved in models/model_Construction\checkpoint-1300\config.json
Model weights saved in models/model_Construction\checkpoint-1300\pytorch_model.bin
Image processor saved in models/model_Construction\checkpoint-1300\preprocessor_config.json
{'eval_loss': 1.8788588047027588, 'eval_accuracy': 0.7443536761172513, 'eval_f1': 0.7443536761172513, 'eval_precision': 0.7443536761172513, 'eval_recall': 0.7443536761172513, 'eval_runtime': 11.4605, 'eval_samples_per_second': 181.58, 'eval_steps_per_second': 11.431, 'epoch': 10.0}
{'loss': 1.4615, 'learning_rate': 1.8233618233618236e-05, 'epoch': 10.08}
{'loss': 1.3853, 'learning_rate': 1.794871794871795e-05, 'epoch': 10.15}
{'loss': 1.2745, 'learning_rate': 1.7663817663817662e-05, 'epoch': 10.23}
{'loss': 1.4862, 'learning_rate': 1.737891737891738e-05, 'epoch': 10.31}
{'loss': 1.478, 'learning_rate': 1.7094017094017095e-05, 'epoch': 10.38}
{'loss': 1.3839, 'learning_rate': 1.680911680911681e-05, 'epoch': 10.46}
{'loss': 1.3924, 'learning_rate': 1.6524216524216525e-05, 'epoch': 10.54}
{'loss': 1.6478, 'learning_rate': 1.623931623931624e-05, 'epoch': 10.61}
{'loss': 1.2866, 'learning_rate': 1.5954415954415954e-05, 'epoch': 10.69}
{'loss': 1.5892, 'learning_rate': 1.566951566951567e-05, 'epoch': 10.77}
{'loss': 1.3859, 'learning_rate': 1.5384615384615387e-05, 'epoch': 10.84}
{'loss': 1.5176, 'learning_rate': 1.50997150997151e-05, 'epoch': 10.92}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'loss': 1.3353, 'learning_rate': 1.4814814814814815e-05, 'epoch': 11.0}
{'eval_loss': 1.8762869834899902, 'eval_accuracy': 0.7448342143200385, 'eval_f1': 0.7448342143200385, 'eval_precision': 0.7448342143200385, 'eval_recall': 0.7448342143200385, 'eval_runtime': 11.717, 'eval_samples_per_second': 177.605, 'eval_steps_per_second': 11.18, 'epoch': 11.0}
Saving model checkpoint to models/model_Construction\checkpoint-1430
Configuration saved in models/model_Construction\checkpoint-1430\config.json
Model weights saved in models/model_Construction\checkpoint-1430\pytorch_model.bin
Image processor saved in models/model_Construction\checkpoint-1430\preprocessor_config.json
{'loss': 1.5234, 'learning_rate': 1.4529914529914531e-05, 'epoch': 11.08}
{'loss': 1.347, 'learning_rate': 1.4245014245014246e-05, 'epoch': 11.15}
{'loss': 1.4281, 'learning_rate': 1.3960113960113961e-05, 'epoch': 11.23}
{'loss': 1.539, 'learning_rate': 1.3675213675213677e-05, 'epoch': 11.31}
{'loss': 1.303, 'learning_rate': 1.3390313390313392e-05, 'epoch': 11.38}
{'loss': 1.4478, 'learning_rate': 1.3105413105413105e-05, 'epoch': 11.46}
{'loss': 1.3804, 'learning_rate': 1.282051282051282e-05, 'epoch': 11.54}
{'loss': 1.4117, 'learning_rate': 1.2535612535612536e-05, 'epoch': 11.61}
{'loss': 1.3053, 'learning_rate': 1.2250712250712251e-05, 'epoch': 11.69}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 1.331, 'learning_rate': 1.1965811965811967e-05, 'epoch': 11.77}
{'loss': 1.4061, 'learning_rate': 1.168091168091168e-05, 'epoch': 11.84}
{'loss': 1.526, 'learning_rate': 1.1396011396011397e-05, 'epoch': 11.92}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'loss': 1.5574, 'learning_rate': 1.1111111111111112e-05, 'epoch': 12.0}
{'eval_loss': 1.8647862672805786, 'eval_accuracy': 0.7486785199423354, 'eval_f1': 0.7486785199423355, 'eval_precision': 0.7486785199423354, 'eval_recall': 0.7486785199423354, 'eval_runtime': 11.862, 'eval_samples_per_second': 175.434, 'eval_steps_per_second': 11.044, 'epoch': 12.0}
Saving model checkpoint to models/model_Construction\checkpoint-1560
Configuration saved in models/model_Construction\checkpoint-1560\config.json
Model weights saved in models/model_Construction\checkpoint-1560\pytorch_model.bin
Image processor saved in models/model_Construction\checkpoint-1560\preprocessor_config.json
{'loss': 1.5349, 'learning_rate': 1.0826210826210826e-05, 'epoch': 12.08}
{'loss': 1.4205, 'learning_rate': 1.0541310541310543e-05, 'epoch': 12.15}
{'loss': 1.3958, 'learning_rate': 1.0256410256410256e-05, 'epoch': 12.23}
{'loss': 1.3864, 'learning_rate': 9.971509971509972e-06, 'epoch': 12.31}
{'loss': 1.3585, 'learning_rate': 9.686609686609687e-06, 'epoch': 12.38}
{'loss': 1.3619, 'learning_rate': 9.401709401709402e-06, 'epoch': 12.46}
{'loss': 1.2877, 'learning_rate': 9.116809116809118e-06, 'epoch': 12.54}
{'loss': 1.2922, 'learning_rate': 8.831908831908831e-06, 'epoch': 12.61}
{'loss': 1.3789, 'learning_rate': 8.547008547008548e-06, 'epoch': 12.69}
{'loss': 1.476, 'learning_rate': 8.262108262108262e-06, 'epoch': 12.77}
{'loss': 1.3091, 'learning_rate': 7.977207977207977e-06, 'epoch': 12.84}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 1.434, 'learning_rate': 7.692307692307694e-06, 'epoch': 12.92}
{'loss': 1.4873, 'learning_rate': 7.4074074074074075e-06, 'epoch': 13.0}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'eval_loss': 1.8933364152908325, 'eval_accuracy': 0.7453147525228255, 'eval_f1': 0.7453147525228254, 'eval_precision': 0.7453147525228255, 'eval_recall': 0.7453147525228255, 'eval_runtime': 11.85, 'eval_samples_per_second': 175.612, 'eval_steps_per_second': 11.055, 'epoch': 13.0}
Saving model checkpoint to models/model_Construction\checkpoint-1690
Configuration saved in models/model_Construction\checkpoint-1690\config.json
Model weights saved in models/model_Construction\checkpoint-1690\pytorch_model.bin
Image processor saved in models/model_Construction\checkpoint-1690\preprocessor_config.json
{'loss': 1.5399, 'learning_rate': 7.122507122507123e-06, 'epoch': 13.08}
{'loss': 1.4137, 'learning_rate': 6.837606837606839e-06, 'epoch': 13.15}
{'loss': 1.3107, 'learning_rate': 6.5527065527065525e-06, 'epoch': 13.23}
{'loss': 1.3954, 'learning_rate': 6.267806267806268e-06, 'epoch': 13.31}
{'loss': 1.2611, 'learning_rate': 5.982905982905984e-06, 'epoch': 13.38}
{'loss': 1.4962, 'learning_rate': 5.6980056980056985e-06, 'epoch': 13.46}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 1.4817, 'learning_rate': 5.413105413105413e-06, 'epoch': 13.54}
{'loss': 1.5222, 'learning_rate': 5.128205128205128e-06, 'epoch': 13.61}
{'loss': 1.2671, 'learning_rate': 4.8433048433048435e-06, 'epoch': 13.69}
{'loss': 1.3409, 'learning_rate': 4.558404558404559e-06, 'epoch': 13.77}
{'loss': 1.4306, 'learning_rate': 4.273504273504274e-06, 'epoch': 13.84}
{'loss': 1.286, 'learning_rate': 3.988603988603989e-06, 'epoch': 13.92}
{'loss': 1.2618, 'learning_rate': 3.7037037037037037e-06, 'epoch': 14.0}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'eval_loss': 1.8656160831451416, 'eval_accuracy': 0.7496395963479097, 'eval_f1': 0.7496395963479097, 'eval_precision': 0.7496395963479097, 'eval_recall': 0.7496395963479097, 'eval_runtime': 11.9275, 'eval_samples_per_second': 174.47, 'eval_steps_per_second': 10.983, 'epoch': 14.0}
Saving model checkpoint to models/model_Construction\checkpoint-1820
Configuration saved in models/model_Construction\checkpoint-1820\config.json
Model weights saved in models/model_Construction\checkpoint-1820\pytorch_model.bin
Image processor saved in models/model_Construction\checkpoint-1820\preprocessor_config.json
{'loss': 1.4015, 'learning_rate': 3.4188034188034193e-06, 'epoch': 14.08}
{'loss': 1.4103, 'learning_rate': 3.133903133903134e-06, 'epoch': 14.15}
{'loss': 1.3025, 'learning_rate': 2.8490028490028492e-06, 'epoch': 14.23}
{'loss': 1.4244, 'learning_rate': 2.564102564102564e-06, 'epoch': 14.31}
{'loss': 1.2953, 'learning_rate': 2.2792022792022796e-06, 'epoch': 14.38}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 1.3933, 'learning_rate': 1.9943019943019943e-06, 'epoch': 14.46}
{'loss': 1.2524, 'learning_rate': 1.7094017094017097e-06, 'epoch': 14.54}
{'loss': 1.3471, 'learning_rate': 1.4245014245014246e-06, 'epoch': 14.61}
{'loss': 1.2752, 'learning_rate': 1.1396011396011398e-06, 'epoch': 14.69}
{'loss': 1.4186, 'learning_rate': 8.547008547008548e-07, 'epoch': 14.77}
{'loss': 1.3619, 'learning_rate': 5.698005698005699e-07, 'epoch': 14.84}
{'loss': 1.437, 'learning_rate': 2.8490028490028494e-07, 'epoch': 14.92}
{'loss': 1.5222, 'learning_rate': 0.0, 'epoch': 15.0}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'eval_loss': 1.8759976625442505, 'eval_accuracy': 0.7520422873618453, 'eval_f1': 0.7520422873618453, 'eval_precision': 0.7520422873618453, 'eval_recall': 0.7520422873618453, 'eval_runtime': 11.743, 'eval_samples_per_second': 177.212, 'eval_steps_per_second': 11.156, 'epoch': 15.0}
{'train_runtime': 994.0837, 'train_samples_per_second': 125.588, 'train_steps_per_second': 1.962, 'train_loss': 1.9575824316954002, 'epoch': 15.0}
Saving model checkpoint to models/model_Construction\checkpoint-1950
Configuration saved in models/model_Construction\checkpoint-1950\config.json
Model weights saved in models/model_Construction\checkpoint-1950\pytorch_model.bin
Image processor saved in models/model_Construction\checkpoint-1950\preprocessor_config.json
Training completed. Do not forget to share your model on huggingface.co/models =)
Loading best model from models/model_Construction\checkpoint-1950 (score: 0.7520422873618453).
Setting `WANDB_LOG_MODEL` from true to `end` instead
Saving model checkpoint to C:\Users\chris\AppData\Local\Temp\tmpfarx3j7j
Configuration saved in C:\Users\chris\AppData\Local\Temp\tmpfarx3j7j\config.json
Model weights saved in C:\Users\chris\AppData\Local\Temp\tmpfarx3j7j\pytorch_model.bin
Image processor saved in C:\Users\chris\AppData\Local\Temp\tmpfarx3j7j\preprocessor_config.json
Logging model artifacts. ...