Loading cached split indices for dataset at C:\Users\chris\.cache\huggingface\datasets\cringgaard___boats_dataset\default\0.0.0\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\cache-7e02f6d0f03e0fc9.arrow and C:\Users\chris\.cache\huggingface\datasets\cringgaard___boats_dataset\default\0.0.0\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\cache-18fdfce3e1669319.arrow
Loading cached processed dataset at C:\Users\chris\.cache\huggingface\datasets\cringgaard___boats_dataset\default\0.0.0\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\cache-ba86150308d13aed.arrow
Loading cached processed dataset at C:\Users\chris\.cache\huggingface\datasets\cringgaard___boats_dataset\default\0.0.0\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\cache-863f23ab075eb295.arrow
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 56, 57, 59, 60, 61, 62]
[]
['Fin w/bulb & spade rudder', 'Centerboard Dinghy', 'Dbrd. Dinghy', 'Fin w/spade rudder', 'Fin with rudder on skeg', 'Fin Keel', 'Swing Keel', 'Centerboard (Trunk)', 'Keel/Cbrd.', 'Long Keel', 'Full keel with attached rudder', 'Foiling Monohull', 'Fin w/transom hung rudder', 'Lifting Keel', 'Catamaran Twin Dbrd.', 'Scow Twin Cbrd.', 'Catamaran Twin Cbrd.', 'Catamaran Twin Keel', 'Fin w/bulb & dual rudders', 'Fin w/bulb and transom hung rudder', 'Twin Keel', 'Long keel w/trans. hung rudder', 'Modified Full Keel', 'Keel/CB & spade rudder', 'Keel/CB w/dual rudders', 'Wing Keel', 'Fin (shoal draft)', 'Full Keel', 'Fin w/rudder on partial skeg', 'Catamaran Single Dbrd.', 'Fin Keel w/bulb', 'Cbrd w/outboard rudder', 'Trimaran Dbrd.', 'Trimaran Cbrd.', 'Twin Centerboards', 'Triple Keel', 'Cbrd (trunk) w/dual rudders', 'Sheel Keel', 'Lifting keel with dual rudders', 'Leeboard', 'Long keel w/rudder on skeg', 'Twin Daggerboards', 'Pram (Centerboard)', 'Scow Sngl. Cbrd.', 'Swing keel w/outboard rudder', 'Catamaran (no boards/asym.)', 'Daggerboard', 'Pram (Daggerboard)', 'Wing keel w/spade rudder', 'Trimaran with fixed unballasted keel', 'Fin w/dual rudders', 'Twin keels with dual rudders', 'Iceboat (bow steerer)', 'Double-ended with leeboards', 'Twin drop plates', 'Tandem keel', 'Tandem keel w/spade rudder', 'Swing keel w/dual rudders', 'Catamaran w/foils', 'Lifting keel w/bulb, trans. hung rudder', 'Catamaran Single Cntrboard', 'Foiling Trimaran', 'Lifting keel w/bulb; spade rudder', 'Pram (Leeboard)', 'Double-ended with long keel', 'Long keel w/two centerboards', 'Keel/CB w/rudder on skeg']
Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:
- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([67, 768]) in the model instantiated
- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([67]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Setting `WANDB_LOG_MODEL` from true to `end` instead
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 8323
  Num Epochs = 15
  Instantaneous batch size per device = 16
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 4
  Total optimization steps = 1950
  Number of trainable parameters = 85850179
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
{'loss': 4.2991, 'learning_rate': 2.564102564102564e-06, 'epoch': 0.08}
{'loss': 4.1707, 'learning_rate': 5.128205128205128e-06, 'epoch': 0.15}
{'loss': 3.9795, 'learning_rate': 7.692307692307694e-06, 'epoch': 0.23}
{'loss': 3.762, 'learning_rate': 1.0256410256410256e-05, 'epoch': 0.31}
{'loss': 3.3766, 'learning_rate': 1.282051282051282e-05, 'epoch': 0.38}
{'loss': 3.2138, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.46}
{'loss': 2.9504, 'learning_rate': 1.794871794871795e-05, 'epoch': 0.54}
{'loss': 2.9572, 'learning_rate': 2.0512820512820512e-05, 'epoch': 0.61}
{'loss': 2.9082, 'learning_rate': 2.307692307692308e-05, 'epoch': 0.69}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 2.741, 'learning_rate': 2.564102564102564e-05, 'epoch': 0.77}
{'loss': 2.8019, 'learning_rate': 2.8205128205128207e-05, 'epoch': 0.84}
{'loss': 2.6713, 'learning_rate': 3.0769230769230774e-05, 'epoch': 0.92}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'loss': 2.7534, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}
Saving model checkpoint to models/ViT_Hull Type\checkpoint-130
Configuration saved in models/ViT_Hull Type\checkpoint-130\config.json
{'eval_loss': 2.673741340637207, 'eval_accuracy': 0.2532436328688131, 'eval_f1': 0.2532436328688131, 'eval_precision': 0.2532436328688131, 'eval_recall': 0.2532436328688131, 'eval_runtime': 20.0781, 'eval_samples_per_second': 103.645, 'eval_steps_per_second': 6.525, 'epoch': 1.0}
Model weights saved in models/ViT_Hull Type\checkpoint-130\pytorch_model.bin
Image processor saved in models/ViT_Hull Type\checkpoint-130\preprocessor_config.json
{'loss': 2.6898, 'learning_rate': 3.58974358974359e-05, 'epoch': 1.08}
{'loss': 2.5582, 'learning_rate': 3.846153846153846e-05, 'epoch': 1.15}
{'loss': 2.5303, 'learning_rate': 4.1025641025641023e-05, 'epoch': 1.23}
{'loss': 2.5219, 'learning_rate': 4.358974358974359e-05, 'epoch': 1.31}
{'loss': 2.4157, 'learning_rate': 4.615384615384616e-05, 'epoch': 1.38}
{'loss': 2.4889, 'learning_rate': 4.871794871794872e-05, 'epoch': 1.46}
{'loss': 2.404, 'learning_rate': 4.985754985754986e-05, 'epoch': 1.54}
{'loss': 2.4041, 'learning_rate': 4.9572649572649575e-05, 'epoch': 1.61}
{'loss': 2.4054, 'learning_rate': 4.928774928774929e-05, 'epoch': 1.69}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 2.2588, 'learning_rate': 4.9002849002849004e-05, 'epoch': 1.77}
{'loss': 2.3239, 'learning_rate': 4.871794871794872e-05, 'epoch': 1.84}
{'loss': 2.2359, 'learning_rate': 4.8433048433048433e-05, 'epoch': 1.92}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'loss': 2.3818, 'learning_rate': 4.814814814814815e-05, 'epoch': 2.0}
Saving model checkpoint to models/ViT_Hull Type\checkpoint-260
Configuration saved in models/ViT_Hull Type\checkpoint-260\config.json
{'eval_loss': 2.3948347568511963, 'eval_accuracy': 0.3267659778952427, 'eval_f1': 0.3267659778952427, 'eval_precision': 0.3267659778952427, 'eval_recall': 0.3267659778952427, 'eval_runtime': 19.4083, 'eval_samples_per_second': 107.222, 'eval_steps_per_second': 6.75, 'epoch': 2.0}
Model weights saved in models/ViT_Hull Type\checkpoint-260\pytorch_model.bin
Image processor saved in models/ViT_Hull Type\checkpoint-260\preprocessor_config.json
{'loss': 2.3287, 'learning_rate': 4.786324786324787e-05, 'epoch': 2.08}
{'loss': 2.205, 'learning_rate': 4.7578347578347584e-05, 'epoch': 2.15}
{'loss': 2.2534, 'learning_rate': 4.72934472934473e-05, 'epoch': 2.23}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 2.231, 'learning_rate': 4.700854700854701e-05, 'epoch': 2.31}
{'loss': 2.2436, 'learning_rate': 4.672364672364672e-05, 'epoch': 2.38}
{'loss': 2.2461, 'learning_rate': 4.643874643874644e-05, 'epoch': 2.46}
{'loss': 2.1686, 'learning_rate': 4.615384615384616e-05, 'epoch': 2.54}
{'loss': 2.0907, 'learning_rate': 4.586894586894587e-05, 'epoch': 2.61}
{'loss': 2.0997, 'learning_rate': 4.558404558404559e-05, 'epoch': 2.69}
{'loss': 2.1109, 'learning_rate': 4.52991452991453e-05, 'epoch': 2.77}
{'loss': 2.2098, 'learning_rate': 4.501424501424502e-05, 'epoch': 2.84}
{'loss': 2.2077, 'learning_rate': 4.472934472934473e-05, 'epoch': 2.92}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'loss': 2.1131, 'learning_rate': 4.4444444444444447e-05, 'epoch': 3.0}
{'eval_loss': 2.2859272956848145, 'eval_accuracy': 0.3498318116290245, 'eval_f1': 0.3498318116290245, 'eval_precision': 0.3498318116290245, 'eval_recall': 0.3498318116290245, 'eval_runtime': 19.3529, 'eval_samples_per_second': 107.529, 'eval_steps_per_second': 6.769, 'epoch': 3.0}
Saving model checkpoint to models/ViT_Hull Type\checkpoint-390
Configuration saved in models/ViT_Hull Type\checkpoint-390\config.json
Model weights saved in models/ViT_Hull Type\checkpoint-390\pytorch_model.bin
Image processor saved in models/ViT_Hull Type\checkpoint-390\preprocessor_config.json
{'loss': 2.0772, 'learning_rate': 4.415954415954416e-05, 'epoch': 3.08}
{'loss': 2.0176, 'learning_rate': 4.3874643874643876e-05, 'epoch': 3.15}
{'loss': 1.9779, 'learning_rate': 4.358974358974359e-05, 'epoch': 3.23}
