[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 56, 57, 59, 60, 61, 62]
[]
['Fin w/bulb & spade rudder', 'Centerboard Dinghy', 'Dbrd. Dinghy', 'Fin w/spade rudder', 'Fin with rudder on skeg', 'Fin Keel', 'Swing Keel', 'Centerboard (Trunk)', 'Keel/Cbrd.', 'Long Keel', 'Full keel with attached rudder', 'Foiling Monohull', 'Fin w/transom hung rudder', 'Lifting Keel', 'Catamaran Twin Dbrd.', 'Scow Twin Cbrd.', 'Catamaran Twin Cbrd.', 'Catamaran Twin Keel', 'Fin w/bulb & dual rudders', 'Fin w/bulb and transom hung rudder', 'Twin Keel', 'Long keel w/trans. hung rudder', 'Modified Full Keel', 'Keel/CB & spade rudder', 'Keel/CB w/dual rudders', 'Wing Keel', 'Fin (shoal draft)', 'Full Keel', 'Fin w/rudder on partial skeg', 'Catamaran Single Dbrd.', 'Fin Keel w/bulb', 'Cbrd w/outboard rudder', 'Trimaran Dbrd.', 'Trimaran Cbrd.', 'Twin Centerboards', 'Triple Keel', 'Cbrd (trunk) w/dual rudders', 'Sheel Keel', 'Lifting keel with dual rudders', 'Leeboard', 'Long keel w/rudder on skeg', 'Twin Daggerboards', 'Pram (Centerboard)', 'Scow Sngl. Cbrd.', 'Swing keel w/outboard rudder', 'Catamaran (no boards/asym.)', 'Daggerboard', 'Pram (Daggerboard)', 'Wing keel w/spade rudder', 'Trimaran with fixed unballasted keel', 'Fin w/dual rudders', 'Twin keels with dual rudders', 'Iceboat (bow steerer)', 'Double-ended with leeboards', 'Twin drop plates', 'Tandem keel', 'Tandem keel w/spade rudder', 'Swing keel w/dual rudders', 'Catamaran w/foils', 'Lifting keel w/bulb, trans. hung rudder', 'Catamaran Single Cntrboard', 'Foiling Trimaran', 'Lifting keel w/bulb; spade rudder', 'Pram (Leeboard)', 'Double-ended with long keel', 'Long keel w/two centerboards', 'Keel/CB w/rudder on skeg']
Loading cached split indices for dataset at C:\Users\chris\.cache\huggingface\datasets\cringgaard___boats_dataset\default\0.0.0\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\cache-7e02f6d0f03e0fc9.arrow and C:\Users\chris\.cache\huggingface\datasets\cringgaard___boats_dataset\default\0.0.0\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\cache-18fdfce3e1669319.arrow
Loading cached processed dataset at C:\Users\chris\.cache\huggingface\datasets\cringgaard___boats_dataset\default\0.0.0\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\cache-ba86150308d13aed.arrow
Loading cached processed dataset at C:\Users\chris\.cache\huggingface\datasets\cringgaard___boats_dataset\default\0.0.0\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\cache-863f23ab075eb295.arrow
Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:
- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([67, 768]) in the model instantiated
- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([67]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Setting `WANDB_LOG_MODEL` from true to `end` instead
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 8323
  Num Epochs = 15
  Instantaneous batch size per device = 16
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 4
  Total optimization steps = 1950
  Number of trainable parameters = 85850179
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
{'loss': 4.2135, 'learning_rate': 2.564102564102564e-06, 'epoch': 0.08}
{'loss': 4.0717, 'learning_rate': 5.128205128205128e-06, 'epoch': 0.15}
{'loss': 3.9267, 'learning_rate': 7.692307692307694e-06, 'epoch': 0.23}
{'loss': 3.6885, 'learning_rate': 1.0256410256410256e-05, 'epoch': 0.31}
{'loss': 3.3961, 'learning_rate': 1.282051282051282e-05, 'epoch': 0.38}
{'loss': 3.2098, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.46}
{'loss': 2.9627, 'learning_rate': 1.794871794871795e-05, 'epoch': 0.54}
{'loss': 2.9505, 'learning_rate': 2.0512820512820512e-05, 'epoch': 0.61}
{'loss': 2.9197, 'learning_rate': 2.307692307692308e-05, 'epoch': 0.69}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 2.7649, 'learning_rate': 2.564102564102564e-05, 'epoch': 0.77}
{'loss': 2.7861, 'learning_rate': 2.8205128205128207e-05, 'epoch': 0.84}
{'loss': 2.6985, 'learning_rate': 3.0769230769230774e-05, 'epoch': 0.92}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'loss': 2.7629, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}
{'eval_loss': 2.6809535026550293, 'eval_accuracy': 0.26189332051898123, 'eval_f1': 0.028758737004765313, 'eval_precision': 0.040792112470958375, 'eval_recall': 0.03661527995906016, 'eval_runtime': 17.476, 'eval_samples_per_second': 119.078, 'eval_steps_per_second': 7.496, 'epoch': 1.0}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Saving model checkpoint to models/ViT_Hull Type\checkpoint-130
Configuration saved in models/ViT_Hull Type\checkpoint-130\config.json
Model weights saved in models/ViT_Hull Type\checkpoint-130\pytorch_model.bin
Image processor saved in models/ViT_Hull Type\checkpoint-130\preprocessor_config.json
{'loss': 2.7142, 'learning_rate': 3.58974358974359e-05, 'epoch': 1.08}
{'loss': 2.556, 'learning_rate': 3.846153846153846e-05, 'epoch': 1.15}
{'loss': 2.5608, 'learning_rate': 4.1025641025641023e-05, 'epoch': 1.23}
{'loss': 2.5381, 'learning_rate': 4.358974358974359e-05, 'epoch': 1.31}
{'loss': 2.4037, 'learning_rate': 4.615384615384616e-05, 'epoch': 1.38}
{'loss': 2.4957, 'learning_rate': 4.871794871794872e-05, 'epoch': 1.46}
{'loss': 2.4252, 'learning_rate': 4.985754985754986e-05, 'epoch': 1.54}
{'loss': 2.4145, 'learning_rate': 4.9572649572649575e-05, 'epoch': 1.61}
{'loss': 2.4035, 'learning_rate': 4.928774928774929e-05, 'epoch': 1.69}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 2.2711, 'learning_rate': 4.9002849002849004e-05, 'epoch': 1.77}
{'loss': 2.331, 'learning_rate': 4.871794871794872e-05, 'epoch': 1.84}
{'loss': 2.2514, 'learning_rate': 4.8433048433048433e-05, 'epoch': 1.92}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'loss': 2.3747, 'learning_rate': 4.814814814814815e-05, 'epoch': 2.0}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Saving model checkpoint to models/ViT_Hull Type\checkpoint-260
Configuration saved in models/ViT_Hull Type\checkpoint-260\config.json
Model weights saved in models/ViT_Hull Type\checkpoint-260\pytorch_model.bin
Image processor saved in models/ViT_Hull Type\checkpoint-260\preprocessor_config.json
{'eval_loss': 2.3935303688049316, 'eval_accuracy': 0.3157135992311389, 'eval_f1': 0.055333674154430995, 'eval_precision': 0.0687340173468962, 'eval_recall': 0.060412182902314364, 'eval_runtime': 17.576, 'eval_samples_per_second': 118.4, 'eval_steps_per_second': 7.453, 'epoch': 2.0}
{'loss': 2.3153, 'learning_rate': 4.786324786324787e-05, 'epoch': 2.08}
{'loss': 2.1828, 'learning_rate': 4.7578347578347584e-05, 'epoch': 2.15}
{'loss': 2.1989, 'learning_rate': 4.72934472934473e-05, 'epoch': 2.23}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 2.2133, 'learning_rate': 4.700854700854701e-05, 'epoch': 2.31}
{'loss': 2.2397, 'learning_rate': 4.672364672364672e-05, 'epoch': 2.38}
{'loss': 2.2229, 'learning_rate': 4.643874643874644e-05, 'epoch': 2.46}
{'loss': 2.1729, 'learning_rate': 4.615384615384616e-05, 'epoch': 2.54}
{'loss': 2.0817, 'learning_rate': 4.586894586894587e-05, 'epoch': 2.61}
{'loss': 2.0943, 'learning_rate': 4.558404558404559e-05, 'epoch': 2.69}
{'loss': 2.0921, 'learning_rate': 4.52991452991453e-05, 'epoch': 2.77}
{'loss': 2.1891, 'learning_rate': 4.501424501424502e-05, 'epoch': 2.84}
{'loss': 2.1867, 'learning_rate': 4.472934472934473e-05, 'epoch': 2.92}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'loss': 2.0894, 'learning_rate': 4.4444444444444447e-05, 'epoch': 3.0}
{'eval_loss': 2.252484083175659, 'eval_accuracy': 0.3604036520903412, 'eval_f1': 0.06863146130791246, 'eval_precision': 0.08480686820972966, 'eval_recall': 0.07577784141913761, 'eval_runtime': 17.6204, 'eval_samples_per_second': 118.102, 'eval_steps_per_second': 7.435, 'epoch': 3.0}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Saving model checkpoint to models/ViT_Hull Type\checkpoint-390
Configuration saved in models/ViT_Hull Type\checkpoint-390\config.json
Model weights saved in models/ViT_Hull Type\checkpoint-390\pytorch_model.bin
Image processor saved in models/ViT_Hull Type\checkpoint-390\preprocessor_config.json
{'loss': 2.0423, 'learning_rate': 4.415954415954416e-05, 'epoch': 3.08}
{'loss': 2.0464, 'learning_rate': 4.3874643874643876e-05, 'epoch': 3.15}
{'loss': 1.9758, 'learning_rate': 4.358974358974359e-05, 'epoch': 3.23}
{'loss': 1.9995, 'learning_rate': 4.3304843304843306e-05, 'epoch': 3.31}
{'loss': 2.006, 'learning_rate': 4.301994301994302e-05, 'epoch': 3.38}
{'loss': 2.079, 'learning_rate': 4.2735042735042735e-05, 'epoch': 3.46}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 2.038, 'learning_rate': 4.2450142450142457e-05, 'epoch': 3.54}
{'loss': 1.9721, 'learning_rate': 4.216524216524217e-05, 'epoch': 3.61}
{'loss': 1.9179, 'learning_rate': 4.1880341880341886e-05, 'epoch': 3.69}
{'loss': 2.008, 'learning_rate': 4.15954415954416e-05, 'epoch': 3.77}
{'loss': 2.0003, 'learning_rate': 4.131054131054131e-05, 'epoch': 3.84}
{'loss': 1.9329, 'learning_rate': 4.1025641025641023e-05, 'epoch': 3.92}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'loss': 2.0786, 'learning_rate': 4.074074074074074e-05, 'epoch': 4.0}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Saving model checkpoint to models/ViT_Hull Type\checkpoint-520
Configuration saved in models/ViT_Hull Type\checkpoint-520\config.json
Model weights saved in models/ViT_Hull Type\checkpoint-520\pytorch_model.bin
Image processor saved in models/ViT_Hull Type\checkpoint-520\preprocessor_config.json
{'eval_loss': 2.210533618927002, 'eval_accuracy': 0.367611725132148, 'eval_f1': 0.07163858985234978, 'eval_precision': 0.07226974335617596, 'eval_recall': 0.08584787686968637, 'eval_runtime': 17.438, 'eval_samples_per_second': 119.337, 'eval_steps_per_second': 7.512, 'epoch': 4.0}
{'loss': 1.9165, 'learning_rate': 4.045584045584046e-05, 'epoch': 4.08}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 1.8313, 'learning_rate': 4.0170940170940174e-05, 'epoch': 4.15}
{'loss': 1.9419, 'learning_rate': 3.988603988603989e-05, 'epoch': 4.23}
{'loss': 1.9188, 'learning_rate': 3.9601139601139604e-05, 'epoch': 4.31}
{'loss': 1.9128, 'learning_rate': 3.931623931623932e-05, 'epoch': 4.38}
{'loss': 1.8638, 'learning_rate': 3.903133903133903e-05, 'epoch': 4.46}
{'loss': 1.9218, 'learning_rate': 3.874643874643875e-05, 'epoch': 4.54}
{'loss': 1.8324, 'learning_rate': 3.846153846153846e-05, 'epoch': 4.61}
{'loss': 1.9464, 'learning_rate': 3.817663817663818e-05, 'epoch': 4.69}
{'loss': 1.7936, 'learning_rate': 3.789173789173789e-05, 'epoch': 4.77}
{'loss': 1.8361, 'learning_rate': 3.760683760683761e-05, 'epoch': 4.84}
{'loss': 1.8726, 'learning_rate': 3.732193732193732e-05, 'epoch': 4.92}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'loss': 1.8151, 'learning_rate': 3.7037037037037037e-05, 'epoch': 5.0}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Saving model checkpoint to models/ViT_Hull Type\checkpoint-650
Configuration saved in models/ViT_Hull Type\checkpoint-650\config.json
Model weights saved in models/ViT_Hull Type\checkpoint-650\pytorch_model.bin
Image processor saved in models/ViT_Hull Type\checkpoint-650\preprocessor_config.json
{'eval_loss': 2.173140287399292, 'eval_accuracy': 0.36713118692936086, 'eval_f1': 0.0903690533402412, 'eval_precision': 0.09663280399484483, 'eval_recall': 0.09517978442905953, 'eval_runtime': 17.907, 'eval_samples_per_second': 116.212, 'eval_steps_per_second': 7.316, 'epoch': 5.0}
{'loss': 1.8542, 'learning_rate': 3.675213675213676e-05, 'epoch': 5.08}
{'loss': 1.8349, 'learning_rate': 3.646723646723647e-05, 'epoch': 5.15}
{'loss': 1.7741, 'learning_rate': 3.618233618233619e-05, 'epoch': 5.23}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 1.7279, 'learning_rate': 3.58974358974359e-05, 'epoch': 5.31}
{'loss': 1.7602, 'learning_rate': 3.561253561253561e-05, 'epoch': 5.38}
{'loss': 1.7229, 'learning_rate': 3.5327635327635325e-05, 'epoch': 5.46}
{'loss': 1.7931, 'learning_rate': 3.504273504273504e-05, 'epoch': 5.54}
{'loss': 1.6632, 'learning_rate': 3.475783475783476e-05, 'epoch': 5.61}
{'loss': 1.7375, 'learning_rate': 3.4472934472934476e-05, 'epoch': 5.69}
{'loss': 1.7981, 'learning_rate': 3.418803418803419e-05, 'epoch': 5.77}
{'loss': 1.7244, 'learning_rate': 3.3903133903133905e-05, 'epoch': 5.84}
{'loss': 1.8017, 'learning_rate': 3.361823361823362e-05, 'epoch': 5.92}
{'loss': 1.731, 'learning_rate': 3.3333333333333335e-05, 'epoch': 6.0}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'eval_loss': 2.1682958602905273, 'eval_accuracy': 0.3762614127823162, 'eval_f1': 0.0868613268070926, 'eval_precision': 0.10369502359499184, 'eval_recall': 0.08866253889196335, 'eval_runtime': 17.965, 'eval_samples_per_second': 115.836, 'eval_steps_per_second': 7.292, 'epoch': 6.0}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Saving model checkpoint to models/ViT_Hull Type\checkpoint-780
Configuration saved in models/ViT_Hull Type\checkpoint-780\config.json
Model weights saved in models/ViT_Hull Type\checkpoint-780\pytorch_model.bin
Image processor saved in models/ViT_Hull Type\checkpoint-780\preprocessor_config.json
{'loss': 1.6663, 'learning_rate': 3.304843304843305e-05, 'epoch': 6.08}
{'loss': 1.7627, 'learning_rate': 3.2763532763532764e-05, 'epoch': 6.15}
{'loss': 1.6253, 'learning_rate': 3.247863247863248e-05, 'epoch': 6.23}
{'loss': 1.7025, 'learning_rate': 3.2193732193732194e-05, 'epoch': 6.31}
{'loss': 1.6907, 'learning_rate': 3.190883190883191e-05, 'epoch': 6.38}
{'loss': 1.6703, 'learning_rate': 3.162393162393162e-05, 'epoch': 6.46}
{'loss': 1.6139, 'learning_rate': 3.133903133903134e-05, 'epoch': 6.54}
{'loss': 1.6143, 'learning_rate': 3.105413105413106e-05, 'epoch': 6.61}
{'loss': 1.6113, 'learning_rate': 3.0769230769230774e-05, 'epoch': 6.69}
{'loss': 1.6658, 'learning_rate': 3.0484330484330486e-05, 'epoch': 6.77}
{'loss': 1.6815, 'learning_rate': 3.01994301994302e-05, 'epoch': 6.84}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 1.7176, 'learning_rate': 2.9914529914529915e-05, 'epoch': 6.92}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'loss': 1.6302, 'learning_rate': 2.962962962962963e-05, 'epoch': 7.0}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Saving model checkpoint to models/ViT_Hull Type\checkpoint-910
Configuration saved in models/ViT_Hull Type\checkpoint-910\config.json
Model weights saved in models/ViT_Hull Type\checkpoint-910\pytorch_model.bin
Image processor saved in models/ViT_Hull Type\checkpoint-910\preprocessor_config.json
{'eval_loss': 2.11625599861145, 'eval_accuracy': 0.38395002402691014, 'eval_f1': 0.09510190954711686, 'eval_precision': 0.10428437235238001, 'eval_recall': 0.10039938134707842, 'eval_runtime': 17.7716, 'eval_samples_per_second': 117.097, 'eval_steps_per_second': 7.371, 'epoch': 7.0}
{'loss': 1.6279, 'learning_rate': 2.9344729344729345e-05, 'epoch': 7.08}
{'loss': 1.6475, 'learning_rate': 2.9059829059829063e-05, 'epoch': 7.15}
{'loss': 1.5969, 'learning_rate': 2.8774928774928778e-05, 'epoch': 7.23}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 1.5271, 'learning_rate': 2.8490028490028492e-05, 'epoch': 7.31}
{'loss': 1.6604, 'learning_rate': 2.8205128205128207e-05, 'epoch': 7.38}
{'loss': 1.6176, 'learning_rate': 2.7920227920227922e-05, 'epoch': 7.46}
{'loss': 1.624, 'learning_rate': 2.7635327635327633e-05, 'epoch': 7.54}
{'loss': 1.6085, 'learning_rate': 2.7350427350427355e-05, 'epoch': 7.61}
{'loss': 1.6258, 'learning_rate': 2.706552706552707e-05, 'epoch': 7.69}
{'loss': 1.5436, 'learning_rate': 2.6780626780626784e-05, 'epoch': 7.77}
{'loss': 1.5662, 'learning_rate': 2.64957264957265e-05, 'epoch': 7.84}
{'loss': 1.4999, 'learning_rate': 2.621082621082621e-05, 'epoch': 7.92}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'loss': 1.5326, 'learning_rate': 2.5925925925925925e-05, 'epoch': 8.0}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Saving model checkpoint to models/ViT_Hull Type\checkpoint-1040
Configuration saved in models/ViT_Hull Type\checkpoint-1040\config.json
{'eval_loss': 2.110868453979492, 'eval_accuracy': 0.3829889476213359, 'eval_f1': 0.107502420134566, 'eval_precision': 0.14305777374266646, 'eval_recall': 0.10741263890341726, 'eval_runtime': 17.666, 'eval_samples_per_second': 117.797, 'eval_steps_per_second': 7.415, 'epoch': 8.0}
Model weights saved in models/ViT_Hull Type\checkpoint-1040\pytorch_model.bin
Image processor saved in models/ViT_Hull Type\checkpoint-1040\preprocessor_config.json
{'loss': 1.539, 'learning_rate': 2.564102564102564e-05, 'epoch': 8.08}
{'loss': 1.5459, 'learning_rate': 2.535612535612536e-05, 'epoch': 8.15}
{'loss': 1.5401, 'learning_rate': 2.5071225071225073e-05, 'epoch': 8.23}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 1.5665, 'learning_rate': 2.4786324786324787e-05, 'epoch': 8.31}
{'loss': 1.4234, 'learning_rate': 2.4501424501424502e-05, 'epoch': 8.38}
{'loss': 1.5027, 'learning_rate': 2.4216524216524217e-05, 'epoch': 8.46}
{'loss': 1.4486, 'learning_rate': 2.3931623931623935e-05, 'epoch': 8.54}
{'loss': 1.4575, 'learning_rate': 2.364672364672365e-05, 'epoch': 8.61}
{'loss': 1.4833, 'learning_rate': 2.336182336182336e-05, 'epoch': 8.69}
{'loss': 1.5079, 'learning_rate': 2.307692307692308e-05, 'epoch': 8.77}
{'loss': 1.474, 'learning_rate': 2.2792022792022794e-05, 'epoch': 8.84}
{'loss': 1.5178, 'learning_rate': 2.250712250712251e-05, 'epoch': 8.92}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'loss': 1.4807, 'learning_rate': 2.2222222222222223e-05, 'epoch': 9.0}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Saving model checkpoint to models/ViT_Hull Type\checkpoint-1170
Configuration saved in models/ViT_Hull Type\checkpoint-1170\config.json
Model weights saved in models/ViT_Hull Type\checkpoint-1170\pytorch_model.bin
Image processor saved in models/ViT_Hull Type\checkpoint-1170\preprocessor_config.json
{'eval_loss': 2.084254503250122, 'eval_accuracy': 0.4012493993272465, 'eval_f1': 0.11846853073105343, 'eval_precision': 0.16135086598958667, 'eval_recall': 0.11768868021089293, 'eval_runtime': 16.4836, 'eval_samples_per_second': 126.246, 'eval_steps_per_second': 7.947, 'epoch': 9.0}
{'loss': 1.4391, 'learning_rate': 2.1937321937321938e-05, 'epoch': 9.08}
{'loss': 1.3642, 'learning_rate': 2.1652421652421653e-05, 'epoch': 9.15}
{'loss': 1.422, 'learning_rate': 2.1367521367521368e-05, 'epoch': 9.23}
{'loss': 1.4132, 'learning_rate': 2.1082621082621086e-05, 'epoch': 9.31}
{'loss': 1.4162, 'learning_rate': 2.07977207977208e-05, 'epoch': 9.38}
{'loss': 1.3635, 'learning_rate': 2.0512820512820512e-05, 'epoch': 9.46}
{'loss': 1.4104, 'learning_rate': 2.022792022792023e-05, 'epoch': 9.54}
{'loss': 1.4566, 'learning_rate': 1.9943019943019945e-05, 'epoch': 9.61}
{'loss': 1.4124, 'learning_rate': 1.965811965811966e-05, 'epoch': 9.69}
{'loss': 1.3559, 'learning_rate': 1.9373219373219374e-05, 'epoch': 9.77}
{'loss': 1.4287, 'learning_rate': 1.908831908831909e-05, 'epoch': 9.84}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 1.4189, 'learning_rate': 1.8803418803418804e-05, 'epoch': 9.92}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'loss': 1.4728, 'learning_rate': 1.8518518518518518e-05, 'epoch': 10.0}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Saving model checkpoint to models/ViT_Hull Type\checkpoint-1300
Configuration saved in models/ViT_Hull Type\checkpoint-1300\config.json
Model weights saved in models/ViT_Hull Type\checkpoint-1300\pytorch_model.bin
Image processor saved in models/ViT_Hull Type\checkpoint-1300\preprocessor_config.json
{'eval_loss': 2.1179933547973633, 'eval_accuracy': 0.38202787121576165, 'eval_f1': 0.11997420976486864, 'eval_precision': 0.16305389715893773, 'eval_recall': 0.11646111683358241, 'eval_runtime': 16.1331, 'eval_samples_per_second': 128.99, 'eval_steps_per_second': 8.12, 'epoch': 10.0}
{'loss': 1.2739, 'learning_rate': 1.8233618233618236e-05, 'epoch': 10.08}
{'loss': 1.3061, 'learning_rate': 1.794871794871795e-05, 'epoch': 10.15}
{'loss': 1.283, 'learning_rate': 1.7663817663817662e-05, 'epoch': 10.23}
{'loss': 1.3852, 'learning_rate': 1.737891737891738e-05, 'epoch': 10.31}
{'loss': 1.3809, 'learning_rate': 1.7094017094017095e-05, 'epoch': 10.38}
{'loss': 1.3618, 'learning_rate': 1.680911680911681e-05, 'epoch': 10.46}
{'loss': 1.3806, 'learning_rate': 1.6524216524216525e-05, 'epoch': 10.54}
{'loss': 1.3413, 'learning_rate': 1.623931623931624e-05, 'epoch': 10.61}
{'loss': 1.4314, 'learning_rate': 1.5954415954415954e-05, 'epoch': 10.69}
{'loss': 1.3271, 'learning_rate': 1.566951566951567e-05, 'epoch': 10.77}
{'loss': 1.3791, 'learning_rate': 1.5384615384615387e-05, 'epoch': 10.84}
{'loss': 1.288, 'learning_rate': 1.50997150997151e-05, 'epoch': 10.92}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'loss': 1.34, 'learning_rate': 1.4814814814814815e-05, 'epoch': 11.0}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Saving model checkpoint to models/ViT_Hull Type\checkpoint-1430
Configuration saved in models/ViT_Hull Type\checkpoint-1430\config.json
Model weights saved in models/ViT_Hull Type\checkpoint-1430\pytorch_model.bin
Image processor saved in models/ViT_Hull Type\checkpoint-1430\preprocessor_config.json
{'eval_loss': 2.098583459854126, 'eval_accuracy': 0.3945218644882268, 'eval_f1': 0.11386422239023936, 'eval_precision': 0.153948743768942, 'eval_recall': 0.11407053351490576, 'eval_runtime': 16.5858, 'eval_samples_per_second': 125.469, 'eval_steps_per_second': 7.898, 'epoch': 11.0}
{'loss': 1.3095, 'learning_rate': 1.4529914529914531e-05, 'epoch': 11.08}
{'loss': 1.3215, 'learning_rate': 1.4245014245014246e-05, 'epoch': 11.15}
{'loss': 1.326, 'learning_rate': 1.3960113960113961e-05, 'epoch': 11.23}
{'loss': 1.2455, 'learning_rate': 1.3675213675213677e-05, 'epoch': 11.31}
{'loss': 1.3418, 'learning_rate': 1.3390313390313392e-05, 'epoch': 11.38}
{'loss': 1.4359, 'learning_rate': 1.3105413105413105e-05, 'epoch': 11.46}
{'loss': 1.3221, 'learning_rate': 1.282051282051282e-05, 'epoch': 11.54}
{'loss': 1.2894, 'learning_rate': 1.2535612535612536e-05, 'epoch': 11.61}
{'loss': 1.3413, 'learning_rate': 1.2250712250712251e-05, 'epoch': 11.69}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 1.3816, 'learning_rate': 1.1965811965811967e-05, 'epoch': 11.77}
{'loss': 1.3223, 'learning_rate': 1.168091168091168e-05, 'epoch': 11.84}
{'loss': 1.2569, 'learning_rate': 1.1396011396011397e-05, 'epoch': 11.92}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'loss': 1.2155, 'learning_rate': 1.1111111111111112e-05, 'epoch': 12.0}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Saving model checkpoint to models/ViT_Hull Type\checkpoint-1560
Configuration saved in models/ViT_Hull Type\checkpoint-1560\config.json
Model weights saved in models/ViT_Hull Type\checkpoint-1560\pytorch_model.bin
Image processor saved in models/ViT_Hull Type\checkpoint-1560\preprocessor_config.json
{'eval_loss': 2.134882926940918, 'eval_accuracy': 0.39356078808265255, 'eval_f1': 0.10374990249711025, 'eval_precision': 0.13941334279748507, 'eval_recall': 0.10276470188633673, 'eval_runtime': 16.1503, 'eval_samples_per_second': 128.852, 'eval_steps_per_second': 8.111, 'epoch': 12.0}
{'loss': 1.2663, 'learning_rate': 1.0826210826210826e-05, 'epoch': 12.08}
{'loss': 1.1839, 'learning_rate': 1.0541310541310543e-05, 'epoch': 12.15}
{'loss': 1.2655, 'learning_rate': 1.0256410256410256e-05, 'epoch': 12.23}
{'loss': 1.261, 'learning_rate': 9.971509971509972e-06, 'epoch': 12.31}
{'loss': 1.2715, 'learning_rate': 9.686609686609687e-06, 'epoch': 12.38}
{'loss': 1.2571, 'learning_rate': 9.401709401709402e-06, 'epoch': 12.46}
{'loss': 1.2672, 'learning_rate': 9.116809116809118e-06, 'epoch': 12.54}
{'loss': 1.2502, 'learning_rate': 8.831908831908831e-06, 'epoch': 12.61}
{'loss': 1.3029, 'learning_rate': 8.547008547008548e-06, 'epoch': 12.69}
{'loss': 1.2802, 'learning_rate': 8.262108262108262e-06, 'epoch': 12.77}
{'loss': 1.2316, 'learning_rate': 7.977207977207977e-06, 'epoch': 12.84}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 1.3018, 'learning_rate': 7.692307692307694e-06, 'epoch': 12.92}
{'loss': 1.2327, 'learning_rate': 7.4074074074074075e-06, 'epoch': 13.0}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Saving model checkpoint to models/ViT_Hull Type\checkpoint-1690
Configuration saved in models/ViT_Hull Type\checkpoint-1690\config.json
{'eval_loss': 2.1156511306762695, 'eval_accuracy': 0.3983661701105238, 'eval_f1': 0.11402279664986877, 'eval_precision': 0.14891447432227048, 'eval_recall': 0.10977134505890858, 'eval_runtime': 16.1751, 'eval_samples_per_second': 128.655, 'eval_steps_per_second': 8.099, 'epoch': 13.0}
Model weights saved in models/ViT_Hull Type\checkpoint-1690\pytorch_model.bin
Image processor saved in models/ViT_Hull Type\checkpoint-1690\preprocessor_config.json
{'loss': 1.3814, 'learning_rate': 7.122507122507123e-06, 'epoch': 13.08}
{'loss': 1.1783, 'learning_rate': 6.837606837606839e-06, 'epoch': 13.15}
{'loss': 1.2747, 'learning_rate': 6.5527065527065525e-06, 'epoch': 13.23}
{'loss': 1.1512, 'learning_rate': 6.267806267806268e-06, 'epoch': 13.31}
{'loss': 1.3158, 'learning_rate': 5.982905982905984e-06, 'epoch': 13.38}
{'loss': 1.2588, 'learning_rate': 5.6980056980056985e-06, 'epoch': 13.46}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 1.191, 'learning_rate': 5.413105413105413e-06, 'epoch': 13.54}
{'loss': 1.1924, 'learning_rate': 5.128205128205128e-06, 'epoch': 13.61}
{'loss': 1.2061, 'learning_rate': 4.8433048433048435e-06, 'epoch': 13.69}
{'loss': 1.1715, 'learning_rate': 4.558404558404559e-06, 'epoch': 13.77}
{'loss': 1.2364, 'learning_rate': 4.273504273504274e-06, 'epoch': 13.84}
{'loss': 1.1822, 'learning_rate': 3.988603988603989e-06, 'epoch': 13.92}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'loss': 1.2538, 'learning_rate': 3.7037037037037037e-06, 'epoch': 14.0}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Saving model checkpoint to models/ViT_Hull Type\checkpoint-1820
Configuration saved in models/ViT_Hull Type\checkpoint-1820\config.json
Model weights saved in models/ViT_Hull Type\checkpoint-1820\pytorch_model.bin
Image processor saved in models/ViT_Hull Type\checkpoint-1820\preprocessor_config.json
{'eval_loss': 2.0978665351867676, 'eval_accuracy': 0.3901970206631427, 'eval_f1': 0.11937304343118764, 'eval_precision': 0.1480159922421468, 'eval_recall': 0.11552416873758017, 'eval_runtime': 16.236, 'eval_samples_per_second': 128.172, 'eval_steps_per_second': 8.068, 'epoch': 14.0}
{'loss': 1.2188, 'learning_rate': 3.4188034188034193e-06, 'epoch': 14.08}
{'loss': 1.2068, 'learning_rate': 3.133903133903134e-06, 'epoch': 14.15}
{'loss': 1.179, 'learning_rate': 2.8490028490028492e-06, 'epoch': 14.23}
{'loss': 1.2043, 'learning_rate': 2.564102564102564e-06, 'epoch': 14.31}
{'loss': 1.2213, 'learning_rate': 2.2792022792022796e-06, 'epoch': 14.38}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
{'loss': 1.2707, 'learning_rate': 1.9943019943019943e-06, 'epoch': 14.46}
{'loss': 1.0619, 'learning_rate': 1.7094017094017097e-06, 'epoch': 14.54}
{'loss': 1.1535, 'learning_rate': 1.4245014245014246e-06, 'epoch': 14.61}
{'loss': 1.1632, 'learning_rate': 1.1396011396011398e-06, 'epoch': 14.69}
{'loss': 1.1866, 'learning_rate': 8.547008547008548e-07, 'epoch': 14.77}
{'loss': 1.2, 'learning_rate': 5.698005698005699e-07, 'epoch': 14.84}
{'loss': 1.1105, 'learning_rate': 2.8490028490028494e-07, 'epoch': 14.92}
***** Running Evaluation *****
  Num examples = 2081
  Batch size = 16
{'loss': 1.2391, 'learning_rate': 0.0, 'epoch': 15.0}
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Saving model checkpoint to models/ViT_Hull Type\checkpoint-1950
Configuration saved in models/ViT_Hull Type\checkpoint-1950\config.json
Model weights saved in models/ViT_Hull Type\checkpoint-1950\pytorch_model.bin
Image processor saved in models/ViT_Hull Type\checkpoint-1950\preprocessor_config.json
Training completed. Do not forget to share your model on huggingface.co/models =)
Loading best model from models/ViT_Hull Type\checkpoint-1300 (score: 0.11997420976486864).
Setting `WANDB_LOG_MODEL` from true to `end` instead
Saving model checkpoint to C:\Users\chris\AppData\Local\Temp\tmpuhnugff7
Configuration saved in C:\Users\chris\AppData\Local\Temp\tmpuhnugff7\config.json
Model weights saved in C:\Users\chris\AppData\Local\Temp\tmpuhnugff7\pytorch_model.bin
Image processor saved in C:\Users\chris\AppData\Local\Temp\tmpuhnugff7\preprocessor_config.json
Logging model artifacts. ...
{'eval_loss': 2.123955011367798, 'eval_accuracy': 0.3921191734742912, 'eval_f1': 0.11067267519577223, 'eval_precision': 0.13640950470910787, 'eval_recall': 0.10852346421201196, 'eval_runtime': 16.2012, 'eval_samples_per_second': 128.447, 'eval_steps_per_second': 8.086, 'epoch': 15.0}
{'train_runtime': 2422.6886, 'train_samples_per_second': 51.532, 'train_steps_per_second': 0.805, 'train_loss': 1.735152345315004, 'epoch': 15.0}