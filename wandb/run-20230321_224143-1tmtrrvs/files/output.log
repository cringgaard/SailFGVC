[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 56, 57, 59, 60, 61, 62]
[]
Loading cached split indices for dataset at C:\Users\chris\.cache\huggingface\datasets\cringgaard___boats_dataset\default\0.0.0\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\cache-7e02f6d0f03e0fc9.arrow and C:\Users\chris\.cache\huggingface\datasets\cringgaard___boats_dataset\default\0.0.0\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\cache-18fdfce3e1669319.arrow
Loading cached processed dataset at C:\Users\chris\.cache\huggingface\datasets\cringgaard___boats_dataset\default\0.0.0\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\cache-ba86150308d13aed.arrow
Loading cached processed dataset at C:\Users\chris\.cache\huggingface\datasets\cringgaard___boats_dataset\default\0.0.0\cf118af5708518fea28486aed25e2f1632c5b8d5e716255a840c5c012a2b161b\cache-863f23ab075eb295.arrow
loading configuration file config.json from cache at C:\Users\chris/.cache\huggingface\hub\models--google--vit-base-patch16-224-in21k\snapshots\7cbdb7ee3a6bcdf99dae654893f66519c480a0f8\config.json
Model config ViTConfig {
  "_name_or_path": "google/vit-base-patch16-224-in21k",
  "architectures": [
    "ViTModel"
  ],
  "attention_probs_dropout_prob": 0.0,
  "encoder_stride": 16,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "id2label": {
    "0": 3,
    "1": 8,
    "10": 17,
    "11": 18,
    "12": 31,
    "13": 49,
    "14": 16,
    "15": 5,
    "16": 28,
    "17": 6,
    "18": 30,
    "19": 38,
    "2": 12,
    "20": 13,
    "21": 7,
    "22": 57,
    "23": 21,
    "24": 45,
    "25": 25,
    "26": 33,
    "27": 20,
    "28": 42,
    "29": 37,
    "3": 4,
    "30": 47,
    "31": 44,
    "32": 23,
    "33": 46,
    "34": 34,
    "35": 32,
    "36": 19,
    "37": 40,
    "38": 29,
    "39": 35,
    "4": 0,
    "40": 24,
    "41": 41,
    "42": 59,
    "43": 15,
    "44": 64,
    "45": 52,
    "46": 11,
    "47": 10,
    "48": 61,
    "49": 26,
    "5": 2,
    "50": 27,
    "51": 54,
    "52": 50,
    "53": 62,
    "54": 55,
    "55": 48,
    "56": 43,
    "57": 60,
    "58": 51,
    "59": 36,
    "6": 1,
    "60": 39,
    "61": 56,
    "62": 58,
    "63": 66,
    "64": 63,
    "65": 53,
    "7": 14,
    "8": 22,
    "9": 9
  },
  "image_size": 224,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "0": "4",
    "1": "6",
    "2": "5",
    "3": "0",
    "4": "3",
    "5": "15",
    "6": "17",
    "7": "21",
    "8": "1",
    "9": "9",
    "10": "47",
    "11": "46",
    "12": "2",
    "13": "20",
    "14": "7",
    "15": "43",
    "16": "14",
    "17": "10",
    "18": "11",
    "19": "36",
    "20": "27",
    "21": "23",
    "22": "8",
    "23": "32",
    "24": "40",
    "25": "25",
    "26": "49",
    "27": "50",
    "28": "16",
    "29": "38",
    "30": "18",
    "31": "12",
    "32": "35",
    "33": "26",
    "34": "34",
    "35": "39",
    "36": "59",
    "37": "29",
    "38": "19",
    "39": "60",
    "40": "37",
    "41": "41",
    "42": "28",
    "43": "56",
    "44": "31",
    "45": "24",
    "46": "33",
    "47": "30",
    "48": "55",
    "49": "13",
    "50": "52",
    "51": "58",
    "52": "45",
    "53": "65",
    "54": "51",
    "55": "54",
    "56": "61",
    "57": "22",
    "58": "62",
    "59": "42",
    "60": "57",
    "61": "48",
    "62": "53",
    "63": "64",
    "64": "44",
    "66": "63"
  },
  "layer_norm_eps": 1e-12,
  "model_type": "vit",
  "num_attention_heads": 12,
  "num_channels": 3,
  "num_hidden_layers": 12,
  "patch_size": 16,
  "qkv_bias": true,
  "transformers_version": "4.26.1"
}
loading weights file pytorch_model.bin from cache at C:\Users\chris/.cache\huggingface\hub\models--google--vit-base-patch16-224-in21k\snapshots\7cbdb7ee3a6bcdf99dae654893f66519c480a0f8\pytorch_model.bin
Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.bias', 'pooler.dense.weight']
- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
PyTorch: setting up devices
Setting `WANDB_LOG_MODEL` from true to `end` instead
c:\Users\chris\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 8323
  Num Epochs = 15
  Instantaneous batch size per device = 16
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 4
  Total optimization steps = 1950
  Number of trainable parameters = 85849410
