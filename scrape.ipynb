{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import urllib.request as img_request\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from os import makedirs\n",
    "from os import listdir\n",
    "from os import getcwd\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining regex tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pages_tag = re.compile(r'<a href=.*page=(\\d*).*/li>') # For getting the amount of pages on the domain\n",
    "\n",
    "name_tag = re.compile(r'<a href=\\\"https://sailboatdata\\.com/sailboat/.*\\\">(.*)</a>') # For making a list of all the boats on sailboatdata\n",
    "\n",
    "specs_tag = re.compile(r'<div class=\\\" col-\\w\\w-\\d*  col-\\w\\w-6 sailboatdata-label \\\">\\s*(.*):\\s</div>\\s<.*\\s*(.*)') # For scraping data from specific boat url\n",
    "\n",
    "image_tag = re.compile(r'(?:photo|drawing)\\\".*src=\\\"(http.*)\\\"/>')\n",
    "\n",
    "photo_draw_tag = re.compile(r'sailboat/(\\w*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = getcwd()\n",
    "specs = []\n",
    "categories = []\n",
    "boat_data = pd.DataFrame()\n",
    "counter = 0\n",
    "\n",
    "data_dir = \"data/\"\n",
    "img_dir = \"data/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(os.path.exists(img_dir)):\n",
    "    print(\"Making dir\" , img_dir)\n",
    "    makedirs(img_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_url = 'https://sailboatdata.com/sailboat?page={}&paginate=25'\n",
    "\n",
    "print(\"Connecting to\" , general_url.format(1))\n",
    "init_request = requests.get(general_url.format(1))\n",
    "print(init_request.status_code)\n",
    "pages = re.findall(n_pages_tag , init_request.text)\n",
    "n_pages = pages[-1]\n",
    "\n",
    "boat_types = []\n",
    "for i in tqdm(range (1,int(n_pages)+1)):\n",
    "  # print(\"Connecting to\" , general_url.format(i))\n",
    "  r = requests.get(general_url.format(i))\n",
    "  # print(r.status_code)\n",
    "  boat_types += re.findall(name_tag,r.text)\n",
    "  time.sleep(0.5) #To not throw too many requests at the website\n",
    "\n",
    "print(len(boat_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for boat in boat_types:\n",
    "    # GETTNG REQUEST\n",
    "    print(\"Scraping\",boat,\"...\")\n",
    "    r = requests.get(\"https://sailboatdata.com/sailboat/{}?units=metric\".format(boat.replace(\" \",\"-\").replace(\"(\",\"\").replace(\")\",\"\").replace(\".\",\"\")))\n",
    "    raw_text = r.text\n",
    "\n",
    "    # SCRAPING IMAGES\n",
    "    images = re.findall(image_tag,raw_text)\n",
    "    print(\"         -------scraping\")\n",
    "    for image in images:\n",
    "        img_path = str(counter).zfill(5)+\".jpg\"\n",
    "        if not os.path.isfile(img_path):\n",
    "            counter += 1\n",
    "            print(image)\n",
    "            try:\n",
    "                img_request.urlretrieve(image,img_dir+img_path)\n",
    "            except:\n",
    "                print(\"Strange url\" , image.replace(\" \",\"%20\"))\n",
    "                try:\n",
    "                    img_request.urlretrieve(image,img_dir+img_path)\n",
    "                except:\n",
    "                    has_image = False\n",
    "\n",
    "            # SCRAPING SPECS\n",
    "            categories_specs = re.findall(specs_tag,raw_text)\n",
    "            specs = [el[1] for el in categories_specs]\n",
    "            categories = [el[0] for el in categories_specs]\n",
    "            new_row = {categories[i]: specs[i] for i in range(len(categories))}\n",
    "            new_row['name'] = boat\n",
    "            new_row['img_path'] = img_path\n",
    "            boat_data = pd.concat([boat_data, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Done\\n\")\n",
    "    if counter%100 == 1:\n",
    "        print(\"saving\")\n",
    "        boat_data.to_csv(data_dir+\"boat_data.csv\" , index=False)\n",
    "boat_data.to_csv(data_dir+\"boat_data.csv\" , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "data_raw = pd.read_csv(data_dir+\"boat_data.csv\")\n",
    "data_raw"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_cleaner_tag = re.compile(r'([\\d.]+)(\\s*m|\\s*kg)(<.*>)*')\n",
    "\n",
    "def clean_row(row):\n",
    "  cleaned_row = []\n",
    "  for i in range(len(row)):\n",
    "    if i != 32:\n",
    "      try:\n",
    "        cleaned_row.append(float(re.sub(units_cleaner_tag , r'\\g<1>' , row[i].replace(',','') , )))\n",
    "      except:\n",
    "        cleaned_row.append(row[i])\n",
    "    else:\n",
    "      cleaned_row.append(row[i])\n",
    "  return cleaned_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = []\n",
    "for i , row in data_raw.iterrows():\n",
    "  cleaned_data.append(clean_row(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = pd.DataFrame(cleaned_data , columns = data_raw.columns)\n",
    "\n",
    "for column in data_clean.columns:\n",
    "    if data_clean[column].dtype == \"object\" and not column == \"Download Boat Record\" and not column == \"url\" and not column == \"img_path\":\n",
    "        data_clean[column] = data_clean[column].astype('category')\n",
    "        pd.DataFrame(data_clean[column].cat.categories).to_csv(data_dir+column+\".txt\" , index = False , header = False)\n",
    "        data_clean[column] = data_clean[column].cat.codes\n",
    "\n",
    "data_clean.to_csv(data_dir+\"boat_data_clean.csv\" , index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train , data_test = train_test_split(data_clean , test_size = 0.2 , random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"data/train/\"\n",
    "test_dir = \"data/test/\"\n",
    "\n",
    "if not(os.path.exists(train_dir)):\n",
    "    print(\"Making dir\" , train_dir)\n",
    "    makedirs(train_dir)\n",
    "\n",
    "if not(os.path.exists(test_dir)):\n",
    "    print(\"Making dir\" , test_dir)\n",
    "    makedirs(test_dir)\n",
    "\n",
    "\n",
    "for image in data_train['img_path']:\n",
    "    try:\n",
    "        img = Image.open(img_dir+image)\n",
    "        img = img.convert('RGB')\n",
    "        img.save(train_dir+image)\n",
    "    except:\n",
    "        print(\"Image not found\" , image)\n",
    "        data_train = data_train[data_train['img_path'] != image]\n",
    "\n",
    "for image in data_test['img_path']:\n",
    "    try:\n",
    "        img = Image.open(img_dir+image)\n",
    "        img = img.convert('RGB')\n",
    "        img.save(test_dir+image)\n",
    "    except:\n",
    "        print(\"Image not found\" , image)\n",
    "        data_test = data_test[data_test['img_path'] != image]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.to_csv(data_dir+\"boat_data_train.csv\" , index = False)\n",
    "data_test.to_csv(data_dir+\"boat_data_test.csv\" , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.__len__()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir = \"plots\"\n",
    "if not(os.path.exists(plot_dir)):\n",
    "    print(\"Making dir\" , plot_dir)\n",
    "    os.makedirs(plot_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = [\"train\" , \"test\"]\n",
    "size_factor = [1,0.2]\n",
    "for i , data in enumerate([data_train , data_test]):\n",
    "    for column in data_clean.columns:\n",
    "        if not column == \"Download Boat Record\" and not column == \"name\" and not column == \"url\" and not column == \"img_path\":\n",
    "            print(\"Plotting\" , column)\n",
    "            fig = plt.figure(figsize=(10*2,5*2))\n",
    "            if data[column].dtype == \"object\":\n",
    "                to_remove = 50*size_factor[i]\n",
    "                try:\n",
    "                    dat = data[column].value_counts()\n",
    "                    dat = dat[dat > to_remove]\n",
    "                    dat = dat/len(data[column]) # Normalising\n",
    "                    dat.plot(kind='barh')\n",
    "                    plt.annotate(text = \"Total entries were \"+str(len(data[column].value_counts())) , xy = (0.8,0.95) , xycoords = \"axes fraction\")\n",
    "                    plt.annotate(text = \"Removed entries where n<\"+str(to_remove) , xy = (0.8,0.9) , xycoords = \"axes fraction\")\n",
    "                except:\n",
    "                    data[column].value_counts().plot(kind='barh')\n",
    "\n",
    "            else:\n",
    "                data[column].plot(kind='hist' , logy=True)\n",
    "            fig.name = column\n",
    "            fig.suptitle(column+str(\" \")+train_test[i] , fontsize=16)\n",
    "            path = \"plots/\"+column.replace('/',\"_\")+\"_\"+train_test[i]+\".png\"\n",
    "            plt.savefig(path)\n",
    "            fig.clear()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = pd.read_csv(data_dir+\"boat_data_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data_clean.columns:\n",
    "    if (data_clean[column].dtype == \"object\" or data_clean[column].dtype == \"category\") and not column == \"Download Boat Record\" and not column == \"url\" and not column == \"img_path\":\n",
    "        data_clean[column] = data_clean[column].str.strip().str.rstrip('.').str.lower()\n",
    "        data_clean[column] = data_clean[column].astype('category')\n",
    "        pd.DataFrame(data_clean[column].cat.categories).to_csv(data_dir+\"labels/\"+column.replace(\" \",\"_\")+\".txt\" , index = False , header = False)\n",
    "        data_clean[column] = data_clean[column].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train , data_test = train_test_split(data_clean , test_size = 0.2 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.to_csv(data_dir+\"boat_data_train.csv\" , index = False)\n",
    "data_test.to_csv(data_dir+\"boat_data_test.csv\" , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8396"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2099"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2846    16\n",
       "6875    19\n",
       "7273    23\n",
       "9304    19\n",
       "7917    25\n",
       "        ..\n",
       "5734    25\n",
       "5191    25\n",
       "5390    40\n",
       "860     19\n",
       "7270    25\n",
       "Name: Hull Type, Length: 8396, dtype: int8"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[\"Hull Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23    1617\n",
       "25    1245\n",
       "19     959\n",
       "40     623\n",
       "34     465\n",
       "      ... \n",
       "62       1\n",
       "43       1\n",
       "26       1\n",
       "47       1\n",
       "55       1\n",
       "Name: Hull Type, Length: 66, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[\"Hull Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        00000.jpg\n",
       "1        00001.jpg\n",
       "2        00002.jpg\n",
       "3        00003.jpg\n",
       "4        00004.jpg\n",
       "           ...    \n",
       "10490    10490.jpg\n",
       "10491    10491.jpg\n",
       "10492    10492.jpg\n",
       "10493    10493.jpg\n",
       "10494    10494.jpg\n",
       "Name: img_path, Length: 10495, dtype: object"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean['img_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data_clean['img_path'] == \"00000.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edf259275ad4a72d4dd5b452264ad5fb2b635233dff2a31edc6ebc740e55e21b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
