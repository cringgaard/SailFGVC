{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification , AutoImageProcessor , ResNetModel , ImageClassificationPipeline\n",
    "from evaluate import ImageClassificationEvaluator\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "from data.clean_classes import *\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset boats_dataset (C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e)\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "access_token = \"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\"\n",
    "write_token = \"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\"\n",
    "dataset = load_dataset(\"cringgaard/boats_dataset\" , use_auth_token=access_token, split=\"sailboatdata\")\n",
    "image_processor = AutoImageProcessor.from_pretrained('microsoft/resnet-18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedModel\n",
    "from transformers.models.resnet.modeling_resnet import ImageClassifierOutputWithNoAttention\n",
    "from typing import Optional\n",
    "\n",
    "class MultitaskBoatClassifier(PreTrainedModel):\n",
    "    def __init__(self, config, num_classes_list , label2id , id2label):\n",
    "        super().__init__(config)\n",
    "        self.num_classes_list = num_classes_list\n",
    "        self.label2id = label2id\n",
    "        self.id2label = id2label\n",
    "        self.resnet = ResNetModel.from_pretrained(\"microsoft/resnet-18\" , num_labels =Name_Classes.__len__() , label2id=self.label2id , id2label=self.id2label)\n",
    "        self.heads = nn.ModuleList([nn.Sequential(nn.Flatten() , nn.Linear(512, num_classes)) for num_classes in num_classes_list])\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        pixel_values: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> ImageClassifierOutputWithNoAttention:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the image classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.resnet(pixel_values, output_hidden_states=output_hidden_states, return_dict=return_dict)\n",
    "        pooled_outputs = outputs.pooler_output if return_dict else outputs[1]\n",
    "        class_logits = []\n",
    "        for head in self.heads:\n",
    "            class_logits.append(head(pooled_outputs))\n",
    "\n",
    "        loss = None\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = 0\n",
    "            i = 0\n",
    "            for logits in class_logits:\n",
    "                loss += self.criterion(logits, torch.transpose(labels,0,1)[i])\n",
    "                i += 1\n",
    "            loss = loss / len(class_logits)\n",
    "        \n",
    "        # print(class_logits[-1])\n",
    "        # print(class_logits[-1].shape)\n",
    "        return ImageClassifierOutputWithNoAttention(loss=loss, logits=class_logits[-1], hidden_states=outputs.hidden_states)\n",
    "\n",
    "\n",
    "from transformers import PretrainedConfig\n",
    "class MultitaskBoatClassifierConfig(PretrainedConfig):\n",
    "    def __init__(self, num_classes_list = [Hull_Type_Classes.__len__(),Rigging_Type_Classes.__len__(),Construction_Classes.__len__(),Ballast_Type_Classes.__len__(),Designer_Classes.__len__() , Name_Classes.__len__()], label2id = None , **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_classes_list = num_classes_list\n",
    "        self.hidden_size = 512  # Specify the hidden size of the model\n",
    "        self.num_labels = sum(num_classes_list)  # Total number of labels across all classification heads\n",
    "        self.label2id = label2id if label2id is not None else {}\n",
    "        self.id2label = {id: label for label, id in self.label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "from datasets import load_metric\n",
    "accuracy = load_metric(\"accuracy\")\n",
    "f1 = load_metric(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Transforms\n",
    "from torchvision.transforms import Compose, RandomResizedCrop, ToTensor, Normalize\n",
    "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "size = (\n",
    "    image_processor.size[\"shortest_edge\"]\n",
    "    if \"shortest_edge\" in image_processor.size\n",
    "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    ")\n",
    "_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])\n",
    "\n",
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"img_path\"]]\n",
    "    examples[\"labels\"] = examples['name']\n",
    "    del examples[\"name\"]\n",
    "    del examples[\"img_path\"]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions = eval_pred.predictions\n",
    "    labels = eval_pred.label_ids\n",
    "\n",
    "    # print(\"Predictions\",predictions)\n",
    "    # print(\"Labels\",labels)\n",
    "\n",
    "    predictions = predictions.argmax(axis=1)\n",
    "\n",
    "    if len(np.shape(labels)) > 1:\n",
    "        # print(\"Several Labels\")\n",
    "        labels = np.transpose(labels)[-1]\n",
    "        # print(\"Labels\",labels)\n",
    "\n",
    "    metrics = {}\n",
    "    metrics.update(accuracy.compute(predictions=predictions, references=labels))\n",
    "    metrics.update(f1.compute(predictions=predictions, references=labels , average=\"macro\"))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.map(transforms , batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = Name_Classes\n",
    "label2id = {v: k for k, v in id2label.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      " 33%|███▎      | 1/3 [02:20<04:41, 140.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'accuracy': 0.05094283739757133, 'total_time_in_seconds': 139.75463359999958, 'samples_per_second': 72.47702447555936, 'latency_in_seconds': 0.013797475920623909}\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/resnet-18 were not used when initializing ResNetModel: ['classifier.1.weight', 'classifier.1.bias']\n",
      "- This IS expected if you are initializing ResNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ResNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The model 'MultitaskBoatClassifier' is not supported for . Supported models are ['BeitForImageClassification', 'BitForImageClassification', 'ConvNextForImageClassification', 'CvtForImageClassification', 'Data2VecVisionForImageClassification', 'DeiTForImageClassification', 'DeiTForImageClassificationWithTeacher', 'DinatForImageClassification', 'EfficientFormerForImageClassification', 'EfficientFormerForImageClassificationWithTeacher', 'ImageGPTForImageClassification', 'LevitForImageClassification', 'LevitForImageClassificationWithTeacher', 'MobileNetV1ForImageClassification', 'MobileNetV2ForImageClassification', 'MobileViTForImageClassification', 'NatForImageClassification', 'PerceiverForImageClassificationLearned', 'PerceiverForImageClassificationFourier', 'PerceiverForImageClassificationConvProcessing', 'PoolFormerForImageClassification', 'RegNetForImageClassification', 'ResNetForImageClassification', 'SegformerForImageClassification', 'SwinForImageClassification', 'Swinv2ForImageClassification', 'VanForImageClassification', 'ViTForImageClassification', 'ViTHybridForImageClassification', 'ViTMSNForImageClassification'].\n",
      "The model 'MultitaskBoatClassifier' is not supported for image-classification. Supported models are ['BeitForImageClassification', 'BitForImageClassification', 'ConvNextForImageClassification', 'CvtForImageClassification', 'Data2VecVisionForImageClassification', 'DeiTForImageClassification', 'DeiTForImageClassificationWithTeacher', 'DinatForImageClassification', 'EfficientFormerForImageClassification', 'EfficientFormerForImageClassificationWithTeacher', 'ImageGPTForImageClassification', 'LevitForImageClassification', 'LevitForImageClassificationWithTeacher', 'MobileNetV1ForImageClassification', 'MobileNetV2ForImageClassification', 'MobileViTForImageClassification', 'NatForImageClassification', 'PerceiverForImageClassificationLearned', 'PerceiverForImageClassificationFourier', 'PerceiverForImageClassificationConvProcessing', 'PoolFormerForImageClassification', 'RegNetForImageClassification', 'ResNetForImageClassification', 'SegformerForImageClassification', 'SwinForImageClassification', 'Swinv2ForImageClassification', 'VanForImageClassification', 'ViTForImageClassification', 'ViTHybridForImageClassification', 'ViTMSNForImageClassification'].\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      " 67%|██████▋   | 2/3 [04:43<02:21, 141.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'accuracy': 0.05775496100306052, 'total_time_in_seconds': 141.3110155000004, 'samples_per_second': 71.67877156752844, 'latency_in_seconds': 0.013951131947872486}\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "100%|██████████| 3/3 [07:23<00:00, 147.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'accuracy': 0.016980945799190444, 'total_time_in_seconds': 159.09198769999966, 'samples_per_second': 63.6675683448012, 'latency_in_seconds': 0.01570658383848353}\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# set torch device to GPU\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Load the model\n",
    "model_paths = [\n",
    "    r'D:\\\\models\\\\ResNet18_Boat_Class\\\\best_model',\n",
    "    r'D:\\\\models\\\\ResNet18_Boat_Class_multitask\\\\best_model',\n",
    "    r'D:\\\\models\\\\ViT_Boat_Class_ViT\\\\best_model'\n",
    "]\n",
    "for model_path in tqdm(model_paths , total=model_paths.__len__()):\n",
    "    preprocessor = AutoImageProcessor.from_pretrained(model_path+'\\preprocessor_config.json')\n",
    "    try:\n",
    "        model = AutoModelForImageClassification.from_pretrained(model_path)\n",
    "    except:\n",
    "        model = MultitaskBoatClassifier(MultitaskBoatClassifierConfig(label2id = label2id) , num_classes_list = [Hull_Type_Classes.__len__(),Rigging_Type_Classes.__len__(),Construction_Classes.__len__(),Ballast_Type_Classes.__len__(),Designer_Classes.__len__() , Name_Classes.__len__()] , label2id=label2id , id2label=id2label)\n",
    "        model.load_state_dict(torch.load(model_path+'\\pytorch_model.bin'))\n",
    "    # Define the pipeline\n",
    "    pipeline = ImageClassificationPipeline(model=model, feature_extractor=preprocessor, framework=\"pt\", device=0)\n",
    "    evaluator = ImageClassificationEvaluator()\n",
    "    # Run the pipeline\n",
    "    eval_results = evaluator.compute(\n",
    "        model_or_pipeline=model,\n",
    "        feature_extractor=preprocessor,\n",
    "        data=dataset,\n",
    "        input_column='img_path',\n",
    "        label_column='name',\n",
    "        metric=\"accuracy\",\n",
    "        label_mapping=label2id,\n",
    ")\n",
    "    # Compute metrics\n",
    "    # metrics = {}\n",
    "    # metrics.update(accuracy.compute(predictions=eval_results, references=dataset[\"name\"]))\n",
    "    # metrics.update(f1.compute(predictions=eval_results, references=dataset[\"name\"]))\n",
    "    print(model_path.split('\\\\')[3])\n",
    "    print(eval_results)\n",
    "    print('-------------------')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-413421f89d7c70ab.arrow and C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-2119c380af3e3b39.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed36e5765484672a0d2ea3946a50104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-2c1593bce4513b29.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f1ac49df1f45ee80c6b4ec378af4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-bc9c967bcac45d7f.arrow and C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-e58522ff0538dc99.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hull Type\n",
      "10129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4273c781d8464b48939a81b048d5ee9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-3088732afd8804ab.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff0538fee1ca483484004416fc20031b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-0f064c32207dd904.arrow and C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-af751528a2a8eb3e.arrow\n",
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-83b788f58211fa83.arrow\n",
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-54cf8387a5dbf80f.arrow\n",
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-2873b77936432d95.arrow\n",
      "Loading cached split indices for dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-353cca2a16258d93.arrow and C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-209687be36b16de5.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rigging Type\n",
      "10116\n",
      "Construction\n",
      "9387\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f1b929729749dab6da0355b27e1df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-f4510da62889c76e.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ad5951c12746fd9aaa41bfdad835e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-55f9832e451a5ad5.arrow and C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-abd32dd2a8725bed.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ballast Type\n",
      "3713\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022cb4d2054e434c9d1e5ee015130b4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-a240950b63fe3033.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87694198ad4e40ef9269cf9a979b7827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-37f339ba09c3e0ce.arrow and C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-47bf320a99ad9bfa.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Designer\n",
      "9814\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97464c8d85474e718470e622e367d65c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-1f7c057f01358d75.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84bf3c5d7e4b462baf01aa9c18018c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "10129\n"
     ]
    }
   ],
   "source": [
    "label_types = ['Hull Type','Rigging Type','Construction','Ballast Type','Designer','name']\n",
    "for label_type in label_types: \n",
    "    c_names = dataset.column_names[1:]\n",
    "    c_names.remove(label_type)\n",
    "    # Map labels to ids using label map\n",
    "    dataset_specific = dataset.remove_columns(c_names)\n",
    "    labels = dataset.features[label_type].names\n",
    "\n",
    "    dataset_specific = dataset_specific.train_test_split(test_size=0.2, shuffle=True, seed=43)\n",
    "\n",
    "    labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "    labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "    labels_to_remove = np.where(labels_train_counts < 0)[0] # remove labels with less than 2 examples\n",
    "    labels_to_remove = np.union1d(labels_to_remove, np.where(labels_test_counts < 0)[0])\n",
    "    # dataset_specific['train'] = dataset_specific['train'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "    dataset_specific['test'] = dataset_specific['test'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "\n",
    "    id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "    label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "\n",
    "    dataset_specific['train'] = dataset_specific['train'].filter(lambda x: id2label[x[label_type]] not in [\"NaN\"])\n",
    "    dataset_specific['test'] = dataset_specific['test'].filter(lambda x: id2label[x[label_type]] not in [\"NaN\"])\n",
    "\n",
    "    id2label = {int(i): label for i, label in enumerate(labels)}\n",
    "    label2id = {label : int(i) for i, label in enumerate(labels)}\n",
    "\n",
    "    labels = [id2label[label2id[x]] for x in labels]\n",
    "    \n",
    "    labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "    labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "    print(label_type)\n",
    "    print(labels_train_counts.sum() + labels_test_counts.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-4be1d2fb2f937080.arrow and C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-0cceee8728a1c4eb.arrow\n",
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-daecc768d38c8637.arrow\n",
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-82ee4206533f0035.arrow\n",
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-7f4db9268c263170.arrow\n",
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-27c63d8d1201cd47.arrow\n",
      "Loading cached processed dataset at C:\\Users\\chris\\.cache\\huggingface\\datasets\\cringgaard___boats_dataset\\default\\0.0.0\\3780f35f24ee5458f59c11c69640a6f7f9001aaabc6ce51227831bd076a1ce4e\\cache-a19517c4b287c09d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9904\n"
     ]
    }
   ],
   "source": [
    "label_types = ['Hull Type','Rigging Type','Construction','Ballast Type','Designer']\n",
    "dataset_specific = dataset.remove_columns('name')\n",
    "dataset_specific = dataset_specific.train_test_split(test_size=0.2, shuffle=True, seed=43)\n",
    "\n",
    "for label_type in label_types:\n",
    "    labels = np.unique(dataset_specific['train'][label_type])\n",
    "    labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "    labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "    labels_to_remove = np.where(labels_train_counts < 1)[0] # remove labels with less than 2 examples\n",
    "    labels_to_remove = np.union1d(labels_to_remove, np.where(labels_test_counts < 1)[0])\n",
    "    # dataset_specific['train'] = dataset_specific['train'].filter(lambda x: x[label_type] not in labels_to_remove)\n",
    "    dataset_specific['test'] = dataset_specific['test'].filter(lambda x: x[label_type] not in labels_to_remove)            \n",
    "labels_train_counts = np.bincount(dataset_specific['train'][label_type] , minlength=len(labels))\n",
    "labels_test_counts = np.bincount(dataset_specific['test'][label_type] , minlength=len(labels))\n",
    "\n",
    "print(labels_train_counts.sum() + labels_test_counts.sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
